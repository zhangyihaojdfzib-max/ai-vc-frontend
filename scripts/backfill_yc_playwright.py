#!/usr/bin/env python3
"""
YC Library Backfill Script - Playwright é«˜å¹¶å‘ç‰ˆæœ¬
ä½¿ç”¨æ— å¤´æµè§ˆå™¨æŠ“å– JS æ¸²æŸ“çš„é¡µé¢

ç‰¹æ€§ï¼š
- Playwright å¤„ç† JS æ¸²æŸ“
- å¤šæµè§ˆå™¨å®ä¾‹å¹¶è¡Œï¼ˆé»˜è®¤ 4 ä¸ªï¼‰
- è‡ªåŠ¨è¿‡æ»¤è§†é¢‘/æ’­å®¢é¡µé¢
- æ™ºèƒ½å†…å®¹æå–

ä½¿ç”¨æ–¹æ³•:
    python scripts/backfill_yc_playwright.py --max 10 --workers 4   # æµ‹è¯•
    python scripts/backfill_yc_playwright.py --max 100 --workers 6  # 100ç¯‡
    python scripts/backfill_yc_playwright.py --workers 4            # å…¨éƒ¨
"""

import os
import sys
import json
import time
import hashlib
import argparse
import requests
import re
from pathlib import Path
from datetime import datetime
from typing import Optional, List, Dict, Tuple
from xml.etree import ElementTree
from concurrent.futures import ThreadPoolExecutor, as_completed
import threading

import yaml
from openai import OpenAI
from playwright.sync_api import sync_playwright, Browser, Page

# ============================================
# é…ç½®
# ============================================

SITEMAP_URL = "https://www.ycombinator.com/library/sitemap.xml"
SOURCE_NAME = "Y Combinator"
USER_AGENT = "Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36"
DEFAULT_WORKERS = 4  # Playwright å¹¶å‘æ•°ï¼ˆæ¯ä¸ªéœ€è¦ä¸€ä¸ªæµè§ˆå™¨å®ä¾‹ï¼‰
TRANSLATION_MODEL = "deepseek-chat"
MIN_CONTENT_LENGTH = 500  # æœ€å°å†…å®¹é•¿åº¦ï¼Œè¿‡æ»¤è§†é¢‘é¡µé¢

# æœ¯è¯­è¡¨
GLOSSARY = {
    'LLM': 'LLMï¼ˆå¤§è¯­è¨€æ¨¡å‹ï¼‰',
    'GPT': 'GPT',
    'Transformer': 'Transformer',
    'Fine-tuning': 'å¾®è°ƒ',
    'Prompt': 'æç¤ºè¯',
    'RAG': 'RAGï¼ˆæ£€ç´¢å¢å¼ºç”Ÿæˆï¼‰',
    'Agent': 'Agentï¼ˆæ™ºèƒ½ä½“ï¼‰',
    'Product-Market Fit': 'äº§å“å¸‚åœºå¥‘åˆ',
    'PMF': 'PMFï¼ˆäº§å“å¸‚åœºå¥‘åˆï¼‰',
    'Runway': 'ç°é‡‘è·‘é“',
    'Burn Rate': 'çƒ§é’±é€Ÿåº¦',
    'Series A': 'Aè½®',
    'Series B': 'Bè½®',
    'Seed Round': 'ç§å­è½®',
    'MVP': 'MVPï¼ˆæœ€å°å¯è¡Œäº§å“ï¼‰',
    'YC': 'YCï¼ˆY Combinatorï¼‰',
    'Y Combinator': 'Y Combinator',
    'Startup': 'åˆ›ä¸šå…¬å¸',
    'Founder': 'åˆ›å§‹äºº',
    'Co-founder': 'è”åˆåˆ›å§‹äºº',
    'Pitch': 'è·¯æ¼”/æ¨ä»‹',
    'Pivot': 'è½¬å‹',
    'Traction': 'å¢é•¿åŠ¿å¤´',
    'Valuation': 'ä¼°å€¼',
    'SAFE': 'SAFEï¼ˆæœªæ¥è‚¡æƒç®€å•åè®®ï¼‰',
    'Equity': 'è‚¡æƒ',
    'Dilution': 'ç¨€é‡Š',
}

# ============================================
# è·¯å¾„è®¾ç½®
# ============================================

def find_project_root() -> Path:
    current = Path(__file__).resolve().parent
    for _ in range(5):
        if (current / "content" / "posts").exists():
            return current
        if (current / "package.json").exists():
            return current
        current = current.parent
    return Path(__file__).resolve().parent.parent

PROJECT_ROOT = find_project_root()
CONTENT_DIR = PROJECT_ROOT / "content" / "posts"
DATA_DIR = PROJECT_ROOT / "data"

# ============================================
# çº¿ç¨‹å®‰å…¨çš„ URL çŠ¶æ€ç®¡ç†
# ============================================

class URLState:
    def __init__(self):
        self.processed_file = DATA_DIR / "processed_urls.json"
        self.processed = set()
        self._lock = threading.Lock()
        self._load()
    
    def _load(self):
        if self.processed_file.exists():
            with open(self.processed_file, 'r') as f:
                self.processed = set(json.load(f))
    
    def _save(self):
        DATA_DIR.mkdir(parents=True, exist_ok=True)
        with open(self.processed_file, 'w') as f:
            json.dump(list(self.processed), f, indent=2)
    
    def is_processed(self, url: str) -> bool:
        with self._lock:
            return url in self.processed
    
    def mark_processed(self, url: str):
        with self._lock:
            self.processed.add(url)
            self._save()

# ============================================
# è¿›åº¦è®¡æ•°å™¨
# ============================================

class ProgressCounter:
    def __init__(self, total: int):
        self.total = total
        self.completed = 0
        self.success = 0
        self.failed = 0
        self.skipped = 0  # è·³è¿‡çš„è§†é¢‘é¡µé¢
        self._lock = threading.Lock()
        self.start_time = time.time()
    
    def increment(self, status: str = 'success'):
        with self._lock:
            self.completed += 1
            if status == 'success':
                self.success += 1
            elif status == 'skipped':
                self.skipped += 1
            else:
                self.failed += 1
    
    def get_stats(self) -> str:
        with self._lock:
            elapsed = time.time() - self.start_time
            rate = self.completed / elapsed * 60 if elapsed > 0 else 0
            remaining = (self.total - self.completed) / rate if rate > 0 else 0
            return f"[{self.completed}/{self.total}] âœ…{self.success} â­ï¸{self.skipped} âŒ{self.failed} | {rate:.1f}/min | ETA: {remaining:.0f}min"

# ============================================
# Sitemap è·å–
# ============================================

def fetch_sitemap_urls() -> List[str]:
    """ä» sitemap è·å–æ‰€æœ‰æ–‡ç«  URL"""
    print(f"ğŸ“¡ è·å– sitemap: {SITEMAP_URL}")
    
    response = requests.get(SITEMAP_URL, headers={'User-Agent': USER_AGENT}, timeout=30)
    response.raise_for_status()
    
    root = ElementTree.fromstring(response.content)
    ns = {'sm': 'http://www.sitemaps.org/schemas/sitemap/0.9'}
    
    urls = []
    for url_elem in root.findall('.//sm:url', ns):
        loc = url_elem.find('sm:loc', ns)
        if loc is not None and loc.text:
            url = loc.text.strip()
            # åªè¦æ–‡ç« é¡µé¢
            if '/library/' in url and '?' not in url and url.count('/') == 4:
                urls.append(url)
    
    print(f"âœ… æ‰¾åˆ° {len(urls)} ä¸ªé¡µé¢")
    return urls

# ============================================
# Playwright å†…å®¹æŠ“å–
# ============================================

# æµè§ˆå™¨å®ä¾‹æ± 
_browser_pool = {}
_browser_lock = threading.Lock()
_playwright_instance = None

def get_browser(worker_id: int) -> Browser:
    """è·å–æˆ–åˆ›å»ºæµè§ˆå™¨å®ä¾‹"""
    global _playwright_instance
    
    with _browser_lock:
        if _playwright_instance is None:
            _playwright_instance = sync_playwright().start()
        
        if worker_id not in _browser_pool:
            _browser_pool[worker_id] = _playwright_instance.chromium.launch(
                headless=True,
                args=['--disable-gpu', '--no-sandbox', '--disable-dev-shm-usage']
            )
    
    return _browser_pool[worker_id]

def cleanup_browsers():
    """æ¸…ç†æ‰€æœ‰æµè§ˆå™¨å®ä¾‹"""
    global _playwright_instance
    
    with _browser_lock:
        for browser in _browser_pool.values():
            try:
                browser.close()
            except:
                pass
        _browser_pool.clear()
        
        if _playwright_instance:
            try:
                _playwright_instance.stop()
            except:
                pass
            _playwright_instance = None

def fetch_article_with_playwright(url: str, worker_id: int) -> Optional[Dict]:
    """ä½¿ç”¨ Playwright è·å–æ–‡ç« å†…å®¹"""
    try:
        browser = get_browser(worker_id)
        page = browser.new_page()
        
        try:
            page.goto(url, wait_until='networkidle', timeout=30000)
            page.wait_for_timeout(1500)  # ç­‰å¾… JS æ¸²æŸ“
            
            # è·å–æ ‡é¢˜
            title = ""
            try:
                title_elem = page.query_selector('h1')
                if title_elem:
                    title = title_elem.inner_text().strip()
            except:
                pass
            
            # è·å–ä¸»è¦å†…å®¹åŒºåŸŸ
            content = ""
            
            # å°è¯•å¤šç§é€‰æ‹©å™¨
            selectors = [
                'article',
                'main',
                '.prose',
                '.content',
                '[class*="article"]',
                '[class*="content"]',
            ]
            
            for selector in selectors:
                try:
                    elem = page.query_selector(selector)
                    if elem:
                        text = elem.inner_text()
                        if len(text) > len(content):
                            content = text
                except:
                    continue
            
            # å¦‚æœç‰¹å®šé€‰æ‹©å™¨æ²¡æ‰¾åˆ°ï¼Œç”¨ body
            if len(content) < MIN_CONTENT_LENGTH:
                content = page.inner_text('body')
            
            # æ¸…ç†å†…å®¹
            content = clean_content(content)
            
            # æ£€æŸ¥æ˜¯å¦æ˜¯è§†é¢‘é¡µé¢ï¼ˆå†…å®¹å¤ªçŸ­ï¼‰
            if len(content) < MIN_CONTENT_LENGTH:
                return None
            
            return {
                'url': url,
                'content': content,
                'title': title,
                'author': 'Y Combinator',
                'date': None,
            }
            
        finally:
            page.close()
            
    except Exception as e:
        return None

def clean_content(text: str) -> str:
    """æ¸…ç†é¡µé¢å†…å®¹"""
    # ç§»é™¤å¯¼èˆªã€é¡µè„šç­‰
    lines = text.split('\n')
    
    # è¿‡æ»¤æ‰å¤ªçŸ­çš„è¡Œå’Œå¯¼èˆªè¡Œ
    skip_patterns = [
        'Log in', 'Apply', 'Table of Contents', 'Footer',
        'Y Combinator', 'Programs', 'Company', 'Resources',
        'Privacy Policy', 'Terms of Use', 'Â© 2026',
        'Twitter', 'Facebook', 'Instagram', 'LinkedIn', 'Youtube',
        'Startup Directory', 'Startup Library', 'Hacker News',
        'Up next', 'Related', 'views', 'Over 1 year ago',
    ]
    
    cleaned_lines = []
    for line in lines:
        line = line.strip()
        if not line:
            continue
        if len(line) < 10:
            continue
        if any(pattern in line for pattern in skip_patterns):
            continue
        cleaned_lines.append(line)
    
    return '\n\n'.join(cleaned_lines)

# ============================================
# ç¿»è¯‘å™¨
# ============================================

class Translator:
    def __init__(self):
        api_key = os.environ.get('DEEPSEEK_API_KEY')
        if not api_key:
            raise ValueError("è¯·è®¾ç½® DEEPSEEK_API_KEY ç¯å¢ƒå˜é‡")
        
        self.client = OpenAI(
            api_key=api_key,
            base_url=os.environ.get('DEEPSEEK_BASE_URL', 'https://api.deepseek.com')
        )
        self._lock = threading.Lock()
    
    def _build_glossary_text(self) -> str:
        return "\n".join([f"- {en} â†’ {zh}" for en, zh in GLOSSARY.items()])
    
    def translate(self, content: str) -> str:
        """ç¿»è¯‘æ­£æ–‡"""
        max_chunk = 8000
        if len(content) <= max_chunk:
            return self._translate_chunk(content)
        
        # åˆ†æ®µ
        paragraphs = content.split('\n\n')
        chunks = []
        current = ""
        
        for para in paragraphs:
            if len(current) + len(para) + 2 <= max_chunk:
                current += para + "\n\n"
            else:
                if current:
                    chunks.append(current.strip())
                current = para + "\n\n"
        if current.strip():
            chunks.append(current.strip())
        
        translated = []
        for chunk in chunks:
            translated.append(self._translate_chunk(chunk))
        
        return "\n\n".join(translated)
    
    def _translate_chunk(self, text: str) -> str:
        prompt = f"""è¯·å°†ä»¥ä¸‹è‹±æ–‡å†…å®¹ç¿»è¯‘æˆä¸­æ–‡ã€‚

ç¿»è¯‘è¦æ±‚ï¼š
1. å‡†ç¡®ä¼ è¾¾åŸæ–‡å«ä¹‰ï¼Œè¯­è¨€è‡ªç„¶æµç•…
2. ä¿æŒåŸæ–‡çš„æ®µè½ç»“æ„
3. ä¸“ä¸šæœ¯è¯­å‚è€ƒæœ¯è¯­è¡¨ï¼š
{self._build_glossary_text()}
4. ä»£ç å—ã€URLä¿æŒåŸæ ·
5. åªè¾“å‡ºç¿»è¯‘ç»“æœ

åŸæ–‡ï¼š
{text}

ç¿»è¯‘ï¼š"""
        
        try:
            response = self.client.chat.completions.create(
                model=TRANSLATION_MODEL,
                messages=[{"role": "user", "content": prompt}],
                temperature=0.3,
                max_tokens=4000,
            )
            return response.choices[0].message.content.strip()
        except Exception as e:
            return f"[ç¿»è¯‘å¤±è´¥]\n\n{text}"
    
    def generate_metadata(self, content: str, original_title: str) -> Dict:
        categories = ['AIç ”ç©¶', 'AIäº§å“', 'VCè§‚ç‚¹', 'åˆ›ä¸š', 'æŠ€æœ¯è¶‹åŠ¿', 'äº§å“', 'å¢é•¿', 'èèµ„', 'å›¢é˜Ÿç®¡ç†', 'æœªåˆ†ç±»']
        
        prompt = f"""ä¸ºä»¥ä¸‹æ–‡ç« ç”Ÿæˆå…ƒæ•°æ®ï¼ŒJSONæ ¼å¼è¿”å›ï¼š

åŸæ ‡é¢˜ï¼š{original_title}
å†…å®¹ï¼ˆå‰1500å­—ï¼‰ï¼š{content[:1500]}

è¿”å›æ ¼å¼ï¼š
{{"title_zh": "ä¸­æ–‡æ ‡é¢˜", "summary_zh": "100å­—æ‘˜è¦", "category": "åˆ†ç±»", "tags": ["æ ‡ç­¾1", "æ ‡ç­¾2"]}}

åˆ†ç±»é€‰é¡¹ï¼š{', '.join(categories)}
åªè¿”å›JSONã€‚"""
        
        try:
            response = self.client.chat.completions.create(
                model=TRANSLATION_MODEL,
                messages=[{"role": "user", "content": prompt}],
                temperature=0.3,
                max_tokens=500,
            )
            
            result = response.choices[0].message.content.strip()
            if '```' in result:
                result = re.search(r'\{.*\}', result, re.DOTALL).group()
            
            return json.loads(result)
        except:
            return {
                'title_zh': original_title,
                'summary_zh': content[:150] + '...',
                'category': 'æœªåˆ†ç±»',
                'tags': ['YC', 'åˆ›ä¸š']
            }

# ============================================
# æ–‡ç« ç”Ÿæˆ
# ============================================

_file_lock = threading.Lock()

def generate_article(article: Dict, translated_content: str, metadata: Dict) -> Path:
    """ç”Ÿæˆ Markdown æ–‡ä»¶"""
    with _file_lock:
        CONTENT_DIR.mkdir(parents=True, exist_ok=True)
    
    date_str = datetime.now().strftime('%Y-%m-%d')
    url_hash = hashlib.md5(article['url'].encode()).hexdigest()[:8]
    slug = f"{date_str}-ycombinator-{url_hash}"
    filepath = CONTENT_DIR / f"{slug}.md"
    
    front_matter = {
        'title': metadata.get('title_zh', article.get('title', '')),
        'title_original': article.get('title', ''),
        'date': date_str,
        'source': SOURCE_NAME,
        'source_url': article['url'],
        'author': article.get('author', ''),
        'summary': metadata.get('summary_zh', ''),
        'categories': [metadata.get('category', 'æœªåˆ†ç±»')],
        'tags': metadata.get('tags', []),
        'draft': False,
    }
    
    front_matter_yaml = yaml.safe_dump(front_matter, allow_unicode=True, default_flow_style=False, sort_keys=False)
    
    content = f"""---
{front_matter_yaml}---

{translated_content}

---

> æœ¬æ–‡ç”±AIè‡ªåŠ¨ç¿»è¯‘ï¼ŒåŸæ–‡é“¾æ¥ï¼š[{article.get('title', 'åŸæ–‡')}]({article['url']})
"""
    
    with _file_lock:
        with open(filepath, 'w', encoding='utf-8') as f:
            f.write(content)
    
    return filepath

# ============================================
# Worker å‡½æ•°
# ============================================

def process_single_article(args: Tuple[str, int, Translator, URLState, ProgressCounter]) -> Tuple[str, str, str]:
    """å¤„ç†å•ç¯‡æ–‡ç« """
    url, worker_id, translator, state, progress = args
    
    if state.is_processed(url):
        return (url, 'skip', "å·²å¤„ç†")
    
    try:
        # 1. è·å–å†…å®¹
        article = fetch_article_with_playwright(url, worker_id)
        if not article:
            progress.increment('skipped')
            return (url, 'skipped', "â­ï¸ è§†é¢‘/æ’­å®¢é¡µé¢ï¼Œè·³è¿‡")
        
        title = article.get('title', '')[:35]
        
        # 2. ç¿»è¯‘
        translated = translator.translate(article['content'])
        
        # 3. å…ƒæ•°æ®
        metadata = translator.generate_metadata(translated, article.get('title', ''))
        
        # 4. ç”Ÿæˆæ–‡ä»¶
        filepath = generate_article(article, translated, metadata)
        
        # 5. æ ‡è®°å®Œæˆ
        state.mark_processed(url)
        progress.increment('success')
        
        return (url, 'success', f"âœ… {title}...")
    
    except Exception as e:
        progress.increment('failed')
        return (url, 'failed', f"âŒ {str(e)[:40]}")

# ============================================
# ä¸»å‡½æ•°
# ============================================

def main():
    parser = argparse.ArgumentParser(description='YC Library Backfill - Playwrightç‰ˆ')
    parser.add_argument('--max', type=int, default=0, help='æœ€å¤šå¤„ç†å¤šå°‘ç¯‡ï¼ˆ0=å…¨éƒ¨ï¼‰')
    parser.add_argument('--skip', type=int, default=0, help='è·³è¿‡å‰Nç¯‡')
    parser.add_argument('--workers', type=int, default=DEFAULT_WORKERS, help=f'å¹¶å‘æ•°ï¼ˆé»˜è®¤{DEFAULT_WORKERS}ï¼‰')
    args = parser.parse_args()
    
    print("=" * 60)
    print("ğŸš€ YC Library Backfill - Playwright ç‰ˆ")
    print("=" * 60)
    print(f"ğŸ“ é¡¹ç›®ç›®å½•: {PROJECT_ROOT}")
    print(f"ğŸ“ å†…å®¹ç›®å½•: {CONTENT_DIR}")
    print(f"âš¡ å¹¶å‘æ•°: {args.workers}")
    
    # åˆå§‹åŒ–
    state = URLState()
    translator = Translator()
    
    # è·å– URL åˆ—è¡¨
    urls = fetch_sitemap_urls()
    
    # è¿‡æ»¤å·²å¤„ç†çš„
    urls = [u for u in urls if not state.is_processed(u)]
    print(f"ğŸ“Š å¾…å¤„ç†: {len(urls)} ç¯‡")
    
    if args.skip > 0:
        urls = urls[args.skip:]
    if args.max > 0:
        urls = urls[:args.max]
    
    if not urls:
        print("âœ… æ²¡æœ‰éœ€è¦å¤„ç†çš„æ–‡ç« ï¼")
        return
    
    print(f"ğŸ¯ æœ¬æ¬¡å¤„ç†: {len(urls)} ç¯‡")
    print("=" * 60)
    
    progress = ProgressCounter(len(urls))
    
    try:
        with ThreadPoolExecutor(max_workers=args.workers) as executor:
            # åˆ†é… worker_id
            tasks = [(url, i % args.workers, translator, state, progress) for i, url in enumerate(urls)]
            futures = {executor.submit(process_single_article, task): task[0] for task in tasks}
            
            for future in as_completed(futures):
                try:
                    _, status, msg = future.result()
                    print(f"{progress.get_stats()} | {msg}")
                except Exception as e:
                    print(f"{progress.get_stats()} | âŒ Error: {e}")
    
    except KeyboardInterrupt:
        print("\n\nâš ï¸ ç”¨æˆ·ä¸­æ–­")
    
    finally:
        print("\nğŸ§¹ æ¸…ç†æµè§ˆå™¨...")
        cleanup_browsers()
    
    # ç»Ÿè®¡
    elapsed = time.time() - progress.start_time
    print("\n" + "=" * 60)
    print(f"ğŸ‰ å®Œæˆï¼")
    print(f"   âœ… æˆåŠŸç¿»è¯‘: {progress.success} ç¯‡")
    print(f"   â­ï¸ è·³è¿‡è§†é¢‘: {progress.skipped} ç¯‡")
    print(f"   âŒ å¤±è´¥: {progress.failed} ç¯‡")
    print(f"   â±ï¸ è€—æ—¶: {elapsed/60:.1f} åˆ†é’Ÿ")
    if progress.success > 0:
        print(f"   ğŸ“ˆ é€Ÿåº¦: {progress.success / elapsed * 60:.1f} ç¯‡/åˆ†é’Ÿ")
    print("=" * 60)

if __name__ == "__main__":
    main()
