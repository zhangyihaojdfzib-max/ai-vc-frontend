---
title: 全新生成式AI工具开启音乐创作之门
title_original: New generative AI tools open the doors of music creation
date: '2024-10-23'
source: Google DeepMind
source_url: https://deepmind.google/blog/new-generative-ai-tools-open-the-doors-of-music-creation/
author: ''
summary: 本文介绍了Google DeepMind与Google Labs合作推出的新一代AI音乐创作工具。重点展示了重新构想的MusicFX DJ体验，它允许用户通过混合文本提示词实时生成和引导音乐流，并具备直观的控制界面和制作级音质。同时，文章提及了Music
  AI Sandbox工具包的更新及在YouTube Shorts中的应用，旨在通过生成式AI技术降低音乐创作门槛，赋能不同技能水平的创作者进行创新表达。这些工具的开发得到了音乐产业合作伙伴的反馈，并强调了负责任地推动技术发展的理念。
categories:
- AI产品
tags:
- 生成式AI
- AI音乐创作
- MusicFX DJ
- Google DeepMind
- 实时生成
draft: false
translated_at: '2026-02-11T04:31:02.135885'
---

# 全新生成式AI工具开启音乐创作之门

GenMedia音乐团队

![一张交互式生成音乐工具的插图，展示不同用户界面悬浮在带有智能手机网格的彩色渐变背景上。](/images/posts/28dfbf6e7a45.jpg)

注（2025年5月1日）：这些工具现已由Google DeepMind开发的音乐生成模型Lyria和Lyria RealTime提供支持。

我们最新的AI音乐技术现已应用于MusicFX DJ、Music AI Sandbox和YouTube Shorts

近十年来，我们的团队始终在探索**人工智能（AI）**如何支持创作过程，致力于构建赋能爱好者与专业人士发现创意表达新形式的工具。

过去一年间，我们通过**Music AI Incubator**等项目与音乐产业各界伙伴紧密协作。他们的反馈指引着我们尖端的生成式音乐实验，并帮助我们确保新的生成式AI工具能负责任地为所有人开启音乐创作之门。

今日，我们与**Google Labs**合作，推出重新构想的**MusicFX DJ**体验，让任何人都能更轻松地实时交互生成音乐。

我们同时宣布名为**Music AI Sandbox**的音乐AI工具包更新，并重点展示YouTube Dream Track中最新AI音乐技术——这套实验工具可供创作者为其Shorts和视频生成高质量伴奏音乐。

## 用MusicFX DJ生成现场音乐

在今年I/O大会上，我们展示了**MusicFX DJ的早期预览版**——这款数字工具人人都能像乐器般演奏，让不同技能水平的用户都能更便捷地体验现场音乐创作的乐趣。

今日，我们为MusicFX DJ带来多项更新，包括扩展的直观控制选项、重新设计的界面、提升的音频质量及新的模型行为。这些功能让使用者能生成并引导持续流动的音乐，与朋友分享创作成果，并共同进行即兴演奏。

我们与六次格莱美奖得主——歌手、词曲作者、制作人多乐器演奏家**Jacob Collier**密切合作，设计了这些更新，旨在使MusicFX DJ更易上手、实用且富有启发性。

![](/images/posts/f0186397c8b8.jpg)

![](/images/posts/4bf21547fada.jpg)

与传统DJ工具混合现有曲目不同，MusicFX DJ通过允许玩家混合文本**提示词**形式的音乐概念来生成全新音乐。使用者可融合喜爱的流派、乐器和氛围创造新风格，即兴创作现场DJ组曲，或探索可用于制作的新旋律、音色与节奏。

虽非传统乐器，MusicFX DJ却是进入现场音乐创作领域一个平易近人且富有表现力的入口。无论音乐经验如何，用户都能通过直观控制生成并引导独特且持续演变的音乐声景。

> 你塑造着这种实时音效黏土，它充满无限惊喜，本质上试图炼金术般融合或锻造那些本不可能产生联系的事物之间的联系。

MusicFX DJ基于两项创新方法：首先，我们将离线生成音乐模型适配为实时流式生成。通过训练模型依据先前生成的音乐及玩家提供的文本提示词来生成下一段音乐片段实现此功能。

其次，不同于典型文生音乐模型使用单一固定文本提示词，我们赋予玩家混合多个文本提示词并随时间调整混合比例的能力。模型通过混合每个提示词的**嵌入/向量**表征实现此功能，各嵌入向量的相对重要性由玩家通过滑块选择。模型利用这些组合嵌入向量来引导音乐风格。

流程图展示MusicFX DJ如何生成持续音乐流：依据先前片段创建下一片段，同时通过文本提示词和权重滑块进行引导。

### 构建更直观的控制方式

我们与Jacob共同探索并构建了专有控制方式，这些控制对初学者直观易懂，鼓励实验探索，并提供比单纯文本提示词更多元的创意表达路径。

通过MusicFX DJ的新控件，玩家可以指挥乐器编排，通过增减贝斯、鼓组等乐器轻松制造段落转换与低音骤降。他们还能调整音乐质感维度，如明亮或阴暗、重复或随机、平滑或粗糙的听觉与感受体验。

玩家亦可控制调性与速度，使其更易在长时间即兴演奏中与现有音乐或他人配合。我们的团队非常享受将MusicFX DJ与传统乐器配合使用，并期待听到他人运用这些新功能创作的作品。

### 生成制作级音质

作为合作的一部分，我们还探索了玩家如何将模型输出既作为灵感来源，又作为大型作曲的组成部分。但我们早期模型缺乏专业音频制作所需的音质。得益于音频研究团队的最新创新（包括新型神经音频编解码器和优化的网络架构），MusicFX DJ现已能实时流式传输制作级48kHz立体声音频。

### 分享与下载音频

受Jacob注重**与其他艺术家**及**与观众**创意协作的启发，我们希望让MusicFX DJ创作的音乐更易分享与互动。玩家现可下载60秒MusicFX DJ音频，并与朋友分享会话——朋友不仅能观看演奏回放，还可随时接管控制权，将音乐引向全新方向。

## 扩展的Music AI Sandbox工具包

**Music AI Sandbox**是一套实验性音乐AI工具集，旨在增强通过YouTube **Music AI Incubator**与我们合作的音乐人、制作人和词曲作者的工作流程。它已成为宝贵试验场，用于收集音乐产业各界艺术家、词曲作者及合作伙伴对我们最新、最具实验性生成音乐工具的反馈。虽然Music AI Sandbox目前未公开提供，但其中成功的元素将整合到谷歌广泛可及的产品中。

自今年I/O大会公开展示Music AI Sandbox以来，我们还与**Google技术与社会团队**紧密合作，以改善用户体验，大规模连接艺术社群收集反馈。这项工作帮助我们对此工具集背后的模型进行了重大更新。

不久后，受信测试者将能勾勒歌曲草稿，并使用多轨视图配合精确控制来组织和完善作曲。新版Music AI Sandbox整合了我们最新技术（包括驱动MusicFX DJ的模型），以及循环生成、声音转换和局部修复等流行功能，帮助用户无缝连接音乐轨道的各个部分。

![更新版Music AI Sandbox用户界面设计截图，该版本配备多轨视图，可通过精确控制帮助组织和完善作曲。](/images/posts/157078afd85f.jpg)

更新版Music AI Sandbox用户界面设计截图，该版本配备多轨视图，可通过精确控制帮助组织和完善作曲。

## YouTube Dream Track实验现可生成器乐配乐

基于我们与YouTube的持续合作，我们升级了**Dream Track实验**，允许美国创作者探索多种流派与提示词，利用强大的文生音乐模型生成器乐配乐。

我们最新的音乐生成模型采用了一种新颖的强化学习方法进行训练，不仅音频质量更高，而且能更好地关注用户文本提示词的细微差别。负责任地部署生成技术是我们的核心价值观，因此所有由 MusicFX DJ 和 Dream Track 生成的音乐都使用 SynthID 进行了水印处理。

## 共同构建音乐创作的未来

过去一年，我们很高兴能与音乐界的合作伙伴携手，共同开发既能响应专业人士需求，又能为下一代音乐人拓宽使用途径的技术。

我们期待在共同构建音乐创作未来的过程中深化这些合作伙伴关系，开发出更优秀的工具来激发创造力。

这项工作的实现得益于以下核心研究和工程人员的努力：Andrea Agostinelli、Zalán Borsos、George Brower、Antoine Caillon、Cătălina Cangea、Noah Constant、Michael Chang、Chris Deaner、Timo Denk、Chris Donahue、Michael Dooley、Jesse Engel、Christian Frank、Beat Gfeller、Tobenna Peter Igwe、Drew Jaegle、Matej Kastelic、Kazuya Kawakami、Pen Li、Ethan Manilow、Yotam Mann、Colin McArdell、Brian McWilliams、Adam Roberts、Matt Sharifi、Ian Simon、Ondrej Skopek、Marco Tagliasacchi、Cassie Tarakajian、Alex Tudor、Victor Ungureanu、Mauro Verzetti、Damien Vincent、Luyu Wang、Björn Winkler、Yan Wu 和 Mauricio Zuluaga。

MusicFX DJ 由 Antoine Caillon、Noah Constant、Jesse Engel、Alberto Lalama、Hema Manickavasagam、Adam Roberts、Ian Simon 和 Cassie Tarakajian 开发，并与来自 Google Labs 的合作伙伴 Obed Appiah-Agyeman、Tahj Atkinson、Carlie de Boer、Phillip Campion、Sai Kiran Gorthi、Kelly Lau-Kee、Elias Roman、Noah Semus、Trond Wuellner、Kristin Yim 和 Jamie Zyskowski 合作完成。我们向 Jacob Collier、Ben Bloomberg 和 Fran Haincourt 致以最深切的感谢，感谢他们在整个开发过程中提供的宝贵反馈。

Music AI Sandbox 由 Andrea Agostinelli、George Brower、Ross Cairns、Michael Chang、Yeawon Choi、Chris Deaner、Jesse Engel、Reed Enger、Beat Gfeller、Tom Hume、Tom Jenkins、Max Edelmann、Drew Jaegle、Jacob Kelly、DY Kim、David Madras、Hema Manickavasagam、Ethan Manilow、Yotam Mann、Colin McArdell、Chris Reardon、Felix Riedel、Adam Roberts、Arathi Sethumadhavan、Eleni Shaw、Sage Stevens、Amy Stuart、Luyu Wang、Pawel Wluka 和 Yan Wu 开发，并与我们在 YouTube 以及技术与社会的合作伙伴协作完成。

Dream Track 由 Andrea Agostinelli、Zalán Borsos、Geoffrey Cideron、Timo Denk、Michael Dooley、Christian Frank、Sertan Girgin、Myriam Hamed Torres、Matej Kastelic、Pen Li、Brian McWilliams、Matt Sharifi、Ondrej Skopek、Marco Tagliasacchi、Mauro Verzetti、Mauricio Zuluaga 开发，并与我们在 YouTube 的合作伙伴协作完成。

特别感谢 Aäron van den Oord、Tom Hume、Douglas Eck、Eli Collins、Mira Lane、Koray Kavukcuoglu 和 Demis Hassabis 在整个研究过程中富有洞察力的指导和支持。感谢 Mahyar Bordbar 和 DY Kim 帮助协调这些工作，以及 YouTube 艺术家合作团队在音乐行业合作方面给予的支持。

我们也感谢 Google DeepMind 和 Alphabet 内许多其他做出贡献的个人，包括我们在 YouTube 的合作伙伴。

### 用生成式 AI 赋能 YouTube 创作者

![](/images/posts/91512f75bbcb.jpg)

### 为视频生成音频

![](/images/posts/82441e510765.jpg)

### 改变音乐创作的未来

![](/images/posts/b0c697b7dd5e.jpg)

---

> 本文由AI自动翻译，原文链接：[New generative AI tools open the doors of music creation](https://deepmind.google/blog/new-generative-ai-tools-open-the-doors-of-music-creation/)
> 
> 翻译时间：2026-02-11 04:31
