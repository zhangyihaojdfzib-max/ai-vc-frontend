---
title: AI管理AI：工具调用准确率突破临界点，催生模型星座架构
title_original: AI Managing AI
date: '2026-01-22'
source: Tomasz Tunguz
source_url: https://www.tomtunguz.com/the-scaffolding-shift/
author: ''
summary: 文章指出，随着大模型工具调用准确率从两年前的不足50%提升至如今的90%以上，AI系统正从单体架构转向由“前沿模型执行官”协调多个专用专家模型的“星座架构”。这种转变源于工具调用可靠性的质变，使得将任务路由给第三方专家成为可能。文章认为，未来的创业机会不在于训练最大的模型，而在于构建那些会被“执行官”优先调用的、在特定领域表现卓越的专家模型，同时讨论了模型蒸馏等技术在平衡性能与效率中的作用。
categories:
- 技术趋势
tags:
- AI编排
- 工具调用
- 模型架构
- 专家模型
- AI代理
draft: false
translated_at: '2026-01-23T04:38:56.002442'
---

有才华的人会被提升为管理者。有才华的模型也是如此。Claude 管理代码执行。Gemini 在 CRM 和聊天之间路由请求。GPT-5 可以协调公开股票研究。

为何是现在？工具调用的准确性跨越了一个临界点。两年前，GPT-4 在函数调用任务上的成功率不到 50%。模型会幻觉参数、调用错误端点、在对话中途忘记上下文。如今，最先进的模型在函数调用基准测试中的准确率已超过 90%1。像 Gemini 3 这样的最新模型，其实际性能明显优于基准测试所显示的结果。

我们真的需要万亿参数的模型仅仅是为了进行函数调用吗？令人惊讶的是，是的。

针对小型动作模型（即仅针对工具选择训练的轻量级网络）的实验在生产环境中失败了2。它们缺乏世界知识。事实证明，管理需要上下文。

如今，编排器通常将自己生成为一个子 Agent（例如 Claude Code 会启动另一个 Claude Code）。这种对称性不会持续下去。

"苦涩的教训"3坚持认为，越来越大的模型应该处理一切。但经济学提出了反驳：蒸馏和强化微调可以产生体积缩小 40%、速度提升 60% 的模型，同时保留 97% 的性能4。

来自不同供应商的专用 Agent 正在涌现。前沿模型成为"执行官"，在专家之间路由请求。这些专家可以是第三方供应商，他们都力争在自己领域做到最好。

专家星座需要可靠的工具调用。当工具调用只有 50% 的时间有效时，团队会构建单体架构，将所有功能都保留在一个模型内，以最小化故障点。当它有 90% 的时间有效时，团队就会将任务路由给专家，并整合他们的能力。

前沿实验室将拥有编排层。但他们无法拥有每一个专家。那些构建了最佳浏览器使用 Agent、最佳检索系统、最佳 BI Agent 的初创公司，可以接入这些星座并占据自己的生态位。

新的初创公司机会并非来自训练最大的模型，而是来自训练那些"执行官"会优先调用的专家模型。

1. 伯克利函数调用排行榜 (BFCL) 测试 API 调用准确性。TAU-bench 衡量现实场景中的工具增强推理能力（论文）。↩︎
2. Salesforce 的 xLAM 是专门为工具选择设计的大型动作模型。虽然对于简单的工具调用快速且准确，但小型动作模型在何时使用工具的复杂推理上存在困难。↩︎
3. Rich Sutton 颇具影响力的文章，主张利用计算的通用方法胜过手工设计的领域知识。《苦涩的教训》。↩︎
4. 参见 DistilBERT，它比 BERT 体积小 40%，速度快 60%，同时保留了 BERT 97% 的性能。OpenAI 的模型蒸馏也能实现类似的效率提升。↩︎

伯克利函数调用排行榜 (BFCL) 测试 API 调用准确性。TAU-bench 衡量现实场景中的工具增强推理能力（论文）。↩︎

Salesforce 的 xLAM 是专门为工具选择设计的大型动作模型。虽然对于简单的工具调用快速且准确，但小型动作模型在何时使用工具的复杂推理上存在困难。↩︎

Rich Sutton 颇具影响力的文章，主张利用计算的通用方法胜过手工设计的领域知识。《苦涩的教训》。↩︎

参见 DistilBERT，它比 BERT 体积小 40%，速度快 60%，同时保留了 BERT 97% 的性能。OpenAI 的模型蒸馏也能实现类似的效率提升。↩︎

> 本文由AI自动翻译，原文链接：[AI Managing AI](https://www.tomtunguz.com/the-scaffolding-shift/)
> 
> 翻译时间：2026-01-23 04:38
