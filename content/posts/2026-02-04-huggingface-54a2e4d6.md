---
title: 社区评测：告别黑箱排行榜，拥抱透明评估
title_original: 'Community Evals: Because we''re done trusting black-box leaderboards
  over the community'
date: '2026-02-04'
source: Hugging Face Blog
source_url: https://huggingface.co/blog/community-evals
author: ''
summary: 本文介绍了Hugging Face推出的去中心化、透明的社区评测体系。针对当前AI模型基准测试分数饱和、结果不一致且与实际性能脱节的问题，该方案允许社区通过PR公开提交模型在基准数据集上的评估结果。评估分数存储在模型仓库中，并与基准数据集排行榜自动同步，所有过程可追溯、可复现。此举旨在聚合分散的评估信息，提高透明度，推动构建更可靠的模型评估生态，但不会完全取代传统封闭评估。
categories:
- AI基础设施
tags:
- 模型评估
- 开源社区
- Hugging Face
- 基准测试
- 可复现性
draft: false
translated_at: '2026-02-06T04:15:19.282024'
---

# 社区评测：因为我们不再相信黑箱排行榜胜过社区共识

TL;DR：Hugging Face 上的基准数据集现在可以托管排行榜。模型自行存储评估分数。所有环节相互关联。社区可通过 PR 提交结果。已验证徽章证明结果可复现。

## 当前评测体系的问题

让我们直面 2026 年评测领域的现状。MMLU 准确率已饱和超过 91%。GSM8K 达到 94% 以上。HumanEval 已被攻克。但根据使用反馈，某些在基准测试中表现优异的模型仍无法可靠地浏览网页、编写生产代码或处理多步骤任务而不产生幻觉。基准分数与实际性能之间存在明显差距。

此外，**已公布的基准分数内部也存在差异**。不同来源报告的结果各不相同。从模型卡片、论文到评估平台，报告分数缺乏统一标准。这导致社区缺乏可信的单一数据源。

## 我们推出的解决方案

去中心化且透明的评估报告体系。

我们将引导 Hugging Face Hub 的评估体系向新方向发展：通过去中心化报告机制，允许整个社区公开提交基准测试分数。初期我们将从 4 个基准测试开始，逐步扩展至最相关的基准集。

对于基准测试：
数据集仓库现可注册为基准测试（MMLU-Pro、GPQA、HLE 已上线）。它们会自动聚合 Hub 上报告的评估结果，并在数据集卡片中展示排行榜。基准测试通过基于 Inspect AI 格式的 `eval.yaml` 定义评估规范，确保任何人都能复现结果。报告结果需符合任务定义要求。

![基准测试示意图](/images/posts/0f982b48c4ae.png)

对于模型：
评估分数存储在模型仓库的 `.eval_results/*.yaml` 中。它们会显示在模型卡片上，并同步至基准数据集。**模型作者的结果**和**结果提交的开放 PR** 都将被聚合。模型作者可关闭分数 PR 并隐藏结果。

对于社区：
任何用户均可通过 PR 为任意模型提交评估结果。结果将显示为"社区提交"，无需等待模型作者合并或关闭。社区可引用论文、模型卡片、第三方评估平台或 inspect eval 日志等来源。社区可像讨论普通 PR 一样讨论分数。由于 Hub 基于 Git 构建，所有评估记录的添加、修改等操作均有历史追溯。来源示例如下：

![模型示意图](/images/posts/8d864086f60e.png)

了解更多评估结果详情，请查阅[文档](https://huggingface.co/docs)。

## 此举的意义

去中心化评估将公开社区已存在于模型卡片、论文等来源的分数。通过公开这些分数，社区可以在此基础上进行聚合、追踪和理解领域内的评分动态。所有分数都将通过 Hub API 公开，便于构建精选排行榜、仪表盘等工具。

社区评测不会取代基准测试，发布结果的排行榜和封闭评估仍然至关重要。但我们认为，基于可复现评估规范贡献开放评估结果对领域发展具有重要意义。

这不会解决基准饱和问题，也不会弥合基准与现实的差距，更无法杜绝在测试集上训练的行为。但它通过公开评估内容、方法、时间和执行者，让整个游戏规则变得透明。

最重要的是，我们希望将 Hub 打造成构建和分享可复现基准测试的活跃平台，特别关注那些能更有效挑战 SOTA 模型的新任务和新领域。

## 快速开始

提交评估结果：
将您完成的评估以 YAML 文件形式发布到任意模型仓库的 `.eval_results/` 目录。

查看分数：
访问[基准数据集页面](https://huggingface.co/datasets/open-llm-leaderboard)浏览分数。

注册新基准：
在您的数据集仓库添加 `eval.yaml` 并[联系我们](mailto:community-evals@huggingface.co)加入候选列表。

本功能处于测试阶段。我们正在开放环境中持续完善，欢迎提供反馈。

---

> 本文由AI自动翻译，原文链接：[Community Evals: Because we're done trusting black-box leaderboards over the community](https://huggingface.co/blog/community-evals)
> 
> 翻译时间：2026-02-06 04:15
