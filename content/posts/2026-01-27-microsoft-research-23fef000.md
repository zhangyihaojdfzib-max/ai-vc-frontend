---
title: UniRG利用强化学习提升医学影像报告生成质量
title_original: UniRG aims to improve medical imaging reports using RL
date: '2026-01-27'
source: Microsoft Research
source_url: https://www.microsoft.com/en-us/research/blog/unirg-scaling-medical-imaging-report-generation-with-multimodal-reinforcement-learning/
author: ''
summary: 本文介绍了通用报告生成（UniRG）框架，该框架采用强化学习技术优化医学影像报告生成。与传统的监督微调方法不同，UniRG通过结合基于规则、模型和LLM的复合奖励信号，直接优化临床准确性，使模型与真实放射学实践对齐。其训练模型UniRG-CXR在多个数据集、评估指标、诊断任务及不同患者亚组中均实现了最先进的性能，显著提高了报告的可靠性和跨机构泛化能力，减少了临床错误。
categories:
- AI研究
tags:
- 医学AI
- 强化学习
- 医学影像
- 报告生成
- 多模态模型
draft: false
translated_at: '2026-01-28T04:38:43.861487'
---

## 概览

- AI驱动的医学影像报告生成可帮助医疗服务提供者提升效率和生产力。
- 由于不同提供者之间的报告实践差异很大，当前模型难以训练。
- 通用报告生成（UniRG）使用强化学习，将模型训练与真实世界的放射学实践对齐，而非替代性的文本生成目标。
- UniRG 在数据集、评估指标、诊断任务、纵向设置和人口统计亚组中均实现了最先进的性能。
- 测试结果表明，在具有临床意义的奖励信号指导下，强化学习能显著提高医学视觉-语言模型的可靠性和泛化能力。

AI可用于根据胸部X光片等医学图像生成具有临床意义的放射学报告。医学影像报告生成可以减轻报告负担，同时提高医疗专业人员的工作流程效率。除了现实世界的益处，报告生成也已成为评估医疗保健AI中多模态推理能力的关键基准。

尽管大型视觉-语言模型推动了近期进展，但当前系统在真实临床环境中仍面临重大限制。其中一个挑战源于不同机构、科室和患者群体之间放射学报告实践的广泛差异。在特定数据集上通过监督微调训练的模型，可能会学习其特定的措辞和惯例，而非更通用的模式——这被称为过拟合问题。因此，该模型在该数据上表现良好，但在未见过的机构或外部数据集上评估时效果不佳。此外，由于模型训练通常旨在生成与现有报告相似的文本，一些书写良好但临床不准确的报告可能会蒙混过关。

在本博客中，我们介绍**通用报告生成（UniRG）**(opens in new tab)，这是一个基于强化学习的医学影像报告生成框架。这项工作是一个旨在推进医学AI研究的研究原型，未经临床使用验证。UniRG 使用强化学习作为一种统一机制，直接优化基于临床的评估信号，使模型训练与真实世界的放射学实践对齐，而非替代性的文本生成目标。利用此框架，我们训练了 **UniRG-CXR**(opens in new tab)，这是一个大规模的、最先进的胸部X光报告生成模型，涵盖来自80多家医疗机构的超过56万项研究、78万张图像和22.6万名患者。

据我们所知，这是首个在报告级指标、疾病级诊断准确性、跨机构泛化、纵向报告生成和人口统计亚组方面均实现一致最先进性能的报告生成模型。这些结果表明，在具有临床意义的奖励信号指导下，强化学习可以显著提高医学视觉-语言模型的可靠性和泛化能力。

聚焦：微软研究通讯

## 微软研究通讯

与微软的研究社区保持联系。

## 用于扩展医学影像报告生成的统一框架

UniRG 通过结合监督微调与强化学习来构建最先进的报告生成模型，强化学习优化了一个整合了基于规则的指标、基于模型的语义指标和基于LLM的临床错误信号的复合奖励。这种方法使得最终模型 **UniRG-CXR** 能够从多样化的数据源中学习，超越特定数据集的报告模式，并学习能够跨机构、指标和临床情境泛化的表征。值得注意的是，截至2026年1月22日，**UniRG-CXR** 在权威的 **ReXrank 排行榜**(opens in new tab)（一个胸部X光图像解读的公共排行榜）上创造了新的最先进水平，以显著优势超越了先前的最佳模型（图1）。

![图1. UniRG-CXR概览。(a) 训练数据：UniRG-CXR在MIMIC-CXR、CheXpert Plus和ReXGradient-160k的训练集上进行训练，涵盖不同机构和患者群体。(b) 训练与奖励：以当前图像、临床背景（如指征）以及可选的先前研究作为输入，UniRG-CXR使用GRPO强化学习来优化结合了基于规则、基于模型和基于LLM指标的复合奖励。(c) 评估：我们在保留的测试集（MIMIC-CXR、CheXpert Plus、ReXGradient）和未见过的数据集（IU Xray和专有数据）上评估UniRG-CXR。报告质量使用ReXrank指标和基于LLM的临床错误指标衡量，而诊断能力则通过从生成报告中提取的基于F1的疾病分类进行评估。(d) ReXrank结果：UniRG-CXR在四个数据集和两种生成设置（仅发现部分，以及发现+印象部分）上均实现了SOTA性能，相比先前最先进的系统显示出显著提升。](/images/posts/ab70c03a7f16.png)

## 跨指标和临床错误的全面改进

UniRG-CXR 并非以牺牲其他指标为代价在单一指标上表现出色，而是在许多不同的报告质量衡量标准上实现了均衡的改进。更重要的是，它生成的报告具有显著更少的临床显著错误。这表明该模型不仅在学习如何听起来像一份放射学报告，而且能更好地捕捉潜在的临床事实。明确优化临床正确性有助于模型避免常见的失败模式，即流畅的语言掩盖了不正确或缺失的发现（图2）。

![图2. UniRG-CXR实现了最先进的性能，在各项指标上带来一致且全面的性能提升。(a) 在ReXrank排行榜上，UniRG-CXR（绿色）在所有评估指标上均显示出稳健、普遍的改进。(b). 从相同的SFT检查点开始，与在单一指标上进行RL相比，使用我们的复合奖励进行RL在各项指标上实现了更均衡的增益，并获得了最高的RadCliQ-v1分数。此消融研究在MIMIC上训练和测试。(c). 关于训练动态的消融研究表明，完整的RL（UniRG-CXR）相比仅在BLEU上进行RL，获得了显著更好的RadCliQ-v1分数。(d). 在训练过程中，完整的RL（UniRG-CXR）显示每份报告的临床错误数稳步下降，而一个不具备错误感知能力的消融运行（即移除CheXprompt指标优化）则轨迹波动，没有持续改进。(c)和(d)均显示了在MIMIC上训练的消融研究在1024个MIMIC验证集上的结果。(e). 案例研究表明，与MedVersa和MedGemma不同，UniRG-CXR可以生成无错误的报告。(f). 与先前模型相比，UniRG-CXR产生的报告中有$\leq 1$个错误的比例显著更高，而$\geq 4$个错误的比例更低。](/images/posts/7b6bc8d754b1.png)

## 在纵向报告生成中的强大性能

在临床实践中，放射科医生经常将当前图像与先前的检查进行比较，以确定病情是改善、恶化还是未变。UniRG-CXR 能够有效地整合这种历史信息，生成反映随时间有意义变化的报告。这使得模型能够更准确地描述新发现、疾病进展或消退，更接近放射科医生跨患者病史进行推理的方式，而非孤立地处理每次检查（图3）。

![图3. UniRG-CXR 增强了纵向报告生成能力。(a). 在纵向报告生成任务中，将 UniRG-CXR 及其非纵向消融版本与先前模型进行比较，结果显示 UniRG-CXR 表现出最佳性能，且纵向信息对性能有益。(b). 从首次就诊到更复杂的第5次及以上就诊，UniRG-CXR 在不同纵向就诊时间点均实现了最佳性能，表明其改进是全面的。相比之下，GPT-5、GPT-4o 和 MedGemma 等先前模型的表现几乎未能超越复制先前报告的基线（灰色线）。(c). 与那些相比复制先前基线（虚线）几乎没有改进的先前模型相比，UniRG-CXR 在不同时间性病变变化类别（包括新发病变、无变化、进展和消退，由 GPT-5 根据真实报告分类）上均显著且持续地提升了性能。每个类别都展示了定性示例，其中 UniRG-CXR 根据输入正确预测了时间性变化。本图中所有结果均基于 MIMIC 测试集，并在可用时使用了先验信息。](/images/posts/837c6441f78a.png)

## 跨机构和人群的稳健泛化能力

即使应用于从未见过的机构数据，UniRG-CXR 仍能保持强劲性能。这表明模型正在学习通用的临床模式，而非记忆特定机构的报告风格。此外，其在不同患者亚组（包括年龄、性别和种族）中的表现保持稳定。这种稳健性对于现实世界部署至关重要，因为模型必须在多样化的人群和医疗环境中可靠地运行（图4）。

![图4. UniRG-CXR 的泛化性与稳健性。(a). 我们在两个来自未见过的机构的数据集（IU-Xray 和 PD（专有数据））上以零样本设置评估 UniRG-CXR。UniRG-CXR 始终优于先前模型，在这一具有挑战性的设置中保持了显著的性能优势。(b) 和 (c) 展示了在 MIMIC-CXR 和 PD 数据集上的疾病级别 F1 分数，并强调 UniRG-CXR 在疾病级别诊断准确性方面仍然是整体表现最佳的模型。(d). UniRG-CXR 在性别、年龄和种族亚组中均表现出稳定且稳健的性能，所有这些都超过了次优模型的性能（虚线）。](/images/posts/d192a6adccdc.png)

## UniRG 是迈向规模化医学影像报告生成的有希望的一步

UniRG 引入了一个基于强化学习的框架，重新思考了医学影像报告生成模型的训练和评估方式。通过直接优化基于临床的奖励信号，UniRG-CXR 在数据集、评估指标、诊断任务、纵向设置和人口统计学亚组中均实现了最先进的性能，解决了纯监督方法长期存在的局限性。

展望未来，该框架可以扩展到其他成像模态和临床任务，并与更丰富的多模态患者数据（如既往影像、实验室结果和临床记录）相结合。更广泛地说，UniRG 凸显了强化学习作为下一代稳健、可泛化且与临床对齐的医学基础模型核心组成部分的前景。

UniRG 体现了微软在推进用于精准健康的多模态生成式 AI 方面的更大承诺，其他令人兴奋的进展包括 GigaPath、BiomedCLIP、LLaVA-Rad、BiomedJourney、BiomedParse、TrialScope、Curiosity。

论文合著者：Qianchu Liu, Sheng Zhang, Guanghui Qin, Yu Gu, Ying Jin, Sam Preston, Yanbo Xu, Sid Kiblawi, Wen-wai Yim, Tim Ossowski, Tristan Naumann, Mu Wei, Hoifung Poon

## 认识作者

### Sheng Zhang

首席研究员

### Flora Liu

高级研究员

### Guanghui Qin

### Mu Wei

首席应用科学经理

### Hoifung Poon

真实世界证据总经理

## 继续阅读

![背景图案](/images/posts/326ecfc92d95.jpg)

### GigaTIME：利用多模态 AI 生成的虚拟人群扩展肿瘤微环境建模

### 在生成式 AI 时代驾驭医学教育

### PadChest-GR：一个用于胸部 X 光片的双语接地气放射学报告基准

![Medprompt 在 MedQA 基准测试上性能的可视化说明。从左到右沿水平线移动，图示展示了不同的 Medprompt 组件及其累加贡献如何提高准确率：从零样本的 81.7% 准确率开始，到随机少样本的 83.9% 准确率，到随机少样本加思维链的 87.3% 准确率，到 kNN 少样本加思维链的 88.4% 准确率，再到集成加选项重排的 90.2% 准确率。](/images/posts/53295d271e02.png)

### 下一代基础模型运行时策略的进展

---

> 本文由AI自动翻译，原文链接：[UniRG aims to improve medical imaging reports using RL](https://www.microsoft.com/en-us/research/blog/unirg-scaling-medical-imaging-report-generation-with-multimodal-reinforcement-learning/)
> 
> 翻译时间：2026-01-28 04:38
