---
title: 我们如何通过TaylorSeer方法优化FLUX.1 Kontext图像生成
title_original: How we optimized FLUX.1 Kontext [dev] – Replicate blog
date: '2025-07-15'
source: Replicate Blog
source_url: https://replicate.com/blog/flux-kontext-optimization
author: ''
summary: 本文介绍了Replicate团队为优化FLUX.1 Kontext [dev]图像生成模型所采用的TaylorSeer方法。该方法的核心是利用泰勒级数近似，通过缓存模型在先前时间步输出的多阶导数（变化量），来近似估计后续时间步的中间图像特征，从而减少冗余计算，加速生成过程。文章详细阐述了从“朴素缓存”、线性近似到TaylorSeer非线性近似的演进逻辑，并解析了该方法在FLUX.1
  Kontext中的具体实现步骤，包括缓存结构的设计和计算步骤的调度策略。这一优化旨在保证图像质量的同时显著提升推理速度。
categories:
- AI基础设施
tags:
- 模型优化
- 扩散模型
- 推理加速
- FLUX.1
- TaylorSeer
draft: false
translated_at: '2026-01-27T00:52:46.269836'
---

-   Replicate
-   Blog

# 我们如何优化 FLUX.1 Kontext [dev]

-   shridharathi
-   alexarmbr

FLUX.1 Kontext [dev]

![FLUX.1 Kontext optimization graphic](/images/posts/fa1303b443e4.webp)

除了将我们的 FLUX.1 Kontext [dev] 实现开源之外，我们还希望提供更多指导，说明我们如何在保证质量的前提下选择对其进行优化。

在这篇文章中，你将主要了解 TaylorSeer 优化方法，这是一种通过使用缓存的图像变化（导数）和基于泰勒级数近似推导出的公式来近似中间图像预测的方法。

优化爱好者们，请继续阅读。

（我们的大部分实现信息来自以下论文。）

如果你前往我们 FLUX.1 Kontext [dev] 仓库中 `predict.py` 的 `predict` 函数，你会找到主要的逻辑。（强烈建议先研究仓库代码，并将本文作为理解其结构的指南。）

让我们来分解一下。

## 关于 TaylorSeer

当使用 FLUX.1 Kontext 生成新图像时，你需要在多个时间步上应用扩散变换——连续大约 30 步。在每一步，一系列 Transformer 层会预测对正在去噪的图像的更新。这个过程可能需要一段时间。

在任何一个给定的时间步，模型预测的变化与之前时间步的预测存在冗余。我们可以通过在某些时间步缓存模型的输出，并在未来的时间步重用这些缓存输出来利用这些冗余。这种“朴素缓存”——即直接重用最后一个特征或潜在值——有时效果尚可，但可能导致图像模糊、细节丢失，有时甚至完全失真。

你可以尝试稍微聪明一点的方法：线性近似。你可以通过查看最后两步之间的差异（即一阶有限差分）并延长这条线来估计下一步。这更好一些，但仍然不够理想。它无法捕捉曲线、加速度或非线性变化——而这些在扩散模型中都很常见。

TaylorSeer 为此提供了一个解决方案。它使用**泰勒级数**，通过**一系列缓存的导数**来近似模型在某个时间步的输出，从而捕捉非线性变化。

以下是其核心思想的数学表述。为了预测特定层 `l` 在时间步 `t+k` 的特征，我们使用截断的泰勒展开：

![FLUX.1 Kontext optimization graphic](/images/posts/fd255b6b4c2c.webp)

注意求和需要特征函数的 i 阶导数。由于我们无法计算实际的导数，我们可以使用每个 i-1 阶和 i 阶导数之间的有限差分。请查阅论文了解确切的数学推导，但当你进行替换并稍作简化后，会得到以下公式：

![FLUX.1 Kontext optimization equation 2](/images/posts/a280376a9e1a.webp)

这就是我们在时间步 `t+k` 特征的最终近似值。

现在，我们有了一个通过使用上述估计来加速扩散过程的方法，用于特定时间步的特征计算。

我们设置了一个 TaylorSeer 缓存，以便在需要时执行此近似：

```
order = n_derivatives + 1
taylor_seer_state = {
    "dY_prev": [None] * order,
    "dY_current": [None] * order,
    "last_non_approximated_step": 0,
    "current_step": 0,
}
```

这里，`order = n_derivatives + 1`。例如，如果 `n_derivatives = 2`，那么 `order = 3`，我们缓存：

-   `dY_current[0]`：当前特征
-   `dY_current[1]`：一阶导数
-   `dY_current[2]`：二阶导数

`denoise()` 函数的前几步总是计算完整的预测，用于初始化有限差分。后续的步骤则可以进行近似。

## 逐步解析：TaylorSeer 如何在 Flux Kontext 中工作

准备好输入后，我们使用 `generate_compute_step_map()` 来决定哪些步骤需要计算，哪些可以近似：

```
def generate_compute_step_map(acceleration_level: str, num_inference_steps: int):
    
    if acceleration_level == "none":
        return [True] * num_inference_steps
    
    elif acceleration_level == "go fast":
        # compute first and last 4 steps and all steps in between alternating
        k = [False, True]
        compute_step_map = [k[i % 2] for i in range(num_inference_steps)]
        compute_step_map[:4] = [True] * 4
        compute_step_map[-4:] = [True] * 4
        return compute_step_map
    
    elif acceleration_level == "go really fast":
        # compute first + last 3 steps and all steps in between alternate between computing full once and approximating twice
        k = [False, True, False]
        compute_step_map = [k[i % 3] for i in range(num_inference_steps)]
        compute_step_map[:3] = [True] * 3
        compute_step_map[-3:] = [True] * 3
        return compute_step_map
    ....
```

`generate_compute_step_map()` 遵循一个简单的规则：总是计算开头和结尾的几步，因为模型在这些步骤中做出的改变最大。在中间步骤中，对于“go fast”模式，我们每隔一步计算一次；对于“go really fast”模式，则每隔两步计算一次。像“第一块缓存”这样的自适应方法（检查第一个 Transformer 块的输出变化有多大）可以智能地确定跳过哪些步骤，但这种硬编码的策略效果很好。

# 两条路径：计算或近似

在去噪循环中：

```
if compute_step_map[current_step]:
    pred = model(...)  # full prediction
    taylor_seer_state['dY_current'] = approximate_derivative(...)
else:
    pred = approximate_value(...)  # predicted using TaylorSeer
```

让我们分解每条路径。

### 路径 1：完整计算

我们正常运行模型并更新存储的有限差分（导数）：

```
dY_current[i+1] = (dY_current[i] - dY_prev[i]) / finite_difference_window
```

这是从低阶差分递归计算高阶有限差分的视图。第 `m+1` 阶导数来自第 `m` 阶导数值在经历的时间间隔内的差值。

这些差分近似地描述了特征值随时间的变化情况。

### 路径 2：使用泰勒级数近似

如果我们决定跳过某一步（基于 `compute_step_map`），我们使用缓存的差分来估计下一个特征更新（来自方程 2 的近似值）：

```
output += (1 / math.factorial(i)) * dY_current[i] * (elapsed_steps ** i)
```

与运行完整模型进行单步去噪所需的时间相比，计算此近似值所需的时间几乎是瞬时的。

### 更新潜在表示

在每一步，无论是计算还是近似，我们都将预测的增量应用到图像的潜在表示上：

```
img = img + (t_prev - t_curr) * pred
```

这使得图像变换能够随时间步演进。

去噪循环结束后，我们返回最终的图像！

## 总结

我们并非在每个时间步都评估模型，而是：

1.  缓存**过去的预测及其有限差分**。
2.  使用**泰勒级数**来近似模型在跳过步骤的输出。
3.  将模型调用次数从 30 次减少到大约 10-15 次（取决于速度设置）。
4.  保持质量，尤其是在生成的开头和结尾，那里的准确性最为重要。

TaylorSeer 为我们提供了一种原则性、灵活的方法，利用特征动态来预测图像生成中的中间步骤。它比运行每一步更快，也比线性外推更智能。

你可以在我们的 FLUX.1 Kontext 仓库的 `denoise()` 和 `taylor_utils.py` 中找到所有这些内容。

深入研究这个仓库，并告诉我们你的发现！

尝试 FLUX.1 Kontext [dev]

---

> 本文由AI自动翻译，原文链接：[How we optimized FLUX.1 Kontext [dev] – Replicate blog](https://replicate.com/blog/flux-kontext-optimization)
> 
> 翻译时间：2026-01-27 00:52
