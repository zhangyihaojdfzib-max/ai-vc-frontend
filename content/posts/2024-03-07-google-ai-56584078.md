---
title: 社会学习：大语言模型如何通过自然语言协作提升性能
title_original: 'Social learning: Collaborative learning with large language models'
date: '2024-03-07'
source: Google AI Blog
source_url: http://blog.research.google/2024/03/social-learning-collaborative-learning.html
author: null
summary: 本文探讨了大语言模型（LLM）通过社会学习框架进行协作学习的可能性。研究提出了一种基于自然语言的知识共享方法，使LLM智能体能够像人类一样通过口头指导或合成示例相互教学，同时保护数据隐私。实验表明，通过生成合成示例或指令，模型能在多数任务上达到与使用原始数据相当的性能，且通过调整的Secret
  Sharer方法量化了隐私泄露风险。该框架为LLM的协作学习提供了新方向，平衡了模型性能与隐私保护。
categories:
- AI研究
tags:
- 大语言模型
- 社会学习
- 协作学习
- 隐私保护
- 自然语言处理
draft: false
---

社会学习：与大语言模型的协作学习
2024年3月7日
Amirkeivan Mohtashami，研究实习生，与 Florian Hartmann，软件工程师，Google Research
快速链接

大语言模型（LLM）在解决使用自然语言指定的任务方面已显著提升了技术水平，其性能通常已接近人类水平。随着这些模型越来越多地赋能辅助性智能体（Agent），让它们能够像人类在社交环境中那样有效地相互学习，将是有益的，这将使得基于LLM的智能体能够相互提升性能。

为了讨论人类的学习过程，班杜拉和沃尔特斯在1977年提出了社会学习的概念，概述了人类使用的不同观察学习模式。一种常见的向他人学习的方法是通过口头指导（例如来自老师），描述如何进行特定行为。或者，学习也可以通过模仿行为的现场示例，即通过现场模型进行。

鉴于LLM在模仿人类交流方面取得的成功，在我们的论文《社会学习：迈向与大语言模型的协作学习》中，我们研究了LLM是否能够利用社会学习相互学习。为此，我们概述了一个社会学习框架，在该框架中，LLM使用自然语言以保护隐私的方式相互分享知识。我们在多个数据集上评估了该框架的有效性，并提出了在此情境下衡量隐私的量化方法。与之前协作学习的方法（例如通常依赖梯度的常见联邦学习方法）不同，在我们的框架中，智能体完全使用自然语言相互教学。

**面向LLM的社会学习**

为了将社会学习扩展到语言模型，我们考虑这样一种场景：一个学生LLM应该从多个已经掌握该任务的教师实体那里学习如何解决任务。在我们的论文中，我们评估了学生在各种任务上的表现，例如短文本消息（SMS）中的垃圾邮件检测、解决小学数学问题以及基于给定文本回答问题。

语言模型已展现出仅需少量示例即可执行任务的卓越能力——这一过程称为小样本学习。考虑到这一点，我们提供任务的人工标注示例，使教师模型能够将其传授给学生。社会学习的一个主要应用场景出现在这些示例由于隐私问题等原因无法直接与学生共享时。

为了说明这一点，让我们看一个垃圾邮件检测任务的假设示例。一个教师模型位于设备端，一些用户自愿将他们收到的消息标记为“垃圾邮件”或“非垃圾邮件”。这些是有用的数据，可以帮助训练学生模型区分垃圾邮件和非垃圾邮件，但与其他用户共享个人消息会侵犯隐私，应予以避免。为了防止这种情况，社会学习过程可以将知识从教师模型转移给学生，使其了解垃圾邮件的特征，而无需共享用户的个人文本消息。

我们通过与上述已确立的人类社会学习理论进行类比，来研究这种社会学习方法的有效性。在这些实验中，我们使用PaLM 2-S模型作为教师和学生。

**合成示例**

作为对传统社会学习中描述的现场教学模型的对应，我们提出一种学习方法，即教师为任务生成新的合成示例并与学生分享。这源于一种想法：可以创建一个与原始示例足够不同但同样具有教育意义的新示例。事实上，我们观察到生成的示例与真实示例足够不同，从而保护了隐私，同时仍能达到与使用原始示例相当的性能。

我们在任务套件上评估了通过合成示例进行学习的有效性。特别是当示例数量足够多时（例如 n = 16），我们观察到在大多数任务中，共享原始数据与通过社会学习使用合成数据进行教学之间没有统计学上的显著差异，这表明隐私的改善不必以模型质量为代价。

唯一的例外是垃圾邮件检测，使用合成数据进行教学会导致准确率较低。这可能是因为当前模型的训练过程使其倾向于只生成非垃圾邮件的示例。在论文中，我们还研究了用于选择优质示例子集的聚合方法。

**合成指令**

鉴于语言模型在遵循指令方面的成功，口头指令模型也可以自然地适用于语言模型，即让教师为任务生成一条指令。我们的实验表明，提供这样生成的指令能有效提升零样本提示的性能，达到与小样本提示使用原始示例相当的准确率。然而，我们确实发现教师模型在某些任务上可能无法提供好的指令，例如由于输出格式要求复杂。

对于Lambada、GSM8k和随机插入任务，提供合成示例比提供生成的指令效果更好，而在其他任务中，生成的指令获得了更高的准确率。这一观察表明，教学方法的选择取决于手头的任务，类似于最有效的教学方法因人因任务而异。

**对私有示例的记忆**

我们希望社会学习中的教师在不泄露原始数据具体信息的情况下教导学生。为了量化这个过程泄露信息的倾向性，我们使用了Secret Sharer——一种用于量化模型对其训练数据记忆程度的流行方法，并将其调整适用于社会学习场景。我们选择此方法是因为它之前曾被用于评估联邦学习中的记忆问题。

为了将Secret Sharer方法应用于社会学习，我们设计了“金丝雀”数据点，以便具体衡量训练过程对它们的记忆程度。这些数据点被包含在教师用于生成新示例的数据集中。社会学习过程完成后，我们可以测量学生对于教师使用过的秘密数据点的置信度，相比于那些甚至未与教师共享的类似数据点，增加了多少。

在我们论文详细讨论的分析中，我们使用了包含姓名和代码的金丝雀示例。我们的结果表明，学生仅对教师使用过的金丝雀示例表现出略微更高的置信度。相比之下，当原始数据点直接与学生共享时，对包含的金丝雀示例的置信度远高于对保留集的置信度。这支持了以下结论：教师确实是在利用其数据进行教学，而不是简单地复制数据。

**结论与后续步骤**

我们引入了一个社会学习框架，允许能够访问私有数据的语言模型通过文本交流传递知识，同时保持数据的隐私性。在此框架中，我们确定了分享示例和分享指令作为基本模式，并在多个任务上对其进行了评估。此外，我们将Secret Sharer指标调整适用于我们的框架，提出了一个衡量数据泄露的指标。

作为后续步骤，我们正在寻找改进教学过程的方法，例如通过增加反馈循环和迭代。

此外，我们希望探索将社会学习应用于文本以外的其他模态。

致谢  
我们要感谢论文的共同作者Matt Sharifi、Sian Gooding、Lukas Zilka和Blaise Aguera y Arcas。同时，我们也要感谢Victor Cărbune、Zachary Garrett、Tautvydas Misiunas、Sofia Neata和John Platt提供的宝贵反馈，这些意见极大地完善了本文。此外，我们还要感谢Tom Small制作了动画图示。

---

> 本文由AI自动翻译，原文链接：[Social learning: Collaborative learning with large language models](http://blog.research.google/2024/03/social-learning-collaborative-learning.html)
> 
> 翻译时间：2026-01-05 17:14
