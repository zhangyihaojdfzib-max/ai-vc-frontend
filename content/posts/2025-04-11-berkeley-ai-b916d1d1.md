---
title: 利用结构化查询与偏好优化防御提示词注入攻击
title_original: Defending against Prompt Injection with Structured Queries (StruQ)
  and Preference Optimization (SecAlign)
date: '2025-04-11'
source: Berkeley AI Research (BAIR)
source_url: http://bair.berkeley.edu/blog/2025/04/11/prompt-injection-defense/
author: Ritwik Gupta
summary: 本文针对大语言模型集成应用面临的头号威胁——提示词注入攻击，提出了两种无需额外成本的微调防御方法：结构化指令微调（StruQ）和特殊偏好优化（SecAlign）。StruQ通过模拟注入攻击训练模型忽略数据中的恶意指令，SecAlign则通过偏好优化强化模型对预期指令的遵循。实验表明，两种方法能将多种攻击的成功率降至接近0%，其中SecAlign在面对复杂优化攻击时仍保持低于15%的成功率，且基本不影响模型通用能力。文章还介绍了部署安全LLM的五个步骤。
categories:
- AI研究
tags:
- 提示词注入
- 大语言模型安全
- 对抗性防御
- 模型微调
- 结构化查询
draft: false
translated_at: '2026-01-05T16:35:07.384Z'
---

> 本文由AI自动翻译，原文链接：[Defending against Prompt Injection with Structured Queries (StruQ) and Preference Optimization (SecAlign)](http://bair.berkeley.edu/blog/2025/04/11/prompt-injection-defense/)
> 
> 翻译时间：2026-01-05 13:16
