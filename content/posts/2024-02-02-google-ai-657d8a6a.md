---
title: 早期读出干预：缓解虚假特征与简单性偏差
title_original: Intervening on early readouts for mitigating spurious features and
  simplicity bi
date: '2024-02-02'
source: Google AI Blog
source_url: http://blog.research.google/2024/02/intervening-on-early-readouts-for.html
author: null
summary: 本文探讨了深度学习中模型因数据偏差而依赖虚假特征的问题，并提出了基于早期读出的解决方案。研究通过两种方法应对挑战：一是利用早期读出的错误置信度作为指标，改进模型蒸馏过程，提升学生模型对虚假特征的鲁棒性；二是引入特征筛技术，通过交替识别和擦除网络早期层中的简单偏差特征，迫使模型学习更复杂、更具预测性的特征，从而显著提升模型在未知领域的泛化能力。实验在多个标准基准数据集上验证了方法的有效性。
categories:
- AI研究
tags:
- 深度学习
- 模型偏差
- 特征学习
- 模型泛化
- 负责任AI
draft: false
translated_at: '2026-01-06T14:49:02.033Z'
---

通过早期读出干预来缓解虚假特征与简单性偏差
2024年2月2日
作者：Google Research 预博士研究员 Rishabh Tiwari 与研究科学家 Pradeep Shenoy
快速链接

现实世界中的机器学习模型通常在有限数据上训练，这些数据可能包含非预期的统计偏差。例如，在CELEBA名人图像数据集中，女性名人中金发比例过高，导致分类器在预测大多数女性面孔的发色时错误地输出“金发”——在此例中，性别成为预测发色的虚假特征。此类不公平偏差可能在医疗诊断等关键应用中产生重大影响。

令人惊讶的是，近期研究还发现深度网络存在放大此类统计偏差的内在倾向，即所谓的深度学习简单性偏差。这种偏差表现为深度网络倾向于在训练早期识别弱预测性特征，并持续依赖这些特征，而未能识别更复杂且可能更准确的特征。

基于上述认知，我们通过应用早期读出和特征遗忘技术，针对虚假特征与简单性偏差的双重挑战提出了简单有效的解决方案。首先，在《使用早期读出来调节蒸馏中的特征偏差》中，我们证明从深度网络早期层进行预测（称为“早期读出”）能够自动提示所学表征的质量问题。具体而言，当网络依赖虚假特征时，这些预测更容易出错，且错误置信度更高。我们利用这种错误置信度来改进模型蒸馏的效果——在这种场景中，较大的“教师”模型指导较小“学生”模型的训练。随后在《使用特征筛克服深度网络中的简单性偏差》中，我们通过让网络“遗忘”问题特征并促使它寻找更优、更具预测性的特征，直接对这些指示信号进行干预。与先前方法相比，这显著提升了模型在未知领域中的泛化能力。我们的AI原则与负责任AI实践指导着这些高级应用的研究开发，并帮助我们应对统计偏差带来的挑战。

| 对比使用特征筛与未使用特征筛训练的两种模型假设性响应的动画 |
用于去偏差蒸馏的早期读出

我们首先阐述早期读出的诊断价值及其在去偏差蒸馏中的应用，即确保学生模型通过蒸馏继承教师模型对特征偏差的鲁棒性。我们从标准蒸馏框架出发，该框架中学生模型的训练结合了标签匹配（最小化学生输出与真实标签的交叉熵损失）和教师匹配（最小化学生与教师输出在给定输入下的KL散度损失）。

假设在学生模型的中间表征之上训练一个线性解码器（即名为Aux的小型辅助神经网络）。我们将该线性解码器的输出称为网络表征的早期读出。我们的发现是：早期读出在包含虚假特征的实例上会产生更多错误，且这些错误的置信度高于其他错误的置信度。这表明早期读出错误的置信度是模型依赖潜在虚假特征的一个相当可靠的自动化指标。

我们利用该信号在逐实例基础上调节教师模型对蒸馏损失的贡献，从而显著提升了训练后学生模型的性能。

我们在已知包含虚假相关性的标准基准数据集（Waterbirds、CelebA、CivilComments、MNLI）上评估了我们的方法。这些数据集均包含共享可能以虚假方式与标签相关的属性的数据分组。例如，上述CelebA数据集包含{金发男性、金发女性、非金发男性、非金发女性}等分组，在预测发色时模型通常在{非金发女性}组上表现最差。因此，模型性能的一个衡量指标是其最差组准确率，即数据集中所有已知分组中的最低准确率。我们在所有数据集上都提升了学生模型的最差组准确率；此外，在四个数据集中的三个上我们还提升了整体准确率，这表明我们对任一组的改进并未以牺牲其他组准确率为代价。更多细节详见我们的论文。

| 不同蒸馏技术的最差组准确率与教师模型对比。我们的方法在所有数据集上均优于其他方法。 |
使用特征筛克服简单性偏差

在第二个密切相关的项目中，我们直接对早期读出的信息进行干预，以改进特征学习与泛化能力。工作流程在识别问题特征和从网络中擦除已识别特征之间交替进行。我们的核心假设是：早期特征更容易产生简单性偏差，通过擦除（“筛选”）这些特征，我们可以促使学习更丰富的特征表征。

| 使用特征筛的训练工作流程。我们在识别问题特征（训练迭代）和从网络中擦除它们（遗忘迭代）之间交替进行。 |
我们更详细地描述识别与擦除步骤：

- 识别简单特征：我们通过前向传播和反向传播以常规方式训练主模型和读出模型（即上述AUX）。需注意辅助层的反馈不会反向传播至主网络，这是为了强制辅助层从已有特征中学习，而非在主网络中创建或强化特征。

- 应用特征筛：我们旨在通过使用新颖的遗忘损失Lf来擦除神经网络早期层中已识别的特征，该损失即为读出与标签均匀分布之间的交叉熵。本质上，所有导致非平凡读出的信息都将从主网络中擦除。在此步骤中，辅助网络和主网络的上层保持不变。

我们可以通过少量配置参数具体控制特征筛如何应用于给定数据集。通过改变辅助网络的位置和复杂度，我们控制被识别和擦除特征的复杂度。通过调整学习步骤与遗忘步骤的混合比例，我们控制模型学习更复杂特征的挑战程度。这些依赖数据集的选择通过超参数搜索来确定，以最大化验证准确率（泛化的标准度量）。由于我们在搜索空间中包含“无遗忘”（即基线模型），我们期望找到至少与基线效果相当的设置。

下方展示了基线模型（中行）与我们的模型（底行）在两个基准数据集——偏差活动识别（BAR）和动物分类（NICO）上学到的特征。特征重要性使用基于梯度的后验重要性评分（GRAD-CAM）进行估计，光谱中的橙红色端表示高重要性，青蓝色表示低重要性。

如下图所示，我们训练后的模型专注于主要目标对象，而基线模型则倾向于关注那些更简单且与标签存在虚假关联的背景特征。

通过学习这种更优、可泛化特征的能力，我们在现实世界虚假特征基准数据集（BAR、CelebA Hair、NICO和ImagenetA）上相较于一系列相关基线取得了显著提升，幅度最高达11%（见下图）。更多细节请参阅我们的论文。
| 我们的特征筛选方法在一系列特征泛化基准数据集上，相较于最接近的基线显著提升了准确率。 |
结论
我们希望关于早期读出及其在特征筛选中用于泛化的研究工作，既能推动新一类对抗性特征学习方法的发展，也能帮助提升深度学习系统的泛化能力和鲁棒性。

致谢
将早期读出应用于去偏蒸馏的研究工作是与我们的学术合作伙伴——印度孟买理工学院的Durga Sivasubramanian、Anmol Reddy以及Ganesh Ramakrishnan教授合作完成的。我们衷心感谢Praneeth Netrapalli和Anshul Nasery的反馈与建议。同时感谢Nishant Jain、Shreyas Havaldar、Rachit Bansal、Kartikeya Badola、Amandeep Kaur以及谷歌研究院印度站全体预博士研究员参与研究讨论。特别感谢Tom Small为本文制作了动画。

---

> 本文由AI自动翻译，原文链接：[Intervening on early readouts for mitigating spurious features and simplicity bi](http://blog.research.google/2024/02/intervening-on-early-readouts-for.html)
> 
> 翻译时间：2026-01-06 04:29
