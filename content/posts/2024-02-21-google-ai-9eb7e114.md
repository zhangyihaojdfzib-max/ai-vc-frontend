---
title: 设备端语言模型私有训练进展：Gboard实现强差分隐私保证
title_original: Advances in private training for production on-device language models
date: '2024-02-21'
source: Google AI Blog
source_url: http://blog.research.google/2024/02/advances-in-private-training-for.html
author: null
summary: 本文介绍了Google在Gboard设备端语言模型私有训练方面的研究进展。通过结合联邦学习和差分隐私技术，所有下一词预测神经网络模型均实现了正式的差分隐私保证，其中部分模型达到了ε<1的强隐私保证。文章概述了隐私保护原则、技术发展历程以及在生产环境中大规模部署差分隐私的实践，标志着在直接利用用户数据训练模型的同时，实现了可量化的强隐私保护。
categories:
- AI产品
tags:
- 差分隐私
- 联邦学习
- 设备端AI
- 语言模型
- 隐私保护
draft: false
---

**面向生产级设备端语言模型的私有训练进展**
2024年2月21日
发布者：Google 研究科学家 Zheng Xu，软件工程师 Yanxiang Zhang
快速链接

经过训练、能够根据输入文本预测下一个词的语言模型，是许多应用的关键技术[1, 2]。在 Gboard 中，LM 通过支持下一词预测、智能撰写、智能补全与建议、滑动输入和校对等功能，来改善用户的输入体验。将模型部署在用户设备而非企业服务器上，具有延迟更低、模型使用隐私性更好等优势。虽然直接利用用户数据训练设备端模型能有效提升 NWP 和智能文本选择等应用的性能表现，但在模型训练中保护用户数据的隐私至关重要。

| 由设备端语言模型驱动的 Gboard 功能。 |

在这篇博客中，我们将讨论自 2017 年联邦学习的概念验证开发以及 2022 年正式差分隐私保证以来，多年的研究进展如何为 Gboard LM 的私有训练提供动力。FL 使手机能够在所有训练数据保留在设备上的情况下协作学习一个模型，而 DP 则提供了一种可量化的数据匿名化度量。形式上，DP 通常由 (ε, δ) 来表征，数值越小代表保证越强。当 δ 值较小时，机器学习模型在 ε=10 时被认为具有合理的 DP 保证，在 ε=1 时则被认为具有强 DP 保证。

截至目前，Gboard 中所有 NWP 神经网络 LM 均通过 FL 进行训练并具有正式的 DP 保证，并且未来所有基于用户数据训练的 Gboard LM 发布都要求具备 DP 保证。这 30 多个 Gboard 设备端 LM 已支持 7 种以上语言和 15 个以上国家/地区，并满足 δ 值小至 10^-10、ε 值在 0.994 到 13.69 之间的 (ε, δ)-DP 保证。据我们所知，这是 Google 乃至全球已知在生产环境中最大规模的用户级 DP 部署，也是首次宣布对直接在用户数据上训练的模型实现了 ε < 1 的强 DP 保证。

**Gboard 中的隐私原则与实践**

在《Gboard 中的私有联邦学习》一文中，我们讨论了不同的隐私原则目前如何在生产模型中体现，包括：

*   **透明度和用户控制**：我们披露了使用哪些数据、用于何种目的、在各种渠道中如何处理，以及 Gboard 用户如何轻松配置学习模型中的数据使用。
*   **数据最小化**：FL 会立即聚合仅用于改进特定模型的、有针对性的更新。安全聚合是一种加密方法，可进一步确保只能访问临时更新的聚合结果。
*   **数据匿名化**：服务器应用 DP 以防止模型记忆单个用户训练数据中的独特信息。
*   **可审计性与可验证性**：我们已在开源代码中公开了关键的算法方法和隐私核算。

**发展简史**

近年来，FL 已成为利用用户数据训练 Gboard 设备端 LM 的默认方法。2020 年，一种通过裁剪模型更新并添加噪声的 DP 机制被用于防止训练西班牙西班牙语 LM 时的记忆问题，该模型满足有限的 DP 保证。2022 年，借助 DP-FTRL 算法，西班牙西班牙语 LM 成为首个直接在用户数据上训练、并宣布具有正式 (ε=8.9, δ=10^-10)-DP 保证的生产神经网络模型，因此满足了合理的隐私保证。

**联邦学习中的默认差分隐私**

在《具有差分隐私的 Gboard 语言模型联邦学习》一文中，我们宣布 Gboard 中所有 NWP 神经网络 LM 都具有 DP 保证，并且未来所有基于用户数据训练的 Gboard LM 发布都要求具备 DP 保证。在 FL 中启用 DP 需遵循以下实践：

*   使用多语言 C4 数据集对模型进行预训练。
*   通过在公共数据集上的模拟实验，找到一个允许高实用性的较大 DP 噪声信号比。增加参与单轮模型更新的客户端数量可以在保持噪声比不变以获得良好实用性的同时提升隐私性，直至达到 DP 目标或系统及用户群体规模允许的最大值。
*   根据 FL 系统中的计算预算和估计用户群体规模，配置参数以限制每个客户端的贡献频率。
*   运行 DP-FTRL 训练，通过自适应裁剪或基于经验固定值来限制每台设备的更新幅度。

此外，还可以应用在提升计算和通信效率以适应规模和敏感度方面的进展来启用 SecAgg。

| 具有差分隐私和（安全聚合）的联邦学习。 |

**报告 DP 保证**

已发布的 Gboard NWP LM 的 DP 保证在下方的条形图中可视化。x 轴显示了按语言-地区标记并在相应用户群体上训练的 LM；y 轴显示了当 δ 固定为小值 10^-10 时 (ε, δ)-DP 的 ε 值。根据 A/B 测试期间的用户交互指标衡量，这些模型的实用性要么显著优于之前生产中的非神经网络模型，要么与之前没有 DP 的 LM 相当。例如，通过应用最佳实践，西班牙西班牙语模型的 DP 保证从 ε=8.9 提升至 ε=5.37。SecAgg 还额外用于训练西班牙西班牙语模型和美国英语模型。更多关于 DP 保证的细节遵循《如何为 ML 添加 DP》指南中概述的原则在附录中报告。

**迈向更强的 DP 保证**

许多已发布 LM 的 ε~10 DP 保证在实践中已被认为对 ML 模型是合理的，而 Gboard 中 DP FL 的旅程仍在继续，旨在改善用户输入体验的同时保护数据隐私。我们很高兴地宣布，巴西葡萄牙语和拉丁美洲西班牙语的生产 LM 首次以 ε ≤ 1 的 DP 保证进行训练和发布，这满足了第一级的强隐私保证。具体来说，(ε=0.994, δ=10^-10)-DP 保证是通过运行先进的矩阵分解 DP-FTRL 算法实现的，每轮服务器模型更新有超过 12,000 台设备参与，高于常见的 6,500+ 台设备的设置，并且通过精心配置的策略，在巴西庞大的葡萄牙语用户群体中，限制每个客户端在 14 天内的总共 2000 轮训练中最多参与两次。使用类似设置，es-US 西班牙语 LM 在拉丁美洲多个国家合并的大规模用户群体中训练，以达到 (ε=0.994, δ=10^-10)-DP。ε ≤ 1 的 es-US 模型显著提升了多个国家的实用性，并在哥伦比亚、厄瓜多尔、危地马拉、墨西哥和委内瑞拉发布。对于西班牙较小的用户群体，仅将 DP-FTRL 替换为 MF-DP-FTRL 而无需增加每轮参与设备数量，es-ES LM 的 DP 保证就从 ε=5.37 提升至 ε=3.42。更多技术细节在隐私核算的 colab 中披露。

| Gboard NWP LM 的 DP 保证（紫色条代表首次发布的 ε=8.9 的 es-ES 模型；青色条代表使用 MF-DP-FTRL 训练的模型的隐私改进；级别来自《如何为 ML 添加 DP》指南；en-US* 和 es-ES* 额外使用了 SecAgg 训练）。

讨论与后续步骤
我们的经验表明，差分隐私（DP）在实践中可以通过客户端参与的系统算法协同设计来实现，当用户规模庞大且聚合大量设备贡献时，隐私性和实用性均可达到较高水平。通过利用公共数据、新型MF-DP-FTRL算法以及更精确的隐私核算，可以改善隐私-效用-计算之间的权衡关系。借助这些技术，实现ε ≤ 1的强差分隐私保障是可能的，但仍具挑战性。实证隐私审计[1, 2]的前沿研究表明，差分隐私模型的实际隐私保护效果可能优于最坏情况下的理论保障。在持续推动算法创新的同时，我们应优先关注隐私-效用-计算这三个维度中的哪一个？

我们正积极致力于机器学习所有隐私相关领域的研究，包括将DP-FTRL扩展至分布式差分隐私、提升可审计性与可验证性。可信执行环境为在可验证隐私前提下大幅扩展模型规模提供了新机遇。近期大语言模型（LLM）领域的突破促使我们重新思考：如何在隐私训练中更有效地利用公开信息，以及未来LLM、设备端语言模型与Gboard生产系统之间将产生哪些更深层次的交互。

致谢
作者感谢Peter Kairouz、Brendan McMahan和Daniel Ramage对博文初稿的宝贵意见，感谢Shaofeng Li和Tom Small协助制作动态图表，同时感谢谷歌各部门团队在算法设计、基础设施实现和生产维护方面提供的支持。以下合作者对本研究成果作出了直接贡献：

研究与算法开发：Galen Andrew, Stanislav Chiknavaryan, Christopher A. Choquette-Choo, Arun Ganesh, Peter Kairouz, Ryan McKenna, H. Brendan McMahan, Jesse Rosenstock, Timon Van Overveldt, Keith Rush, Shuang Song, Thomas Steinke, Abhradeep Guha Thakurta, Om Thakkar, Yuanbo Zhang。

基础设施、生产与领导支持：Mingqing Chen, Stefan Dierauf, Billy Dou, Hubert Eichner, Zachary Garrett, Jeremy Gillula, Jianpeng Hou, Hui Li, Xu Liu, Wenzhi Mao, Brett McLarnon, Mengchen Pei, Daniel Ramage, Swaroop Ramaswamy, Haicheng Sun, Andreas Terzis, Yun Wang, Shanshan Wu, Yu Xiao, Shumin Zhai。

---

> 本文由AI自动翻译，原文链接：[Advances in private training for production on-device language models](http://blog.research.google/2024/02/advances-in-private-training-for.html)
> 
> 翻译时间：2026-01-06 02:08
