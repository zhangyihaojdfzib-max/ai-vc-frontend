---
title: 实现AGI需要超越大语言模型的新思路
title_original: The New Ideas Needed for AGI
date: '2025-04-28'
source: 红杉资本 (Sequoia)
source_url: https://sequoiacap.com/article/new-ideas-for-agi/
author: ''
summary: 文章指出，当前大语言模型（LLM）虽取得显著进展，但其依赖规模化数据和缺乏确定性推理能力的弱点，阻碍了通用人工智能（AGI）的实现。作者以ARC-AGI基准测试为例，说明该测试旨在评估系统从少量数据中高效学习新任务的能力，而这正是LLM的短板。真正的AGI可能需要结合非语言层面的思维表征、新的学习算法以及自动化的架构搜索，而非仅仅依赖Transformer模型的扩展。
categories:
- AI研究
tags:
- AGI
- 大语言模型
- 基准测试
- 推理能力
- Transformer
draft: false
translated_at: '2026-02-07T04:03:15.740783'
---

# 实现AGI所需的新思路

大语言模型（LLM）的优势恰恰也是其弱点。真正的通用智能可能需要一种语言无法提供的、确定性的思维与推理能力。

"规模并非万能，我们需要新思路。" 不仅仅是新思路，还需要新的基准测试。这是**ARC Prize**和Zapier联合创始人Mike Knoop在接受我们最新一期**Training Data**播客采访时提出的简明反主流观点。ARC Prize基于Knoop的联合创始人**François Chollet**早在2019年创建的一个基准测试，该测试至今仍顽固地抵抗着被破解的命运。

当前人工智能的发展态势，完全体现了Transformer架构和大语言模型规模化带来的惊人成效，导致一个又一个"人类水平"的基准测试被接连攻克。那么ARC-AGI有何不同？为何现有方法对其无效？究竟需要哪些新思路？

首先，正如Chollet所言，ARC-AGI基准测试的难度是许多其他AI基准测试所不具备的。它的设计初衷就是抵抗"记忆"，无论投入多少数据和算力。它对人类来说很容易，但对AI却很难。事实上，解决它意味着系统能够从极少量的数据中学习一项新任务——这与当前AI的能力恰恰相反。

## 问题的核心谜题

AI应用领域的创业者可以看到客户正在何处部署基于LLM的解决方案——更重要的是，他们**没有**在何处部署。客户服务成为最主要的对外应用场景并不令人意外。这是一项劳动密集型工作，以往的自动化效果很差，净推荐值（NPS）得分也 notoriously 低。虽然已经有人工介入，但有了LLM，人工参与仅限于升级处理的案例。

还有许多内部用例，即使有时会失败，也能为员工节省大量时间。但AI产品更广泛采用的最大瓶颈，在于LLM不受约束的特性所导致的信任缺失。像Knoop的Zapier这样的工作流自动化软件，其功能是经过形式化验证、名副其实的。相比之下，除非被一个健壮的认知架构所约束，否则LLM可能会（不可预测地）产生"超说明书"的虚构内容。

Knoop非常推崇Rich Sutton那篇具有先见之明的文章**《苦涩的教训》**（我们播客采访过的每个人也都如此）。他指出，尽管Sutton关于规模化学习和搜索有效性的观点在今天比五年前更加正确，但AI中尚未从规模化中受益的一个方面正是**架构搜索本身**。事实上，迄今为止针对ARC-AGI基准测试最有效的解决方案，都是以自动化和动态的方式探索架构空间，而不是像大多数研究人员仍在做的那样手工构建静态架构。

Chollet将AGI定义为**获取新技能的效率**。ARC-AGI基准测试本身是一套包含400个矩阵谜题的集合，这些谜题清晰地描述了人类能够基于一套核心的先验知识（如对称性和旋转）直观匹配的模式，而机器则难以精确可靠地学习这些知识。Chollet设计这些任务时设定，如果在整个测试集上达到人类水平分数，就意味着系统能够在这个高度可变但内部一致的谜题空间中高效地学习一项新任务。

![](/images/posts/28f1957ac295.png)

这暗示（并且**当代神经科学正在证明**），思维和推理中存在**非语言层面**，需要用语言之外的东西来表征。世界上所有的词语都不足以提供足够的训练数据来真正学习这些先验知识。解决ARC似乎需要以不同于GPT-4o或Claude Sonnet的方式学习不同的Token。

## 改造Transformer

Knoop还观察到，Transformer架构在形式上能够以100%的准确率表示非常深的演绎推理链，但缺失的是**恰当的学习算法**。过去几年LLM取得的巨大进步——以及可用算力的爆炸式增长——可能对实现AGI来说是必要的，但还不够充分。

基准测试在AI领域历史悠久，可以追溯到图灵测试，它花了50年才被"击败"，却未能证明任何关于智能本质的东西。ARC-AGI基准测试与此前一项名为"威诺格拉德模式"的智能挑战形成了鲜明对比。该模式以斯坦福大学教授**Terry Winograd**（顺便提一下，他教过谷歌创始人谢尔盖·布林和拉里·佩奇）提出的一对歧义句命名，由Hector Levesque于2012年提出，作为图灵测试的替代方案。尽管Winograd在1972年声称，计算机若没有对现实世界语境的"理解"，就不可能正确消除此类句子的歧义，但到了2019年，BERT语言模型已经足够强大，声称达到了90%的准确率，该基准测试遂被认为已解决。

相比之下，ARC的构建是为了模拟**确定性的必然**。每个谜题都可以被解决，并且只有一种解决方法。学习这样一组谜题，就是学习一种不变性的感觉，就像1+1=2，或者一个音符是音高完美的C。这种精确性正是LLM生成的智能所缺失的。

Knoop将LLM描述为"**本质上在进行非常高维度的记忆**"。其能力来自于对生成的模型进行推理，以产生具有真实性表象的高维输出。你可以把LLM想象成织布机，你可以在上面按需编织数字媒体。

可能赢得ARC的模型，将生成比这些语言织布机更坚实、更精确的产物——或许是锻造厂？AGI需要的是一个足够灵活以学习新事物，但又足够确定以使其所学可靠无误的框架。

## 欢迎局外人

我们希望AI学习的东西——我们期望AGI成为的样子——显然远远超出了ARC测试集中包含的二维谜题。很容易将这个基准测试视为另一个没有实际应用价值的玩具问题而加以否定。但一个获胜系统所实现的学习方式，很可能是一种全新的东西，超越了当前所有前沿实验室都在追求的数据和算力规模化。这样的AGI可能也会更安全，推出速度更慢，与其说是奇点，不如说是人类阶梯式技术进步的延续。

ARC Prize的一个重要部分是推动ARC-AGI基准测试解决方案的**开源**。通过引起人们对这个问题的关注，并为超过85%准确率的解决方案提供超过100万美元的奖金，Knoop和Chollet希望重塑研究领域，使其回归到那种曾带来当前突破的开放合作模式。

大型实验室显然也在探索新思路，但或许更像是支线任务而非主线任务。从我们与创业者的交流经验来看，正如Factory的Matan Grinberg所说，"比这个领域的所有其他人都更加痴迷"的**单一专注**，才是带来突破的关键。

Knoop和Chollet在推动一个停滞不前的基准测试上取得进展的追求，与Patrick Collison呼吁通过发展**更敏捷、跨学科的机构**来**提高科学进步速度**的倡议遥相呼应。当我们问Knoop他认为谁会为ARC Prize提供获胜方案时，他说："我认为它会来自一个**局外人**，一个思维方式略有不同、拥有不同人生经历的人，或者是一个能够跨领域交叉融合几个真正重要想法的人。"

## 相关主题

![](/images/posts/bb568bac9183.png)

## Zapier的Mike Knoop谈ARC Prize与AGI

![](/images/posts/3e104ca69f1a.jpg)

## LangChain的Harrison Chase谈AI智能体

![](/images/posts/c0e9d0b00425.jpg)

## "恰到好处"的智能体与认知架构

# 获取红杉社区的最佳故事。

---

> 本文由AI自动翻译，原文链接：[The New Ideas Needed for AGI](https://sequoiacap.com/article/new-ideas-for-agi/)
> 
> 翻译时间：2026-02-07 04:03
