---
title: 筑造未来：2024红杉开源学者与vLLM、Chatbot Arena的诞生
title_original: 'Building the Future: Meet the 2024 Sequoia Open Source Fellows'
date: '2024-11-11'
source: 红杉资本 (Sequoia)
source_url: https://sequoiacap.com/article/building-the-future-meet-the-2024-sequoia-open-source-fellows/
author: ''
summary: 本文介绍了2024年红杉开源学者项目中的两个杰出开源项目——vLLM和Chatbot Arena的诞生故事。vLLM由加州大学伯克利分校Sky Computing
  Lab的研究员李卓翰、权宇硕等开发，通过创新的PagedAttention算法解决了大语言模型服务中的内存管理瓶颈。Chatbot Arena则由同一实验室的郑联民、蒋伟林等创建，通过众包偏好数据建立了评估大语言模型的事实标准。两个项目的成功都强调了强大开源社区的关键作用。
categories:
- AI研究
tags:
- 开源项目
- 大语言模型
- 模型评估
- 加州大学伯克利分校
- 红杉资本
draft: false
translated_at: '2026-02-13T04:15:04.048348'
---

# 筑造未来：认识2024年红杉开源学者

来自同一个享誉盛名的加州大学伯克利分校实验室，诞生了两个突破性项目：vLLM与Chatbot Arena。

2022年夏天，加州大学伯克利分校新成立的Sky Computing Lab的一群博士研究员遇到了一个难题。他们一直致力于通过跨GPU分配工作来提高大型深度学习模型的效率。但当他们搭建新框架的演示时，性能问题立刻凸显，且十分严重。

"速度慢得离谱，"项目团队成员、曾隶属于诞生了Databricks和Anyscale的著名实验室RISElab（Sky Lab的前身）的李卓翰回忆道。"我们意识到内存管理将成为服务这些模型的一个巨大瓶颈——我们想更深入地研究这个问题。"

于是在接下来的几个月里，李卓翰和研究员权宇硕深入钻研，最终受经典虚拟内存和分页技术启发，开发出一种前景广阔的算法，他们称之为"PagedAttention"。紧接着在11月30日，OpenAI发布了ChatGPT。业界对大语言模型以及他们项目的兴趣瞬间爆炸式增长。

突然间，科技公司和研究机构如潮水般推出新模型，每个模型都需要在日益稀缺的GPU上运行——而李卓翰和权宇硕的想法可能正是解决这一难题的钥匙。最终，他们与实验室同事、前Anyscale工程师Simon Mo合作，为他们现已命名为`vLLM`的开源项目举办了首次见面会。

![vLLM贡献者权宇硕、李卓翰和Simon Mo。](/images/posts/03d1b2125077.jpg)

"我对此越来越兴奋，但那次见面会后，我更加兴奋了，"Mo说。"每个人都有那么多问题，那么高的热情。"这早期印证了Sky Lab负责人、Databricks联合创始人Ion Stoica长期以来向他的学生们强调的一个原则：社区是关键。

"一个开源项目不仅仅是代码，"Stoica说。"在我参与的每一个项目中，建立一个强大的社区对成功都至关重要。"

vLLM的早期采用者中包括一个名为Vicuna的新模型，它来自Sky Lab内的另一组研究人员——包括郑联民、盛颖、张浩和蒋伟林，由Stoica和Joseph Gonzalez指导。蒋伟林此前曾与权宇硕在SkyPilot（一个在云端运行大语言模型、AI和批处理作业的框架）上合作过。但自从ChatGPT发布后，他也将重心转移，对构建开源大语言模型的可能性着迷。

成果Vicuna于2023年3月发布。它基于Meta的LLaMA，但有一个创新之处：研究人员部分使用了来自ShareGPT（一个用于分享ChatGPT对话的Chrome插件）的数据对其进行训练，这使其在聊天机器人应用中特别有用。

"这起初只是一个有趣的项目，看到它效果这么好，我们很惊讶，"蒋伟林说。"我们想与所有人分享。"团队很快购买了一个域名lmsys.org，在那里他们可以发布博客文章并运行他们新聊天机器人的演示。两周内，他们就有了数百万访客——但伴随着兴奋而来的还有批评。

"人们质疑我们的模型是否真的更好，作为研究人员，我们想要一种科学的方式来让他们信服，"蒋伟林回忆道。"你究竟如何评估模型之间的优劣？"

在那个新大语言模型几乎每周甚至每天都会发布的时候，这不仅对Vicuna，而且对任何构建模型或在模型之上构建的人来说，都是一个关键问题。为了帮助回答这个问题，郑联民、盛颖、蒋伟林和他们的队友又找来了一位伯克利研究员：理论统计学家Anastasios Angelopoulos。"基础问题吸引了我，而且这显然非常重要——影响力就在那里，"Angelopoulos回忆道。当团队探索基准测试和评估平台可能是什么样子时，他致力于增加统计严谨性。五月，他们启动了新项目`Chatbot Arena`，用户可以在那里将Vicuna与其他开源模型进行比较——同样在五月，他们推出了实时排行榜，排名依据来自真实用户使用模型时产生的众包偏好数据。

![Angelopoulos、蒋伟林、Stoica和Chatbot Arena团队。](/images/posts/93ad8ae32f3e.jpg)

如今，Chatbot Arena已成为评估模型性能的事实标准，每月用户超过一百万——每当有新模型发布时，包括Sam Altman、Jeff Dean等在内的行业领袖都会提及他们在Chatbot Arena上的评估结果。几乎所有主要模型提供商——包括OpenAI、Google、Meta和xAI——都会在模型发布前定期与Chatbot Arena团队分享模型的变体，以便这些数据能为他们的开发过程提供参考。

与构建vLLM的同事们一样，蒋伟林和Angelopoulos将项目的成功很大程度上归功于实验室对社区的重视。"自从我参与以来，持续努力建立这种信任一直是一项持续的工作，"Angelopoulos说。今年早些时候，Chatbot Arena团队发布了政策文件，概述了他们的方法论和动机。因为该项目不将其数据货币化，而是依赖免费额度和捐赠，"我们知道人们可能会对我们的动机持怀疑态度，"Angelopoulos承认。"所以我们想非常明确地表示，我们唯一的动机就是进行最好的科学研究。我们只想要真相。"

与此同时，vLLM社区也在应对自身的快速增长。自2023年6月发布其开源库以来，它在GitHub上获得了令人印象深刻的28,000颗星，并被许多顶级科技公司的开发者使用。今年，英伟达、AWS、Cloudflare以及使用vLLM进行翻译和儿童安全监控的游戏公司Roblox都举办了见面会。"每当我们发现我iPhone上已有的某个应用是由vLLM驱动的，这都让我们非常有成就感，"权宇硕说。"我们接触的真实用户越多，我们就越确信我们做的是正确的事情。"

但对于任何成功的开源项目而言，增长都是一把双刃剑；每个新模型或硬件的发布都需要李卓翰、权宇硕、Mo和vLLM贡献者们进行耗时且昂贵的冲刺。"质量对这个项目的成功绝对至关重要，因此我们需要对每一次更改进行稳健的测试——尤其是在有这么多人贡献的情况下，"Mo说。每次测试成本10美元，跨越多种GPU，学术资金甚至拨款和捐赠很快就变得难以为继。

事实上，Stoica表示，在大语言模型时代，开源项目的资金压力"至少高出一个数量级"。"你有多种GPU，你还有所有这些其他加速器。而且规模也不同，"他解释道。"10年前，一家新初创公司的大部分资金会用于增加人员。今天，资金流向了基础设施。"

但这里，社区再次发挥了作用。红杉资本合伙人Lauren Reeder表示，到2024年春天，她已从多家投资组合公司那里听到了对vLLM的赞誉——它为他们节省了大量工程团队的时间和精力。于是Reeder在X上联系了他们，Mo邀请她访问实验室。

"我见到了Simon、Woosuk和Zhuohan，他们解释了关于测试、成本和社区的一些动态。这给我印象最深——很多开源项目由一个人运营，有点像肩负着全世界的重担，"她说。"但这绝对是社区运营的，近80%的贡献来自实验室外部。"

前一年，Reeder和合伙人Bogomil Balkansky牵头推出了红杉的`开源学者计划`。该计划没有任何附加条件，也不期望创业——只是支持对红杉投资组合公司及许多其他公司成功至关重要的项目。Reeder认为vLLM是完美契合，李卓翰、权宇硕和Mo成为了红杉开源学者。

Chatbot Arena团队同样靠着临时方案和纯粹的意志力应对着项目的火爆。虽然免费额度支付了LLM（大语言模型）调用和托管费用，但团队急需技术任务方面的帮助，例如更新Chatbot Arena的用户界面以支持多模态模型。他们的工作常常让他们熬到凌晨4点；“我们的人手实在不够，”Angelopoulos说。但他们对于接受模型提供商除免费额度之外的任何支持都犹豫不决，生怕损害自己的独立性。

消息再次传到了Reeder那里，她现在已亲身了解到Sky Lab密集的人才储备——并且看到创始人们反复将Chatbot Arena作为他们在模型之间做选择的试金石。她、Balkansky以及红杉资本的其他合伙人都对在2024年增设第二个奖学金项目持开放态度，在发布申请征集后，他们收到了数百份申请可供选择。但Chiang和Angelopoulos脱颖而出。

“Chatbot Arena致力于保持根本上的中立，这一事实对我们来说实际上非常重要，”她说。“相比于其他可能被广泛使用但带有更多商业动机的项目，我们觉得对于这个项目，我们的支持才能真正产生影响。”

Chiang和Angelopoulos于八月成为奖学金获得者，并表示这笔资金确实让他们得以腾出手来完成清单上至关重要的待办事项。一如既往，他们以用户为先的方式来使用新获得的资源：例如，通过与一个红队社区的近期合作，他们正在探索不同模型的可控性与潜在安全问题之间的关系。

Li、Kwon和Mo也迅速将红杉的支持用于他们的CI账单，目前正在重构vLLM，以减少和防止那些常常困扰快速增长系统的技术债务。Mo表示，他们的主要目标仍然是易用性和性能：“我们想打造世界上最好用、最高效、最快的推理引擎。”他们的社区也以同样的方式在进步；就在去年秋天，90%的贡献还来自伯克利，而现在这个数字仅为25%。

对于vLLM和Chatbot Arena而言，多模态模型的崛起都迫在眉睫，因为两个团队都在进行更新以支持图像、视频和代码。Chiang和Angelopoulos最近与卡内基梅隆大学的Wayne Chi和Valerie Chen合作，他们开发了一个名为Copilot Arena的VSCode扩展，允许用户在补全模型之间来回切换——并允许平台收集关于哪些模型在代码自动补全任务上表现最佳的偏好数据。“我们知道社区对此非常关心，”Angelopoulos说。“我们认为这可能意义重大。”

Reeder表示，vLLM和Chatbot Arena取得的进展只是一个开始——不仅是对这些项目而言，对整个开源社区也是如此。“我们今年注意到，基础设施栈的许多创新都来自开源——这是我们决定扩大奖学金项目的原因之一，”她说。“这些项目拥有社区的支持。每个人都在踊跃参与并试图提供帮助，这种方式我们很久没见过了。”

“我们很兴奋看到他们如何继续推动事物向前发展。开源正在真正地构建未来。”

如果您正在从事开源构建并有兴趣成为奖学金获得者，请访问sequoiacap.com/oss了解更多信息并申请。

## 相关主题

![](/images/posts/a9e1a19a9666.jpg)

## 新奖学金项目：红杉如何支持开源

![](/images/posts/19363740b650.jpg)

## 保持开源思维

## 红杉开源奖学金

# 获取来自红杉社区的最佳故事。

---

> 本文由AI自动翻译，原文链接：[Building the Future: Meet the 2024 Sequoia Open Source Fellows](https://sequoiacap.com/article/building-the-future-meet-the-2024-sequoia-open-source-fellows/)
> 
> 翻译时间：2026-02-13 04:15
