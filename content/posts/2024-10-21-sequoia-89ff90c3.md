---
title: 生成式AI的o1行动：从快速响应到慢速推理的演进
title_original: Generative AI’s Act o1
date: '2024-10-21'
source: 红杉资本 (Sequoia)
source_url: https://sequoiacap.com/article/generative-ais-act-o1/
author: ''
summary: 本文探讨了生成式AI领域从依赖预训练的“快速思考”向推理时进行“慢速思考”的重要转变。随着基础LLM市场格局趋于稳定，竞争焦点正转向开发具备“系统2”深度推理能力的新层。文章以OpenAI的o1（Strawberry）模型为例，分析了其通过推理时计算实现通用推理的突破，并类比AlphaGo的思考机制，指出深度强化学习正在催生全新的智能体应用层，这将重塑AI市场的创业与投资机会。
categories:
- 技术趋势
tags:
- 生成式AI
- 推理计算
- OpenAI o1
- AI智能体
- 系统2思维
draft: false
translated_at: '2026-02-13T04:16:46.827985'
---

![](/images/posts/61307dfcaeb8.jpg)

# 生成式AI的o1行动

生成式AI革命已进入第二年，研究正推动该领域从“快速思考”——即基于预训练的快速响应——迈向“慢速思考”——即在推理时进行思考。这一演进正在解锁一批全新的智能体应用。

在我们发表《生成式AI：一个创造性的新世界》一文两周年之际，AI生态系统已大不相同，我们对于未来趋势有一些预测。

生成式AI市场的基础层正趋于稳定，形成了一套关键规模化参与者与联盟之间的平衡格局，包括微软/OpenAI、AWS/Anthropic、Meta以及谷歌/DeepMind。只有那些拥有经济引擎并能获取巨额资本的规模化玩家仍在牌桌上。虽然竞争远未结束（并且正以博弈论的方式不断升级），但市场结构本身正在固化。显然，我们将获得越来越廉价且丰富的下一个Token预测。

随着LLM市场结构趋于稳定，下一个前沿领域正在浮现。焦点正转向推理层的开发与规模化，其中“系统2”思维占据主导地位。受AlphaGo等模型启发，该层旨在赋予AI系统在推理时进行审慎推理、问题解决和认知操作的能力，超越快速的模式匹配。新的认知架构和用户界面正在塑造这些推理能力如何交付给用户并与之交互。

这一切对AI市场的创业者意味着什么？对现有的软件公司又意味着什么？作为投资者，我们认为生成式AI技术栈中哪个层级最具回报潜力？

在我们关于生成式AI市场现状的最新文章中，我们将探讨基础LLM层的整合如何为规模化这些高阶推理和智能体能力的竞赛奠定基础，并讨论具有新颖认知架构和用户界面的新一代“杀手级应用”。

## 永远的草莓地

2024年最重要的模型更新当属OpenAI的o1（曾用名Q*，亦被称为Strawberry）。这不仅是OpenAI在模型质量排行榜上重夺应有地位的宣示，也是对现有架构的一次显著改进。更具体地说，这是首个具备真正通用推理能力的模型范例，他们通过推理时计算实现了这一点。

这意味着什么？预训练模型是在海量数据上进行下一个Token预测。它们依赖“训练时计算”。规模涌现的一个属性是基础推理能力，但这种推理非常有限。如果能更直接地教会模型推理呢？这正是Strawberry正在实现的目标。当我们说“推理时计算”时，指的是让模型在给出回答前停下来思考，这需要在推理时消耗更多计算资源（因此称为“推理时计算”）。“停下来思考”的部分就是推理。

## AlphaGo × LLM

那么，当模型停下来思考时，它在做什么？

让我们先快速回顾2016年3月的首尔。深度学习史上最具开创性的时刻之一在此上演：AlphaGo与传奇围棋大师李世石的对决。这不仅仅是又一场人机对战——这是世界见证AI超越单纯模式模仿、真正进行思考的时刻。

是什么让AlphaGo不同于之前的游戏AI系统，比如深蓝？与LLM类似，AlphaGo首先通过预训练来模仿人类专家，其训练数据来自约3000万步历史棋谱以及更多的自我对弈数据。但AlphaGo并非直接给出预训练模型的即时反应，而是花时间停下来思考。在推理时，模型会在大量潜在的未来情景中进行搜索或模拟，对这些情景进行评分，然后选择预期价值最高的情景（或答案）作为回应。给予AlphaGo的时间越多，它的表现就越好。如果没有推理时计算，模型无法击败顶尖人类棋手。但随着推理时间的增加，AlphaGo的表现越来越好——直至超越最优秀的人类。

让我们回到LLM世界。在此复制AlphaGo的难点在于构建价值函数，即对回答进行评分的函数。如果是下围棋，这相对直接：你可以模拟对局直至终局，看谁获胜，然后计算下一步棋的期望价值。如果是编程，也相对直接：你可以测试代码看它是否运行。但你如何评价一篇论文的初稿？或一份旅行计划？或一份长文档的关键术语摘要？这正是当前方法在推理上的难点，也是为什么Strawberry在逻辑相关的领域（例如编程、数学、科学）表现相对较强，而在更开放、非结构化的领域（例如写作）则不那么强的原因。

虽然Strawberry的具体实现是严格保密的，但其核心思想涉及围绕模型生成的思维链进行强化学习。对模型思维链的审查表明，一些根本性且令人兴奋的事情正在发生，这实际上类似于人类的思考和推理方式。例如，o1展现出在遇到困难时回溯的能力，这是增加推理时间带来的涌现属性。它还展现出像人类一样思考问题的能力（例如，通过想象球体上的点来解决几何问题），以及以新方式思考问题的能力（例如，以人类不会采用的方式解决编程竞赛中的问题）。

研究团队正在努力推进推理时计算，这方面的新思路层出不穷（例如，计算奖励函数的新方法，缩小生成器/验证器差距的新方法），以提升模型的推理能力。换句话说，深度强化学习再次变得重要，它正在催生一个全新的推理层。

## 系统1与系统2思维

从预训练的本能反应（“系统1”）到更深层、审慎的推理（“系统2”）的飞跃，是AI的下一个前沿。模型仅仅知道事物是不够的——它们需要暂停、评估并实时推理决策。

可以将预训练视为系统1层。无论模型是在数百万步围棋棋谱（AlphaGo）还是PB级的互联网规模文本（LLM）上预训练的，其任务都是模仿模式——无论是人类对弈还是语言。但模仿，尽管强大，并非真正的推理。它无法恰当地通过思考来处理复杂的新情况，尤其是那些超出训练样本的情况。

这就是系统2思维发挥作用的地方，也是最新一波AI研究的焦点。当模型“停下来思考”时，它不仅仅是在生成学习到的模式或基于过去数据吐出预测。它是在生成一系列可能性，考虑潜在结果，并基于推理做出决策。

对于许多任务，系统1绰绰有余。正如诺姆·布朗在我们最新一期《训练数据》节目中指出，花更长时间思考不丹的首都是什么并无帮助——你要么知道，要么不知道。快速、基于模式的回忆在这里完全适用。

但当我们面对更复杂的问题时——比如数学或生物学的突破——快速、本能的反应就不够用了。这些进步需要深度思考、创造性的问题解决，以及最重要的——时间。AI也是如此。要应对最具挑战性、最有意义的问题，AI需要超越快速的样本内响应，花时间进行那种定义人类进步的深思熟虑的推理。

![](/images/posts/72b6404c099b.png)

![](/images/posts/c07cbd0c10f1.jpg)

## 新的扩展定律：推理竞赛已经开始

o1论文最重要的洞见是，出现了一种新的扩展定律。

大语言模型的预训练遵循一个已被充分理解的扩展定律：在模型预训练上投入的计算资源和数据越多，模型性能就越好。

o1论文为计算扩展开辟了一个全新的维度：你给模型提供的推理时（或“测试时”）计算资源越多，它的推理能力就越强。

![](/images/posts/222b449ba854.jpg)

来源：OpenAI o1 技术报告

当模型可以思考数小时、数天甚至数十年时，会发生什么？我们能解决黎曼猜想吗？我们能回答阿西莫夫的最后一个问题吗？

这种转变将使我们从依赖大规模预训练集群的世界，转向**推理云**——一种能够根据任务复杂性动态扩展计算资源的环境。

## 一个模型统治一切？

随着OpenAI、Anthropic、谷歌和Meta扩展其推理层并开发越来越强大的推理机器，会发生什么？我们会有一个统治一切的模型吗？

生成式AI市场初期的一个假设是，一家单一的模型公司将变得如此强大和包罗万象，以至于会吞并所有其他应用。到目前为止，这个预测在两个方面被证明是错误的。

首先，模型层竞争激烈，各家公司在SOTA能力上不断你追我赶。**有可能**有人通过广泛的领域自我博弈实现持续自我改进并达到起飞状态，但目前我们还没有看到任何证据。恰恰相反，模型层竞争异常激烈，自上次开发者大会以来，GPT-4的每Token价格已下降98%。

其次，除了ChatGPT这个显著的例外，这些模型在很大程度上未能作为突破性产品进入应用层。现实世界是混乱的。伟大的研究者们没有意愿去理解每个垂直领域中每个可能功能的、错综复杂的端到端工作流程。对他们来说，止步于API层面既具有吸引力，在经济上也是理性的，让开发者世界去应对现实世界的混乱。这对应用层来说是个好消息。

## 混乱的现实世界：定制化认知架构

作为一名科学家，你规划和执行行动以达到目标的方式，与作为一名软件工程师的工作方式大相径庭。而且，即使同为软件工程师，在不同公司的工作方式也各不相同。

随着研究实验室进一步推动水平通用推理的边界，我们仍然需要应用或特定领域的推理来交付有用的人工智能Agent。混乱的现实世界需要大量领域和应用特定的推理，这些无法有效地编码到一个通用模型中。

![](/images/posts/60f9acbebbde.png)

于是，**认知架构**应运而生，或者说，你的系统如何思考：即接收用户输入并执行行动或生成响应的代码和模型交互流程。

例如，在Factory的案例中，他们的每个“机器人”产品都有一个定制的认知架构，模仿人类思考方式来解决特定任务，比如审查拉取请求，或者编写并执行迁移计划以将服务从一个后端更新到另一个后端。Factory机器人会分解所有依赖项，提出相关的代码更改，添加单元测试并引入人工审查。然后在批准后，在开发环境中对所有文件运行更改，如果所有测试通过则合并代码。就像人类可能会做的那样——通过一系列离散的任务，而不是一个笼统的、黑盒式的答案。

## 应用层发生了什么？

想象一下你想在AI领域创业。你瞄准技术栈的哪一层？你想在基础设施层竞争吗？祝你好运能击败英伟达和超大规模云提供商。你想在模型层竞争吗？祝你好运能击败OpenAI和马克·扎克伯格。你想在应用层竞争吗？祝你好运能击败企业IT部门和全球系统集成商。哦，等等。这听起来实际上相当可行！

基础模型很神奇，但它们也很混乱。主流企业无法处理黑盒、幻觉和笨拙的工作流程。消费者盯着空白的提示词框，不知道该问什么。这些都是应用层的机会。

两年前，许多应用层公司被嘲笑为“不过是GPT-3之上的包装器”。如今，这些“包装器”被证明是构建持久价值的少数可靠方法之一。最初作为“包装器”起步的公司，已经演变成了“认知架构”。

应用层AI公司不仅仅是基础模型之上的用户界面。远非如此。它们拥有复杂的认知架构，通常包括多个基础模型，并配以某种路由机制，用于RAG的向量和/或图数据库，确保合规的护栏，以及模仿人类在工作流程中推理方式的应用程序逻辑。

## 服务即软件

云转型是软件即服务。软件公司变成了云服务提供商。这是一个价值3500亿美元的机会。得益于Agentic推理，AI转型是**服务即软件**。软件公司将劳动力转化为软件。这意味着可寻址市场不是软件市场，而是以**万亿美元**计的服务市场。

![](/images/posts/384ede507caa.jpg)

销售“工作”意味着什么？Sierra是一个很好的例子。B2C公司将Sierra放在他们的网站上与客户交谈。待完成的工作是解决客户问题。Sierra按问题解决次数收费。这里没有所谓的“席位”。你有一项工作需要完成。Sierra来完成它。他们相应获得报酬。

这是许多AI公司的真正方向。Sierra受益于拥有优雅的故障处理模式（升级到人工客服）。并非所有公司都如此幸运。一个新兴的模式是先以副驾驶模式部署（人在回路中），并利用这些实践来赢得以自动驾驶模式部署（无人在回路中）的机会。GitHub Copilot就是这方面的一个好例子。

## 新一代Agentic应用

随着生成式AI推理能力的萌芽，一类新的Agentic应用开始出现。

这些应用层公司呈现出什么形态？有趣的是，这些公司看起来与它们的云时代前辈不同：

*   云公司瞄准的是软件利润池。AI公司瞄准的是服务利润池。
*   云公司销售软件（美元/席位）。AI公司销售工作成果（美元/结果）。
*   云公司喜欢采用自下而上的模式，拥有无摩擦的分发渠道。AI公司越来越多地采用自上而下的模式，拥有高接触、高信任度的交付模式。

我们看到，在知识经济的各个领域，都涌现出了一批新的Agentic应用。以下是一些例子。

*   Harvey：AI律师
*   Glean：AI工作助手
*   Factory：AI软件工程师
*   Abridge：AI医疗文书员
*   XBOW：AI渗透测试员
*   Sierra：AI客户支持Agent

通过将这些服务的边际成本降至与推理成本骤降相一致的水平，这些Agentic应用正在扩展并创造新的市场。

以XBOW为例。XBOW正在构建一个AI“渗透测试员”。“渗透测试”是对计算机系统进行的模拟网络攻击，公司执行此测试以评估自身安全系统。在生成式AI出现之前，公司只在有限的情况下（例如合规要求时）雇佣渗透测试员，因为人工渗透测试非常昂贵：这是一项由高技能人员执行的手动任务。然而，XBOW**目前正在展示**基于最新推理大语言模型构建的自动化渗透测试，其性能可与最高技能的人工渗透测试员相媲美。这极大地扩展了渗透测试市场，并为各种规模和类型的公司开启了持续渗透测试的可能性。

## 这对SaaS领域意味着什么？

今年早些时候，我们与有限合伙人会面。他们最关心的问题是：“人工智能转型会摧毁你们现有的云公司吗？”

我们最初持坚定的默认立场：“不会。”初创公司与现有企业之间的经典竞争，是一场初创公司构建分销渠道与现有企业构建产品之间的赛跑。那些拥有酷炫产品的年轻公司，能否在拥有客户基础的现有企业推出酷炫产品之前，赢得大量客户？鉴于人工智能的诸多魔力源自基础模型，我们默认的假设是“不会”——现有企业会发展得很好，因为这些基础模型对他们和对初创企业世界同样开放，并且他们拥有数据和分销渠道的既有优势。初创公司的主要机会并非取代现有的软件公司，而是瞄准那些可自动化的工作领域。

话虽如此，我们现在不再那么确定了。请参考上文关于认知架构的论述。将一个模型的原始能力转化为一个引人注目、可靠、端到端的商业解决方案，需要大量的工程工作。如果我们只是严重低估了“AI原生”的真正含义呢？

二十年前，本地部署软件公司对SaaS的理念嗤之以鼻。“这有什么大不了的？我们也能运行自己的服务器并通过互联网交付这些东西！”当然，从概念上讲这很简单。但随之而来的是一场彻底的商业重塑。工程产品开发从瀑布模式和产品需求文档转向敏捷开发和A/B测试。市场进入策略从自上而下的企业销售和牛排晚餐转向自下而上的产品驱动增长和产品分析。商业模式从高客单价和维护收入流转向高净收入留存率和基于使用量的定价。很少有本地部署公司成功完成了转型。

如果人工智能是一场类似的变革呢？人工智能的机会是否可能既是销售工作，又是取代软件？

通过Day.ai，我们得以一窥未来。Day是一个AI原生CRM。系统集成商通过配置Salesforce来满足客户需求，赚取数十亿美元。而Day仅需访问你的电子邮件和日历，并回答一份一页纸的问卷，就能自动生成一个完全为你业务量身定制的CRM。它还没有所有花哨的功能，但一个自动生成、无需人工输入即可保持更新的CRM所展现的魔力，已经促使人们开始转向使用它。

## 投资版图

作为投资者，我们把精力花在哪里？资金正投向何处？以下是我们的一些快速看法。

**基础设施**

这是超大规模云服务商的领域。它由博弈论行为驱动，而非微观经济学。对风险投资家来说，这是个糟糕的领域。

**模型**

这是超大规模云服务商和财务投资者的领域。超大规模云服务商正在用资产负债表换取利润表，投入的资金最终会以计算收入的形式回流到他们的云业务中。财务投资者则受到“被科学惊艳”偏见的驱使。这些模型超级酷，这些团队令人印象深刻。微观经济学见鬼去吧！

**开发者工具和基础设施软件**

对战略投资者吸引力较小，但对风险投资家更有趣。在云转型期间，这一层诞生了约15家收入超过10亿美元的公司，我们怀疑人工智能领域也可能出现类似情况。

**应用层**

对风险投资而言最有趣的一层。在云转型期间，应用层诞生了约20家收入超过10亿美元的公司，在移动转型期间又诞生了约20家，我们怀疑这里也会出现同样的情况。

![](/images/posts/d8d04d1b6cea.png)

## 结语

在生成式AI的下一幕中，我们预计推理研发的影响将波及应用层。这些影响快速而深刻。迄今为止，大多数认知架构都融入了巧妙的“解除束缚”技术；既然这些能力正更深地融入模型本身，我们预计智能体应用将迅速变得更加复杂和稳健。

回到研究实验室，在可预见的未来，推理和推理时计算将继续是一个重要主题。既然我们有了新的扩展定律，下一场竞赛已经开始。但对于任何特定领域，收集现实世界数据并编码特定领域和应用的认知架构仍然很困难。这再次表明，解决混乱现实世界中多样化问题方面，最后一英里应用提供商可能占据上风。

展望未来，像Factory的机器人那样的多智能体系统，可能会作为模拟推理和社会学习过程的方式开始普及。一旦我们能完成工作，我们就可以让团队协作完成更多工作。

我们所有人都在热切期待生成式AI的“第37步”，那个时刻——就像AlphaGo与李世石第二局比赛时那样——一个通用AI系统以某种超乎人类、感觉像是独立思考的方式让我们惊讶。这并不意味着AI“觉醒”，而是我们模拟了感知、推理和行动的过程，AI能够以真正新颖且有用的方式进行探索。这实际上可能就是AGI，如果是这样，它将不是一个单一事件，而仅仅是技术的下一个阶段。

![](/images/posts/9134a846a631.jpg)

## 生成式AI：一个创造性的新世界

## 生成式AI的第二幕

![](/images/posts/a30a889f157a.png)

## AI的6000亿美元问题

![](/images/posts/e1a4f130cbfa.jpg)

## 与fal合作：生成式媒体公司

# 获取红杉社区的最佳故事。

---

> 本文由AI自动翻译，原文链接：[Generative AI’s Act o1](https://sequoiacap.com/article/generative-ais-act-o1/)
> 
> 翻译时间：2026-02-13 04:16
