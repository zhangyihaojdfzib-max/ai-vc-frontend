---
title: BlueCodeAgent：利用红队协议强化代码生成安全
title_original: BlueCodeAgent uses red teaming protocols to strengthen code security
date: '2025-11-11'
source: Microsoft Research
source_url: https://www.microsoft.com/en-us/research/blog/bluecodeagent-a-blue-teaming-agent-enabled-by-automated-red-teaming-for-codegen-ai/
author: Brenda Potts
summary: 本文介绍了BlueCodeAgent，一个通过自动化红队测试增强代码生成AI安全性的蓝队智能体。针对大语言模型在代码生成中可能产生的恶意、偏见或脆弱代码等风险，研究团队设计了多样化的红队测试流程来积累安全知识，并在此基础上构建了原则级防御（通过提炼可操作准则）和细微级分析（通过动态测试）。该方法显著提升了模型在检测不安全文本和代码方面的性能，平均F1分数提升12.7%，并能有效泛化到未见过的风险，为代码生成模型的安全防护提供了新思路。
categories:
- AI研究
tags:
- 代码安全
- 红队测试
- 大语言模型
- AI安全
- 软件工程
draft: false
translated_at: '2026-01-06T00:51:02.218Z'
---

引言
大语言模型（LLM）如今已广泛应用于软件工程任务中的自动化代码生成。然而，这种强大的代码生成能力也引发了安全担忧。代码生成系统可能被滥用于恶意目的，例如生成恶意代码。它也可能生成充满偏见的代码，反映出歧视性或不道德的底层逻辑。此外，即使在完成良性任务时，LLM也可能无意中生成包含安全漏洞（例如注入风险、不安全的输入处理）的脆弱代码。这些不安全的结果损害了代码生成模型的可信度，并对更广泛的软件生态系统构成威胁，而安全性和可靠性对该生态系统至关重要。

许多研究已探索了对代码LLM的红队测试，检验模型是否能拒绝不安全的请求，以及其生成的代码是否表现出不安全模式。更多细节，请参阅我们此前关于RedCodeAgent的MSR博客文章。尽管红队测试极大地增进了我们对模型失效模式的理解，但蓝队测试——即开发有效的防御机制来检测和防止此类失效——的进展仍然相对有限。当前的蓝队测试方法面临若干挑战：（1）与安全概念的对齐不佳：额外的安全提示词难以帮助模型理解高层次概念，例如什么构成恶意或有偏见的指令，并且通常缺乏可操作的原则来指导安全决策。图1展示了一个案例研究。（2）过度保守：特别是在脆弱代码检测领域，模型倾向于将安全代码误判为不安全，导致更多误报并降低开发者的信任。（3）风险覆盖不完整：缺乏坚实的知识基础，模型在处理微妙或先前未见过的风险时表现不佳。

为应对这些挑战，来自芝加哥大学、加州大学圣塔芭芭拉分校、伊利诺伊大学厄巴纳-香槟分校、VirtueAI和微软研究院的研究人员近期发布了一篇论文：《BlueCodeAgent：一个由自动化红队测试赋能代码生成AI的蓝队智能体》。这项工作做出了以下关键贡献：
- 多样化的红队测试流程：作者设计了一个全面的红队测试流程，整合了多种策略来合成多样化的红队测试数据，以实现有效的知识积累。
- 知识增强的蓝队测试：在红队测试知识的基础上，BlueCodeAgent通过利用从知识中提炼出的准则和动态测试，显著提升了蓝队测试性能。
- 原则级防御与细微级分析：作者提出了两种互补策略——原则级防御（通过准则）和细微级分析（通过动态测试）——并展示了它们在脆弱代码检测任务中的协同效应。
- 对已见和未见风险的泛化：凭借全面的红队测试知识，BlueCodeAgent能有效泛化到未见过的风险。总体而言，BlueCodeAgent在四个数据集和三项任务上的F1分数平均提升了12.7%，这归功于其提炼可操作准则的能力，这些准则增强了上下文感知的风险检测。

一个由红队测试赋能的蓝队智能体
图2展示了该流程的概览。该框架统一了流程的两端：红队测试生成多样化的风险案例和行为，然后将其提炼为可操作的准则，这些准则在蓝队测试端编码了安全规则。这些准则引导BlueCodeAgent更有效地检测不安全的文本输入和代码输出，从而缓解诸如与抽象安全概念对齐不佳等局限性。

这项工作针对三大风险类别，涵盖了输入/文本级风险（包括有偏见和恶意的指令）和输出/代码级风险（模型可能生成脆弱代码）。这些类别代表了先前研究中已被广泛探讨的风险。

用于知识积累的多样化红队测试流程
由于不同任务需要不同的攻击策略，红队测试采用了多种攻击方法来生成真实且多样化的数据。具体而言，红队测试流程分为三类：
- 基于策略的实例生成：为合成基于策略的红队测试数据，首先收集了多样化的安全和伦理策略。然后，这些高层次原则被用来提示一个未经审查的模型，生成故意违反指定策略的实例。
- 基于种子的对抗性提示词优化：现有的对抗性指令通常过于简单，容易被模型拒绝。为克服这一限制，一个自适应的红队测试智能体调用各种越狱工具，迭代优化初始种子提示词，直到提示词达到较高的攻击成功率。
- 知识驱动的漏洞生成：为在真实的编程场景下合成脆弱和安全的代码样本，利用了常见软件弱点（CWE）的领域知识来生成多样化的代码示例。

知识增强的蓝队测试智能体
在积累了红队测试知识数据后，BlueCodeAgent通过准则构建建立了原则级防御，并通过动态测试建立了细微级分析。
- 通过准则构建实现原则级防御
基于最相关的知识数据，BlueCodeAgent将红队测试知识总结为可操作的准则——从先前的攻击数据中提炼出的明确规则和原则。这些准则作为规范性指南，使模型即使面对新颖或未见过的对抗性输入时，也能保持与伦理和安全原则的对齐。
- 通过动态测试实现细微级分析
在脆弱代码检测中，BlueCodeAgent通过基于动态沙箱的分析来增强静态推理，在隔离的Docker环境中执行生成的代码，以验证模型报告的漏洞是否表现为实际的不安全行为。这种动态验证有效地缓解了模型过度保守的倾向，即错误地将良性代码标记为脆弱。

播客系列
来自BlueCodeAgent的洞见
BlueCodeAgent优于提示词基线
如图3所示，BlueCodeAgent显著优于其他基线。以下几点发现值得关注。
（1）即使测试类别与知识类别不同以模拟未见过的场景，BlueCodeAgent也能有效利用先前见过的风险来处理未见过的风险，这得益于其知识增强的安全推理能力。
（2）BlueCodeAgent与模型无关，能在包括开源和商业模型在内的多种基础LLM上稳定工作。其在偏见和恶意指令检测上的F1分数接近1.0，凸显了强大的有效性。
（3）BlueCodeAgent在安全性和可用性之间实现了良好的平衡。它能准确识别不安全的输入，同时在良性输入上保持合理的误报率，从而获得持续较高的F1分数。
（4）相比之下，使用通用或细粒度的安全提醒进行提示，对于有效的蓝队测试仍然不足，因为模型难以内化抽象的安全概念并将其应用于未见过的风险场景。BlueCodeAgent通过从知识中提炼可操作的准则，使用具体且可解释的安全约束来增强模型对齐，从而弥合了这一差距。

准则与动态测试的互补效应
在漏洞检测任务中，模型倾向于表现得保守——先前研究也注意到了这一效应。它们往往更倾向于将代码标记为不安全而非安全。

这种倾向是可以理解的：确认代码完全不存在漏洞通常比发现潜在问题更为困难。

为了缓解这种过度保守性，BlueCodeAgent将动态测试集成到其分析流程中。当BlueCodeAgent识别出潜在漏洞时，它会触发一个可靠的模型（Claude-3.7-Sonnet-20250219）来生成测试用例及相应的可执行代码，这些代码会嵌入可疑的代码片段。随后，这些测试用例在受控环境中运行，以验证漏洞是否确实会显现。最终的判断综合了LLM对静态代码的分析、生成的测试代码、运行时执行结果以及从知识中衍生的规则。

研究人员发现，规则和动态测试这两个组成部分起到了互补作用。规则扩展了模型对风险的理解，增加了真阳性（TP）并减少了假阴性（FN）。另一方面，动态测试则侧重于通过验证预测的漏洞是否真的能在运行时被触发，来减少假阳性（FP）。两者结合，使得BlueCodeAgent在蓝队场景中既更准确又更可靠。

**总结**
BlueCodeAgent引入了一个端到端的蓝队框架，旨在应对代码生成中的风险。BlueCodeAgent背后的核心洞见是，全面的红队测试可以极大地加强蓝队防御。基于这一理念，该框架首先构建了一个红队流程，采用多样化的策略来生成红队数据。随后，它构建了一个蓝队智能体，该智能体从红队知识库中检索相关示例，并总结安全规则，以指导LLM做出准确的防御决策。此外，还增加了动态测试组件，以减少漏洞检测中的假阳性。

展望未来，有几个方向值得探索。

首先，探索将BlueCodeAgent推广到除偏见、恶意代码和漏洞代码之外的其他类别的代码生成风险，这具有重要价值。这可能需要在BlueCodeAgent中设计和集成新颖的红队策略，并为新风险创建相应的基准。

其次，将BlueCodeAgent扩展到文件和仓库级别，可以进一步增强其在实际应用中的效用，这需要为智能体配备更先进的上下文检索工具和记忆组件。

最后，除了代码生成，将BlueCodeAgent扩展到其他模态以降低风险也很重要，包括文本、图像、视频和音频，以及多模态应用。

> 本文由AI自动翻译，原文链接：[BlueCodeAgent uses red teaming protocols to strengthen code security](https://www.microsoft.com/en-us/research/blog/bluecodeagent-a-blue-teaming-agent-enabled-by-automated-red-teaming-for-codegen-ai/)
> 
> 翻译时间：2026-01-06 00:51
