---
title: 构想：从女性机器学习社群到负责任AI的未来
title_original: 'Ideas: Community building, machine learning, and the future of AI'
date: '2025-12-01'
source: Microsoft Research
source_url: https://www.microsoft.com/en-us/research/podcast/ideas-community-building-machine-learning-and-the-future-of-ai/
author: Alyssa Hughes
summary: 本文基于微软研究播客《构想》对“机器学习领域的女性”（WiML）研讨会两位联合创始人的访谈。她们回顾了WiML如何从一个2006年由三位博士生发起的小型研讨会，发展成为支持全球女性及非二元性别研究者的非营利组织。对话深入探讨了社群建设的重要性、她们在微软推动负责任人工智能的协作，以及给年轻研究者的建议。文章展现了技术发展背后的人文关怀与多元包容的价值观，并附有多篇关于AI公平性、可解释性及评估的前沿研究资料。
categories:
- AI研究
tags:
- 机器学习
- 女性社群
- 负责任人工智能
- AI伦理
- 微软研究
draft: false
translated_at: '2026-01-05T16:35:07.389Z'
---

每一项新兴技术的背后，都有一个推动其前进的伟大构想。在微软研究播客系列《构想》中，微软研究社区的成员们探讨了驱动他们研究的信念、启发研究的经历与思想家，以及研究旨在实现的积极人文影响。

2006年，三位博士生组织了“机器学习领域的女性”研讨会（WiML），为机器学习领域的女性提供了一个交流与分享研究的空间。自此，该活动每年举办，规模和使命都在不断扩大。

在本期节目中，WiML的两位联合创始人——微软高级首席研究经理詹恩·沃特曼·沃恩和微软副总裁、杰出科学家汉娜·瓦拉赫——回顾了该研讨会的第二十届活动。她们讨论了WiML如何从一个可能仅举办一次的活动，发展成为支持全球女性及非二元性别个体的非营利组织；她们的友谊与合作，包括她们在微软定义负责任人工智能方面所做的贡献；以及她们会给年轻时的自己哪些建议。

了解更多：
- 《促进对大语言模型的适当依赖：解释、来源与不一致性的作用》
出版物 | 2025年4月
- 《立场：评估生成式人工智能系统是一项社会科学测量挑战》
出版物 | 2025年1月
- 《操纵与衡量模型可解释性》
出版物 | 2021年5月
- 《提升机器学习系统的公平性：行业从业者需要什么？》
出版物 | 2019年6月
- WiML研讨会 @ NeurIPS 2025（在新标签页中打开）
活动主页
- 机器学习领域的女性（WiML）（在新标签页中打开）
组织主页

订阅微软研究播客：

**文字稿**
[音乐]
**系列介绍**：您正在收听的是《构想》，一档深入探索技术研究世界及代码背后深刻问题的微软研究播客。在本系列中，我们将探索塑造我们未来的技术以及推动这些技术前进的伟大构想。
[音乐淡出]

**詹恩·沃特曼·沃恩**：大家好，欢迎收听。我是詹恩·沃特曼·沃恩。本周，世界各地的机器学习研究人员将参加一年一度的神经信息处理系统大会（NeurIPS）。今年的NeurIPS让我格外兴奋，因为有一个同期活动——第二十届“机器学习领域的女性”年度研讨会（在新标签页中打开），即WiML。我将以导师和主旨演讲者的身份参加。

为了庆祝WiML成立20周年，今天我请来了我的长期合作者、同事、密友，也是“机器学习领域的女性”研讨会的联合创始人——汉娜·瓦拉赫。

你知道，我们彼此认识已经很久了。在很多方面，在我们最终都来到微软从事负责任人工智能工作之前，我们走过了非常平行且时常交汇的道路。所以我想，以我们交织轨迹的故事来开启这期播客可能会很有趣。

那么，让我们从20年前说起，大约是我们最初萌生WiML想法的时候。你当时在哪里，在做什么？

**汉娜·瓦拉赫**：是的，我当时是剑桥大学的博士生，师从已故的大卫·麦凯。我专注于用于文本分析的机器学习，那时我实际上刚开始研究用于文本分析的贝叶斯潜变量模型，我的研究重点确实是尝试将n-gram语言建模的思想与统计主题建模相结合，以期提出能更好地建模文本的模型。

我当时还做着一件超级奇怪的两国奔波的事。我在剑桥读博士，但在博士第一年结束时，我作为访问研究生在宾夕法尼亚大学待了三个月，我非常喜欢那里，以至于三个月结束时我说，我能延长到一整年吗？剑桥说可以；宾大也说可以。于是我就这么做了，实际上后来还延长了一年又一年，如此反复。

但我在宾大的第一个完整学年，就是那时我遇到了你，那是在访问学生周末活动上。系里的老师告诉我必须努力争取你（加入）。我完全没想到那实际上会是一段超过20年友谊的开始。

**沃特曼·沃恩**：是的，我仍然清楚地记得那个访问周末。实际上，我遇到了你；遇到了我的丈夫杰夫；还遇到了我的博士生导师迈克尔·卡恩斯，都在同一天，在那个访问学生周末。所以当时我并不知道，但那对我来说是非常重要的一天。

大约在我开始在宾大读博的时候，我从事的是机器学习理论和算法经济学研究。所以即使在那个时候，你知道，就像我现在一样，我对人与人工智能系统的交叉领域感兴趣。但由于我的训练背景是理论，我的“人”往往是那些数学上理想化的人，他们有明确的偏好和信念，行为方式也非常明确。

从事这样的学习理论研究对我很有吸引力，因为它非常简洁和精确。完全没有现实世界的混乱。你只需写下包含你所有假设的模型，而由此推导出的一切在某种意义上都是客观的。

所以我真的很享受这项工作，而且当时有你在系里我也非常兴奋。说实话，我也很爱宾大。那真是一个很棒的环境。实际上几周前我刚回去过，去做讲座。我度过了一段美妙的时光。但我要说，当时计算机科学系是男性主导的。在我那届入学的博士生中，我们有20个人，而我是唯一的女性。但我们设法建立了一个社群。我们有每周一次的女士早午餐，我很喜欢，这类事情真的支撑我度过了博士阶段。

**瓦拉赫**：是的，我也很喜欢那个女士早午餐。那对我产生了巨大的影响，在某种程度上也支撑我度过了博士阶段。

而且，和你一样，我一直对人的方面感兴趣。在博士期间，我意识到我感兴趣的不是为了文本本身而分析文本，对吧。我感兴趣是因为文本是人们相互交流的方式之一。你知道，人们不是为了写文本而写文本。他们写作是因为试图传达某些东西。而这正是我真正感兴趣的。正是文本的这些社会性方面让我觉得超级有趣。

所以博士毕业后，我得到了一份博士后工作，专注于将文本作为更广泛社会过程的一部分进行分析。之后，我最终在麻省大学获得了一个教职，也是麻省大学计算社会科学研究所（在新标签页中打开）的四位创始成员之一。我是计算机科学领域的，另外还有一位统计学助理教授、一位政治学助理教授和一位社会学助理教授。在很多方面，这都是我梦寐以求的工作。我拿着薪水去开发和使用机器学习方法来研究社会过程，并回答社会科学家想要研究的问题。这非常棒。我想，你差不多在同一时间开始了教职，对吧？

**沃特曼·沃恩**：是的。我也做了博士后。首先，我在哈佛做了一年博士后，非常有趣。然后我在2010年在加州大学洛杉矶分校开始了计算机科学的终身教职轨道职位。

同样，你知道，那是一个男性主导的环境。我的系里大部分是男性。但也许比这更重要的是，我在那里真的没有什么人脉网络。你知道，很孤独。一个例外是米哈埃拉·范德沙尔。她当时在加州大学洛杉矶分校，不过不在我所在的系，她对我颇为关照。所以我很感激有那样的支持。

但总的来说，这个职位并不太适合我，当时我承受的压力比我记忆中人生任何阶段都要大。

沃拉赫：确实。所以在那之后，你最终转到了微软研究院，对吗？

沃特曼·沃恩：是的。

沃拉赫：你最终为何选择加入微软研究院？

沃特曼·沃恩：嗯，那是在2012年。当时微软研究院刚刚在纽约市开设了新的实验室，而在这个实验室工作基本上是我的梦想职位。我记得在他们正式开放实验室之前，我一听说这个消息就尝试申请了。

当时这个实验室主要聚焦三个领域：机器学习、算法经济学和计算社会科学。而我当时的研究正好横跨这三个领域。所以这感觉像是一个绝佳的机会，能让我的工作完美融入并真正受到重视。

当时的算法经济学小组其实正在构建预测市场，以整合关于未来事件的信息，而他们的工作正是基于我的一些理论研究——看到这个感觉真的太酷了。这让我非常兴奋。而且我当时已经认识那里的几个人了，比如约翰·兰福德和当时在经济学组的戴夫·彭诺克，因为在他们来微软之前，我曾在雅虎研究院与他们两人一起实习过。我也非常期待能再次与他们共事。

要知道，即使在我加入实验室时，那里也是13位男性和我。所以，性别比例依然不理想。我觉得在某些方面这对我来说尤其困难，因为我天生是个非常害羞的人，在职业生涯的那个阶段，我还没有建立起应有的自信。但另一方面，我发现研究方向的契合度实在太高了，让我无法拒绝。我猜你也能理解这一点，因为一两年后你也来到纽约实验室加入了我的团队。那么，你当时为何做出这个转变呢？

沃拉赫：是的，我原本预期自己会热爱我的教职工作。它聚焦于所有让我兴奋的内容。但出乎意料的是，我并没有那么喜欢。倒不是说有某件具体的事情我不喜欢，而是多种因素混合的结果。不过，我确实热爱我的研究，这一点我很清楚。但我并不快乐。所以我花了一个夏天，尽可能多地与从事各种不同工作的人交谈，目的就是想了解他们的日常生活是怎样的。你是我交谈过的人之一，但我也和很多其他人聊过。

经过那个夏天的交流，我最终决定申请业界的工作。我投了很多地方，也拿到了不少录用通知。但我最终决定加入微软研究院纽约实验室，因为在所有我考虑的去向中，只有他们说：“我们欣赏你的研究，我们喜欢你做的事情。你愿意来这里继续做同样的研究吗？”

这对我非常有吸引力，因为我热爱我的研究。我当然想去那里继续我的研究，尤其是能和像你、邓肯·瓦茨这样我一直非常敬仰的人共事。他当时也在那里。那里真正专注于计算社会科学，但更多了一些产业视角。那里还有这些出色的机器学习研究员。出于许多和你相似的原因，我对加入那个实验室感到非常兴奋，尤其高兴能再次和你在同一个机构工作。

沃特曼·沃恩：是啊，我很高兴至少能沾一点光……

沃拉赫：哦，当然。

沃特曼·沃恩：……为多年前把你招来微软。

沃拉赫：哦，是的。

沃特曼·沃恩：没错。你当时能加入我也非常兴奋，不过时间上有点不巧，我错过了你头几个月，因为当时我正在休产假，迎接我的第一个女儿。我得说我有两个女儿，我很自豪能在这个播客中提到，她们都对数学和阅读很感兴趣。

沃拉赫：是的，她们都很棒。

嗯，所以我们最终在同一个地方工作了。但尽管如此，我们还是花了好几年时间才开始真正在研究上合作。你还记得我们是怎么开始一起工作的吗？

沃特曼·沃恩：记得，我以前经常讲这个故事。实际上，那是在一次关于人工智能与社会的专题讨论会上，我想大概是2016年，在华盛顿特区举行的。会上有人声称，很快我们的人工智能系统就会变得非常强大，以至于我们决策中的所有不确定性都将被消除。这个说法不知怎么的，真的让我很恼火。我对此非常生气，因为我觉得这简直是……

沃拉赫：我记得。

沃特曼·沃恩：……一种非常不负责任的言论。所以我回到纽约后，我想我是在实验室里向你抱怨了这件事，而这次谈话最终引发了我们之间更长时间的讨论，内容是关于沟通不确定性的重要性，以及解释预测背后假设的重要性等等。

沃拉赫：这确实是……我对此非常兴奋，因为作为一名贝叶斯主义者，多年来我一直被反复灌输这一点。贝叶斯统计学是我所做的很多机器学习工作的基础，其核心就是明确陈述假设和量化不确定性。所以我对这些东西有非常强烈的感受。

沃特曼·沃恩：是的。不知怎么的，我们所有的这些讨论促使我们去研读当时机器学习社区关于可解释性的一些文献。当时有很多论文声称模型是可解释的，却没有停下来定义是对谁可解释、或者为了什么目的可解释。从未真正将这些模型放在真实的人面前进行测试。我们想为此做点什么。于是我们开始用真人进行受控实验，结果发现，我们常常不能相信自己对“什么使模型可解释”的直觉。

沃拉赫：是的，那项工作中经常出现的一个问题就是，如何衡量这些模糊抽象的人类概念，比如可解释性——它们本身就很难定义，更不用说量化、测量等等了。

沃特曼·沃恩：完全正确。我想我们在这项工作中真正纠结的第一个问题就是，“可解释”、“可理解”这些当时被随意使用的术语，到底意味着什么。

嗯，我们最终和我们的同事福鲁·普尔萨布齐、杰克·霍夫曼以及丹·戈尔茨坦一起做了一些研究，这仍然是我最喜欢的论文之一……

沃拉赫：我也是。

沃特曼·沃恩：……在这项工作中，我们发现将可解释性视为一种潜在属性非常有用，它可以受到模型或系统设计的不同特性的影响。比如模型拥有的特征数量、模型是否是线性的，甚至是模型的用户界面等因素。

这对我来说是一个入门项目，因为这是我真正开始感到兴奋的、更偏向人机交互（HCI）的项目之一，而不是像过去那样专注于理论研究。它在我心中点燃了巨大的兴奋火花。

当时对我来说，这感觉比我正在做的其他事情更重要，我只想在这项工作上投入越来越多的时间。

我想说另一个对我产生非常类似影响的项目，是我们几乎在同一时期共同参与的，那就是与肯·霍斯坦合作开展的、旨在梳理行业从业者在人工智能公平性领域所面临挑战的工作。

沃拉赫：哦，是的。没错。那个项目太有趣了，我从中学到了很多。如果我没记错的话，我们最初聘请了肯作为实习生，他当时应该是卡内基梅隆大学的人机交互博士生……

沃特曼·沃恩：是的。

沃拉赫：……来与我们一起为公平性工具（比如 Fairlearn 工具包）创建某种用户体验。我们启动那个项目时——那是与米罗·杜迪克和哈尔·多梅合作的——我们让肯与微软以及许多其他组织的从业者进行了大量交流，以了解他们是如何使用（或未使用）像 Fairlearn 这样的公平性工具包的。

我想指出的是，在那个时间点，学术研究界极度关注所有这些简单的量化指标，用于在预测和预测性机器学习模型的背景下评估公平性，并认为可以基于此构建工具来帮助从业者评估其预测模型的公平性，甚至可能做出更公平的预测。而这正是 Fairlearn 工具包最初开发的目的。所以，我们最终询问所有这些从业者，最初只是作为我们认为这个项目最终要做的铺垫。

我们还询问了这些从业者关于他们当前工作中围绕公平性的实践和挑战，以及他们额外的支持需求。他们觉得在哪些方面已经拥有了合适的工具、流程和实践，又在哪些方面感觉有所欠缺。这确实令人大开眼界，因为我们的发现与我们预期的截然不同。有两点尤其突出。

第一点是，我们发现了远超出预测范畴的、广泛得多的应用场景。我们最初假设所有这些从业者都在用预测性机器学习模型做事，但实际上，我们发现他们在做各种各样的事情。有一堆无监督的工作；还有一堆基于语言的工作——诸如此类。事后看来，这在如今可能并不令人惊讶，因为生成式 AI 的兴起，以及整个机器学习和 AI 领域确实不再那么专注于那种狭隘的分类-回归式的预测。但在当时，这非常令人惊讶，尤其是考虑到学术文献在思考公平时对预测的关注。

我们发现的第二点是，从业者常常难以运用现有的公平性研究，部分原因是当时风靡的这些量化指标，并不真正适用于这些从业者所面临的各种现实世界复杂场景。这背后有很多不同的原因，但其中一个真正突出的点是，问题并不主要在于底层模型之类的东西，而实际上在于涉及各种数据挑战，比如数据收集、敏感属性的收集——这些是实际使用这些公平性指标所必需的。

综上所述，所有这些的结果是，我们最终并没有完成我们最初为那个[笑]实习项目设定的目标。我们……因为我们发现了研究与实践中存在的巨大鸿沟，最终发表了一篇描述这一鸿沟并指出未来重要研究方向的论文。这篇论文做的另一件事是强调了进行此类定性工作以真正理解实践现状的重要性，而不是仅仅假设从业者在做什么或不做什么。

当然，另一个成果是，我们四个人——你、我、米罗和哈尔——从肯那里学到了大量关于人机交互和定性研究的知识，这真是太有趣了。

沃特曼·沃恩：是的，而且我开始面对一个事实：我不能再合理地忽视现实世界中所有这些混乱了，因为从某些方面来说，负责任的人工智能恰恰就是关于这些混乱的。

所以我认为这个项目对我们两人来说都是一个重大的转变。从某些方面来说，从事这项工作以及可解释性工作，确实引领我们积极参与了微软内部在负责任 AI 领域的早期努力。嗯，我们所做的研究直接影响了公司政策，感觉这是一个我们可以产生巨大影响的领域。所以非常令人兴奋。

那么稍微转换一下话题。汉娜，你还记得我们最初是怎么想到 WiML 的吗？

沃拉赫：是的，我记得。那是在 NeurIPS 会议上。那是在 2005 年。那时候……当时的 NeurIPS 是一个非常不同的会议。现在它有数万人参加，在一个巨大的会议中心举行。是的，那里有研究人员，但也有来自科技行业各个领域的人参加，但那时候可不是这样的。

大约在……2005 年，总共大概只有 600 人左右[1]，主会议每年在温哥华举行，然后所有参会者会挤上巴士，一起前往惠斯勒参加研讨会。

沃特曼·沃恩：是的。

沃拉赫：所以和现在的情况完全不同。那是我第三次参加。我想是的。那是我第三次参加这个会议。但那是我第一次和其他女性合住酒店房间。我记得在惠斯勒的研讨会上，我们五个人坐在酒店房间里，谈论着能有五个女性坐在一起聊天是多么神奇。我们有点不敢相信我们竟然有五个人。当时我们都是博士生。于是我们决定列一个名单，开始试图找出机器学习领域的其他女性。我们想出了大约 10 个名字，我们甚至对机器学习领域有 10 位女性感到惊讶。我们认为这是一个巨大的数字。我们非常兴奋。然后我们开始讨论，如果能把她们都聚在一起该多有趣。

于是我们从 NeurIPS 回来，你和我最终一起吃了顿午餐来制定策略。我仍然记得我们一起走出系楼去吃午饭，你走在我前面。我还能想象出你走在我前面时穿的那件外套。我们商量了一下，最终决定和另一位女性丽莎·温纳一起，向格雷斯·霍珀会议提交一个提案，申请一个分会场，让机器学习领域的女性在那里简短介绍她们的研究。

我们联系了在酒店房间里写下的那 10 个名字，并通过这个过程实际上发现了更多机器学习领域的女性，最终在最终提案中列出了大约 25 位女性。我想在某封邮件里，我们中的一个人对另一个人说：“天哪！我简直不敢相信机器学习领域有这么多女性。”

我们提交了这个提案，但最终，提案被格雷斯·霍珀会议拒绝了。但我们对这个想法非常兴奋，而且到那时已经投入了很多，所以我们决定在格雷斯·霍珀会议前一天举办我们自己的同期活动。

我必须说，20年后的今天回想起来，我真不知道当时我们是怎么想的。对于三个博士生而言，这确实是个大胆的举动。而且事实证明，后续所有工作也都得完全靠我们自己完成。

沃特曼·沃恩：是啊。

沃拉赫：我们当时根本不清楚自己在做什么。但格蕾丝·霍珀大会的工作人员非常好心地帮我们联系了会议场地，我们最终居然成功办成了。首届研讨会大约有100位女性参加，而且……我们原本只计划办个简短的分会，结果却办成了整整一天的系列讲座。我办公室里至今还保存着当年所有演讲的摘要手册，这真是段非凡的经历。

沃特曼·沃恩：确实如此。你提到我们当时多么大胆，其实我完全不觉得我们当时意识到自己有多大胆——研讨会提案被拒后，我们坚持认为这件事很重要，决定以在读研究生的身份独立筹办。

刚才我提到职业生涯中许多场合都很少见到女性同行。在WiML成立之前，你在机器学习领域是否也经历过女性社群或人际网络的缺失？你认为建立这样的社群为何重要？

沃拉赫：这种缺失体现在很多方面。就像我几分钟前说的，那是我第三次参加NeurIPS会议，却是我第一次和另一位女性合住酒店房间。这些年来我在很多地方都有类似感受。

首先是本科阶段。后来我从事了大量自由开源软件开发，深度参与Debian Linux发行版相关工作。当时自由开源软件领域的女性参与者比例只有1%到1.5%（在新标签页打开），而Debian社区的女性比例甚至更低。这促使我和其他人共同发起了Debian女性项目（在新标签页打开）。当然，后来在机器学习领域我也面临同样处境。

我认识的机器学习领域女性实在太少了。当时没有太多资深女性前辈可以作为榜样，女性博士生数量也不多。这让我感到难过，因为我对机器学习充满热情，希望将其作为终身事业。但正因为看不到足够多的女性同行，尤其是资深女性，我开始怀疑这是否可能实现。

这些年来我反复思考这个问题。我认为在任何领域——无论是自由开源软件开发、机器学习还是其他领域——构建多元社群都至关重要。有些原因看似微小，比如找到合住酒店房间时感到自在的同伴。

但更多因素会产生更深远的连锁累积效应：在社群中被重视、受接纳、拥有榜样力量、能看到标杆并心想“我未来也想成为那样的人，我能做到”。更重要的是，工作中不同视角的呈现本身就极具价值。

反之，缺乏多元化的社群可能导致诸多问题：形成排外壁垒、滋生有毒或不安全的文化、造成人员流失——当人们感到不受欢迎且不被重视时就会离开。回到不同视角呈现这一点，高度同质化的社群容易形成技术盲区，进而可能造成危害。

沃特曼·沃恩：完全同意。那你当年是否想过，20年后WiML依然存在，我们还能坐在这里录制播客谈论这些？

沃拉赫：（笑）完全没有。我甚至不确定WiML能否办到第二年，以为可能只是一次性活动。更没想到20年后自己还会活跃在机器学习社区，这一切都出乎意料。

不过我有个问题想问你：关于首届研讨会，你印象最深的是什么？

沃特曼·沃恩：很多细节都记忆犹新。我记得策划时我们始终坚持聚焦研究本身。回想首届研讨会的形式，其实就是大家通过演讲或海报展示向彼此介绍自己的研究。

在海报展示环节，我感受到的氛围与其他会议截然不同——更融洽、更积极、更健康。每个人都充满支持与鼓励，但核心始终围绕研究展开。我还记得早上走进会议室时的震撼：看到这么多女性齐聚一堂，意识到我们真的让这件事成为了现实。

当然我们也遇到过一些挑战。你对哪些挑战印象最深？

沃拉赫：很多人确实理解我们的初衷并给予了极大支持。比如宾夕法尼亚大学完全认同我们，为首届研讨会提供了大量资金。但社区里也有人不理解，认为这种研讨会没有必要。

我记得曾和一位机器学习研究员共进晚餐，他说这类研讨会纯属多余，因为女性和男性的经历没有区别。聊了一个半小时后，他提到自己和朋友曾去女子学院的酒吧，感到非常尴尬和不自在。我当即指出（笑）：你刚刚亲自解释了为什么我们需要WiML。所以确实需要反复向一些人解释说明。

另一个挑战是确定可持续的筹资方式。宾大资助了首届研讨会，但这不可持续，他们不可能一直资助。后来我们与艾米·格林沃德合作获得了美国国家科学基金会的资助，也收到了其他组织的捐款。

第三个挑战是选址问题。由于我们坚持聚焦研究，前两届都在格蕾丝·霍珀大会期间举办，但后来觉得那个场合并不完全符合我们的研究导向。

于是我们最终决定将其迁至NeurIPS会议同期举办，这个决定带来了诸多益处，其中有些甚至在我们做决定时都未曾充分考虑到。

其中一个好处是参会者的WiML差旅资助——我们原本提供这笔资助是为了让她们能够支付参加WiML会议的费用，包括酒店住宿等各类开销——如果我们与NeurIPS联合举办，这笔资助实际上也能帮助她们参加NeurIPS会议。

沃特曼·沃恩：是的。

沃拉赫：另一个主要好处是我们将WiML安排在NeurIPS会议的前一天举行。这样一来，在后续整个NeurIPS会议期间，WiML的参会者能在人群中看到熟悉的面孔，而不必感到那么孤单。

沃特曼·沃恩：你刚才谈到了这些挑战。这些挑战随着时间的推移发生了怎样的变化？或者，更广泛地说，你能谈谈这个研讨会以及“机器学习领域的女性”这个组织整体上是如何在这些年演变的吗？我知道你曾担任过WiML的主席。

沃拉赫：是的。变化非常大。首先，最明显也是最重要的是，它从一个我们只是试试看会怎样的单次活动，演变成了一个真正健全的组织。实现这一步的第一步是创建了WiML理事会。正如你刚才提到的，我担任了该理事会的第一任主席。

但自那以后还采取了许多其他步骤。关于WiML理事会，我想强调的一点是，这确实非常重要，因为理事会成员可以专注于组织的长期健康发展，以及那些跨越多年的工作，比如如何获得可持续的资金来源等等。而实际的研讨会组织者则可以专注于诸如发布征稿通知之类的事情。能够将这两种角色分开，确实减轻了研讨会组织者的负担，这意味着我们可以采取这种更长远的视角。

另一个非常重要的步骤是正式成为一个非营利组织。这是在几年前完成的。同样，这在当时是顺理成章的事情，也是朝着创建一个持久、健全的组织迈出的另一步。

但它确实已经自成一体了。说实话，我现在并没有非常积极地参与其中，我认为这很棒。这个组织不再需要我了。这很好。同样让我感到不可思议的是，因为它已经存在了20年，以至于这个领域里有些女性已经不知道没有WiML是什么样子了。

因此，还创建了许多其他社群团体。例如，蒂姆尼特·格布鲁在微软研究院纽约市担任博士后时，共同创立了“Black in AI”。所以你我实际上近距离见证了那个社群团体的创立。现在还有大量其他社群团体，比如“LatinX in AI”（在新标签页中打开）、“Queer in AI”（在新标签页中打开）、“Muslims in ML”（在新标签页中打开）、“Indigenous in AI and ML”（在新标签页中打开）、“New In ML”（在新标签页中打开），仅举几例。

沃特曼·沃恩：是的，而且所有这些团体每年也都在发展壮大。

你知道，今年WiML收到了超过400份投稿。他们接受了250份进行展示。这太了不起了。

沃拉赫：这太疯狂了。

沃特曼·沃恩：是的，没错。而且今年WiML实际上将在NeurIPS的所有三个举办地都有活动。所以，在墨西哥城、哥本哈根，当然还有圣地亚哥的主要研讨会现场，都会有WiML的身影。这真是太棒了。

而且，除此之外，我认为正如你所说，该组织现在能够做的远不止是研讨会本身。例如，WiML现在为机器学习领域的女性和非二元性别个体运行着一个全球性的导师计划，参与者会被匹配一位导师，他们可以参加这些一对一的导师会议、研讨会和小组讨论，这些活动全年都在进行。我想他们每年大约有50位导师注册，但我相信他们总是需要更多。嗯，回顾过去，看到WiML社区所取得的成就和它的成长，真是令人惊叹。

一方面，老实说，我认为创立WiML是我职业生涯中所做的事情之一，如果不是最让我感到自豪的事情的话……

沃拉赫：哦，是的，我也是。

沃特曼·沃恩：……直到今天，但与此同时，我们不能把功劳归于自己。这就像是一个社区共同努力的结果。

沃拉赫：是的。

沃特曼·沃恩：正是这个社区真正推动着我们前进……

沃拉赫：是的。

沃特曼·沃恩：……在过去的20年里，

沃拉赫：是的。

沃特曼·沃恩：……所以这很棒。我不再滔滔不绝了，但这真的很了不起。

沃拉赫：而且这些年来发生变化的不仅仅是WiML。整个行业也发生了巨大的变化。

随着整个AI和机器学习领域的变化，以及你自己从学术界到工业界的转变，你的研究是如何演变的？

沃特曼·沃恩：这是个很好的问题。你知道，我们之前稍微提到过这一点，但我们的研究路径确实以不同的方式演变，但最终到达了这些非常相似的地方——我们都在从事负责任AI的研究，倡导跨学科方法，融入人机交互等技术。我认为这部分是由于社区的转变以及工业界正在发生的事情。在工业界从事负责任AI工作，肯定永远不缺乏有趣的问题需要解决，对吧。

我认为对我们两人来说，我们近年的研究兴趣确实是由我们看到的这些非常实际的挑战所驱动的。我们都早期参与了在微软内部定义负责任AI含义的工作，制定了我们内部的《负责任AI标准》（在新标签页中打开）。我领导了公司内部一个关于AI透明度的跨部门工作组，该工作组既关注我们之前讨论的模型可解释性，也关注其他形式的透明度，比如数据集的数据说明书，以及微软现在随我们所有产品发布的透明度说明。与此同时，你正在领导一个关于公平性的内部工作组。

沃拉赫：是的，接手那个内部工作组可以说是我职业生涯中的一个重大转折点。你知道，当我加入微软时，我专注于计算社会科学，并且完全只做研究，并没有真正参与公司其他部门的事务。

然后在我加入微软第一年年底，我参加了第一届“机器学习中的公平、问责与透明度”研讨会（在新标签页中打开），该研讨会与NeurIPS同期举办，是NeurIPS的研讨会之一。我对此感到非常兴奋，并想，太好了，我打算花大约20%的时间，也许每周一天，研究公平、问责和透明度领域的课题。嗯，结果并非如此。

在接下来的几年里，我最终做了越来越多关于负责任AI的研究，正如你所说，涉及公平性、可解释性等主题。然后在2018年初，我被邀请共同主持这个关于公平性的内部工作组，从那时起，我开始更多地参与微软全公司范围内的负责任AI事务，而不仅仅是微软研究院内部。

这让我非常兴奋，因为负责任AI当时非常新，这意味着研究可以发挥非常重要的作用。这不像是一个已经成熟的领域，工程和政策人员都清楚知道自己在做什么。

这意味着我得以从这种非常偏重研究的工作中拓展出来，更多地与政策、工程等领域的人士合作，从事应用性更强的工作。
事实上，如今我不仅是一名研究者，还在微软研究院内部领导一个名为"社会技术对齐中心"（简称STAC）的小型应用科学团队，专门致力于弥合负责任人工智能领域的研究与实践之间的鸿沟。

沃特曼·沃恩：确实。你认为参与WiML（Women in Machine Learning）是否对这项工作产生了影响？
沃拉赫：是的，毫无疑问。[笑] 特别是在从事与公平性相关的课题时，作为我负责任人工智能工作的一部分，我最终将大量精力集中在与边缘群体相关的事务上。
因此，在我的机器学习工作和WiML相关工作中，一直存在着对边缘群体（尤其是女性）的关注，同时在我的研究工作中也始终思考公平性问题。
WiML影响我工作的另一个重要方面是，如今我与比以往更加多元化的群体合作，而过去我只专注于机器学习、计算社会科学等领域。我的许多合作者都是这些年来通过WiML结识的。

沃特曼·沃恩：当然，行业内部最近还发生了另一个重大转变，即生成式AI引发的热潮。能否谈谈这如何改变了你的研究？
沃拉赫：好的，这确实是另一个重大变化。它从多方面改变了我的工作。其中最重要的一个方面是，生成式AI系统现已无处不在，被广泛应用于各种场景。我们看到许多关于GenAI系统的新闻头条，比如诊断疾病、解决数学问题、编写代码等等。同时也有关于使用生成式AI可能产生各种风险的报道，例如捏造事实、记忆受版权保护的数据、生成有害内容等。面对如此多的关注，很自然地会问：这些说法的证据何在？证据从何而来？我们是否应该相信这些证据？
事实证明，许多证据来自对GenAI系统能力、行为和影响的评估。但当前该领域常用的评估实践，其科学严谨性往往不如我们所愿，这确实是个问题。
最大的挑战之一在于，人们在进行GenAI评估时所关注的概念——如诊断能力、记忆性、有害内容等——比生成式AI时代之前支撑机器学习评估的"预测准确性"这类概念要抽象得多。
当我们审视这些评估GenAI系统所需关注的新概念时，发现它们实际上更类似于社会科学中研究的那些抽象且有争议的概念——那些模糊、难以精确界定的概念。比如政治学中的"民主"，或心理测量学中的"人格特质"。这里确实存在着与这些"软性"概念的关联。
当我主要专注于计算社会科学时，我的大部分工作都集中在开发机器学习方法，以帮助社会科学家测量抽象且有争议的概念。因此，当GenAI开始成为重要事物，我看到所有这些涉及抽象概念测量的评估主张时，我清楚地意识到，如果我们想要真正对AI能做什么、不能做什么做出有意义的论断，就需要对GenAI评估采取不同的方法。
于是，我最终借鉴了我在计算社会科学中关于测量的工作，并开始倡导采用社会科学家用于测量抽象争议概念的框架的一个变体。我这样做是因为我相信——现在仍然相信——这是提高GenAI评估科学严谨性的重要途径。
你当然了解这一切，因为今年夏天在ICML（国际机器学习大会）上，你和我，以及微软研究院、斯坦福大学和密歇根大学的其他一些合作者，共同发表了一篇关于这个框架的立场论文，题为《评估GenAI系统是一项社会科学测量挑战》。

你目前对什么感到兴奋？
沃特曼·沃恩：是的，最近我花了很多时间思考AI与批判性思维：我们如何设计AI系统，以支持适当的依赖、保持人类能动性，并真正鼓励人类进行批判性参与？
我认为在这个领域，我们实际上拥有巨大的机遇，但也存在巨大的风险。如果让我设想对AI未来最乐观的愿景——这对我来说并不容易，因为你知道我天生不是乐观主义者——那将是一个AI帮助人们成长和繁荣的未来，它能够丰富我们人类自身的能力，加深我们人类的思考，并保障我们自身的能动性。
在这样的未来里，我们能够构建出真正帮助我们进行头脑风暴、学习新知识和技能的AI系统，无论是在正规的教育环境中，还是在我们的日常工作中。但我认为，我们不会自然而然地实现这个未来。如果我们想要到达那里，这确实是我们需要精心设计的目标。

沃拉赫：你提到了风险。你看到了哪些风险？
沃特曼·沃恩：是的，这里确实利害攸关。短期来看，存在诸如过度依赖的风险——即使系统出错，也依赖AI系统的输出。这是我本人深入研究过的问题。还存在丧失能动性或独立决策及执行能力的风险，以及确保AI系统的结果与使用这些系统的人的个人或职业价值观相一致的风险。这是我最近在新闻业AI工具背景下一直在研究的问题。还有创新力减弱的风险，我指的是创造力或思想多样性的丧失。
从长远来看，我们面临技能萎缩的风险——由于长期使用AI系统，人们可能会失去或根本无法发展对其职业或生活有益的技能。人们常举的著名例子是，飞行员因依赖自动驾驶系统而丧失执行某些飞行动作的能力。我认为，由于AI，我们已经开始在各种领域看到类似的情况发生。
最后，我要提到的另一个风险，似乎引起了许多与我交谈的人的共鸣，我称之为"乐趣丧失"。当我们把那些真正能从中获得乐趣和满足感的活动部分委托给AI系统时，会发生什么。

沃拉赫：那么，作为一个社区，如果我们担心这些风险，我们应该做些什么？
沃特曼·沃恩：是的，我的意思是，如果我们想要实现这个目标，这必须是一个巨大的社区共同努力。这是一个宏伟的目标。但我认为有几个方面尤其需要着力。
我认为，我们需要为AI系统构建者制定通用的原则和实践，指导他们如何以促进人类能动性和鼓励批判性思维的方式来构建AI系统。我们同样需要为系统用户制定原则和实践。

那么，我们该如何教导大众以能增强其技能和能力、并帮助他们学习新事物的方式来使用人工智能呢？
接着，我相信这也是你非常关心的一点，我认为我们需要在衡量和评估方面做更多工作。我们又一次回到了这些难以捉摸的人类特质上。
我提到过，我在生成式人工智能系统的过度依赖方面做过一些研究，我之所以从那里开始，是因为在风险的宏观尺度上，过度依赖是相对容易衡量的，至少短期内如此。但我们该如何开始思考，在各种情境下、大规模地、在长时间跨度上，去衡量人们使用人工智能时的批判性思维呢？我们该如何衡量人工智能系统对我们整个群体的批判性思维所产生的、那种纵向的影响呢？
顺便提一下，如果听众中有人会参加WiML研讨会，我实际上将就此主题发表一个主旨演讲。对此我感到无比兴奋，首先是因为我对这个主题本身非常兴奋，其次，在WiML整整20年的历史中，我做过几次开幕致辞和类似发言，但这实际上将是我第一次在那里谈论我自己的研究。所以这就像我的梦想一样。我很激动这件事能成真。

**沃拉赫：** 太棒了。哦，真令人兴奋。太好了。
那么，最后一个问题。如果你能回到20年前，给当时的自己一些建议，你会说什么？

**沃特曼·沃恩：** 好的，过去一周我对此思考了一下，我想提三点。
首先，我会告诉自己，要勇敢地表达。你知道，我算是极度内向的人，天生非常害羞，这一直阻碍着我。现在仍然如此。直到我职业生涯中晚得令人尴尬的时候，我才决定为此做点什么，并开始制定策略来帮助自己更多地发言。最终，这开始变得稍微自然了一些。

**沃拉赫：** 什么样的，嗯，什么样的策略？

**沃特曼·沃恩：** 是的，举个例子，我会用很多笔记。为了这次播客，我准备了很多笔记。我是个重度依赖笔记的人，类似这样的方法确实对我有帮助。
我想告诉自己的第二点是，去研究那些你真正希望看到被解决的问题。作为研究人员，我们拥有选择自己方向的惊人自由。早期，我研究的很多问题都是我日常思考时真正享受的。那很有趣。对我来说，它们就像小小的数学谜题。但我常常发现，当我在会议上，人们问起我的工作时，我并不真的想谈论这些问题。从某种意义上说，我只是觉得做起来有趣，但我并不真正在意。我对它没有热情。我不在乎自己是否解决了问题。
所以，很多年前，当我思考自己的研究议程时，我从我们实验室的前主任詹妮弗·蔡斯那里得到了很好的建议。她建议我回顾近期的项目，把它们分成两类：一类是我真的很喜欢做的——日常体验很有趣；另一类是我事后喜欢谈论的，并且对结果感到满意的，然后看看两者的交集在哪里。这件事，我现在说起来可能听起来有点显而易见，但在当时，这真的让我豁然开朗。

**沃拉赫：** 这太酷了。现在我也，有点想，对我所有的项目都这么做，尤其是现在。实际上，正如你所知，我刚刚休了五个月产假，因为我刚生了孩子。所以，当我重新投入这一切时，我正在对所有事情进行一次大的盘点，我很喜欢这个想法。我觉得这真的很酷。

**沃特曼·沃恩：** 这真的改变了我整个研究方式。就像，我们刚才谈到的，我现在做的大部分工作更偏向人机交互，而不是机器学习，因为我发现真正激励我、让我想在会议上与人交流的，是那些关于人的问题。
我想给自己的第三条建议是，你应该让更多人参与到你的工作中来。
外界有一种看法，认为研究是单打独斗的事业，有时会让人觉得竞争非常激烈，对吧。我们都有这种感觉。但一次又一次，我看到最好的研究来自于合作，来自于将具有不同视角的人聚集在一起，他们能以相互尊重的方式挑战彼此，从而使工作变得更好。
你有什么建议想给20年前的自己吗？

**沃拉赫：** 有的。好的。过去一周我也一直在思考这个问题。实际上，我觉得我有很多建议想给过去的自己，[笑] 但有三点是我反复想到的。
好的，首先——这和你的第二点类似——努力去做你觉得最有成就感的工作，即使这意味着要走一条非传统的道路。就我而言，我一直对社会科学感兴趣。回想我还是学生的时候，即使是在读博士期间，做结合计算机科学和社会科学的研究根本就不是主流。因此，结果很可能是，我很容易就会想：“哦，好吧，我想那是不可能的。我还是专注于传统的计算机科学问题吧。”
但那并不是我最终的选择。相反，我最终选择了推动，而且常常是以让我的职业生涯可能比原本更艰难的方式。我不断推动，事实上，直到现在，我仍在继续推动，以跨学科的方式将计算机科学和社会科学结合起来。这并不容易。但累积起来的效果是，我能够做出比我原本可能做的更有影响力的工作，而且我对我所做的工作的享受程度，也远超原本可能的情况。
好的，第二点，勇敢地分享你的工作。这实际上是对现在的我和过去的我的建议，因为我肯定仍然在这方面挣扎。

**沃特曼·沃恩：** 我也是，你知道，实际上，听你这么说我觉得很有趣，因为我觉得你在这方面比我做得好得多。

**沃拉赫：** 我仍然觉得，我在这方面还有很多工作要做。是的，这很难。真的很难。
如你所知，我是个完美主义者，这在某些方面是好的，但在其他方面则不然。其中一个不好的方面是，我对于分享和宣传我的工作会感到非常焦虑，尤其是当我感觉它还不完美的时候。
举个例子，2015年我为ICML写了一篇关于计算社会科学的大篇幅教程，但我从未把幻灯片……我还为它写了完整的讲稿……我从未把幻灯片或讲稿作为资源放到网上，因为我觉得它还需要更多完善。实际上，今年早些时候，当我们在做ICML论文时，我回去看了一下，我惊呆了，因为它很棒。为什么我当时没把它放到网上？所有那些我十年前认为是问题的地方，不，它们根本没什么大不了的。我本应该分享出来的。
再举一个例子，我的应用科学团队STAC，早在2022年，在“LLM-as-a-judge”（大语言模型作为评判者）这种范式普及之前，就已经将LLM作为我们GenAI评估方法的一部分了。

但我当时非常担心，别人会因此对我们产生负面看法，所以我们没有过多分享正在做的事情。现在想来很遗憾，因为我们错失了就此开启一场行业讨论的机会——关于这种"LLM即评判者"的范式。

那么，我的第三点是：研究的社会层面与技术层面同等重要。这里我指的不是社会科学和计算机科学的区别，而是说开展研究的方式——包括你与谁交流、与谁合作、如何处理这些互动——与研究本身同样重要。

在读博士期间，我对于花时间与其他研究者进行社交活动（尤其是在会议上）感到非常不安，因为我总觉得应该去听讲座、读论文、与研究者讨论技术话题，而不是社交。但事后看来，我认为这种想法是错误的。许多这样的社交联系最终对我的研究产生了难以置信的价值，不仅因为我最终与那些最初通过社交认识的人展开了合作，甚至在某些情况下还聘用了他们……

沃特曼·沃恩：是的。

沃拉赫：……还因为我建立的友谊，比如我们之间的友谊，这些年来已成为至关重要的支持网络，尤其是在感到特别困难的时刻。

沃特曼·沃恩：是的，完全同意。我对此深有同感。

说到这里，我要非常感谢你今天和我一起录制这期播客。

沃拉赫：谢谢。

沃特曼·沃恩：回顾WiML过去20年，以及我们职业生涯和友谊的这20年，真的非常愉快。这太棒了，而且如果不是和你一起，我绝不会同意做这件事。

沃拉赫：我也是。[笑声]

感谢各位收听我们的对话。希望你们中有些人能参加12月2日举行的第20届"机器学习领域的女性"年度研讨会（在新标签页中打开）。当然，我和珍都会亲自到场。之后我们也会参加NeurIPS。如果想与我们交流或了解更多今天讨论的内容，欢迎随时联系我们。

[音乐]

结束语：您收听的是《思想》——微软研究播客。更多播客节目请访问 aka.ms/researchpodcast（在新标签页中打开）。

[音乐渐弱]

[1] 沃拉赫后来澄清，2005年神经信息处理系统会议的注册人数约为900人。


> 本文由AI自动翻译，原文链接：[Ideas: Community building, machine learning, and the future of AI](https://www.microsoft.com/en-us/research/podcast/ideas-community-building-machine-learning-and-the-future-of-ai/)
> 
> 翻译时间：2026-01-05 13:12
