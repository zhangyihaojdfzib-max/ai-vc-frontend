---
title: AutoBNN：组合式贝叶斯神经网络实现概率时间序列预测
title_original: 'AutoBNN: Probabilistic time series forecasting with compositional
  bayesian neural networks'
date: '2024-03-28'
source: Google AI Blog
source_url: http://blog.research.google/2024/03/autobnn-probabilistic-time-series.html
author: null
summary: 本文介绍了谷歌研究院开源的AutoBNN工具包，它将传统概率方法的可解释性与神经网络的可扩展性相结合，用于时间序列预测。AutoBNN采用组合式贝叶斯神经网络结构，替代传统高斯过程，在保留可解释性的同时，显著降低了计算成本，并支持GPU/TPU加速。该工具实现了多种基础核与组合运算符，能够自动发现模型并提供高质量的不确定性估计，适用于大规模数据集。
categories:
- AI工程
tags:
- 时间序列预测
- 贝叶斯神经网络
- 概率建模
- 开源工具
- JAX
draft: false
translated_at: '2026-01-04T23:51:14.715Z'
---

AutoBNN：利用组合式贝叶斯神经网络进行概率时间序列预测  
2024年3月28日  
作者：Urs Köster，谷歌研究院软件工程师  

AutoBNN 将传统概率方法的可解释性与神经网络的可扩展性和灵活性相结合，能够利用复杂数据构建精密的时间序列预测模型。  

快速链接  

时间序列问题无处不在，从预测天气和交通模式到了解经济趋势皆是如此。贝叶斯方法始于对数据模式的假设（先验概率），通过收集证据（例如新的时间序列数据）持续更新该假设，最终形成后验概率分布。传统贝叶斯方法（如高斯过程和结构时间序列）被广泛用于时间序列数据建模，例如常用的莫纳罗亚火山二氧化碳数据集。然而，这些方法通常依赖领域专家费力地选择合适的模型组件，且计算成本可能很高。神经网络等替代方案则缺乏可解释性，难以理解其生成预测的机制，且无法提供可靠的置信区间。  

为此，我们推出 AutoBNN——一个基于 JAX 编写的新开源工具包。AutoBNN 能自动发现可解释的时间序列预测模型，提供高质量的不确定性估计，并可有效扩展以适用于大型数据集。本文将阐述 AutoBNN 如何融合传统概率方法的可解释性与神经网络的可扩展性和灵活性。  

AutoBNN  

AutoBNN 基于过去十年间的一系列研究成果，这些研究通过使用具有学习核结构的高斯过程对时间序列建模，提升了预测准确性。高斯过程的核函数编码了对被建模函数的假设，例如趋势、周期性或噪声的存在。通过学习得到的高斯过程核，核函数以组合方式定义：它可以是基础核（如线性核、二次核、周期核、Matérn 核或指数二次核），也可以是通过加法、乘法或变点等运算符组合两个及以上核函数形成的复合核。这种组合核结构服务于两个相关目的：首先，它足够简单，让熟悉自身数据但不一定精通高斯过程的用户能为时间序列构建合理的先验；其次，序列蒙特卡洛等技术可用于对小结构进行离散搜索，并输出可解释的结果。  

AutoBNN 对这些思路进行了改进，在保留组合核结构的同时，用贝叶斯神经网络替代高斯过程。贝叶斯神经网络是一种权重服从概率分布而非固定权重的神经网络，这导致了输出的分布，从而能捕捉预测中的不确定性。与高斯过程相比，贝叶斯神经网络具有以下优势：首先，训练大型高斯过程计算成本高昂，传统训练算法的时间复杂度与时间序列数据点数量的立方成正比；相比之下，对于固定宽度的网络，训练贝叶斯神经网络通常与数据点数量近似呈线性关系。其次，相较于高斯过程训练操作，贝叶斯神经网络更适合 GPU 和 TPU 硬件加速。第三，组合式贝叶斯神经网络能轻松与传统深度贝叶斯神经网络结合，后者具备特征发现能力。我们可以设想一种“混合”架构：用户指定顶层结构为 Add(Linear, Periodic, Deep)，而深度贝叶斯神经网络则负责学习潜在高维协变量信息的贡献。  

那么，如何将具有组合核的高斯过程转化为贝叶斯神经网络呢？单层神经网络通常在神经元数量（即“宽度”）趋于无穷时收敛为高斯过程。最近，研究者发现了反向的对应关系——许多常见的高斯过程核（如 Matérn 核、指数二次核、多项式核或周期核）可通过选择适当的激活函数和权重分布，作为无限宽度的贝叶斯神经网络获得。此外，即使宽度远未达到无限，这些贝叶斯神经网络仍与对应的高斯过程高度接近。例如，下图展示了观测值对之间的协方差差异，以及真实高斯过程与其对应宽度为 10 的神经网络版本的回归结果。  

最后，通过定义贝叶斯神经网络中对应于高斯过程的加法与乘法运算符，并引入输入扭曲以生成周期核，完成了整个转换过程。贝叶斯神经网络的加法直接通过叠加组件网络的输出实现；乘法则通过将各贝叶斯神经网络隐藏层的激活值相乘后应用共享的全连接层来实现。因此，我们仅限于对具有相同隐藏层宽度的贝叶斯神经网络进行乘法运算。  

使用 AutoBNN  

AutoBNN 工具包内置于 TensorFlow Probability 中，基于 JAX 实现并使用 flax.linen 神经网络库。它实现了前文讨论的所有基础核与运算符（线性核、二次核、Matérn 核、指数二次核、周期核、加法、乘法），并新增了一种核和三种运算符：  
- OneLayer 核：单隐藏层 ReLU 贝叶斯神经网络  
- ChangePoint 运算符：允许在两个核之间平滑切换  
- LearnableChangePoint 运算符：与 ChangePoint 类似，但位置和斜率被赋予先验分布并可从数据中学习  
- WeightedSum 运算符  

WeightedSum 以可学习的混合权重组合两个及以上贝叶斯神经网络，其中可学习权重服从狄利克雷先验分布。默认使用浓度为 1.0 的平坦狄利克雷分布。  

WeightedSum 支持“软”结构发现，即同时训练多个可能模型的线性组合。与 AutoGP 等基于离散结构的发现方法不同，这允许我们使用标准梯度方法学习结构，而无需昂贵的离散优化。WeightedSum 让我们能并行评估潜在组合结构，而非串行评估。  

为便于探索，AutoBNN 定义了多种包含顶层或内部 WeightedSum 的模型结构。这些模型的名称可用作任何估计器构造函数的首个参数，例如 sum_of_stumps（所有基础核的 WeightedSum）和 sum_of_shallow（将所有基础核与所有运算符的可能组合相加）。  

下图展示了在 M3 数据集的 N374（始于 1949 年的年度财务时间序列）上进行结构发现的技术示例。六种基础结构为指数二次核（即径向基函数核，简称 RBF）、Matérn 核、线性核、二次核、OneLayer 核和周期核。图中展示了 32 个粒子集合中这些核权重的最大后验估计。所有高似然粒子均赋予周期成分较大权重，赋予线性、二次和 OneLayer 核较低权重，并赋予 RBF 或 Matérn 核较大权重。  

通过将 WeightedSum 作为其他运算符的输入，可以表达丰富的组合结构，同时保持模型紧凑且可学习权重数量较少。例如，我们提供的 sum_of_products 模型（如下图所示）首先创建两个 WeightedSum 的成对乘积，然后对两个乘积求和。通过将部分权重设为零，可以创建多种不同的离散结构。该模型中可能的结构总数达 2^16 种，因为 16 个基础核均可独立启用或关闭。

所有这些结构仅通过训练这一个模型就能被隐式地探索。

然而，我们发现，某些核函数的组合（例如，Periodic核与Matern核或ExponentiatedQuadratic核的乘积）会在许多数据集上导致过拟合。为了防止这种情况，我们定义了像`sum_of_safe_shallow`这样的模型类，该类在使用WeightedSums进行结构发现时会排除此类乘积。

对于训练，AutoBNN提供了AutoBnnMapEstimator和AutoBnnMCMCEstimator来分别执行MAP和MCMC推理。任一估计器都可以与六种似然函数中的任何一种结合使用，其中包括四种基于正态分布（针对连续数据，具有不同的噪声特性）的似然函数，以及两种基于负二项分布（针对计数数据）的似然函数。

要拟合如上图所示的模型，只需使用受scikit-learn启发的估计器接口，编写如下10行代码：

```
import autobnn as ab
model = ab.operators.Add(
    bnns=(ab.kernels.PeriodicBNN(width=50),
          ab.kernels.LinearBNN(width=50),
          ab.kernels.MaternBNN(width=50)))
estimator = ab.estimators.AutoBnnMapEstimator(
    model, 'normal_likelihood_logistic_noise',
    jax.random.PRNGKey(42),
    periods=[12])
estimator.fit(my_training_data_xs, my_training_data_ys)
low, mid, high = estimator.predict_quantiles(my_training_data_xs)
```

结论
AutoBNN为构建复杂的时间序列预测模型提供了一个强大而灵活的框架。通过将BNN和GP的优势与组合核函数相结合，AutoBNN为理解和预测复杂数据开启了无限可能。我们诚邀社区尝试colab，并利用这个库进行创新，解决现实世界的挑战。

致谢
AutoBNN由Colin Carroll、Thomas Colthurst、Urs Köster和Srinivas Vasudevan编写。我们要感谢Kevin Murphy、Brian Patton和Feras Saad的建议和反馈。

---

> 本文由AI自动翻译，原文链接：[AutoBNN: Probabilistic time series forecasting with compositional bayesian neural networks](http://blog.research.google/2024/03/autobnn-probabilistic-time-series.html)
> 
> 翻译时间：2026-01-04 23:51
