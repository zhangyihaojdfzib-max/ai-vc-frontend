---
title: BigCodeArena：首个通过代码执行端到端评估AI代码生成的平台
title_original: 'BigCodeArena: Judging code generations end to end with code executions'
date: '2025-10-07'
source: Hugging Face Blog
source_url: https://huggingface.co/blog/bigcode/arena
author: ''
summary: 本文介绍了BigCodeArena，这是一个创新的“人在回路”评估平台，旨在解决AI代码生成模型难以可靠评估的问题。与仅检查源代码的传统基准不同，该平台允许用户提交编程任务，让不同模型生成代码，并在隔离沙箱中实际执行这些代码，从而观察运行结果、测试交互功能并比较输出质量。平台支持多种编程语言和框架，并已通过社区收集了大量真实场景的偏好数据，为代码生成模型的端到端评估提供了更贴近实际开发环境的解决方案。
categories:
- AI产品
tags:
- 代码生成
- 模型评估
- 人在回路
- 编程工具
- AI基准测试
draft: false
translated_at: '2026-01-29T04:04:54.897039'
---

# BigCodeArena：通过代码执行端到端评估代码生成质量

评估AI生成代码的质量是出了名的困难。人类可以轻易判断一段代码是否"看起来正确"，但要确定它是否实际运行正常、能否妥善处理边界情况、以及能否产生预期结果，则需要运行和测试它。正因如此，今天我们激动地宣布推出**BigCodeArena**——首个通过代码执行来评估代码生成模型的"人在回路"平台。

受LLM评估平台LMArena的启发，我们构建了一个允许任何人并排比较代码生成模型的平台，但有一个关键区别：**您可以实际运行代码并查看其输出结果**。只需提交一个编程任务，观察两个不同模型生成解决方案，执行两个程序，然后投票选出哪个模型产生了更好的结果。所有结果将整理成排行榜，展示社区评分最高的模型。

## 动机

代码生成领域长期缺乏可靠的评估方法。像HumanEval这样的传统基准测试通过预定义测试用例来检验代码，但这些仅代表了现实世界编程任务的极小部分。虽然存在面向通用聊天机器人的人类评估平台，但它们对代码评估效果不佳：阅读原始源代码并在脑海中模拟其执行过程对认知要求很高且容易出错，特别是对于较长的程序或复杂的UI应用程序。

考虑以下场景：

您要求两个AI模型构建一个响应式图片画廊网站。两者都生成了语法正确的代码。但哪个实际上更好？如果不运行代码，几乎无法判断。一个可能生成美观实用的网格布局，而另一个可能存在细微错误或样式问题——这些只有在浏览器中渲染时才会显现。

![bigcodearena-demo](/images/posts/62036f578ce6.png)

这一观察让我们得出关键见解：**执行反馈对于人类可靠判断代码质量至关重要**。而这正是BigCodeArena所提供的。

## BigCodeArena平台

BigCodeArena在Chatbot Arena框架基础上扩展了专为代码评估设计的强大功能：

### 实时执行

模型生成的每个代码片段都会在隔离的沙箱环境中自动执行。无论是Python脚本、React Web应用、PyGame游戏还是C++算法，您都能看到实际输出，而不仅仅是源代码。

### 多语言与框架支持

我们目前支持10种语言（Python、JavaScript、TypeScript、HTML、C、C++、Java、Go、Rust和Markdown）和8种执行环境：

- Web框架：React、Vue、Core Web（原生HTML/CSS/JS）
- Python框架：Streamlit、Gradio、PyGame
- 图表：Mermaid
- 通用解释器：Python和JavaScript代码解释器，以及编译语言运行器

### 交互式测试

与静态代码比较不同，您可以实际与生成的应用程序进行交互：

- 在Web应用中点击按钮并测试UI元素
- 试玩模型生成的游戏
- 编辑代码并重新运行以测试修改
- 查看可视化输出（如图表、图形和示意图）

![bigcodearena](/images/posts/bf4f4dd079e5.png)

### 多轮对话

真实的编程并非一蹴而就。BigCodeArena支持多轮交互，允许您细化需求、请求添加功能或要求修复错误——就像与真实的编程助手协作一样。

## 我们的发现：5个月的社区评估

自2025年2月推出以来，BigCodeArena已收集来自500多名独立用户的**超过14,000次对话**，以及**4,700多份高质量偏好投票**，比较了10个前沿LLM。

### 真实场景中的编程主题

我们的用户探索了极其多样化的编码场景：

- Web设计（36%）：构建响应式网站、交互式仪表板和Web应用
- 问题解决（23%）：算法、数据结构和计算挑战
- 游戏开发（16%）：创建包含物理效果、碰撞检测和图形的交互式游戏
- 科学计算（14%）：数据分析、可视化和数值模拟
- 创意编程（8%）：艺术可视化、生成艺术和实验性界面
- 图表创建（3%）：流程图、系统架构和数据可视化

---

> 本文由AI自动翻译，原文链接：[BigCodeArena: Judging code generations end to end with code executions](https://huggingface.co/blog/bigcode/arena)
> 
> 翻译时间：2026-01-29 04:04
