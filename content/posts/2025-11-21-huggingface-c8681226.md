---
title: 开放ASR排行榜新增多语言与长音频赛道，揭示模型性能趋势
title_original: 'Open ASR Leaderboard: Trends and Insights with New Multilingual &
  Long-Form Tracks'
date: '2025-11-21'
source: Hugging Face Blog
source_url: https://huggingface.co/blog/open-asr-leaderboard
author: null
summary: 文章介绍了开放ASR排行榜新增多语言和长音频转录赛道后的关键发现。研究显示，结合Conformer编码器和LLM解码器的模型在英语准确性上领先，但速度较慢；CTC/TDT解码器则提供高吞吐量。多语言模型存在泛化与专精的权衡，而长音频转录目前闭源系统仍具优势，但开源模型如Whisper和Parakeet也展现出潜力。文章还提供了模型微调指南，并指出社区正推动更多语言和场景的基准测试。
categories:
- AI研究
tags:
- 语音识别
- ASR
- 多模态AI
- 基准测试
- 开源模型
draft: false
translated_at: '2026-01-06T01:04:47.787Z'
---

**开放ASR排行榜：新增多语言与长音频赛道趋势与洞察**

当所有人（甚至他们的奶奶👵）都在推出新的ASR模型时，为你的用例选择合适的模型，可能比选择下一部Netflix剧集更令人不知所措。截至2025年11月21日，Hub上已有150个音频-文本到文本模型和27K个ASR模型🤯。

大多数基准测试都侧重于短格式英语转录（<30秒），而忽略了其他重要任务，例如（1）多语言性能和（2）模型吞吐量，后者对于会议、播客等长音频而言可能是决定性因素。

过去两年，开放ASR排行榜已成为在准确性和效率上比较开源与闭源模型的标准。最近，排行榜新增了多语言和长音频转录赛道🎉。

**TL;DR - 开放ASR排行榜**
*   📝 基于排行榜的ASR趋势新预印本：https://hf.co/papers/2510.06961
*   🧠 **最佳准确性**：Conformer编码器 + LLM解码器（开源获胜 🥳）
*   ⚡ **最快速度**：CTC / TDT解码器
*   🌍 **多语言**：以牺牲单语言性能为代价
*   ⌛ **长音频**：闭源系统仍领先（目前 😉）
*   🧑💻 **微调指南**（Parakeet, Voxtral, Whisper）：持续推动性能提升

**60多个模型的关键发现**

截至2025年11月21日，开放ASR排行榜比较了来自18个组织的60多个开源和闭源模型，覆盖11个数据集。

在最近的一篇预印本中，我们深入探讨了技术设置，并重点介绍了现代ASR的一些关键趋势。以下是一些重要发现👇。

**1. Conformer编码器 🤝 LLM解码器位居榜首 📈**
结合Conformer编码器与大语言模型（LLM）解码器的模型目前在英语转录准确性上领先。例如，英伟达的Canary-Qwen-2.5B、IBM的Granite-Speech-3.3-8B和微软的Phi-4-Multimodal-Instruct实现了最低的词错误率（WER），这表明集成LLM推理能力可以显著提升ASR准确性。
💡 **专业提示**：英伟达推出了Fast Conformer，这是Conformer的一个速度提升2倍的变体，已用于其Canary和Parakeet系列模型。

**2. 速度与准确性的权衡 ⚖️**
虽然准确性很高，但这些LLM解码器往往比更简单的方法慢。在开放ASR排行榜上，效率使用逆实时因子（RTFx）衡量，数值越高越好。
对于更快的推理，CTC和TDT解码器提供了10-100倍的吞吐量，尽管错误率略高。这使得它们非常适合实时、离线或批量转录任务（如会议、讲座或播客）。

**3. 多语言 🌍**
OpenAI的Whisper Large v3仍然是一个强大的多语言基线，支持99种语言。然而，像Distil-Whisper和CrisperWhisper这样的微调或蒸馏变体，在纯英语任务上通常优于原始模型，这显示了有针对性的微调如何提升专业化程度（如何微调？查看Whisper、Parakeet和Voxtral的指南）。
话虽如此，专注于英语往往会减少多语言覆盖范围 👉 这是专业化与泛化之间权衡的经典案例。同样，虽然像Meta的大规模多语言语音（MMS）和Omnilingual ASR这样的自监督系统可以支持1000多种语言，但它们在准确性上落后于特定语言的编码器。
⭐ 虽然目前仅对五种语言进行了基准测试，但我们计划扩展到更多语言，并期待通过GitHub拉取请求为多语言ASR贡献新的数据集和模型。
🎯 除了多语言基准测试，一些社区驱动的排行榜专注于个别语言。例如，开放通用阿拉伯语ASR排行榜比较了现代标准阿拉伯语和地区方言的模型，突显了语音变异和双言现象对当前系统的挑战。同样，俄语ASR排行榜为在俄语特定音系和形态学上评估编码器-解码器和CTC模型提供了一个不断发展的中心。这些本地化努力反映了更广泛的多语言排行榜的使命，即鼓励数据集共享、微调检查点和透明的模型比较，尤其是在ASR资源较少的语言中。

**4. 长音频转录是另一回事 ⏳**
对于长音频（例如播客、讲座、会议），闭源系统仍然略胜一筹。这可能归因于领域调优、自定义分块或生产级优化。
在开源模型中，OpenAI的Whisper Large v3表现最佳。但在吞吐量方面，基于CTC的Conformer表现出色 👉 例如，英伟达的Parakeet CTC 1.1B实现了2793.75的RTFx，而Whisper Large v3为68.56，且词错误率仅适度增加（分别为6.68和6.43）。
权衡是什么？Parakeet仅支持英语，这再次提醒我们多语言与专业化之间的权衡🫠。
⭐ 虽然闭源系统仍领先，但开源创新在此领域潜力巨大。长音频ASR仍然是社区接下来要攻克的最激动人心的前沿领域之一！

**🎤 未完待续**
鉴于ASR发展如此迅速，我们期待看到哪些新架构能推动性能和效率，以及开放ASR排行榜如何继续作为该领域透明、社区驱动的基准，并为其他排行榜（俄语、阿拉伯语和语音深度伪造检测）提供参考。

我们将继续扩展开放ASR排行榜，纳入更多模型、更多语言和更多数据集，敬请关注👀。

👉 想贡献一份力量？请前往GitHub仓库提交拉取请求 🚀


> 本文由AI自动翻译，原文链接：[Open ASR Leaderboard: Trends and Insights with New Multilingual & Long-Form Tracks](https://huggingface.co/blog/open-asr-leaderboard)
> 
> 翻译时间：2026-01-06 01:04
