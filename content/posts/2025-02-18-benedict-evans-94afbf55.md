---
title: 深度研究功能之困：AI生成报告的准确性与信任危机
title_original: The Deep Research problem — Benedict Evans
date: '2025-02-18'
source: Benedict Evans
source_url: https://www.ben-evans.com/benedictevans/2025/2/17/the-deep-research-problem
author: Benedict Evans
summary: 本文以OpenAI深度研究功能生成的智能手机市场份额报告为例，揭示了当前AI研究工具的局限性。作者指出，大语言模型擅长理解模糊问题意图，但在需要精确数据检索和来源判断时表现不佳。报告使用了Statcounter和Statista等有问题的数据源，甚至出现日本市场iOS与Android份额数据完全颠倒的错误。核心矛盾在于：AI试图从概率性问题中输出确定性答案，而任何错误都会导致整个报告不可信。这不仅是准确率百分比的问题，更是关于AI能否胜任需要专业判断的深度研究工作。
categories:
- AI产品
tags:
- 大语言模型
- AI研究工具
- 数据准确性
- OpenAI
- 信息检索
draft: false
---

深度研究的问题
我的日常工作主要是研究和分析。我会构思想要查看的数据并着手寻找；我整理和核对数据，制作图表，觉得它们乏味就重新尝试，寻找新的方法和数据来理解和解释问题，最终产出试图表达我想法的文字和图表。然后我会就此与他人进行讨论。

这通常涉及大量的手工劳动——每张图表背后都隐藏着冰山般的工作量——而OpenAI的深度研究功能看起来像是为我量身定制的。那么，它真的适合吗？

我本可以用一个新问题亲自测试它，但在耗费时间和资金之前，碰巧OpenAI自己的产品页面上有一份关于我相当熟悉的领域——智能手机——的示例报告。让我们来看一看。

这个表格看起来很棒——原本需要数小时工作来汇编的数据，现在全部由机器为我完成了。然而，在把它交给客户之前，我们还是先核对几件事。首先，数据来源是什么？

啊。

我们有两个来源：Statista和Statcounter。Statcounter作为衡量“采用率”的指标是有问题的——它衡量的是流量，而众所周知，不同设备的使用方式不同，高端设备使用更频繁，iPhone偏向高端且使用率也更高。正如我会向实习生解释的那样（我常把AI比作实习生），你确实不能用它来做这个。与此同时，Statista则汇总他人的数据，确保其在搜索引擎优化中排名靠前，然后试图让你注册或付费查看结果。我认为谷歌应该将这家公司从索引中剔除，但即使你不同意，说这是来源就像说来源是“一个谷歌搜索结果”。同样，这是一个实习生级别的问题。

不过，暂且抛开这点，让我们再深入挖掘一下，看一个具体数字——日本。深度研究称日本智能手机市场iOS占69%，Android占31%。这引出了两个问题：这些来源是这么说的吗？它们对吗？这是两种非常不同的问题。

首先，Statcounter尽管如上所述高估了iPhone份额，但实际上并没有给出69%的数据，或者说至少一年多来都没有。嗯。

如果我们查看Statista，必须经过一番周折，但最终发现实际来源是研究公司Kantar Worldpanel，而它给出的数字与深度研究声称的几乎完全相反——Android占63%，iOS占36%。哦。

我们可以继续深究。Kantar的数据月波动高达20个百分点，这不符合硬件存量市场的通常规律，让我不确定它真正追踪的是什么。我们也可以去核对表格中的其他数字，但如果我必须核对表格中的每一个数字，那它并没有为我节省任何时间——我还不如自己动手做。值得一提的是，日本监管机构对我们这里寻找的实际数字进行了一项调查（第25页），显示存量市场份额约为Android 53%，iOS 47%。啊。

我们对此怎么看？

LLM（大语言模型）不是数据库：它们不进行精确、确定、可预测的数据检索，像测试数据库那样测试它们是无关紧要的。但这并不是我们在这里试图做的事情——这是一个更复杂、更有趣的测试。

首先，OpenAI的示例使用了一个不精确的问题：它询问“采用率”，但这意味着什么？我们是在问销量、存量市场份额、使用份额，还是应用支出份额？这些是不同的东西。你想要哪个？其次，找到其中任何一个问题的答案也是不精确的——没有单一的来源可以查询，你需要一些判断力或专业知识来决定使用哪个来源——如上所述，你应该采用Statcounter、Statista、Kantar本身，还是其他东西？

也就是说，这两者实际上都不是直接的“数据库查询”类型的问题——OpenAI是在向模型提出一个概率性问题，而不是一个确定性问题。但那个问题的答案却是确定性的——在弄清楚你真正想要什么以及选择哪种答案之后，你想要的是实际的数字。我们是在从一个概率性问题中寻求一个确定性答案，而看起来模型确实在其自身层面上失败了。在我看来，或者根据我的专业知识，它不应该使用Statcounter或Statista，但即使应该，它也没有从它们那里获取正确的数字。

这让我想起几年前的一个观察：LLM擅长计算机不擅长的事情，而不擅长计算机擅长的事情。OpenAI试图让模型推断出你可能的意思（计算机在这方面真的很差，但LLM擅长），然后让模型进行高度具体的信息检索（计算机擅长这个，但LLM不擅长）。而这并不太奏效。记住，这不是我的测试——这是OpenAI自己的产品页面。OpenAI承诺这款产品能做到它实际上做不到的事情，至少不完全能做到，正如其自身营销材料所展示的那样。

在这个阶段，明显的回应是说模型在不断改进，但这没有抓住重点。你是想告诉我今天的模型把这个表格做对了85%，下一个版本会做到85.5%或91%正确吗？这对我没有帮助。如果表格中有错误，有多少错误并不重要——我无法信任它。另一方面，如果你认为这些模型将达到100%正确，那将改变一切，但这也会是这些系统性质上的根本性改变，而非百分比变化，而且我们不知道这是否可能。

同时，需要明确的是，我专注于一个数字是因为它易于检查和测试，但同样的概念性问题也适用于十页文本：在很大程度上，深度研究会基本正确，但也仅仅是基本正确。

退一步讲，我写这些时心情矛盾，因为我能说这些系统非常出色，但又总是在重要的事情上出错，所以迄今为止最好的用例是那些错误率无关紧要或易于察觉的领域。直接说这些系统非常棒并且一直在改进，就此打住，或者声称错误率意味着它们是自NFT以来最大的时间和金钱浪费，会容易得多。但探索困惑，正如我在这里真正做的，似乎更有趣。

而且这些东西是有用的。如果有人要求你就一个你拥有深厚专业知识的主题撰写一份20页的报告，而你手头并没有现成的20页资料，那么这可以将几天的工作缩短到几个小时，并且你可以修正所有错误。我总是称AI为“无限的实习生”，在我刚才写的内容中有很多可供任何实习生学习的时刻，但也有史蒂夫·乔布斯的那句话：计算机是“思维的自行车”——它能让你用更少的力气走得更远更快，但它自己哪儿也去不了。

再退一步，我认为这里存在两个根本问题。首先，重复一遍，我们不知道错误率是否会消失，因此我们不知道是应该构建那些预设模型有时会出错的产品，还是一两年后我们将构建那些预设我们可以完全依赖模型本身的产品。这与从个人电脑到网络再到智能手机等其他重要技术的局限性截然不同，那些技术我们原则上知道什么能改变、什么不能。我刚才谈到的深度研究的问题会得到解决吗？这个问题的答案将催生两种不同类型的产品。

其次，OpenAI和所有其他基础模型实验室除了资本获取外，没有护城河或防御性，它们在编码和营销之外没有产品市场契合，也没有真正的产品，只有文本框——以及供他人构建产品的API。

深度研究（Deep Research）是众多尝试中的一种，旨在打造一款具有用户粘性的产品，并实例化一个应用场景。但一方面，Perplexity声称几天后推出了同样的功能；另一方面，当前管理错误率的最佳方式似乎是将LLM（大语言模型）抽象为软件内部可管理的API调用——这当然使得基础模型本身更加商品化。事情最终会走向这个结局吗？我们无从得知。

---

> 本文由AI自动翻译，原文链接：[The Deep Research problem — Benedict Evans](https://www.ben-evans.com/benedictevans/2025/2/17/the-deep-research-problem)
> 
> 翻译时间：2026-01-05 17:03
