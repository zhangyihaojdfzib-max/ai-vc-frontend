---
title: "联邦AI立法路线图：保护民众、赋能建设者、赢得未来"
title_original: "A Roadmap for Federal AI Legislation: Protect People, Empower Builders, Win the Future"
date: 2026-01-06
source: "Andreessen Horowitz (a16z)"
source_url: "https://a16z.com/a-roadmap-for-federal-ai-legislation-protect-people-empower-builders-win-the-future/"
summary: "本文提出美国联邦AI立法的九大支柱框架，主张打破创新与安全对立的虚假选择，通过明确责任归属、加强儿童保护、评估国家安全风险等措施，构建既能保障民众安全又能促进竞争与创新的监管环境。文章强调应防止AI成为责任盾牌，为未成年人提供适度保护而非全面禁止，并以证据为基础评估AI在国家安全领域的风险，最终目标是让小型科技企业（初创公司）能在健康市场中成长，确保美国在AI时代的全球竞争力。"
categories:
  - VC观点
tags: ["AI治理", "政策法规", "创新竞争", "风险管控", "创业生态"]
draft: false
---

华盛顿关于人工智能治理的辩论常陷入一系列虚假选择：将创新与安全对立，进步与保护对立，联邦领导力与各州权利对立。但在a16z，我们认为这些并非二元对立。美国要真正实现人工智能的全部潜力，就必须既打造卓越产品，又保护人们免受AI相关危害。国会能够且应当设计一个联邦AI框架，在保护个人与家庭的同时，也守护创新与竞争。这一路径将让我们所称的"小型科技企业"——初创公司和创业者——在推动美国未来增长的同时，有效应对真实风险。

在a16z，我们着眼长远。我们的基金周期长达10至20年，这意味着我们关注的是投资可信赖的产品、稳健的企业和持久的市场——这些将在未来数十年持续繁荣。以牺牲可持续工具和健康市场为代价追求短期估值，对我们投资的创始人、托付资本的投资者、我们的公司都极为不利，最重要的是，对美国人民和企业有害无益。若导致AI产品不安全、不可靠或具有误导性的繁荣-萧条周期出现，那将是失败而非胜利。

联邦AI立法应引领我们走向不同方向：让AI赋能人类，带来社会经济效益。明智的监管对于确保AI长期助力社会繁荣、美国初创企业能在全球舞台竞争至关重要。若说这一愿景有何核心，那便是竞争：缺乏竞争，消费者将获得更差的产品、更慢的进步和更少的选择。而小型科技企业是竞争的关键：没有初创企业，资金雄厚的大型现有企业将掌控市场。

愿景清晰，问题在于如何实现。

关键的第一步是颁布联邦AI立法，为AI治理设定明确标准。我们已就适合小型科技企业的AI政策进行论述，但鉴于共和党与民主党均呼吁国会采取行动，现在是将核心要素整合的时候。以下九大支柱将我们的工作转化为具体政策议程，既能保障美国人安全，又能保持美国领先地位。

**1. AI不应成为责任盾牌**
当恶意行为者利用AI违法时，他们不应躲在技术背后。若有人使用AI系统实施欺诈，其行为仍属欺诈；若企业部署的AI工具在招聘或住房领域存在歧视，民权法应当适用；若公司以不公平或欺骗性方式使用AI，该行为仍应受州和联邦消费者保护法约束。核心原则很简单：AI不是"免罪金牌"。

联邦AI框架应明确这一原则：
当然，禁止将AI作为责任盾牌不意味着剥夺合理抗辩权。被告仍应被允许使用成文法或普通法中的任何抗辩理由；在过失案件中，法官在判定法律责任时仍应考虑被告是否实施了符合行业及企业规模适用最佳实践的善意措施与保障机制。

**2. 加强对儿童的保护**
AI可能伤害任何人，但儿童尤为脆弱。未成年人自我保护能力较弱，且伤害后果可能更严重。因此立法者应考虑为儿童制定额外保护措施。

与其他在线服务类似，13岁以下儿童使用AI服务应获得家长同意。需注意：由于获取同意的实际困难，多数科技服务完全禁止低龄儿童使用。当服务商知晓用户为13-17岁未成年人时，应提供额外保护。

在此情况下，服务商应为家长提供实质性控制权：设置隐私与内容权限、设定使用限制或禁用时段、获取工具使用基本信息。同时应向未成年人清晰说明系统性质：这是AI而非人类；不是持证专业人士（如心理健康服务提供者）；不适用于自杀危机等紧急情况；不能替代持证心理健康服务。

立法者制定这些要求时，应避免全面禁止未成年人使用AI。正如加州州长加文·纽森否决一项过度限制未成年人使用AI产品的提案时所言："我们不能通过完全禁止青少年使用这些工具来为他们迎接AI无处不在的未来做准备。"立法应注意区分"剥夺能力"与"提供保护"，并保持在宪法范围内。

立法者还应要求服务商制定应对特定情况的规程，如用户表达自杀意念或自残倾向时。规程应包含如何拒绝协助用户自我伤害（包括提供自杀方法信息），以及如何将危机用户转介至自杀预防资源。

除上述责任外，立法者应考虑对侵害未成年人的行为（如利用AI引诱或贩卖未成年人）设定民事与刑事处罚。同理，协助自杀禁令不应为涉及AI的情况开设例外。

**3. 评估国家安全风险**
联邦立法还应提升政府对AI在国家安全等高风险领域边际风险的理解。可指定技术型、注重标准的联邦机构来识别、测试和评估国家安全相关能力——例如AI在化学、生物、放射性和核武器攻击中的应用，或规避人类控制的能力。这项工作应咨询独立专家和AI研究人员，以理解现有风险并建立评估程序。此类测量基础设施将确保政策回应相称：能力管理应基于证据而非新闻头条。同样的证据导向方法应指导政策制定者思考AI在进攻性与防御性网络行动中的作用。

AI正以更大规模和更高复杂程度增强民族国家、跨国网络犯罪组织和独立黑客的能力。随着AI技术更易获取，即使技术能力有限者也能对关键基础设施发起复杂攻击。因此，尽管目前只有最复杂的国家级行为体和网络犯罪组织从事此类攻击，未来AI可能使更多国家及其他威胁行为体具备这种能力。但与某些创造不对称攻防能力的技术不同，AI不会产生净新增风险，因为它同时增强攻击者与防御者的能力。联邦框架必须赋能而非限制AI的防御性使用。限制防御策略可能人为制造不对称优势，使攻击者更容易锁定关键基础设施。

AI公司间关于模型可能被用于网络犯罪的信息共享是打击网络攻击的关键对策，但反垄断关切可能限制信息共享程度。因此有针对性的例外条款允许必要时的信息共享至关重要。金融系统因在网络犯罪货币化中的核心作用而尤其易受攻击，但金融机构受制于过时的模型验证规则，阻碍了AI防御的实施。应通过立法和监管改革消除这些障碍。最后，政府应采购部署最先进的防御性AI解决方案。

**4. 实施透明化要求**
透明度有助于人们对使用的AI产品做出知情选择。正如营养标签提供基本信息帮助消费者选择食品，披露一套"AI模型事实"能帮助人们更好地使用AI模型。

同时，政府强制披露信息可能带来挑战：政府披露规定面临宪法约束——若强制企业披露非事实性、具争议性或过度繁琐的信息可能违宪。过于宽泛或繁重的规定对小型科技企业尤其困难，它们无法像大型企业那样承担合规成本。对小型科技企业而言，繁重的披露要求威胁其竞争能力。正如白宫前副首席技术官詹妮弗·帕尔卡所言："文书工作偏爱强者。"

若强制披露未能提供有用信息也可能产生问题。为透明而透明只会增加成本而非价值。立法者设计透明义务时应以人为本：哪些信息能帮助人们做出符合偏好的决策？

若要实现有利于消费者、合法且不过度加重初创企业负担的透明度，立法者可考虑要求基础模型开发者披露以下信息：
- 模型训练数据的主要类别与来源
- 模型的核心能力与局限性
- 已知风险及相应缓解措施
- 持续监控与更新计划
能力较弱的模型应豁免此要求，且披露不应要求企业公开商业秘密或模型权重。

**5. 明确联邦与州的角色划分**
近期关于AI治理的辩论常将联邦与州角色对立：或因涉及州际贸易而主张联邦独享监管权，或因各州是民主实验室且国会尚未颁布全面AI立法而主张州拥有无限监管权。

这两种极端都未体现宪法对州与联邦权力的分配：双方在AI监管中都扮演重要角色。国会应制定管理全国AI市场的规则，各州则监管其境内的AI有害使用。这意味着国会应在模型开发监管中发挥主导作用，因为开源和专有工具必然跨越州界。这也意味着各州应有权执行本州刑事与民事法律，在消费者保护、民权、儿童安全和心理健康等领域禁止AI的有害使用。而在保险、教育等传统属州立法范畴的领域，各州可发挥主导作用。

联邦框架可通过明确国会在AI开发监管中的领导地位来厘清各自角色，同时设置安全港条款，明确各州保留监管AI使用和裁决侵权索赔的能力。

清晰规则对双方都有利：开发者获得可预测的模型构建与部署规则，各州保留保护居民免受具体伤害的必要工具。

**6. 培养适应AI的劳动力**
实现AI的经济社会潜力需要适应AI的劳动力。这意味着支持工人和学生向AI技能决定成败的经济转型，正如当今使用互联网的能力对经济成功至关重要。

支持向AI劳动力转型包括以下方面：
- 扩大STEM教育机会
- 投资职业培训与再培训项目
- 创建行业-教育合作伙伴关系
- 支持终身学习计划

**7. 降低市场准入门槛**
联邦框架可在增强AI市场竞争方面发挥重要作用。方案之一是设立国家AI竞争力研究所，帮助创业者、小企业、研究机构和政府机构降低准入门槛。该机构可提供算力、精选数据集、基准测试评估工具和开源软件环境。此类共享基础设施减少重复建设，为小型项目提供可靠的实验、迭代和成长途径。

开放数据集可能特别有价值。研究所用户可访问非个人数据的开放存储库，政府可确保这些数据集包含政府资助的研究成果。作为该计划的一部分，政府可优先在法律允许且适当时开放自有数据集用于AI训练研究，并创建以公共利益管理的"开放数据公地"。

能源是另一结构性约束。大规模AI模型需要大量算力和能源，因此联邦框架应帮助增加能源供应，同时确保初创企业不被高价挤出或排挤。能源政策应确保消费者和小型科技企业不会在未获得相应收益的情况下承担超大规模企业的能源需求成本。

**8. 投资基础研究**
学术研究与AI产品开发始终紧密相连。大学和公共实验室的突破常孕育定义新一代技术的公司与工具。因此支持这项研究对公共和私营部门的长期创新至关重要。

政府支持应优先关注基础性和颠覆性AI研究。可包括：
- 针对挑战现有范式的高风险高回报"登月项目"的专项资金
- 涵盖短期、中期和长期的平衡研究组合
有前景的研究主题广泛：如何为AI密集型经济设计有效的工人再培训计划；开源工具在促进竞争与安全中的作用；利用AI防御网络威胁；AI改善政府服务提供的潜力。对这些问题的结构化公共研究可为政策提供依据，塑造更有效的产品。

为最大化影响，联邦资助应在可能时要求非敏感研究数据以机器可读格式在允许AI训练和评估的许可下共享。开放这些研究将使公共资金转化为公共基础设施。

**9. 推动政府采用AI**
AI有潜力改善政府运作和公共服务提供方式。每个联邦机构都应制定明确、有时限的计划，说明如何通过AI提升运营效果并降低成本，同时保持公众信任。

作为计划的一部分，机构应定期评估工作流程，确定AI可自动化常规任务、改进大数据集分析和支持更好决策的环节。某些情况下，机构可能需要采购AI工具协助现代化改造。任何采购流程都应让小型科技企业能够参与，且不应在适当时禁止获取开源工具。

机构还应实施试点项目，在大规模部署前测试评估AI工具在特定功能中的应用。这些试点应包含评估影响的明确指标。适当时，机构应就试点项目的设计、实施和评估咨询外部专家。

任何政府内部AI使用都应遵守管理预算办公室发布的使用政策。这些政策应定期更新，反映从试点、机构实施以及不断发展的技术和法律标准中获得的经验。

**结语**
国会采取行动的时机就是现在。数百万美国人日常使用AI，越来越多共识认为这项技术有能力惠及经济和社会。我们知道美国必须赢得全球AI竞赛。美国人民希望他们的代表采取行动，创建安全繁荣的市场，使美国在AI领域引领世界。

不作为会带来其他风险。维持现状将导致AI市场竞争更弱、集中度更高，从而迫使人们使用更差、创新更少的AI产品。

国会不必在保护人民与保护竞争之间做选择。通过确立正确的优先事项和政策，它可以兼顾两者：建立全面框架保护儿童和成人免受AI危害，同时为新进入者敞开构建、创新和成功的大门。

**作者简介**
杰伊·拉马斯瓦米担任安德森·霍洛维茨基金首席法律与政策官，负责法律、合规和政府事务职能。
科林·麦丘恩担任安德森·霍洛维茨基金政府事务主管，负责公司的政治与政策战略。
马特·佩罗特担任安德森·霍洛维茨基金人工智能政策主管，负责公司AI政策战略，并帮助投资组合公司应对AI政策环境。

---

> 本文由AI自动翻译，原文链接：[A Roadmap for Federal AI Legislation: Protect People, Empower Builders, Win the Future](https://a16z.com/a-roadmap-for-federal-ai-legislation-protect-people-empower-builders-win-the-future/)
