---
title: 苹果AI战略：生成式AI是技术而非产品，强调背景与隐私
title_original: Apple intelligence and AI maximalism — Benedict Evans
date: '2024-06-20'
source: Benedict Evans
source_url: https://www.ben-evans.com/benedictevans/2024/06/20/apple-intelligence
author: Benedict Evans
summary: 本文分析了苹果在生成式AI领域的独特战略。与追求通用聊天机器人的“AI极致主义”不同，苹果将AI视为嵌入系统的商品化技术，而非独立产品。其核心在于：1）将AI功能拆解并融入现有操作系统和应用，利用设备端背景信息提供个性化服务；2）强调隐私，通过端侧和私有云处理数据；3）区分“背景模型”与“世界模型”，将开放式查询交由第三方处理。苹果的策略依赖于其十亿级用户平台和硬件生态，试图在AI浪潮中构建防御性优势。
categories:
- AI产品
tags:
- 苹果
- 生成式AI
- AI战略
- 端侧智能
- 隐私计算
draft: false
translated_at: '2026-01-05T17:05:19.595Z'
---

苹果智能与AI极致主义
目前，苹果公司之外尚未有人真正使用过任何苹果智能功能。该功能将于秋季分阶段推出，即便如此，它也无法在80%或90%的iPhone现有设备上运行，因为它需要仅在iPhone 15 Pro上才具备的端侧处理能力。实际效果永远不及演示（初代iPhone除外），苹果可能再次搞砸开发者激励，并且这一切可能并不像看起来那么美好。我们拭目以待。

但与此同时，如果你从演示和截图中抽身，审视其战略，会发现苹果指出了生成式AI中大部分关键问题与杠杆点，并提出了一套关于其如何运作的论点，这与所有的炒作和鼓吹截然不同。

"AI极致主义"的观点认为，具备多模态和"多智能体"能力的通用聊天机器人，将能够接管如今需要大量不同专门软件才能完成的广泛复杂多阶段任务和问题，并且还能自动化处理以前软件根本无法完成的全新复杂任务类别，同样通过一个单一的通用界面实现。聊天机器人或许能用一个提示词取代所有软件——"软件已死"。我对此持怀疑态度，正如我此前所写，但苹果提出的观点恰恰相反：生成式AI是一项技术，而非一个产品。

我认为，苹果正在传递一种观点：生成式AI，包括ChatGPT本身，是一种商品化技术，当它满足以下条件时最为有用：
1.  嵌入一个能为其提供更广泛用户背景信息的系统（可能是搜索、社交、设备操作系统或垂直应用）中；
2.  被拆解为独立的功能（同上），这些功能天生更容易在边缘侧的小型、高能效设备上作为小型、高能效模型运行（由用户付费，而非你的资本支出预算）——这正好，因为……
3.  如果用户每次点击"确定"我们都有边际成本，并且需要新建一大批核电站来运行这一切，那么这项技术永远无法面向大众市场。

那么，首先：苹果构建了一个没有聊天机器人的LLM（大语言模型）。苹果构建了自己的基础模型，根据其公布的基准测试，这些模型与市场上任何其他模型不相上下，但你无法在任何地方直接将原始提示词输入模型并获取原始输出——总会有按钮和选项集来塑造你的请求，并且针对不同功能，会以不同方式呈现给用户。在大多数这些功能中，根本看不到机器人的身影。你不是在提问并得到回答：相反，你的邮件被优先排序，或者你点击"总结"，摘要就会出现。你可以向Siri输入请求（Siri本身只是众多使用苹果模型的功能之一），但即便如此，你得到的也不是原始模型输出：你得到的是图形用户界面。LLM（大语言模型）被抽象为一次API调用。

这意味着苹果的基础模型不会像Gemini那样，建议你在披萨上涂胶水，原因很简单：你根本无法让它回答那种开放性问题。苹果将此视为一项技术，用于实现新类别的功能和能力，由设计和产品管理来塑造技术的行为和用户的所见，而不是一个你向其索求的神谕。

相反，"神谕"只是一个功能，苹果正在区分"背景模型"和"世界模型"。苹果的模型能够访问你手机所拥有的关于你的所有背景信息，从而驱动这些功能，并且这一切都是私密的，无论是在设备端还是在苹果的"私有云"中。但如果你询问如何利用一张你购买杂货的照片来创作，那么这就与你的背景无关了，苹果会提议将其发送给第三方世界模型——目前是ChatGPT。世界模型确实接受开放式提示词并确实会给你原始输出，它可能告诉你把胶水涂在披萨上，但这被明确区分为一种不同的体验，你应有不同的预期，当然，这也是OpenAI的品牌风险，而非苹果的。同时，那个世界模型得不到你的任何背景信息，只有你的一次性提示词。

我们尚需观察苹果的背景模型实际效果如何，但原则上，它看起来确实相当具有防御性。无论是OpenAI还是其他新兴公司的云模型（Anthropic、Mistral等），都没有你的电子邮件、消息、位置、照片、文件等信息。谷歌确实拥有世界模型，并且如果你使用Android，它也能访问你的背景信息，但这在美国是明显的少数（而且，能够本地处理这些功能的Android用户比例甚至比iPhone用户比例更低）。微软的AI PC拥有部分此类背景信息，尤其是工作背景，但对如今大多数人而言，智能手机才是拥有所有真实背景信息的主要设备，而非PC。Meta拥有那些背景信息吗？可能有一部分。未来某个时候，这里将引发一场有趣的反垄断讨论。但关键在于，你需要先拥有自己的十亿级用户平台才能构建这个：你无法从零开始，仅凭一个网站就做到。

另一方面，OpenAI在这种关系中的定位有多强的防御性？并不强。

去年五月，一份泄露的谷歌备忘录声称LLM（大语言模型）领域没有护城河，因为每个人基本上都能获得相同的训练数据，并且会出现优秀的开源模型。这几乎就是已经发生的情况：唯一的护城河是资本和获取英伟达芯片的渠道（目前而言），根据不同的计算方式，市场上存在从六七个到十几个顶级模型，OpenAI领先，但优势并不足够大。苹果并未声称其新的基础模型在所有方面都是最好的，但它似乎足以满足其想要提供的功能需求。这不会像搜索或操作系统那样发展——目前尚无迹象表明会出现明显的赢家通吃效应。苹果可以构建自己的基础模型——这不过是资金问题。

因此，OpenAI（显然）被"免费"分发给数亿苹果用户，并承担所有推理成本，以换取向用户推销高级订阅服务的机会（尽管纵观苹果WWDC的所有演示，尚不清楚它将如何做到这一点）。但它同时也被当作一个可互换的插件来对待。这里有一个非常明显的类比：谷歌每年支付200亿美元给苹果，以成为默认搜索引擎。苹果AI主管约翰·詹南德雷亚在本周活动后明确做出了这个比较——"我有点把它看作Safari处理搜索引擎的方式"——而克雷格·费德里吉表示，他认为不同的问题可能会使用不同的"世界模型"。这意味着，苹果可能会将航班问题发送给一个世界模型，而将烹饪查询发送给另一个。

但是，网络搜索是正确的类比吗？还是我们应该看看地图？苹果认为，试图构建一个与谷歌一样好的搜索引擎没有意义，其他人也未能真正成功。另一方面，苹果确实构建了地图，尽管初期搞砸了，但苹果地图现在至少"足够好"，因为同样，除了资本之外没有真正的护城河。已经很清楚的是，OpenAI不是新的谷歌：不会只有一个赢家。

而且，可以肯定的是，苹果自己构建并在其私有云中运行的基础模型本身就是一个"世界模型"，你可以向它询问披萨食谱——只是到目前为止，苹果决定不提供那种用户界面。苹果让OpenAI承担创造披萨胶水食谱的品牌风险，让错误率和滥用问题成为别人的麻烦，而自己则安全地隔岸观火。下一步，可能是向Bing和谷歌招标默认位置，但与此同时，越来越多的用例将悄然从第三方转移到苹果自己的模型上。

归根结底，是苹果自家的软件决定查询请求的去向，以及哪些请求真正需要第三方参与。

当然，这并非新鲜事——早在 Llama 3 发布时（甚至更早），情况就已明朗：LLM（大语言模型）将成为以边际成本出售的商品，核心问题在于你在此基础上构建什么产品——这也是 OpenAI 聘请 Kevin Weil 担任产品负责人的原因。但苹果也指出，一整个类别的 LLM 产品将构建在云端大语言模型无法触及之处，或者仅需一个 API 调用的场景中。

这引出了一个更广泛的论点。科技界有句老话：每个人都在试图将别人的产品商品化、将自己的产品免费化，或者两者兼施。Meta 正在免费提供 Llama（包括模型、权重，目前甚至在其应用中免费提供嵌入查询），而那些超大规模云服务商则希望为模型收费，因为 Meta 希望其成为廉价的商品化基础设施，并通过上层的服务和功能实现差异化。苹果正在做非常类似的事情。运行“苹果智能”的大量计算发生在用户设备上，由用户而非苹果的资本支出预算买单，而且“苹果智能”是免费的。（我们尚不清楚苹果私有云的成本，以及本地查询与云端查询的可能比例。）英伟达上季度售出了 250 亿美元的 AI 芯片，超大规模云服务商今年可能在数据中心上花费约 1500 亿美元，但全球智能手机市场规模超过 4000 亿美元，PC 市场超过 2000 亿美元，而这些是由你的用户支付的。这些数字并非直接可比（显然如此！），但这是一个相关的比较。没人能确切知道几年后情况会如何——模型会变得更大，但效率也会更高，边缘计算会更快——但存在非常强大的驱动力，促使尽可能多的计算转移到设备端。

商品化往往也意味着集成。曾几何时，“拼写检查”是一个需要花费数百美元单独购买的产品，市场上有数十种竞争产品，但随着时间的推移，它首先被集成到文字处理器中，然后是操作系统。上一波机器学习浪潮也发生了同样的事情——风格迁移或图像识别作为独立产品只存在了很短时间，随后就变成了功能。如今，“总结这份文档”是 AI 功能，你需要一个每月 20 美元的云端大语言模型，但明天操作系统将免费提供此功能。“AI 就是那些尚未奏效的东西。”

我也好奇这对英伟达意味着什么。正如我经常且谨慎指出的，我不是芯片分析师，而真正的芯片和数据中心分析师经常谈论英伟达的护城河，既包括芯片本身，也包括其构建的开发者软件生态。苹果足够强大，可以走自己的路，就像它将 Mac 迁移到自研芯片一样：它控制着芯片之上的软件和 API，这些是开发者网络效应的基础，并且它拥有世界级的芯片团队以及台积电的优先供应渠道。当今还有谁能与之相比？谷歌的 TPU 吗？似乎不太可能有很多其他科技公司，即使是巨头，会构建自己完全定制的、从芯片到图形用户界面的 AI 技术栈。变革之处在于模型运行的位置：完整的基础模型目前还无法装入手机，但真实用例越是源于将那个模型和“预言机”拆解为功能，推理就越可能更快地转向边缘。苹果再次指出了这个问题。

最后，所有这些都还只是假设。就在 18 个月前，这些都还未实现，我们尚未达到产品市场契合（PMF）。许多发达国家高达半数人口已经尝试过生成式 AI，但其中一半人从未尝试第二次。对于如此新的事物，这是极高的认知度，但并非真正的用户粘性。我们不知道产品会是什么样，市场会如何，科学会如何发展，一切仍在飞速变化。可能在 Agent（智能体）或错误率方面会有新的突破，彻底改变用例。

与此同时，现有巨头总是试图将新事物变成一项功能。谷歌和微软在过去 18 个月里将大语言模型“喷洒”到其所有产品中，每一家企业级 SaaS 公司也是如此：我的前同事 Steven Sinofsky 说，“互联网上的每个文本框都将获得一个大语言模型”。苹果的做法略有不同——它提出为你手机上的所有操作建立一个统一的上下文模型，并基于此驱动功能，而不是在公司内部各个互不相连的点上添加互不关联的、由 LLM 驱动的功能。但它仍然试图将“颠覆性”的新技术变成一项功能，并试图将 ChatGPT 装入一个盒子，限制在相当狭窄的用例范围内，并且可以与 Anthropic 或 Gemini 互换。

正如开头所说，这确实是关于生成式 AI 未来的唯一核心问题——这是一种新的通用工具，由一家公司的一款产品完成数百家公司数百款软件的工作，还是一种通用技术，将为数百或数千家公司的产品内部赋能功能？


> 本文由AI自动翻译，原文链接：[Apple intelligence and AI maximalism — Benedict Evans](https://www.ben-evans.com/benedictevans/2024/06/20/apple-intelligence)
> 
> 翻译时间：2026-01-05 17:05
