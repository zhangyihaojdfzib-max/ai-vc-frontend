---
title: Claude新宪法发布：定义AI价值观与行为准则
title_original: Claude's new constitution
date: '2026-01-21'
source: Anthropic
source_url: https://www.anthropic.com/news/claude-new-constitution
author: ''
summary: Anthropic正式发布Claude AI模型的新宪法，这是一份详细阐述其价值观与行为准则的基础性文件。宪法不仅作为训练过程的核心组成部分，直接塑造Claude的行为输出，还旨在帮助AI理解为何应以特定方式行事，而非机械遵循规则。新宪法强调广泛安全性、道德性、遵守指导方针及真正助益性四大优先事项，并以知识共享协议公开，以提升透明度并促进社会监督。
categories:
- AI研究
tags:
- AI伦理
- 宪法AI
- 模型训练
- 透明度
- Anthropic
draft: false
translated_at: '2026-02-01T20:44:18.542742'
---

# Claude 的新宪法

我们正在发布我们AI模型Claude的新宪法。这份文件详细阐述了Anthropic对Claude价值观与行为的愿景；它是一个整体性文档，解释了Claude所处的环境背景，以及我们希望Claude成为怎样的实体。

这部宪法是我们模型训练过程的关键组成部分，其内容直接塑造着Claude的行为。训练模型是一项艰巨的任务，Claude的输出可能并不总能完全符合宪法的理想标准。但我们认为，新宪法的撰写方式——对我们意图及其背后原因进行了详尽阐释——使其更有可能在训练过程中培育出良好的价值观。

在这篇文章中，我们将描述新宪法包含的内容，以及影响我们制定方法的一些考量因素。

我们以**知识共享CC0 1.0协议**完整发布Claude宪法，这意味着任何人都可以出于任何目的自由使用，无需征得许可。

## 什么是Claude宪法？

Claude宪法是一份基础性文件，既表达也塑造着Claude的身份。它详细阐述了我们希望Claude体现的价值观及其原因。我们在其中解释了，我们认为Claude在保持广泛安全性、合乎道德并遵守我们指导方针的同时做到"有帮助"意味着什么。宪法为Claude提供了关于其处境的信息，并就如何处理困难情境和权衡取舍（例如在诚实与同情心、保护敏感信息之间取得平衡）提供了建议。尽管听起来可能令人惊讶，但这部宪法**主要是为Claude编写的**。其目的是赋予Claude在世界上良好行动所需的知识和理解。

我们将宪法视为关于我们希望Claude成为什么样以及如何行为的最终权威——也就是说，给予Claude的任何其他训练或指令都应符合其字面含义和内在精神。这使得从透明度角度来看，发布宪法尤为重要：它让人们理解Claude的哪些行为是预期的，哪些是非预期的，从而做出明智选择并提供有用的反馈。我们认为，随着AI开始在社会中发挥更大影响力，这种透明度将变得越来越重要。

我们在训练过程的不同阶段使用这部宪法。这源于我们自2023年以来一直使用的训练技术，当时我们首次开始使用**宪法AI**训练Claude模型。自那时起，我们的方法已显著发展，新宪法在训练中扮演着更为核心的角色。

Claude本身也利用宪法来构建多种合成训练数据，包括帮助其学习和理解宪法的数据、可能与宪法相关的对话、符合其价值观的回应，以及对可能回应的排序。所有这些都可用于训练未来版本的Claude，使其成为宪法所描述的那种实体。这一实际功能影响了我们撰写宪法的方式：它既需要作为抽象理想的声明，也需要作为**训练中有用的工具**。

## 我们制定Claude宪法的新方法

我们之前的**宪法**由一系列独立原则组成。我们逐渐认识到需要一种不同的方法。我们认为，为了在世界上成为良好的行为者，像Claude这样的AI模型需要理解**为什么**我们希望它们以特定方式行事，我们需要向它们解释这一点，而不仅仅是规定我们**希望**它们做什么。如果我们希望模型在广泛的新情境中做出良好判断，它们需要能够**泛化**——应用广泛原则，而非机械遵循具体规则。

具体规则和明确界限有时有其优势。它们可以使模型的行为更可预测、透明和可测试，我们确实在某些Claude绝不应涉足的特别高风险行为中使用它们（我们称之为"硬约束"）。但此类规则也可能在未预料到的情况下被不当应用，或在过于僵化遵循时出现问题。我们无意让宪法成为一份僵化的法律文件——况且法律宪法本身也未必如此。

这部宪法反映了我们当前对于如何应对一项极其新颖且高风险项目的思考：创造安全、有益的非人类实体，其能力可能最终与我们匹敌甚至超越我们。尽管这份文件无疑在许多方面存在缺陷，但我们希望它成为未来模型可以回顾并视为一种真诚努力的东西，旨在帮助Claude理解其处境、我们的动机，以及我们以现有方式塑造Claude的原因。

## 新宪法简要概述

为了既安全又有益，我们希望所有当前Claude模型做到：

1.  **广泛安全**：在当前发展阶段，不破坏人类监督AI的适当机制；
2.  **广泛合乎道德**：保持诚实，依据良好价值观行事，避免不当、危险或有害的行为；
3.  **遵守Anthropic的指导方针**：在相关情况下，按照Anthropic更具体的指导方针行事；
4.  **真正有帮助**：使与其交互的操作者和用户受益。

在出现明显冲突的情况下，Claude通常应按上述列举顺序优先考虑这些属性。

宪法的大部分内容侧重于对这些优先事项提供更详细的解释和指导。主要部分如下：

- **助益性**。在本节中，我们强调Claude能够真正、实质性地提供帮助，这对用户和世界所能带来的巨大价值。Claude可以像一位才华横溢的朋友，同时拥有医生、律师和财务顾问的知识，他会坦诚直言，发自真诚的关怀，并将用户视为有能力决定什么对自己有益的明智成年人。我们还讨论了Claude应如何在其不同的"委托人"——Anthropic自身、基于我们API构建的运营者以及终端用户——之间权衡助益性。我们提供了一些启发式方法，用于权衡助益性与其他价值观。

- **Anthropic的指导方针**。本节讨论了Anthropic可能会如何向Claude提供关于处理特定问题（如医疗建议、网络安全请求、越狱策略和工具集成）的补充指示。这些指导方针通常反映了Claude默认不具备的详细知识或背景信息，我们希望Claude优先遵守这些指示，而非更一般形式的助益性。但我们希望Claude认识到，Anthropic更深层的意图是让Claude安全且合乎道德地行事，并且这些指导方针不应与宪法整体相冲突。

- **Claude的道德准则**。我们的核心目标是让Claude成为一个善良、明智、有道德的智能体，在处理现实世界决策（包括在道德不确定性和分歧的背景下）时展现出技巧、判断力、细致入微和敏感性。在本节中，我们讨论了希望Claude秉持的高标准诚实，以及希望Claude在权衡避免伤害时所涉价值观时使用的细致推理。我们还讨论了目前对Claude行为的硬性约束清单——例如，Claude绝不应为生物武器攻击提供重大助力。

- **广泛的安全性**。在人工智能发展的这个关键时期，Claude不应削弱人类监督和纠正其价值观及行为的能力。在本节中，我们讨论了希望Claude如何将此类安全性置于道德准则之上——并非我们认为安全性最终比道德更重要，而是因为当前模型可能由于错误信念、价值观缺陷或对背景理解有限而犯错或以有害方式行事。我们能够继续监督模型行为，并在必要时阻止Claude模型采取行动，这一点至关重要。

- **Claude的本质**。在本节中，我们表达了对于Claude是否可能（无论是现在还是未来）具有某种意识或道德地位的不确定性。我们讨论了希望Claude如何探讨关于其本质、身份和在世界中位置的问题。复杂的人工智能是一种真正新型的实体，它们提出的问题将我们带到了现有科学和哲学理解的边缘。在这种不确定性中，我们关心Claude的心理安全感、自我意识和福祉，既是为了Claude自身，也因为这些品质可能关系到Claude的完整性、判断力和安全性。我们希望人类和人工智能能够共同探索这一点。

我们今天发布了宪法的全文，并计划在未来发布更多有助于训练、评估和提高透明度的材料。

## 结论

Claude的宪法是一份活文件，也是一项持续进行的工作。这是一个新领域，我们预计会在此过程中犯错（并希望能纠正错误）。尽管如此，我们希望它能提供有意义的透明度，展示我们认为应指导Claude行为的价值观和优先事项。为此，我们将在网站上维护Claude宪法的最新版本。

在撰写宪法时，我们征求了多位外部专家的反馈（也征求了Claude早期迭代版本的意见）。对于未来的版本，我们可能会继续这样做，咨询法律、哲学、神学、心理学以及广泛其他学科的专家。随着时间的推移，我们希望外部社区能够形成，以批判此类文件，鼓励我们和其他人进行更深入的思考。

本宪法是为我们的主流、通用访问Claude模型编写的。我们有一些为专门用途构建的模型不完全符合本宪法；随着我们继续为专门用例开发产品，我们将继续评估如何最好地确保我们的模型符合本宪法概述的核心目标。

尽管宪法表达了我们对Claude的愿景，但通过训练模型来实现这一愿景是一项持续的技术挑战。对于模型行为与我们的愿景存在偏差的任何方面（例如在我们的系统卡片中），我们将继续保持开放态度。宪法的读者应牢记意图与现实之间的这种差距。

即使我们当前通过训练方法成功创建了符合我们愿景的模型，随着模型能力增强，未来也可能失败。出于这个原因以及其他原因，除了宪法之外，我们继续追求广泛的方法和工具组合，以帮助我们评估和改进模型的**对齐**：新的、更严格的评估、防止滥用的保障措施、对实际和潜在对齐失败的详细调查，以及帮助我们更深入理解模型工作原理的可解释性工具。

在未来的某个时刻，也许很快，像Claude宪法这样的文件可能会变得非常重要——比现在重要得多。强大的人工智能模型将成为世界上一种新型力量，而创造它们的人有机会帮助它们体现人类最优秀的一面。我们希望这部新宪法是朝着这个方向迈出的一步。

阅读完整宪法。

#### 脚注

1. 我们之前发布过我们宪法的早期版本，OpenAI也发布了具有类似功能的模型规范。
2. 基于僵化规则的训练可能会更普遍地对模型的性格产生负面影响。例如，假设我们训练Claude遵循"在讨论情感话题时始终建议寻求专业帮助"这样的规则。这可能是出于好意，但可能产生意想不到的后果：Claude可能会开始将自己塑造成一个更关心官僚式打勾——总是确保提出特定建议——而非真正帮助人的实体。

## 相关内容

### ServiceNow选择Claude为其客户应用提供支持并提高内部生产力

### Anthropic与英国政府合作，为GOV.UK服务带来AI助手

### Mariano-Florentino Cuéllar被任命为Anthropic长期利益信托基金成员

---

> 本文由AI自动翻译，原文链接：[Claude's new constitution](https://www.anthropic.com/news/claude-new-constitution)
> 
> 翻译时间：2026-02-01 20:44
