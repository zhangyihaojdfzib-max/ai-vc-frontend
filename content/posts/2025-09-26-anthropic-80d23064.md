---
title: Claude更新用户条款与隐私政策，引入数据训练选择权
title_original: Updates to Consumer Terms and Privacy Policy
date: '2025-09-26'
source: Anthropic
source_url: https://www.anthropic.com/news/updates-to-our-consumer-terms
author: ''
summary: Anthropic宣布更新Claude消费者条款与隐私政策，核心变化包括：允许用户自主选择是否将对话数据用于模型训练；若选择同意，数据保留期将从30天延长至5年，否则维持原政策。该更新适用于免费版、专业版和Max版用户，不涉及商业条款服务。用户需在2025年10月8日前做出选择，并可通过隐私设置随时调整。此举旨在提升模型安全性、减少误判，并推动编码、推理等能力的持续改进。
categories:
- AI产品
tags:
- Claude
- 隐私政策
- 数据训练
- 用户选择权
- 模型改进
draft: false
translated_at: '2026-02-10T04:30:35.186364'
---

# 消费者条款与隐私政策更新

今天我们推出了消费者条款与隐私政策的更新，这将帮助我们提供更强大、更实用的人工智能模型。我们现在让用户选择是否允许使用其数据来改进Claude，并加强我们防范诈骗和滥用等有害行为的保障措施。调整您的偏好设置非常简单，并且可以随时进行。

这些更新适用于我们Claude免费版、专业版和Max版的用户，包括当他们使用与这些套餐关联的账户中的Claude Code时。这些更新**不适用于**我们商业条款下的服务，包括Claude for Work、Claude for Government、Claude for Education或API使用（包括通过Amazon Bedrock和Google Cloud的Vertex AI等第三方）。

通过参与，您将帮助我们提高模型安全性，使我们的有害内容检测系统更加准确，减少误标无害对话的可能性。您还将帮助未来的Claude模型在编码、分析和推理等技能上取得进步，最终为所有用户带来更好的模型。

您始终可以控制此设置以及我们是否以这种方式使用您的数据。如果您是新用户，可以在注册过程中选择您的偏好。现有用户将在一个弹出窗口中看到选择，如下所示。

![现有Claude应用用户的应用内通知](/images/posts/c689daa96c35.jpg)

从今天开始，我们将推出通知，以便您可以查看这些更新并管理您的设置。如果您是现有用户，您需要在2025年10月8日之前接受更新后的消费者条款并做出决定。如果您选择现在接受新政策，它们将立即生效。这些更新仅适用于新的或恢复的聊天和编码会话。2025年10月8日之后，您需要在模型训练设置中做出选择才能继续使用Claude。您可以随时在**隐私设置**中更改您的选择。

## 延长数据保留期

如果您允许我们使用您的数据进行模型训练，我们还将把数据保留期延长至五年。这个更新的保留期限仅适用于新的或恢复的聊天和编码会话，并将使我们能够更好地支持模型开发和安全改进。如果您删除了与Claude的对话，它将不会被用于未来的模型训练。如果您选择不提供数据进行模型训练，您将继续适用我们现有的30天数据保留期。

新的五年保留期也将适用于您就Claude对提示词的回复向我们提交的**反馈**。

为了保护用户的隐私，我们结合使用工具和**自动化流程**来过滤或混淆敏感数据。我们不会将用户数据出售给第三方。

您可以在下面的FAQ部分找到关于消费者条款和隐私政策更新的更多详细信息。

#### 有哪些变化？

-   当此设置**开启时**，我们将使用免费版、专业版和Max版账户的数据来训练新模型（包括当您从这些账户使用Claude Code时）。
    -   如果您是现有用户，您现在可以选择您的偏好，您的选择将立即生效。此设置仅适用于Claude上新的或恢复的聊天和编码会话。没有额外活动的先前聊天将不会用于模型训练。您需要在**2025年10月8日**之前做出选择。
    -   如果您是新用户，您可以在注册过程中选择您的模型训练设置。
    -   您可以随时在您的**隐私设置**中更改您的选择。
-   如果您允许我们使用您的数据进行模型改进，我们还将把数据保留期延长至五年，此设置仅适用于新的或恢复的聊天和编码会话。如果您不选择此选项，您将继续适用我们现有的30天数据保留期。

这些更新**不适用于**我们商业条款下的服务，包括：

-   Claude for Work，包括我们的团队版和企业版套餐
-   我们的API、Amazon Bedrock或Google Cloud的Vertex API
-   Claude Gov和Claude for Education

#### 为什么要进行这些更改？

所有大语言模型，如Claude，都是使用大量数据进行训练的。来自真实世界交互的数据提供了宝贵的见解，帮助我们了解哪些回复对用户最有用和最准确。例如，当开发人员通过与AI模型协作来调试代码时，这种交互提供了有价值的信号，有助于改进未来模型在类似编码任务上的表现。这就形成了一个反馈循环，帮助模型随着时间的推移变得更好。

由您选择是否允许使用您的数据来改进新的Claude模型，您可以随时在**隐私设置**中更改您的选择。

#### 为什么要延长数据保留期？

人工智能的开发周期长达数年——今天发布的模型在18到24个月前就开始开发了。在整个训练过程中保持数据的一致性也有助于使模型更加一致：在相似数据上训练的模型将以相似的方式响应、推理和生成输出，使得模型升级之间的变化对用户来说更加平滑。

延长的保留期还有助于我们改进分类器——帮助我们识别滥用的系统——以检测有害的使用模式。当这些系统能够从更长时间收集的数据中学习时，它们在识别滥用、垃圾信息或误用等活动方面会变得更好，帮助我们确保Claude对每个人都安全。

如果您更改了关于提供数据进行训练的设置或删除了您的账户，我们将把您的数据排除在未来的模型训练之外。如果您删除单个聊天，它们也不会被包含在未来的训练中。在此处了解更多关于我们数据保留实践的信息。

#### 我需要采取什么行动？

现有用户将看到一个应用内通知，询问您是否希望分享您的聊天和编码会话以改进模型。您可以立即做出选择，或者选择"稍后决定"并在以后决定。您需要在2025年10月8日之前做出选择。如果您选择此选项，更新后的5年数据保留政策也将立即适用于新的和恢复的聊天和编码会话。一旦2025年10月8日到来，您需要选择您的偏好才能继续使用Claude。

如果您今天注册Claude，您将在注册流程中看到此决定。请记住——您可以随时在隐私设置中更新您的偏好。

#### 如果我允许我的数据用于模型训练，然后又改变了主意，会发生什么？

您可以随时在隐私设置中更新您的选择。如果您决定关闭模型训练设置，我们将不会使用您与Claude进行的任何新的聊天和编码会话来用于未来的模型训练。您的数据仍将被包含在已经开始的模型训练和已经训练好的模型中，但我们将停止在未来的模型训练运行中使用您先前存储的聊天和编码会话。

## 相关内容

### 介绍Claude Opus 4.6

我们正在升级我们最智能的模型。在智能体编码、计算机使用、工具使用、搜索和金融领域，Opus 4.6都是一个行业领先的模型，通常优势明显。

### Claude是一个思考的空间

我们做出了一个选择：Claude将保持无广告。我们解释了为什么广告激励与真正有用的AI助手不相容，以及我们计划如何在不妨碍用户信任的情况下扩大访问。

### Apple的Xcode现在支持Claude Agent SDK

---

> 本文由AI自动翻译，原文链接：[Updates to Consumer Terms and Privacy Policy](https://www.anthropic.com/news/updates-to-our-consumer-terms)
> 
> 翻译时间：2026-02-10 04:30
