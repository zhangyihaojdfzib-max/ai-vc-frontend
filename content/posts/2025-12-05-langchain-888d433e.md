---
title: 在Terminal Bench 2.0上评估DeepAgents CLI智能体性能
title_original: Evaluating DeepAgents CLI on Terminal Bench 2.0
date: '2025-12-05'
source: LangChain Blog
source_url: https://www.blog.langchain.com/evaluating-deepagents-cli-on-terminal-bench-2-0/
author: ''
summary: 本文介绍了如何在Terminal Bench 2.0基准测试平台上评估DeepAgents CLI编码智能体的实际表现。DeepAgents CLI是一个开源的终端驱动智能体，具备文件操作、shell执行和记忆功能。文章重点探讨了使用Harbor沙盒框架解决评估中的环境隔离问题，该框架支持Docker、Modal等多种容器化环境，能自动执行测试和评分。DeepAgents
  CLI在89项跨领域任务中获得了42.5%的分数，与Claude Code表现相当。
categories:
- AI产品
tags:
- AI智能体
- 基准测试
- 终端工具
- 沙盒技术
- 代码生成
draft: false
translated_at: '2026-01-21T04:39:29.622629'
---

![在 Terminal Bench 2.0 上评估 DeepAgents CLI](/images/posts/a53937d2cc84.png)


# 在 Terminal Bench 2.0 上评估 DeepAgents CLI

作者：Vivek Trivedy 和 Eugene Yurtsev

DeepAgents CLI 是一个构建在 Deep Agents SDK 之上的编码智能体，它提供了一个交互式终端界面，具备 shell 执行、文件系统工具和记忆功能。

DeepAgents CLI 在实际任务中的表现究竟如何？

在这篇文章中，我们将展示如何在 Terminal Bench 2.0 上评估 DeepAgents CLI。Terminal Bench 2.0 是一个基准测试，用于衡量智能体在软件工程、生物学、安全性和游戏等领域的 89 项任务中的能力。

DeepAgents CLI（由 Sonnet 4.5 驱动）在 Terminal Bench 上获得了约 42.5% 的分数，与 Claude Code 本身的表现相当。

## 什么是 DeepAgents CLI

DeepAgents CLI 是一个由终端驱动的编码智能体。它是开源的，用 Python 编写，并且与模型无关。

DeepAgents CLI 是一个由终端驱动的编码智能体，它是开源的，用 Python 编写，并且与模型无关。它内置了多种功能，包括文件操作、shell 命令执行、网络搜索、通过待办事项进行任务规划，以及跨会话的持久化记忆存储。

```
export ANTHROPIC_API_KEY="your-api-key" uvx deepagents-cli

该智能体会通过差异对比的方式提出更改建议，在修改文件前需获得您的批准。

```

观看演示视频以了解其实际运行情况。

## 挑战：运行隔离的评估

在我们能够评估任何东西之前，我们需要解决一个基本问题：**我们如何每次都在一个干净、隔离的环境中运行我们的智能体？**

DeepAgents 最近添加了一个**沙盒抽象层**，使其能够与不同的执行环境协同工作。一个编码智能体会修改文件、安装包并运行命令——每次测试都可能留下影响后续测试的痕迹。我们需要隔离，以便每次测试都从一个干净的状态开始，并且能够并行运行许多测试，同时保证智能体无法影响您的本地机器的安全性。

### Harbor：沙盒化智能体执行

这就是 **Harbor** 的用武之地。Harbor 是一个用于在容器化环境中大规模评估智能体的框架，支持 Docker、Modal、Daytona、E2B 和 Runloop 作为沙盒提供者。它负责处理：

- 在基准测试任务上**自动执行测试**
- **自动奖励评分**以验证任务完成情况
- 预构建评估数据集的注册，例如 Terminal Bench

Harbor 处理了在隔离环境中运行智能体的所有基础设施复杂性，让您可以专注于改进您的智能体。

我们构建了 **deepagents-harbor** 以使评估变得简单直接：

```
git clone <https://github.com/langchain-ai/deepagents.git>
cd libs/harbor
uv sync

# 使用 API 密钥配置 .env
cp .env.example .env

# 通过 Docker 运行
uv run harbor run --agent-import-path deepagents_harbor:DeepAgentsWrapper \\
  --dataset terminal-bench@2.0 -n 1 --jobs-dir jobs/terminal-bench --env docker

# 通过 Daytona 大规模运行（需要 DAYTONA_API_KEY）
  --dataset terminal-bench@2.0 -n 10 --jobs-dir jobs/terminal-bench --env daytona

```

我们发现 Daytona 对于大规模运行评估特别有帮助，它允许我们同时运行 40 个试验，并显著加快了迭代周期。

Harbor 提供了一个具备 shell 执行能力的沙盒环境。我们构建了一个 HarborSandbox 后端，它封装了这个环境，并在 shell 命令之上实现了文件系统工具（例如，`edit_file`、`read_file`、`write_file`、`ls`）。

```
class DeepAgentHarbor(BaseAgent):
    async def run(
        self,
        instruction: str,
        environment: BaseEnvironment,
        context: AgentContext,
    ) -> None:
        # 创建一个封装 Harbor 环境并提供文件系统工具的 DeepAgents 后端
        backend = HarborSandbox(environment)

        # 使用 Harbor 后端初始化 DeepAgent CLI
        agent, _ = create_cli_agent(
            model=self._model,
            backend=backend,
            ...
        )

        # 运行智能体
        result = await agent.ainvoke(
            {"messages": [{"role": "user", "content": instruction}]},
        )

```

## Terminal Bench 测试内容

Terminal Bench 2.0 包含 89 项任务，涵盖软件工程、生物学、安全性和游戏等领域。它衡量智能体通过终端在计算机环境中操作的能力。

- **path-tracing**：从渲染的图像中逆向工程 C 程序
- **chess-best-move**：使用国际象棋引擎寻找最优走法
- **git-multibranch**：包含合并冲突的复杂 git 操作
- **sqlite-with-gcov**：构建带有代码覆盖率的 SQLite，分析报告

任务的难度范围很广——**有些任务需要很多操作**（例如，`cobol-modernization` 需要近 10 分钟和 100 多次工具调用），而较简单的任务则在几秒钟内完成。

**自动验证：**

每个任务都包含 Harbor 自动运行的验证逻辑，根据智能体的解决方案是否满足任务要求来分配奖励分数（0 表示不正确，1 表示正确）。

我们在 Terminal Bench 2.0 上使用 `claude-sonnet-4-5` 运行了 DeepAgents CLI，进行了 2 次试验，分别获得了 **44.9%** 和 **40.4%** 的分数（平均：**42.65%**）。这个基线水平与**使用相同模型的其他实现**相当。

虽然不同运行之间存在相当大的采样方差，但这个基线验证了 DeepAgents 提供了一个具有竞争力的基础。

通过在 Terminal Bench 2 上运行 DeepAgents CLI，我们已经确立了 DeepAgents 作为一个坚实的起点。在接下来的文章中，我们将探讨如何系统地分析智能体轨迹，并确定具体的优化方案以提高性能。

- DeepAgents
- Harbor
- deepagents-harbor 代码
- Terminal Bench 2.0

来自 LangChain 团队和社区的更新

正在处理您的申请...

成功！请检查您的收件箱并点击链接确认订阅。

抱歉，出错了。请重试。


> 本文由AI自动翻译，原文链接：[Evaluating DeepAgents CLI on Terminal Bench 2.0](https://www.blog.langchain.com/evaluating-deepagents-cli-on-terminal-bench-2-0/)
> 
> 翻译时间：2026-01-21 04:39
