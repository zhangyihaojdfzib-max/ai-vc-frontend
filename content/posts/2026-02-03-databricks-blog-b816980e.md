---
title: 基于Databricks的领域专家引导式自优化橄榄球聊天机器人
title_original: Self-Optimizing Football Chatbot Guided by Domain Experts on Databricks
date: '2026-02-03'
source: Databricks Blog
source_url: https://www.databricks.com/blog/self-optimizing-football-chatbot-guided-domain-experts-databricks
author: ''
summary: 本文介绍了一种在Databricks平台上构建的自优化智能体架构，旨在解决通用大语言模型在特定领域（如美式橄榄球战术分析）中难以捕捉细微差别的问题。该方案通过两个阶段实现：首先构建一个能调用确定性SQL工具的基础智能体；然后利用MLflow持续捕获领域专家反馈，校准评估器标准，并迭代优化系统提示词，从而将人类专业知识系统地注入AI系统，实现质量的持续提升与可控的部署体验。
categories:
- AI产品
tags:
- 自优化智能体
- Databricks
- MLflow
- 领域知识
- AI评估
draft: false
translated_at: '2026-02-04T04:23:38.711930'
---

通用的LLM（大语言模型）评估器和静态提示词难以捕捉特定领域的细微差别。判断什么是一份“优秀”的橄榄球防守分析需要深厚的橄榄球知识：防守阵型、阵型倾向、情境背景。通用评估器会忽略这些。对于法律审查、医疗分诊、财务尽职调查或任何依赖专家判断的领域，情况也是如此。

本文介绍了一种基于 Databricks Agent Framework 构建的**自优化智能体**架构，其中企业特定的人类专业知识利用 MLflow 持续提升 AI 质量，而开发者则能控制整个体验。我们以美式橄榄球防守协调员助理作为贯穿本文的示例：这是一个能够调用工具的智能体，可以回答诸如“在 3档6码的情况下，11人进攻阵型中谁会持球？”或“对手在半场最后两分钟会做什么？”等问题。以下示例展示了该智能体通过 Databricks Apps 与用户交互。

## 从智能体到自优化系统

该解决方案分为两个阶段：构建智能体，然后利用专家反馈持续优化它。

### 构建

1.  **数据摄取**：将领域数据（逐场数据、参与数据、阵容名单）加载到 Unity Catalog 中受治理的 Delta 表中。我们摄取了来自 `nflreadpy` 的两年（2023-2024）橄榄球参与和逐场数据作为该智能体的数据源。
2.  **创建工具**：将 SQL 函数定义为 Unity Catalog 工具，供智能体调用，利用已提取的数据。
3.  **定义并部署智能体**：将工具连接到 `ResponsesAgent`，在提示词注册表中注册一个基线系统提示词，并部署到模型服务。
4.  **初始评估**：使用 LLM 评估器运行自动化评估，并使用自定义评估器的基线版本记录追踪。

### 优化

1.  **捕获专家反馈**：领域专家审查智能体输出，并通过 MLflow 标注会话提供结构化反馈。
2.  **对齐评估器**：使用 MLflow 的 `align()` 函数来校准基线 LLM 评估器，使其匹配领域专家的偏好，教会它在该领域中什么是“优秀”。
3.  **优化提示词**：MLflow 的 `optimize_prompts()` 在已对齐的评估器指导下，使用 GEPA 优化器迭代改进原始系统提示词。
4.  **重复**：每次 MLflow 标注会话都用于改进评估器，进而用于优化系统提示词。整个过程可以实现自动化，以自动推广超过性能基准的新提示词版本；或者，根据观察到的失败模式，为手动更新智能体（例如添加更多工具或数据）提供信息。

构建阶段使你获得一个初始原型，而优化阶段则加速你进入生产阶段，利用领域专家反馈作为引擎持续优化你的智能体。

![DC Assistant Pipeline](/images/posts/46e55ef9eaf5.png)

## 架构概述

该智能体平衡了概率性和确定性：LLM 解释用户查询的语义意图并选择正确的工具，而确定性的 SQL 函数则以 100% 的准确率提取数据。例如，当教练询问“我们的对手如何攻击突袭？”时，LLM 将其解释为对传球冲击/防守覆盖分析的请求，并选择 `success_by_pass_rush_and_coverage()`。SQL 函数从底层数据中返回精确的统计数据。通过使用 Unity Catalog 函数，我们确保统计数据 100% 准确，而 LLM 则处理对话上下文。

让我们通过 DC 助理实现中的代码和输出来逐步了解每个步骤。

## 构建

### 1. 数据摄取。

一个设置笔记本（00_setup.ipynb）定义了整个工作流中使用的所有全局配置变量：工作空间目录/模式、MLflow 实验、LLM 端点、模型名称、评估数据集、Unity Catalog 工具名称和身份验证设置。此配置持久化到 `config/dc_assistant.json` 中，并由所有下游笔记本加载，确保整个流程的一致性。此步骤是可选的，但有助于整体组织。

配置完成后，我们通过 `nflreadpy` 加载橄榄球数据，并应用增量处理以准备供智能体使用：删除未使用的列、标准化模式，并将清理后的 Delta 表持久化到 Unity Catalog。以下是一个简单的数据加载示例，不涉及太多数据处理：

此过程的输出是 Unity Catalog 中受治理的 Delta 表（逐场数据、参与数据、阵容名单、球队、球员），这些表已准备好用于工具创建和智能体使用。

### 2. 创建工具。

智能体需要确定性工具来查询底层数据。我们将这些工具定义为 Unity Catalog SQL 函数，用于计算各种情境维度下的进攻倾向。每个函数接收如 `team` 和 `season` 等参数，并返回智能体可用于回答协调员问题的聚合统计数据。在此示例中，我们仅使用基于 SQL 的函数，但也可以配置**基于 Python 的 UC 函数**、**向量搜索索引**、**模型上下文协议工具**以及 **Genie 空间**，作为智能体可以利用的附加功能，以补充监督该过程的 LLM。

以下示例展示了 `success_by_pass_rush_and_coverage()`，它计算传球/跑动比例、EPA（预期得分增加值）、成功率以及获得的码数，并按传球冲击人数和防守覆盖类型分组。该函数包含一个 `COMMENT` 来描述其用途，LLM 利用此信息来决定何时调用它。

由于这些函数存在于 Unity Catalog 中，它们继承了平台的治理模型：基于角色的访问控制、血缘追踪以及跨工作空间的可发现性。团队可以查找和重用工具而无需重复逻辑，管理员可以清晰了解智能体可以访问哪些数据。

### 3. 定义并部署智能体。

创建智能体可以像使用 AI Playground 一样简单。选择要使用的 LLM，添加你的 Unity Catalog 工具，定义你的系统提示词，然后点击“创建智能体笔记本”以导出一个笔记本，该笔记本会生成 `ResponsesAgent` 格式的智能体。以下截图展示了此工作流程的实际操作。导出的笔记本包含智能体定义结构，通过 `UCFunctionToolkit` 将你的 UC 函数连接到智能体。

为了实现自优化循环，我们将系统提示词注册到提示词注册表中，而不是硬编码。这使得优化阶段可以在不重新部署智能体的情况下更新提示词：

一旦智能体代码经过测试且模型注册到 Unity Catalog，将其部署到持久端点就像下面的代码一样简单。这将创建一个启用了 MLflow Tracing 的模型服务端点、用于记录请求/响应的推理表以及自动扩缩容：

对于最终用户访问，该智能体也可以部署为 Databricks App，提供一个聊天界面，协调员和分析师可以直接使用，而无需访问笔记本或 API。引言中的截图展示了这种基于 App 的部署的实际效果。

### 4. 初始评估。

智能体部署后，我们使用 LLM 评估器运行自动化评估，以建立基线质量度量。MLflow 支持**多种评估器类型**，我们结合使用了三种。

*   **内置评估器**：开箱即用地处理常见的评估标准。`RelevanceToQuery()` 检查响应是否回答了用户的问题。
*   **基于准则的评估器**：根据特定的基于文本的规则以通过/失败的方式进行评估。我们定义了一个准则，确保响应使用适当的职业橄榄球术语：

*   **自定义评估器**：使用 `make_judge()` 进行领域特定的评估，完全控制评分标准。这是我们在优化阶段将对齐到领域专家反馈的评估器：

定义好所有评估器后，我们可以对数据集运行评估：

customfootball_analysis_basejudge 提供了一个基线评分，但这仅反映了我们为 LLM（大语言模型）评判而从头创建评分标准的一次尽力尝试，而非真正的领域专业知识。MLflow Experiments UI 向我们展示了智能体在此基线评判器上的表现，以及每个示例的评分理由。

在优化阶段，我们将使足球分析评判器与 SME（主题专家）偏好对齐，教会它对于防守协调员分析而言，“好”的真正含义是什么。

## 优化

### 5. 收集专家反馈。

随着智能体部署和基线评估完成，我们进入优化循环。这是领域专业知识被编码到系统中的环节，首先通过对齐的 LLM 评判器，然后通过由我们对齐的评判器指导的系统提示词优化，直接编码到智能体中。

我们首先创建一个标签模式，该模式使用与我们通过 `make_judge()` 创建的足球分析评判器相同的指令和评估标准。然后，我们创建一个标注会话，使我们的领域专家能够审查在 `evaluate()` 任务中使用的相同轨迹的响应，并通过 Review App（如下图所示）提供他们的评分和反馈。

此反馈成为评判器对齐的基准事实。通过观察基线评判器与 SME 评分在何处出现分歧，我们可以了解评判器在这个特定领域犯了哪些错误。

### 6. 对齐评判器。

既然我们拥有了同时包含领域专家反馈和 LLM 评判器反馈的轨迹，我们就可以利用 MLflow 的 `align()` 功能，将我们的 LLM 评判器与我们的领域专家反馈对齐。一个对齐的评判器反映了您领域专家的视角和您组织的独特数据。对齐以一种以前不可能的方式将领域专家引入开发过程：领域反馈直接塑造了系统衡量质量的方式，使得智能体性能指标既可靠又可扩展。

`align()` 允许您使用自己的优化器或默认的二元 SIMBA（简化多重自助聚合）优化器。在本例中，我们利用一个定制的 SIMBA 优化器来校准一个李克特量表评判器：

接下来，我们检索在整个过程中已标记的、同时包含 LLM 评判器评分和 SME 反馈的轨迹。这些配对评分正是 SIMBA 用来学习通用判断与专家判断之间差距的数据。

以下截图显示了正在进行中的对齐过程。模型识别出 LLM 评判器与 SME 反馈之间的差距，提出新的规则和细节以纳入评判器来缩小这些差距，然后评估新的候选评判器，看它们是否超越了基线评判器的性能。

此过程的最终输出是一个直接反映领域专家反馈并包含详细指令的对齐评判器。

有效对齐的技巧：

*   对齐的目标是让您在开发过程中感觉有领域专家坐在您身边。这个过程可能会导致您的基线智能体性能评分降低，这意味着您的基线评判器定义不够明确。既然您拥有了一个能以 SME 相同方式评判智能体的评判器，您就可以进行手动或自动的改进以提高性能。
*   对齐过程的效果取决于所提供的反馈质量。质量优于数量。对较少数量示例（最少 10 个）提供详细、一致的反馈，比对大量示例提供不一致的反馈能产生更好的结果。

定义质量通常是推动智能体性能提升的主要障碍。无论采用何种优化技术，如果没有清晰的质量定义，智能体性能都会不尽如人意。Databricks 提供了一个研讨会，通过一个迭代的、跨职能的练习来帮助客户定义质量。要了解更多信息，请联系您的 Databricks 客户团队或填写此表格。

### 7. 优化提示词。

有了一个反映 SME 偏好的对齐评判器，我们现在可以自动改进智能体的系统提示词。MLflow 的 `optimize_prompts()` 函数使用 GEPA，基于对齐评判器的评分迭代优化提示词。GEPA（遗传-帕累托）由 Databricks CTO Matei Zaharia 共同创建，是一种遗传进化提示算法，它利用大语言模型对提示词进行反思性变异，使其能够迭代优化指令，在优化模型性能方面超越传统的强化学习技术。

GEPA 优化器不是让开发者猜测在系统提示词中添加哪些形容词，而是通过数学方式进化提示词，以最大化专家定义的特定评分。优化过程需要一个包含预期响应的数据集，以引导优化器朝向期望的行为，如下所示：

GEPA 优化器获取当前系统提示词，并迭代地提出改进方案，根据对齐的评判器评估每个候选方案。在这里，我们获取初始提示词、我们创建的优化数据集以及对齐的评判器，以利用 MLflow 的 `optimize_prompts()`。然后，我们使用 GEPA 优化器，在对齐评判器的指导下创建一个新的系统提示词：

以下截图显示了系统提示词的变化——旧的在左边，新的在右边。最终选择的提示词是对齐评判器评分最高的那个。由于空间原因，新提示词已被截断，但从这个例子可以清楚地看出，我们已经能够整合领域专家的反馈，构建出一个基于特定领域语言、并包含如何处理某些请求的明确指导的提示词。

利用 SME 反馈自动生成此类指导的能力，本质上允许您的 SME 仅通过对智能体轨迹提供反馈，就能间接地向智能体提供指令。

在本例中，根据我们对齐的评判器，新提示词在我们的优化数据集上带来了更好的性能，因此我们为新注册的提示词赋予了生产别名，使我们能够使用这个改进后的提示词重新部署我们的智能体。

提示词优化技巧：

*   优化数据集应涵盖您的智能体将处理的查询的多样性。包括边缘情况、模糊请求以及工具选择至关重要的场景。
*   预期响应应描述智能体应该做什么（调用哪些工具，包含哪些信息），而不是确切的输出文本。
*   开始时将 `max_metric_calls` 设置在 50 到 100 之间。更高的值会探索更多候选方案，但会增加成本和运行时间。
*   GEPA 优化器从失败模式中学习。如果对齐的评判器因遗漏基准或小样本警告而扣分，GEPA 就会将这些要求注入到优化后的提示词中。

### 8. 闭环：自动化与持续改进。

我们走过的各个步骤可以编排成一个持续优化的流水线，其中领域专家标注成为优化循环的触发器，并且所有内容都可以使用 Asset Bundles 包含在一个 Databricks 作业中：

1.  SME 通过 MLflow Labeling Session UI 标注智能体输出，对真实生产轨迹提供评分和评论。
2.  流水线检测到新标签，并拉取同时包含 SME 反馈和基线 LLM 评判器评分的轨迹。
3.  运行评判器对齐，生成一个根据最新 SME 偏好校准的新评判器版本。
4.  运行提示词优化，使用对齐的评判器迭代改进系统提示词。
5.  条件性升级：如果新提示词超过性能阈值，则将其推送到生产环境。这可能涉及触发另一个评估作业，以确保新提示词能推广到其他示例。
6.  随着提示词注册表提供优化版本，智能体自动改进。

当领域专家完成标注会话后，系统会触发一个`evaluate()`任务，对相同的轨迹生成LLM（大语言模型）评判分数。`evaluate()`任务完成后，系统会执行一个`align()`任务，将LLM评判结果与领域专家的反馈进行对齐。该任务完成后，系统会运行`optimize_prompts()`任务，生成一个经过改进的新系统提示词。这个新提示词可以立即在新数据集上进行测试，如果效果合适，即可推广到生产环境。

整个过程可以实现全自动化，但也可以在任意步骤中引入人工审核，让开发者能够完全控制自动化程度。随着领域专家持续进行标注，该流程会不断重复，从而实现对Agent（智能体）新版本的快速性能测试，并获得开发者真正可信的累积性能提升。

借助Databricks Agent Framework和MLflow，这种架构改变了Agent（智能体）随时间演进的方式。开发者不再需要猜测什么是好的回答，而是由领域专家通过专业反馈直接塑造Agent（智能体）的行为。评判对齐和优化流程将领域专业知识转化为具体的系统变更，同时开发者仍能保持对整个系统的控制，包括决定哪些部分自动化以及在哪里允许人工干预。

在本文中，我们阐述了如何定制一个Agent（智能体），使其能体现职业足球领域专家所关注的具体语言和细节。DC Assistant展示了这种模式，但该方法适用于任何依赖专家判断的领域：法律文件审阅、职业棒球击球准备、医疗分诊、高尔夫击球分析、客户支持升级，或任何其他开发者难以在没有领域专家支持下明确界定“好”标准的应用场景。

请尝试将此方法应用于您自己的特定领域问题，看看它如何基于领域专家的反馈驱动自动化持续改进！

了解更多关于Databricks Sports和Agent Bricks的信息，或申请演示，了解您的组织如何利用其获得竞争优势洞察。

---

> 本文由AI自动翻译，原文链接：[Self-Optimizing Football Chatbot Guided by Domain Experts on Databricks](https://www.databricks.com/blog/self-optimizing-football-chatbot-guided-domain-experts-databricks)
> 
> 翻译时间：2026-02-04 04:23
