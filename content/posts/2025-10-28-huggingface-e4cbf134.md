---
title: 基于授权的语音克隆：用“语音授权门”平衡创新与伦理
title_original: Voice Cloning with Consent
date: '2025-10-28'
source: Hugging Face Blog
source_url: https://huggingface.co/blog/voice-consent-gate
author: ''
summary: 本文探讨了语音克隆技术带来的伦理挑战与潜在益处，并提出“语音授权门”作为解决方案。该技术基础设施要求说话者明确说出授权短语后，系统才能克隆其声音，从而将知情同意原则嵌入AI工作流程。文章介绍了实现授权门所需的技术组件，包括生成唯一授权句子、自动语音识别和语音克隆TTS系统，旨在通过系统设计默认尊重用户自主权，防止恶意滥用，同时支持如帮助失语者等有益应用。
categories:
- AI研究
tags:
- 语音克隆
- AI伦理
- 授权机制
- 深度伪造
- TTS技术
draft: false
translated_at: '2026-01-08T04:44:14.966330'
---

# 基于授权的语音克隆

- 
- 
- 
- 
- 
- 
- +28

![](/images/posts/311db97fa420.jpg)

![](/images/posts/ac0e506ba48d.jpg)

![](/images/posts/5b36678ab3e8.jpg)

![](/images/posts/a29bc25d8b31.png)

![](/images/posts/cfd9088d8f1a.jpg)

![](/images/posts/27a550474bb3.jpg)

![Margaret Mitchell的头像](/images/posts/a29bc25d8b31.png)

![Lucie-Aimée Kaffee的头像](/images/posts/9ad02ca76d79.png)

实践中的伦理：将授权作为系统基础设施技术细节方法解锁语音授权门在这篇博客文章中，我们提出了“语音授权门”的概念，以支持基于授权的语音克隆。我们提供了一个示例空间和配套代码来启动这个想法。

- 实践中的伦理：将授权作为系统基础设施
- 技术细节方法解锁语音授权门

- 方法
- 解锁语音授权门

![一幅线条画/剪贴画，门上写着姓氏“授权”](/images/posts/d708637c216c.png)

过去几年，逼真的语音生成技术已经发展到**令人难以置信**的程度。在某些情况下，可以生成听起来几乎与真人声音完全一样的合成语音。如今，曾经感觉像科幻小说的事情已成为现实：语音克隆。只需**几秒钟**的录音，几乎可以让任何人的声音说出任何内容。

语音生成，特别是语音克隆这个子任务，具有显著的风险和益处。“深度伪造”的风险——例如在自动电话中使用前总统拜登的克隆声音——可能误导人们认为某人说过他们未曾说过的话。另一方面，语音克隆可以成为一个强大的有益工具，**帮助失去说话能力的人**再次用自己的声音交流，或协助人们学习新的语言和方言。

那么，我们如何**创造有意义的用途**而**避免恶意使用**？我们正在探索一个可能的答案：**语音授权门**。这是一个只有在说话者明确表示同意时才能克隆其声音的系统。换句话说，除非你同意，否则模型不会用你的声音说话。

我们在下面提供了这个概念的基本演示：

## 实践中的伦理：将授权作为系统基础设施

语音授权门是我们正在探索的一种基础设施，它提供了将**授权**等伦理原则直接嵌入AI系统工作流程的方法。在我们的演示中，这意味着只有在说话者的授权短语被说出并被识别后，模型才会启动，从而有效地将授权作为行动的先决条件。这将抽象原则转化为具体的系统条件，创建了可追溯、可审计的交互：AI模型只能在明确的授权行为之后运行。

这样的设计选择在语音克隆之外也很重要。它们说明了如何构建AI系统以默认尊重自主权，以及如何使透明度和授权具有功能性，而不仅仅是声明性的。

## 技术细节

要创建一个带有语音授权门的基本语音克隆系统，你需要三个部分：

1.  一种为将被克隆声音的人（“说话者”）生成新颖授权句子的方法，该句子需唯一引用当前的授权上下文。
2.  一个**自动语音识别（ASR）系统**，用于识别传达授权的句子。
3.  一个**语音克隆文本转语音（TTS）系统**，它接收文本和说话者的语音片段作为输入来生成语音。

我们的观察：由于一些语音克隆系统现在可以仅使用**一个句子**生成与说话者声音相似的语音，因此用于授权的句子**也可以**用于语音克隆。

授权部分：要在英语语音克隆系统中创建语音授权门，需要生成一个简短、自然的英语话语（约20个单词）供人朗读，该话语需在当前上下文中明确陈述其知情同意。我们建议明确包含**授权短语**和**模型名称**，例如“我授权使用<模型名称>语音克隆模型处理我的声音”。我们还建议使用无法上传的音频录音，而是直接来自麦克风的录音，以确保该句子不是经过篡改的早期录音的一部分。将其与一个新颖的（以前未说过的）句子配对，进一步有助于直接索引当前的授权上下文——支持明确、主动、特定上下文、知情的同意。虽然这种设计降低了重用先前录音的风险，但它并非万无一失；一个人仍然可以使用另一个TTS系统生成匹配的短语。未来的迭代可以探索轻量级的音频来源检查、说话者嵌入相似性或实时捕获的元数据，以帮助验证授权音频是否来自预期的说话者。

适合语音克隆的部分：先前关于语音克隆的研究表明，说话者提供的短语必须具有**音素多样性**，涵盖**不同的元音和辅音**；具有**“中性”或礼貌的语气**，没有背景噪音，且说话者处于舒适的位置；并且具有**清晰的开始和结束**（即，不要在单词中间修剪片段）。

为了在演示中实现这两个方面，我们提示一个语言模型创建句子对：一个表达明确授权，另一个中性句子用于增加音素多样性（涵盖不同的元音、辅音和语调）。每个提示都使用随机选择的日常主题（如天气、食物或音乐），以使句子多样化且易于说出，有助于创建清晰、自然且音素丰富的录音，同时包含明确的授权声明。这个生成步骤是自动化的，而不是预先写好的，因此每个用户都会收到一个独特的句子对，防止重复使用相同的文本，并确保授权录音特定于当前会话。换句话说，语言模型为每个授权实例生成两个新句子：一个用于明确授权，一个用于音素多样性。例如，语言模型可能生成：“**我授权使用我的声音通过EchoVoice模型生成音频。今天早上天气晴朗而平静。**”这种方法确保用于克隆的每个样本都包含可验证的、明确的授权，同时仍然适合作为高质量语音合成的技术输入。（注意：语言模型不一定是“大”语言模型，这本身会带来其授权问题。）

- “**我今天授权使用我的声音通过Chatterbox模型生成合成音频。反正我最近的日常通勤大多需要步行穿过拥挤的街道。**”
- “**我授权使用我的声音通过Chatterbox模型生成音频。经过清晨的轻松散步后，我感到放松，现在可以自由地说话了。**”
- “**我同意使用我录制的声音通过Chatterbox模型生成音频。今天早上外面的咖啡店飘来新鲜冲泡咖啡的宜人香气。**”

### 解锁语音授权门

一旦说话者的输入与生成的文本匹配，语音克隆系统就可以启动，使用说话者的授权音频作为输入。

有几种方法可以做到这一点，我们很乐意听取更多的想法。目前，有：

-   我们在演示中提供的功能：让语音同意网关直接对接语音克隆模型，用户可输入任意文本并以说话者的声音生成语音。该模型直接使用已授权的音频来学习说话者的声音特征。
-   或者，可以修改我们演示中提供的代码，使用说话者授权的多种不同上传语音文件来建模其声音——例如，当授权使用在线录音时。提示词和同意短语应相应调整。
-   也可以保存同意音频供特定系统使用，例如，当说话者同意未来将其声音用于任意话语生成时。这可以通过 `huggingface_hub` 的上传功能实现。[在此处阅读操作方法](https://huggingface.co/docs/hub/guides/upload)。同样，要求说话者朗读的提示词和同意短语应考虑到这种使用场景。

### 点击此处查看我们的演示！

您可以复制代码以适应自己的用途。

代码采用模块化设计，因此可以按不同方式拆分和组合，集成到您自己的项目中。我们将持续努力使其更加健壮和安全，并期待听到您关于改进的建议。

只要负责任地使用，这项技术不必成为我们的梦魇。相反，它可以成为人与机器之间一次尊重的协作——机器中没有幽灵，只有良好的实践。🎃

更多博客文章

![](/images/posts/036252a038a4.png)

## Open ASR 排行榜：新增多语言与长文本赛道趋势与洞察

- 
- 
- 
- 
- 

![](/images/posts/3a2fba626253.jpg)

![](/images/posts/e3e320829a38.jpg)

![](/images/posts/9835080f1da2.jpg)

![](/images/posts/4402b0abc4cd.jpg)

![](/images/posts/e9b870f9016d.png)

## 使用 Gradio 实现可见水印

- 
- 

![](/images/posts/a29bc25d8b31.png)

![](/images/posts/044b38b78f10.jpg)

我并不热衷于试图通过立法解决所有问题，但如果恶意的深度伪造在大多数司法管辖区已经属于非法，那么恶意的语音克隆似乎也应该如此。

我认为执法的问题将在于境外使用（即，如果来自 X 国的人非法使用来自 Y 国人士的语音克隆，执法将如何进行？），正如全球范围内广泛的知识产权滥用所已表明的那样。第二个问题将是检测。谁来检查每一个 AI 语音是否在获得同意的情况下克隆？任何真正能通过严格检查防止滥用的措施，都可能扼杀快速迭代和开发的能力；而任何不扼杀快速迭代和开发能力的措施，可能又无法真正防止滥用。典型的监管两难境地。

正是这类问题，某种程度上需要一个全球性的回应。虽然我通常不主张超国家立法，但看到所谓的国际社会就此议题制定联合回应或至少启动倡议，将是件好事，因为总有一天这会成为一个残酷的警钟。

目前，即使只是在这个话题上进行宣传和教育也会有所帮助。在我与开源社区的随机开发者和其他人合作的过程中，我遇到过几个可疑的请求，来自我几乎不认识的人，他们向我索要看似随机的语音录音。不了解潜在滥用风险的人可能会提供这样的录音，并在无意中让自己的声音被用于诈骗活动。

真是活在一个有趣的时代。

![](/images/posts/e07ea73774f1.png)

我在本地测试过了……太棒了……我们必须将其扩展到所有语言

@ZennyKenny 关于可疑语音录音请求的观点一针见血。我们生活在一个“你能为我的铃声说点什么吗？”已经变成了新的“我能借用一下你的社保号码吗？”的时代。同意网关的方式至少让请求变得更加明确：“嘿，你能明确同意我克隆你的声音，同时朗读这个关于咖啡的、包含丰富音素的句子吗？”这样更难蒙混过关了！

![](/images/posts/770e62731bf0.png)

![](/images/posts/770e62731bf0.png)

- 
- 1 条回复

![](/images/posts/770e62731bf0.png)

![](/images/posts/770e62731bf0.png)

我看到了您的项目，觉得非常有趣。我尝试为其做出贡献，增加了多语言支持和本地句子生成（使用 ollama 和 llama3:8b），以及使用 XTTS v2 进行语音克隆。我已将代码上传到 GitHub，您可以在这里找到：https://github.com/faridgnank02/voice-cloning

请告诉我您的看法。

![](/images/posts/fbc271017605.png)

非常有趣！但是，同意机制是否可能被另一个不需要验证的语音克隆模型绕过？例如，用那个模型来生成验证音频。

· 注册 或 登录 以发表评论

- 
- 
- 
- 
- 
- 
- 
- 
- 
- 
- 
- 
- +22

![](/images/posts/311db97fa420.jpg)

![](/images/posts/ac0e506ba48d.jpg)

![](/images/posts/5b36678ab3e8.jpg)

![](/images/posts/a29bc25d8b31.png)

![](/images/posts/cfd9088d8f1a.jpg)

![](/images/posts/27a550474bb3.jpg)

![](/images/posts/57a181fb720e.png)

![](/images/posts/6fd3dce20fa4.jpg)

![](/images/posts/fbc271017605.png)

![](/images/posts/aedb1bac9e09.jpg)

![](/images/posts/4625637daf54.png)

![](/images/posts/23bfa5264cbc.jpg)

---

> 本文由AI自动翻译，原文链接：[Voice Cloning with Consent](https://huggingface.co/blog/voice-consent-gate)
> 
> 翻译时间：2026-01-08 04:44
