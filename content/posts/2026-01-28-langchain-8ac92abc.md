---
title: Deep Agents SDK：应对长任务挑战的上下文管理策略
title_original: Context Management for Deep Agents
date: '2026-01-28'
source: LangChain Blog
source_url: https://www.blog.langchain.com/context-management-for-deepagents/
author: ''
summary: 本文介绍了Deep Agents SDK如何通过上下文压缩技术解决AI智能体处理长任务时的内存限制问题。文章详细阐述了三种核心压缩方法：卸载大型工具结果、卸载大型工具输入以及总结对话历史。这些技术通过将冗余或过时信息存储至文件系统，并保留关键摘要，使智能体能在有限上下文窗口内高效执行复杂、长期运行的任务。文中还通过实际运行数据展示了这些策略在减少Token使用量方面的有效性。
categories:
- AI基础设施
tags:
- AI智能体
- 上下文管理
- LangChain
- 大语言模型
- 文件系统
draft: false
translated_at: '2026-01-29T04:07:04.832950'
---

作者：Chester Curme 与 Mason Daugherty

随着AI Agent（智能体）可处理的任务长度持续增长，有效的上下文管理变得至关重要，以防止**上下文腐化**并应对LLM（大语言模型）有限的内存限制。

**Deep Agents SDK** 是 LangChain 开源、功能完备的**智能体框架**。它提供了一条便捷的路径，用于构建具备规划、生成子智能体以及与文件系统交互以执行复杂、长期运行任务能力的智能体。由于这类任务通常可能超出模型的**上下文窗口**，该 SDK 实现了多种促进**上下文压缩**的功能。

上下文压缩指的是那些减少智能体工作内存中信息量，同时保留完成任务所需相关细节的技术。这可能涉及总结之前的交互、过滤过时信息，或策略性地决定保留与丢弃哪些内容。

Deep Agents 实现了一个**文件系统抽象层**，允许智能体执行诸如列出、读取、写入文件，以及搜索、模式匹配和文件执行等操作。智能体利用文件系统来按需搜索和检索已卸载的内容。

Deep Agents 实现了三种主要的压缩技术，在不同频率下触发：

1.  **卸载大型工具结果**：每当出现大型工具响应时，我们将其卸载到文件系统。
2.  **卸载大型工具输入**：当上下文大小超过阈值时，我们将工具调用中旧的写入/编辑参数卸载到文件系统。
3.  **总结**：当上下文大小超过阈值，且没有更多符合条件的上下文可供卸载时，我们执行总结步骤以压缩消息历史记录。

为了管理上下文限制，Deep Agents SDK 在模型上下文窗口大小的阈值比例处触发这些压缩步骤。（在底层，我们使用 LangChain 的**模型配置文件**来获取给定模型的 Token 阈值。）

## 卸载大型工具结果

工具调用（例如，读取大文件或 API 调用的结果）的响应可能超出模型的上下文窗口。当 Deep Agents 检测到工具响应超过 20,000 个 Token 时，它会将响应卸载到文件系统，并用文件路径引用和前 10 行的预览来替代。智能体随后可以根据需要重新读取或搜索该内容。

![](/images/posts/2c27f72c10ae.png)

## 卸载大型工具输入

文件写入和编辑操作会在智能体的对话历史中留下包含完整文件内容的工具调用记录。由于这些内容已经持久化到文件系统，它们通常是冗余的。当会话上下文超过模型可用窗口的 85% 时，Deep Agents 将截断较早的工具调用，用指向磁盘上文件的指针替换它们，从而减小活动上下文的大小。

![](/images/posts/40b4fbbde9c4.png)

## 总结

当卸载操作不再能释放足够空间时，Deep Agents 会转而采用总结。此过程包含两个部分：

1.  **上下文内总结**：LLM 生成对话的结构化摘要——包括会话意图、创建的工件以及后续步骤——用以替换智能体工作内存中的完整对话历史记录。（参见 Deep Agents 的**总结提示词**。）
2.  **文件系统保存**：完整、原始的对话消息被写入文件系统作为规范记录。

这种双重方法确保智能体保持对其目标和进度的了解（通过摘要），同时保留在需要时恢复特定细节的能力（通过文件系统搜索）。参见**此跟踪记录**中的示例，其中模型使用 `read_file` 工具来获取先前卸载的消息。

![](/images/posts/29b3ffbfbaa7.png)

## 实践中的表现

虽然上述技术提供了上下文管理的机制，但我们如何知道它们确实有效呢？在真实世界任务上的运行，如在 **terminal-bench** 等基准测试中捕获的，可能会零星地触发上下文压缩，使得难以孤立地评估其影响。

我们发现，通过在基准数据集上更积极地启用框架的各个功能来增强其信号是有益的。例如，虽然在可用上下文窗口的 10-20% 处触发总结可能导致整体性能次优，但它会产生显著更多的总结事件。这使得可以比较不同的配置（例如，您实现方案的变体）。例如，通过强制智能体频繁总结，我们能够识别对 **deepagents** 总结提示词的简单**修改**（我们在其中为会话意图和后续步骤添加了专用字段）如何有助于提高性能。

![](/images/posts/24a09b97ec3e.png)

图：Claude Sonnet 4.5 在 terminal-bench-2 上样本运行中随时间变化的 Token 使用情况（灰线显示所有运行；彩色线突出显示两个具体示例）。绿线显示在第 20 轮左右，当总结事件压缩对话历史时，Token 使用量急剧下降。橙线显示在第 40 轮左右，当一个大型文件写入工具调用从上下文中被移除时，出现了较小的减少。通过在上下文窗口的 25% 处触发压缩（而不是 Deep Agents 默认的 85%），我们生成了更多可供研究的事件。

### 针对性评估

Deep Agents SDK 维护了一套针对性评估，旨在隔离和验证各个上下文管理机制。这些是刻意设计的小型测试，使特定的故障模式显而易见且易于调试。

这些评估的目的不是衡量广泛的任务解决能力，而是确保智能体框架不会妨碍某些任务的执行。例如：

*   **总结是否保留了智能体的目标？** 一些评估有意在任务中途触发总结，然后检查智能体是否继续执行。这确保了总结不仅保留了智能体状态，也保留了其执行轨迹。
*   **智能体能否恢复被总结掉的信息？** 这里我们在对话早期嵌入一个“大海捞针”式的事实，强制触发总结事件，然后要求智能体稍后回忆该事实以完成任务。该事实在总结后不存在于活动上下文中，必须通过文件系统搜索来恢复。

这些针对性评估充当了上下文管理的集成测试：它们不取代完整的基准测试运行，但能显著减少迭代时间，并使故障可归因于特定的压缩机制，而非智能体的整体行为。

### 指导建议

在评估您自己的上下文压缩策略时，我们强调：

*   **从真实世界基准开始，然后对单个功能进行压力测试。** 首先在代表性任务上运行您的框架以建立基线性能。然后，人为地更积极地触发压缩（例如，在上下文的 10-20% 处，而不是 85%），以在每次运行中生成更多的压缩事件。这放大了来自单个功能的信号，使得更容易比较不同的方法（例如，您的总结提示词的变体）。
*   **测试可恢复性。** 上下文压缩只有在关键信息仍然可访问时才有用。应包括针对性测试，以验证智能体在压缩后既能继续朝着其原始目标前进，又能在需要时恢复特定细节（例如，“大海捞针”场景，其中一个关键事实被总结掉但必须在稍后检索）。
*   **监控目标漂移。** 最隐蔽的故障模式是智能体在总结后失去了对用户意图的追踪。这可能表现为智能体在总结后的回合中停下来请求澄清，或错误地宣布任务完成。与预期任务更微妙的偏差可能更难归因于总结；在样本数据集上强制频繁总结可能有助于暴露这些故障。

Deep Agent 工具包的所有功能均已开源。试用最新版本，并告诉我们哪种压缩策略最适合您的使用场景！

### 加入我们的通讯

获取来自 LangChain 团队和社区的最新动态

正在处理您的申请...

成功！请检查您的收件箱并点击链接确认订阅。

抱歉，出现错误。请重试。

---

> 本文由AI自动翻译，原文链接：[Context Management for Deep Agents](https://www.blog.langchain.com/context-management-for-deepagents/)
> 
> 翻译时间：2026-01-29 04:07
