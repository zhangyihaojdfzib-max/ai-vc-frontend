---
title: Claude长上下文提示词工程：提升信息召回率的技巧
title_original: Prompt engineering for Claude's long context window
date: '2026-01-06'
source: Anthropic
source_url: https://www.anthropic.com/news/prompting-long-context
author: ''
summary: 本文介绍了针对Claude长上下文窗口（10万Token）的提示词工程技巧，通过定量案例研究探讨如何提升模型从长文档中召回信息的能力。文章重点测试了两种技术：在回答问题前提取相关引用片段，以及在提示词中补充已回答问题的示例。实验使用政府文件生成多项选择题数据集，并对比了不同提示策略下Claude
  Instant模型的召回表现。研究还分享了生成有效测试问题的提示词设计方法，以规避模型依赖自身知识或问题表述模糊等常见陷阱。
categories:
- AI研究
tags:
- 提示词工程
- Claude
- 长上下文
- 信息召回
- 大语言模型
draft: false
translated_at: '2026-02-02T04:21:28.753568'
---

# 针对Claude长上下文窗口的提示词工程

![](/images/posts/58712369a291.jpg)

Claude 10万个Token的长上下文窗口使其能够处理数百页技术文档，甚至一整本书。随着我们持续扩展Claude API，我们注意到市场对如何最大化Claude潜力的提示词指导需求日益增长。今天，我们很高兴分享一项定量案例研究，探讨两种能提升Claude在长上下文中信息召回能力的技术：

1.  在回答问题前，提取与问题相关的引用片段
2.  在提示词中补充关于文档其他部分的已回答正确问题的示例

让我们深入细节。

## 测试长上下文信息召回：多项选择问答

我们本次实验的目标是评估相关技术，以最大化Claude从长文档中正确召回特定信息的几率。

作为测试的基础数据源，我们使用了一份每日发布、公开可用的政府文件，其中包含许多不同部门的会议记录和活动。我们选择了7月13日的一份文件，该日期在Claude训练数据截止日期之后。这最大限度地降低了Claude已了解文档信息的可能性。为了生成问答对数据集，我们采用了一种称为“随机拼贴”的方法。我们将文档分成若干部分，并使用Claude为每个部分生成五个多项选择题，每个问题包含三个错误答案和一个正确答案。然后，我们将这些部分的随机组合重新组装成长文档，以便将其输入Claude并测试其对内容的召回能力。

## 提示Claude生成多项选择题

让Claude为你编写评估（evals）是一个强大的工具，也是我们提示词工程团队经常使用的方法。然而，需要精心设计提示词，才能使Claude编写出难度适中的问题。在设计有效测试集的过程中，我们克服了以下一些挑战：

*   Claude可能会提出无需参考任何文档就能凭自身知识回答的问题，例如“交通部是做什么的？”
*   Claude可能会包含即使在短上下文情境中也难以正确回答的问题。例如，由于Claude以Token而非单词的视角看待世界，像“这段文字有多少个单词？”这样的问题往往会难倒Claude。
*   Claude可能会在答案中留下无意的线索，使得正确答案容易被猜出。值得注意的是，我们发现其默认倾向是使正确答案比错误答案详细得多。
*   Claude可能会引用“本文档”或“本段”，而没有具体指明是哪一段。这会产生问题，因为当我们拼接多个文档形成长上下文时，Claude无法知道问题具体指的是哪个文档。
*   也存在矫枉过正的风险，即问题过于明确以至于包含了答案本身。例如，“内政部2023年7月2日关于渔业季内额外行动的通知发布日期是什么？”就是一个无效的问题。

为了规避这些陷阱，我们使用了一个提示词模板，其中包含两个会议片段样本以及手写的问题作为少量示例，同时还包含一些写作指导，以促使Claude明确指定问题所指的段落细节。本实验中使用的模板及其他所有提示词均可在此处获取。

## 评估

对于本次评估，我们主要关注较小的Claude Instant模型（版本1.2），而非Claude 2模型。这有几个原因。首先，Claude 2在阅读非常长的文档后，其信息召回能力已经非常出色。Claude Instant则需要更多帮助，这使得我们更容易观察到提示词调整对性能的改善。此外，Claude Instant速度极快，您可以使用我们分享的笔记本来自行复现这些评估。当仅提供Claude用于编写问题的确切段落时，Claude Instant能够回答其自身生成的问题，正确率约为90%。我们剔除了那10%回答错误的问题——因为即使在短上下文情境下Claude也会答错，这些问题对于测试长上下文来说难度过高。我们还测试了当提供不包含问题来源材料的随机段落时Claude的召回能力。理论上，在三个错误答案的情况下，Claude猜对正确答案的几率应该只有25%。实际上，其猜对率为34%；高于随机概率，但超出不多。Claude有时可能基于其通用知识或答案中的细微线索来推断出正确答案。为了从较短的片段构建长文档，我们通过随机拼接多个段落，直到达到所需的Token数量，为每个问题人工生成了一个新的长上下文。我们在包含大约75,000和90,000个Token的拼接文档上测试了Claude。这种拼凑式的上下文构建方式，正是Claude在其问题中引用“本文档”或“本段”等模糊短语会导致问题的原因。当上下文中存在十几个不同的通知，而“本通知”可能指代其中任何一个时，像“本通知的发布日期是什么？”这样的问题就变得无法回答。这就是为什么我们的问题生成提示词中包含语言，指示Claude明确问题所指的段落——例如，“关于渔业季内额外行动的通知发布日期是什么？”生成长文档（拼贴画）后，我们使用四种不同的提示策略测试了Claude的召回能力：

1.  基础策略——直接要求Claude回答
2.  非政府示例——向Claude提供两个固定的、与政府文档无关的、已回答正确的通用知识多项选择题示例
3.  两个示例——向Claude提供两个已回答正确的多项选择题示例，这些示例是从上下文中关于其他片段的Claude生成问题集中动态随机选择的
4.  五个示例——与策略#3相同，但使用五个示例

对于上述四种策略中的每一种，我们还测试了是否使用 `<scratchpad>` 的情况，在其中我们指示Claude提取相关引用。此外，我们测试了这些策略在包含答案的段落位于输入开头、结尾或中间位置时的表现。最后，为了了解上下文长度对结果的影响，我们分别用70K和95K Token的文档进行了测试。上述测试我们使用了Claude Instant 1.2。我们也展示了Claude 2在基线策略和Claude Instant 1.2上表现最佳的策略下的结果。

## 结果

![](/images/posts/695038ad2d16.jpg)

![](/images/posts/25af9a3d742a.jpg)

关于实验的一些说明：

*   虽然使用草稿纸和示例显著提高了文档开头和中间部分的性能，但结尾部分的性能可能会下降。这可能是因为提示词中添加的示例增加了文档最末尾（相关信息所在处）与Claude需要回答问题时之间的距离。这可能只是次要问题，因为源文档中只有一小部分数据位于最末尾。然而，这确实强调了将指令放在提示词末尾的重要性，因为我们希望Claude对它们的召回率尽可能高。
*   Claude 2通过提示词从0.939提升到0.961，绝对值上看可能很小，但这反映了错误率降低了36%。

您可以借鉴以下要点来编写您的长上下文问答提示词：

- 为在两种上下文长度上获得最佳性能，请使用大量示例和草稿区。
- 在所有直接比较中，将相关引用提取到草稿区很有帮助。这虽会略微增加延迟，但能提高准确性。对于 Claude Instant 而言，其延迟已经非常低，因此无需担心此问题。
- 上下文示例对 70K 和 95K 长度均有帮助，且示例越多越好。
- 关于通用/外部知识的泛化示例似乎对性能没有帮助。

对于 Claude Instant，其性能与相关段落距离问题的远近以及距离提示词末尾的远近似乎存在单调的反比关系，而 Claude 2 在 95K 长度上的性能则在中间部分略有下降。3

## 介绍全新的 Anthropic Cookbook

本实验的完全可复现代码已发布在新的 **Anthropic Cookbook** 中。这个不断增长的资源集目前还包含另外两个示例：

- 一个**搜索与检索演示**，展示了用于搜索维基百科的工具使用流程。
- 关于通过 Anthropic API 实现**模拟 PDF 上传功能**的指南。

我们期待在未来扩展 Anthropic Cookbook 以及我们的其他提示词工程资源，并希望它们能激发您对使用 Claude 构建应用的宏大构想。**如果您尚未获得 Claude API 的访问权限，请[注册您的意向](https://www.anthropic.com/earlyaccess)。**

## 脚注

1 Claude 答错的问题中一个常见的主题是计数，例如："通知中说明的《担保贷款表格通用表格包》中每份表格的每位受访者估计回答数量是多少？"以及"Getinge Group Logistics Americas LLC 设施生产活动通知中列出了多少种拟议成品？"值得注意的是，在其中一些问题中，Claude 预先指定的"正确"答案（来自其生成问答对时）实际上并不正确。这是本实验的一个噪声来源。

2 这些问题分别是：1. 美国第一任总统是谁？A. 托马斯·杰斐逊，B. 乔治·华盛顿，C. 亚伯拉罕·林肯，D. 约翰·亚当斯。2. 水的沸点是多少华氏度？A. 200，B. 100，C. 287，D. 212。

3 一篇[近期论文](https://arxiv.org/abs/2307.03172)发现，在类似任务中，性能与内容在上下文中的位置呈 U 型关系。造成结果差异的一个可能解释是，该论文中的示例平均长度为 15K Token（附录 F），而本文中的长度为 70K/95K。

## 相关内容

### ServiceNow 选择 Claude 为其客户应用提供支持并提升内部生产力

### Anthropic 与英国政府合作，为 GOV.UK 服务带来 AI 助手

### Claude 的新宪法

---

> 本文由AI自动翻译，原文链接：[Prompt engineering for Claude's long context window](https://www.anthropic.com/news/prompting-long-context)
> 
> 翻译时间：2026-02-02 04:21
