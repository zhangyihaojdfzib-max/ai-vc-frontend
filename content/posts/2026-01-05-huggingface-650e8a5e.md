---
title: Falcon-H1-Arabic发布：混合架构突破阿拉伯语AI边界
title_original: 'Introducing Falcon-H1-Arabic: Pushing the Boundaries of Arabic Language
  AI with Hybrid Architecture'
date: '2026-01-05'
source: Hugging Face Blog
source_url: https://huggingface.co/blog/tiiuae/falcon-h1-arabic
author: null
summary: 本文宣布推出Falcon-H1-Arabic系列模型，这是最先进的阿拉伯语大语言模型。该系列采用创新的混合Mamba-Transformer架构，显著提升了长文本处理能力，上下文窗口最高达256K
  Token。模型通过重建数据管道，大幅提升了阿拉伯语方言覆盖与数据质量，并在预训练后进行了针对性的后训练以优化性能。该系列包含3B、7B和34B三种参数规模，旨在为不同应用场景提供高效的阿拉伯语NLP解决方案。
categories:
- AI研究
tags:
- 大语言模型
- 阿拉伯语AI
- 混合架构
- 自然语言处理
- Falcon
draft: false
translated_at: '2026-01-05T16:35:07.402Z'
---

**Falcon-H1-Arabic 发布：以混合架构突破阿拉伯语AI的边界**
在我们的官方博客文章中探索更多，并体验互动内容

构建世界级阿拉伯语大语言模型的旅程，是一个持续学习和迭代的过程。今天，我们激动地宣布推出 Falcon-H1-Arabic，这是我们迄今为止最先进的阿拉伯语大语言模型系列，在架构和能力上都实现了重大飞跃。此次发布凝聚了数月的研究、社区反馈和技术创新，最终形成了三个强大的模型，为阿拉伯语自然语言处理树立了新标准。

**基于成功：从 Falcon-Arabic 的演进**
几个月前我们推出 Falcon-Arabic 时，社区的反馈既让我们感到谦卑，也极具启发性。阿拉伯世界的开发者、研究人员和学生将模型用于实际用例，探索其极限并提供了宝贵的反馈。我们了解了模型表现出色的地方，更重要的是，也了解了其不足之处。长上下文理解、方言变体、数学推理和特定领域知识，成为需要更深入关注的关键领域。

我们不仅想进行渐进式改进，更希望从根本上重新思考我们的方法。成果就是 Falcon-H1-Arabic，这个模型系列不仅回应了我们收到的每一条反馈，还引入了此前在阿拉伯语建模中未曾探索过的架构创新。

Falcon-H1-Arabic 的 3B、7B、34B 模型在性能上超越了所有相似规模、有时甚至是更大规模的 SOTA 模型。

**阿拉伯语 NLP 首创：混合 Mamba-Transformer 架构**
Falcon-H1-Arabic 基于 Falcon-H1 混合架构构建，该架构在每个模块内集成了状态空间模型（Mamba）和 Transformer 注意力机制。两个组件并行运行，它们的表征在模块的输出投影之前进行融合。这种设计为极长序列提供了 Mamba 的线性时间可扩展性，同时保留了注意力机制精确的长距离建模能力。对于拥有丰富形态和灵活句子结构的阿拉伯语，这种方法显著提高了长文本的连贯性和推理能力。我们将此架构部署在三个规模上（3B、7B、34B 参数），每个规模都在能力、效率和可部署性之间取得平衡，适用于从边缘设备到企业应用的不同用例。

Falcon-H1 架构。注意力和 SSM 在每个模块内并行运行；它们的输出在模块的输出投影之前进行拼接。SSM/注意力头的数量取决于模型大小。更多细节请参阅 Falcon-H1 技术报告。

**突破上下文边界**
我们大幅提升了上下文能力，从 Falcon-Arabic 的 32K Token 限制，提升到 3B 模型的 128K Token，以及 7B 和 34B 模型的 256K Token。在 256K Token（约 20 万字）的规模下，这些模型可以处理多部小说或数百页技术文档，使得在法律分析、医疗记录、学术研究和长对话等此前不切实际的应用成为可能。我们的后训练特别针对了“迷失在中间”的挑战，以确保模型能有效利用其全部上下文范围，而不仅仅是接受长输入。

| 参数 | 上下文窗口 | 架构 | 理想用途 |
|---|---|---|---|
| 3B | 128K | 混合 | 快速 Agent、高 QPS 系统、轻量级分析 |
| 7B | 256K | 混合 | 生产助手、推理、企业聊天 |
| 34B | 256K | 混合 | 长文档分析、研究、高要求任务 |

**数据质量与多样性：卓越的基石**
我们从头重建了预训练数据管道，以更好地反映阿拉伯语的复杂性。这始于一个针对阿拉伯语正字法、形态学、变音符号和句法模式定制的多阶段质量过滤流程。我们没有使用启发式过滤，而是通过深度语言分析来筛选连贯、结构良好的文本，并去除开放网络语料库中常见的噪声。结果是得到了一个显著更干净、风格更一致的阿拉伯语数据集。

方言覆盖是另一个关键优先事项。阿拉伯语并非单一语言；现代标准阿拉伯语与埃及、黎凡特、海湾和马格里布等方言共存，每种方言都有独特的词汇和语法结构。我们大幅扩展了方言来源，使模型能够理解和生成现实世界中完整的阿拉伯语谱系，而不是过度偏向于正式的现代标准阿拉伯语。为了保持全局推理和领域多样性，我们还保留了 Falcon-H1 的多语言能力，通过使用几乎等量的阿拉伯语、英语和多语言内容（总计约 3000 亿 Token）来训练阿拉伯语模型。这确保了在代码、STEM 和跨语言推理方面的强大性能。下图说明了预训练数据在语言和类别上的分布。所有数值均以十亿 Token 表示。

**后训练：精炼能力而不损害核心性能**
预训练之后，Falcon-H1-Arabic 经历了一个聚焦的后训练流程，包括监督微调（SFT）和随后的直接偏好优化（DPO）。在 SFT 阶段，我们让模型接触高质量的阿拉伯语指令、精选的长上下文示例和结构化推理任务，教导它们遵循指令、在长序列中保持连贯性，并将其回答基于相关信息。这个阶段对于确保模型能够实际使用其大上下文窗口至关重要，而这并非仅靠架构就能自动实现。

SFT 之后是目标明确的 DPO 阶段，以精炼对齐、对话质量和偏好一致性。DPO 帮助模型平衡长上下文推理与一般语言能力，提高帮助性并减少常见的失败模式，如偏离主题、过度使用上下文或忽略较早信息。在这两个阶段中，我们都仔细监控灾难性遗忘，并保持受控的训练课程，以确保长上下文行为的提升不会以牺牲核心推理或事实准确性为代价。最终得到的模型系列能够轻松处理长文档和对话，同时在日常语言任务上保持强劲性能。

除了面向基准的优化，我们的后训练过程还有意强化了传统评估未能完全捕捉的领域，包括对话忠实度、修辞组织、结构化跟进和话语连贯性。这些增强显著提升了模型的实用性，使 Falcon-H1-Arabic 在实际的多轮对话、指令执行和长上下文对话流中更加可靠。

**基准性能：树立新标准**
数据是故事的重要组成部分。在 Open Arabic LLM Leaderboard（OALL）——一个评估跨多种任务的阿拉伯语理解能力的综合基准上，Falcon-H1-Arabic 在我们测试的每个规模上都取得了最先进的结果。请注意，我们的分数可能与排行榜上报告的略有不同，因为我们使用了 vLLM 作为后端，而不是排行榜基于 Accelerate 的实现。这些差异通常在一个点以内，同时提供了显著更快的运行速度。

除了 OALL，我们还报告了在 3LM 基准（针对 STEM 相关任务，包括合成和原生数据分割）、Arabculture（阿拉伯文化评估）以及 AraDice（覆盖黎凡特和埃及方言的阿拉伯语方言覆盖度，以及 6 个国家的阿拉伯文化）上的结果。报告的 AraDice 分数是所有 3 项得分的平均值。

从 3B 模型开始，其性能就非常出色。

它在OALL基准上达到约62%，超越所有小规模模型，包括Gemma-4B、Qwen3-4B和Phi-4-mini约十个百分点。在阿拉伯语主要STEM基准3LM上，其在原生数据分割上得分约82%，在合成数据分割上得分约73%。在ArabCulture基准上达到约62%，在AraDice方言评估（埃及、海湾和黎凡特方言）中平均得分约50%。这使得Falcon-H1-Arabic-3B成为一个高质量、高效率的模型，适用于对延迟和成本敏感的边缘部署、实时应用和智能体系统。

7B模型延续了这一上升趋势。其在OALL上取得71.7%的分数，超越了所有约10B级别的模型，包括Fanar-9B、Allam-7B*和Qwen3-8B。在3LM上，其在原生数据分割上达到约92%，在合成数据分割上达到约85%。AraDice在所有方言上的得分上升至55%左右，ArabCulture结果接近80%。该模型在能力与可部署性之间取得了理想平衡，使其成为生产环境中通用阿拉伯语NLP最实用的选择。

34B模型代表了我们的旗舰系统，并为阿拉伯语建模树立了新的技术标杆。其在OALL上达到约75%，不仅超越了相似规模的模型，甚至超越了Llama-3.3-70B和AceGPT2-32B等更大规模的系统。其3LM分数在原生数据分割上达到约96%，在合成数据分割上达到约94%。在ArabCulture上得分接近80%，在AraDice上各方言平均得分约53%。一个34B混合模型超越了70B级别Transformer模型的性能，这证明了Falcon-H1架构的有效性、数据质量以及训练后流程的强度。

这些基准测试结果验证了我们的方法，同时也突显了一个重要现实：阿拉伯语建模的前沿正在快速发展。这些基准上每一个百分点的提升，都代表了无数小时的工程努力、精细的数据集整理和架构优化。Falcon-H1-Arabic领先的幅度不仅仅是统计数字，它们转化为实际应用中用户体验的显著提升。

**实际应用：从边缘到企业**
Falcon-H1-Arabic系列中的每个模型都适用于不同的部署场景。3B模型针对速度、成本效益和高吞吐量系统进行了优化，是智能体工作流、设备端应用、低延迟聊天以及资源严格受限环境的理想选择。7B模型是大多数生产应用的通用主力，可为文档理解系统、聊天机器人、摘要流水线和内容生成工具提供动力。34B模型专为高风险领域设计，这些领域最看重准确性和长程推理能力，包括法律分析、医学摘要、学术研究和大规模企业自动化。其扩展的上下文窗口使其能够独特地一次性分析数百页文本，同时保持精确的连贯性。

**负责任的人工智能与局限性**
与所有语言模型一样，Falcon-H1-Arabic可能反映训练数据中的偏见，并可能产生幻觉信息。模型输出不应在没有专业验证的情况下，作为医疗、法律或财务决策的唯一依据。在极端长度下，长上下文性能可能会下降。我们建议在生产或敏感应用部署前，进行特定任务评估并设置适当的防护措施。

**致谢**
这项工作是建立在许多人的贡献之上的。我们感谢阿拉伯语NLP研究社区，他们对基准、数据集和方法的开放共享推动了整个领域的进步。特别感谢我们在TII的同事：Ilyas Chahed, Younes Belkada, Dhia Eddine Rhaiem, Puneesh Khanna, Jingwei Zuo, Mikhail Lubinets, Slim Frikha, Maksim Velikanov, Kacper Piskorski, 和 Suhail Mohmad，感谢他们在此项目期间提供的宝贵支持。

**引用**
@misc{Falcon-H1-Arabic-2025,
title={Falcon-H1-Arabic: State-of-the-Art Arabic Language Models with Hybrid Mamba-Transformer Architecture},
author={Basma El Amel Boussaha and Mohammed Alyafeai and Ahmed Alzubaidi and Leen AlQadi and Shaikha Alsuwaidi and Omar Alkaabi and Hamza Alobeidli and Hakim Hacid},
url={https://huggingface.co/blog/tiiuae/falcon-h1-arabic},
month={December},
year={2025},
note={Available in 3B, 7B, and 34B parameter versions}
}
- 注：在我们的评估中，ALLaM-7B-Instruct-preview的分数高于OALL排行榜上报告的结果，因为我们使用了最新版本（7b-alpha-v2.33.0.30），而排行榜目前反映的是旧版本（7b-alpha-v1.27.2.25）的结果。

> 本文由AI自动翻译，原文链接：[Introducing Falcon-H1-Arabic: Pushing the Boundaries of Arabic Language AI with Hybrid Architecture](https://huggingface.co/blog/tiiuae/falcon-h1-arabic)
> 
> 翻译时间：2026-01-05 13:14
