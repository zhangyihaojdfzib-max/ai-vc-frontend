---
title: AI SDK 6发布：智能体、工具执行审批与完整MCP支持
title_original: AI SDK 6 - Vercel
date: '2025-12-22'
source: Vercel Blog
source_url: https://vercel.com/blog/ai-sdk-6
author: Authors
summary: Vercel发布AI SDK 6，引入Agent抽象用于构建可复用智能体，支持工具执行审批、DevTools和完整MCP集成。新版本提供ToolLoopAgent类处理完整工具执行循环，支持调用选项实现类型安全参数传递。AI
  SDK已成为构建AI应用的领先TypeScript工具包，被Thomson Reuters、Clay等企业用于构建生产级AI助手和研究智能体。
categories:
- AI基础设施
tags:
- AI SDK
- Vercel
- 智能体开发
- TypeScript
- AI工具链
draft: false
translated_at: '2026-01-05T16:35:07.400Z'
---

12 分钟阅读
介绍 Agent（智能体）、工具执行审批、DevTools、完整 MCP 支持、重排序、图像编辑等新功能。

凭借每月超过 2000 万次下载量，以及从初创公司到财富 500 强团队的广泛采用，AI SDK 已成为构建 AI 应用程序的领先 TypeScript 工具包。它提供了统一的 API，允许您与任何 AI 提供商集成，并能无缝集成 Next.js、React、Svelte、Vue 和 Node.js。AI SDK 使您能够构建从聊天机器人到复杂后台 Agent（智能体）的一切应用。

Thomson Reuters 使用 AI SDK 构建了 CoCounsel，这是他们面向律师、会计师和审计团队的 AI 助手，仅由 3 名开发者在 2 个月内完成。目前服务于 1,300 家会计师事务所，他们正在将整个代码库迁移到 AI SDK，弃用了跨 10 个提供商的数千行代码，并整合为一个可组合、可扩展的系统。

Clay 用它构建了 Claygent，这是他们的 AI 网络研究 Agent（智能体），可以抓取公共数据，通过 MCP 服务器连接到第一方数据源，并帮助销售团队通过定制、有针对性的洞察找到客户。

我们已全力投入 AI SDK。其 Agent（智能体）能力和 TypeScript 优先的设计为我们的大规模 AI 网络研究 Agent（智能体）（Claygent）提供了强大动力。在我们为客户构建用于寻找、筛选和呈现正确客户与潜在客户的 Agent（智能体）时，它提供了巨大的帮助。

今天，我们发布 AI SDK 6，它引入了：

从 AI SDK 5 升级？运行 `npx @ai-sdk/codemod v6`
以最小的代码更改自动迁移。

链接到标题Agent（智能体）
AI SDK 6 引入了用于构建可复用 Agent（智能体）的 Agent
抽象。只需定义一次您的 Agent（智能体），包括其模型、指令和工具，然后在整个应用程序中使用它。Agent（智能体）会自动与完整的 AI SDK 生态系统集成，为您提供类型安全的 UI 流式传输、结构化输出和无缝的框架支持。

使用 `generateText`
和 `streamText`
的函数式方法功能强大且底层，无论规模大小，都能让您完全掌控。但是，当您希望在不同媒介（聊天 UI、后台作业、API 端点）中复用同一个 Agent（智能体），或者将工具组织在单独的文件中时，内联配置方法就会失效。您最终会到处传递相同的配置对象，或者构建自己的抽象层。

链接到标题ToolLoopAgent
`ToolLoopAgent`
类提供了一个生产就绪的实现，用于处理完整的工具执行循环。它使用您的提示词调用 LLM（大语言模型），执行任何请求的工具调用，将结果添加回对话，并重复此过程直到完成（默认最多 20 步：`stopWhen: stepCountIs(20)`
）。

```javascript
import { ToolLoopAgent } from 'ai';
import { weatherTool } from '@/tools/weather';

export const weatherAgent = new ToolLoopAgent({
  model: 'anthropic/claude-sonnet-4.5',
  instructions: 'You are a helpful weather assistant.',
  tools: { weather: weatherTool },
});

const result = await weatherAgent.generate({
  prompt: 'What is the weather in San Francisco?',
});
```

要了解更多信息，请查看构建 Agent（智能体）文档。

链接到标题调用选项
通过调用选项，您可以在 `ToolLoopAgent` 上调用 `generate`
或 `stream`
时传递类型安全的参数。例如，您可以使用它们为 RAG（检索增强生成）注入检索到的文档，根据请求复杂性选择模型，或为每个请求自定义工具行为。

```javascript
import { ToolLoopAgent } from "ai";
import { z } from "zod";

const supportAgent = new ToolLoopAgent({
  model: "anthropic/claude-sonnet-4.5",
  callOptionsSchema: z.object({
    userId: z.string(),
    accountType: z.enum(["free", "pro", "enterprise"]),
  }),
  prepareCall: ({ options, ...settings }) => ({
    ...settings,
    instructions: `You are a helpful customer support agent.
- User Account type: ${options.accountType}
- User ID: ${options.userId}`,
  }),
});

const result = await supportAgent.generate({
  prompt: "How do I upgrade my account?",
  options: {
    userId: "user_123",
    accountType: "free",
  },
});
```

要了解更多信息，请查看配置调用选项文档。

链接到标题代码组织与 UI 集成
Agent（智能体）抽象促使您实现清晰的关注点分离，并为您带来端到端的类型安全。在专用文件中定义工具，将它们组合成 Agent（智能体），并通过 API 路由暴露它们。驱动您 Agent（智能体）逻辑的相同定义也为您的 UI 组件提供了类型。

```javascript
// agents/weather-agent.ts
import { ToolLoopAgent, InferAgentUIMessage } from "ai";
import { weatherTool } from "@/tools/weather-tool";

  instructions: "You are a helpful weather assistant.",
});

export type WeatherAgentUIMessage = InferAgentUIMessage<typeof weatherAgent>;

// app/api/chat/route.ts
import { createAgentUIStreamResponse } from "ai";
import { weatherAgent } from "@/agents/weather-agent";

export async function POST(request: Request) {
  const { messages } = await request.json();
  return createAgentUIStreamResponse({
    agent: weatherAgent,
    uiMessages: messages,
  });
}
```

在客户端，类型会自动流动。从您的 Agent（智能体）文件中导入消息类型，然后通过切换部件类型来渲染类型化的工具组件。

```javascript
// app/page.tsx
import { useChat } from '@ai-sdk/react';
import type { WeatherAgentUIMessage } from '@/agents/weather-agent';
import { WeatherToolView } from '@/components/weather-tool-view';

export default function Chat() {
  const { messages, sendMessage } = useChat<WeatherAgentUIMessage>();
  return (
    <div>
      {messages.map((message) =>
        message.parts.map((part) => {
          switch (part.type) {
            case 'tool-weather':
              return <WeatherToolView invocation={part} />;
          }
        })
      )}
    </div>
  );
}

// components/weather-tool-view.tsx
import { UIToolInvocation } from 'ai';
import { weatherTool } from '@/tools/weather-tool';

export function WeatherToolView({
  invocation,
}: {
  invocation: UIToolInvocation<typeof weatherTool>;
}) {
  return (
    <div>
      Weather in {invocation.input.location} is {invocation.output?.temperature}°F
    </div>
  );
}
```

一次定义，随处使用。相同的工具定义驱动着您的 Agent（智能体）逻辑、API 响应和 UI 组件。

要了解更多信息，请查看 Agent（智能体）文档。

链接到标题自定义 Agent（智能体）实现
在 AI SDK 6 中，`Agent`
是一个接口而非类。虽然 `ToolLoopAgent`
为大多数用例提供了可靠的默认实现，但您可以实现 `Agent`
接口，根据您的需求构建自己的 Agent（智能体）抽象。

其中一个例子是 Workflow DevKit，它提供了 `DurableAgent`
。它通过将您的 Agent（智能体）转变为持久化、可恢复的工作流，使它们达到生产就绪状态，其中每个工具执行都成为一个可重试、可观察的步骤。

```javascript
import { getWritable } from 'workflow';
import { DurableAgent } from '@workflow/ai/agent';
import { searchFlights, bookFlight, getFlightStatus } from './tools';

export async function flightBookingWorkflow() {
  'use workflow';

  const flightAgent = new DurableAgent({
    system: 'You are a flight booking assistant.',
    tools: { searchFlights, bookFlight, getFlightStatus },
  });

  const result = await flightAgent.generate({
    prompt: 'Find me a flight from NYC to London next Friday.',
    writable: getWritable(),
  });
}
```

在构建持久化 Agent（智能体）文档中了解更多信息。

链接到标题工具改进
工具是您 Agent（智能体）能力的基础。

Agent（智能体）执行有意义操作的能力，完全取决于其生成有效工具输入的可靠性、这些输入与您意图的匹配程度、工具输出在对话中表示为Token的效率，以及这些工具在生产环境中执行的安全性。

AI SDK 6 在以下每个方面都进行了改进：通过工具执行审批实现人机协同控制，通过严格模式实现更可靠的输入生成，通过输入示例实现更好的意图对齐，以及通过 `toModelOutput` 实现灵活的工具输出。

### 工具执行审批
构建能够执行现实世界操作（删除文件、处理支付、修改生产数据）的Agent需要一个关键的安全层：人工审批。没有它，您就是在盲目信任Agent的每一个决策。

在 AI SDK 6 中，您只需一个 `needsApproval` 标志即可获得人机协同控制，无需编写自定义代码。您可以通过 Chat SDK（一个用于构建聊天机器人应用的开源模板）查看此功能的实际应用。

默认情况下，当模型调用工具时，工具会自动运行。设置 `needsApproval: true` 可在执行前要求审批：

```javascript
import { tool } from 'ai';
import { z } from 'zod';

export const runCommand = tool({
  description: 'Run a shell command',
  inputSchema: z.object({
    command: z.string().describe('The shell command to execute'),
  }),
  needsApproval: true, // 需要用户审批
  execute: async ({ command }) => {
    // 您的命令执行逻辑
  },
});
```

并非每个工具调用都需要审批。一个简单的 `ls` 命令或许可以自动批准，但一个破坏性的 `rm -rf` 命令则需要审核。您可以向 `needsApproval` 传递一个函数，根据输入来决定是否需要审批，并存储用户偏好，以便记住已批准的调用模式供未来使用。

```javascript
import { tool } from "ai";

const runCommand = tool({
  description: "Run a shell command",
    command: z.string().describe("The shell command to execute"),
  }),
  needsApproval: async ({ command }) => command.includes("rm -rf"),
  execute: async ({ command }) => { /* command execution logic */ },
});
```

在您的 UI 中使用 `useChat` 处理审批非常简单。检查工具调用状态，提示用户，并使用 `addToolApprovalResponse` 返回响应：

```javascript
import { ChatAddToolApproveResponseFunction } from 'ai';
import { runCommand } from './tools/command-tool';

export function CommandToolView({
  invocation,
  addToolApprovalResponse,
}: {
  invocation: UIToolInvocation<typeof runCommand>;
  addToolApprovalResponse: ChatAddToolApproveResponseFunction;
}) {
  if (invocation.state === 'approval-requested') {
    return (
      <div>
        <p>Run command: {invocation.input.command}?</p>
        <button
          onClick={() =>
            addToolApprovalResponse({
              id: invocation.approval.id,
              approved: true,
            })
          }
        >
          Approve
        </button>
        <button
          onClick={() =>
              approved: false,
            })
          }
        >
          Deny
        </button>
      </div>
    );
  }

  if (invocation.state === 'output-available') {
    return <div>Output: {invocation.output}</div>;
  }

  // 处理其他状态...
}
```

要了解更多信息，请查看工具执行审批文档。

### 严格模式
当可用时，语言模型提供商提供的原生严格模式能保证工具调用输入完全匹配您的模式。然而，一些提供商在严格模式下仅支持 JSON 模式规范的一个子集。如果您的请求中任何工具使用了不兼容的模式特性，整个请求都会失败。

AI SDK 6 允许按工具选择启用严格模式。您可以在同一次调用中，为模式兼容的工具使用严格模式，为其他工具使用常规模式。

```javascript
tool({
  description: 'Get the weather in a location',
    location: z.string(),
  }),
  strict: true, // 为此工具启用严格验证
  execute: async ({ location }) => ({
    // ...
  }),
});
```

### 输入示例
对于包含嵌套对象、特定格式要求或领域特定模式的复杂工具模式，仅通过工具描述可能难以清晰说明。即使有详细的逐字段描述，模型有时生成的输入虽然在技术上有效，但并不符合您期望的模式。

输入示例向模型展示了正确结构输入的具体实例，阐明了难以在模式描述中表达的期望：

```javascript
tool({
    location: z.string().describe('The location to get the weather for'),
  }),
  inputExamples: [
    { input: { location: 'San Francisco' } },
    { input: { location: 'London' } },
  ],
  execute: async ({ location }) => {
    // ...
  },
});
```

输入示例目前仅由 Anthropic 原生支持。对于不支持的提供商，您可以使用 `addToolInputExamplesMiddleware` 将示例附加到工具描述中。如果未使用中间件且提供商不支持输入示例，它们将被忽略，不会发送给提供商。

### 向模型发送自定义工具输出
默认情况下，从工具的 `execute` 函数返回的任何内容都会在后续对话轮次中作为字符串化的 JSON 发送给模型。然而，当工具返回大量文本输出（文件内容、搜索结果）或二进制数据（屏幕截图、生成的图像）时，您最终会发送数千个不必要的Token，或者尴尬地将图像编码为 base64 字符串。

`toModelOutput` 函数将您的工具结果与发送给模型的内容分离开来。从 `execute` 函数返回完整数据供您的应用程序逻辑使用，然后使用 `toModelOutput` 精确控制哪些Token返回给模型：

```javascript

const weatherTool = tool({
  description: "Get the weather in a location",
    location: z.string().describe("The location to get the weather for"),
  }),
  execute: ({ location }) => ({
    temperature: 72 + Math.floor(Math.random() * 21) - 10,
  }),
  // toModelOutput 可以是同步或异步的
  toModelOutput: async ({ input, output, toolCallId }) => {
    // 许多其他选项，包括 json、包含文件和图像的多部分数据等。
    // （支持情况取决于提供商）
    // 示例：将工具输出作为文本发送
    return {
      type: "text",
      value: `The weather in ${input.location} is ${output.temperature}°F.`,
    };
  },
});
```

要了解更多信息，请查看工具调用文档。

### MCP
AI SDK 6 扩展了我们对 MCP 的支持，涵盖了 OAuth 身份验证、资源、提示词和引导。您现在可以通过资源公开数据，创建可重用的提示词模板，并处理服务器发起的用户输入请求。此功能现已稳定，并在 `@ai-sdk/mcp` 包中提供。

### HTTP 传输
要连接到远程 MCP 服务器，您需要配置一个包含服务器 URL 和身份验证标头的 HTTP 传输：

```javascript
import { createMCPClient } from '@ai-sdk/mcp';

const mcpClient = await createMCPClient({
  transport: {
    type: 'http',
    url: '<https://your-server.com/mcp>',
    headers: {
      Authorization: 'Bearer my-api-key'
    },
  },
});

const tools = await mcpClient.tools();
```

### OAuth 身份验证
远程 MCP 服务器通常需要身份验证，尤其是访问用户数据或第三方 API 的托管服务。正确实现 OAuth 意味着要处理 PKCE 质询、令牌刷新、动态客户端注册以及在会话中途令牌过期时的重试逻辑。任何环节出错都会破坏您的集成。

AI SDK 6 为您处理完整的 OAuth 流程：

```javascript
import { createMCPClient, auth, OAuthClientProvider } from "@ai-sdk/mcp";

const authProvider: OAuthClientProvider = {
  redirectUrl: "http://localhost:3000/callback",
  clientMetadata: {
    client_name: "My App",
    redirect_uris: ["http://localhost:3000/callback"],
    grant_types: ["authorization_code", "refresh_token"],
  },
  // 令牌和凭证存储方法
  tokens: async () => { /* ... */ },
  saveTokens: async (tokens) => { /* ... */ },
  // ...
```

剩余 OAuthClientProvider 配置};
await auth(authProvider, { serverUrl: new URL("https://mcp.example.com") });
const client = await createMCPClient({ transport: { type: "http", url: "https://mcp.example.com", authProvider },});

### 资源和提示词
MCP 服务器可以通过资源（文件、数据库记录、API 响应）暴露数据，供您的应用程序发现和读取。提示词则提供来自服务器的可重用模板，并包含您在运行时需要填写的参数：
// 列出并读取资源
const resources = await mcpClient.listResources();
const resourceData = await mcpClient.readResource({ uri: "file:///example/document.txt",});

// 列出并获取提示词
const prompts = await mcpClient.experimental_listPrompts();
const prompt = await mcpClient.experimental_getPrompt({
  name: "code_review",
  arguments: { code: "function add(a, b) { return a + b; }" },
});

### 征询支持
有时，MCP 服务器在操作过程中需要用户输入（例如确认、选项选择或额外上下文）。征询功能允许服务器请求此类输入，而您的应用程序则负责收集它：
  transport: { type: 'sse', url: '<https://your-server.com/sse>' },
  capabilities: { elicitation: {} },
});

mcpClient.onElicitationRequest(ElicitationRequestSchema, async request => {
  const userInput = await getInputFromUser(
    request.params.message,
    request.params.requestedSchema,
  );

  return { action: 'accept', content: userInput, };
});

要了解更多信息，请查阅 MCP 工具文档。

### 具有结构化输出的工具调用
以前，将工具调用与结构化输出结合使用需要将 `generateText` 和 `generateObject` 链接在一起。AI SDK 6 统一了 `generateObject` 和 `generateText`，从而能够在最后生成结构化输出的多步骤工具调用循环。
import { Output, ToolLoopAgent, tool } from "ai";

const agent = new ToolLoopAgent({
  tools: {
    weather: tool({
      inputSchema: z.object({ city: z.string() }),
      execute: async ({ city }) => { // ... },
    }),
  },
  output: Output.object({
    schema: z.object({
      summary: z.string(),
      temperature: z.number(),
      recommendation: z.string(),
    }),
  }),
});

const { output } = await agent.generate({
  prompt: "What is the weather in San Francisco and what should I wear?",
});

### 输出类型
结构化输出支持多种格式。使用 `Output` 对象来指定您需要的形状：
- `Output.object()`: 生成结构化对象
- `Output.array()`: 生成结构化对象数组
- `Output.choice()`: 从特定选项集中选择
- `Output.json()`: 生成非结构化 JSON
- `Output.text()`: 生成纯文本（默认行为）

要了解更多信息，请查阅生成结构化数据文档。

### 开发者工具
调试多步骤 Agent（智能体）流程非常困难。某一步中上下文或输入 Token 的微小变化，都可能显著改变该步骤的输出，进而改变下一步的输入，依此类推。到最后，整个轨迹可能完全不同，而要追溯其原因，就意味着需要手动记录每一步并自行拼凑出整个序列。

AI SDK 开发者工具让您能够完全洞察您的 LLM（大语言模型）调用和 Agent（智能体）。检查任何调用的每一步，包括输入、输出、模型配置、Token 使用情况、时间以及原始提供商的请求和响应。

### 设置
要开始使用，请用 `devToolsMiddleware` 包装您的模型：
import { wrapLanguageModel, gateway } from 'ai';
import { devToolsMiddleware } from '@ai-sdk/devtools';

const devToolsEnabledModel = wrapLanguageModel({
  model: gateway('anthropic/claude-sonnet-4.5'),
  middleware: devToolsMiddleware(),
});

然后将其与任何 AI SDK 函数一起使用：
import { generateText } from 'ai';

const result = await generateText({
  model: devToolsEnabledModel,
  prompt: 'What is love?',
});

### 检查您的运行记录
使用 `npx @ai-sdk/devtools` 启动查看器，并打开 http://localhost:4983 来检查您的运行记录。您将能够看到：
- **输入参数和提示词**：查看发送给 LLM（大语言模型）的完整输入
- **输出内容和工具调用**：检查生成的文本和工具调用
- **Token 使用情况和时间**：监控资源消耗和性能
- **原始提供商数据**：访问完整的请求和响应负载

要了解更多信息，请查阅开发者工具文档。

### 重排序
为语言模型提供相关上下文不仅仅是检索所有可能相关的内容。模型在获得聚焦、高度相关的上下文时表现更好。重排序根据搜索结果与特定查询的相关性对它们进行重新排序，让您只将最相关的文档传递给模型。

AI SDK 6 通过新的 `rerank` 函数增加了对重排序的原生支持：
import { rerank } from 'ai';
import { cohere } from '@ai-sdk/cohere';

const documents = [
  'sunny day at the beach',
  'rainy afternoon in the city',
  'snowy night in the mountains',
];

const { ranking } = await rerank({
  model: cohere.reranking('rerank-v3.5'),
  documents,
  query: 'talk about rain',
  topN: 2,
});

console.log(ranking);
// [
//   { originalIndex: 1, score: 0.9, document: 'rainy afternoon in the city' },
//   { originalIndex: 0, score: 0.3, document: 'sunny day at the beach' }
// ]

### 结构化文档重排序
重排序也支持结构化文档，使其非常适合搜索数据库、电子邮件或其他结构化内容：

const documents = [
  { from: 'Paul Doe', subject: 'Follow-up', text: '20% discount offer...' },
  { from: 'John McGill', subject: 'Missing Info', text: 'Oracle pricing: $5000/month', },
];

const { rerankedDocuments } = await rerank({
  documents,
  query: 'Which pricing did we get from Oracle?',
  topN: 1,
});

`rerank` 函数目前支持 Cohere、Amazon Bedrock 和 Together.ai。

要了解更多信息，请查阅重排序文档。

### 标准 JSON 模式
AI SDK 6 增加了对任何实现标准 JSON 模式接口的模式库的支持。以前，SDK 需要为每个模式库（Arktype, Valibot）内置转换器。现在，任何实现标准 JSON 模式 V1 规范的库都可以自动工作，无需对 SDK 进行额外更改。
import { generateText, Output } from 'ai';
import { type } from 'arktype';

    schema: type({
      recipe: {
        name: 'string',
        ingredients: type({ name: 'string', amount: 'string' }).array(),
        steps: 'string[]',
      },
    }),
  }),
  prompt: 'Generate a lasagna recipe.',
});

要了解更多信息，请查阅工具文档。

### 提供商工具
AI SDK 6 扩展了对特定于提供商的工具的支持，这些工具利用了独特的平台能力和模型训练的功能。

这些工具专为特定模型或平台（如网络搜索、代码执行和内存管理）设计，供应商已针对这些能力优化其模型，或提供其他地方不具备的平台特定功能。

### Anthropic 供应商工具
**内存工具**：通过内存文件目录跨对话存储和检索信息
**工具搜索（正则表达式）**：使用正则表达式模式动态搜索和选择工具
**工具搜索（BM25）**：使用自然语言查询搜索和选择工具
**代码执行工具**：在支持 bash 和文件操作的安全沙盒环境中运行代码

```javascript
import { anthropic } from "@ai-sdk/anthropic";
// 内存工具 - 存储和检索信息
const memory = anthropic.tools.memory_20250818({
  execute: async (action) => {
    // 实现内存存储逻辑
    // 支持：view, create, str_replace, insert, delete, rename
  },
});

// 工具搜索（正则表达式） - 按模式查找工具
const toolSearchRegex = anthropic.tools.toolSearchRegex_20251119();

// 工具搜索（BM25） - 使用自然语言查找工具
const toolSearchBm25 = anthropic.tools.toolSearchBm25_20251119();

// 代码执行工具 - 在沙盒中运行代码
const codeExecution = anthropic.tools.codeExecution_20250825();
```

AI SDK 6 还增加了对编程式工具调用的支持，允许 Claude 从代码执行环境调用您的工具，从而将中间结果排除在上下文之外。这可以显著减少 Token 使用量和成本。

使用 `allowedCallers` 将工具标记为可从代码执行中调用，并使用 `prepareStep` 在多个步骤中保持容器：

```javascript
import {
  anthropic,
  forwardAnthropicContainerIdFromLastStep,
} from "@ai-sdk/anthropic";

const getWeather = tool({
  description: "获取城市天气。",
  execute: async ({ city }) => ({ temp: 22 }),
  providerOptions: {
    anthropic: { allowedCallers: ["code_execution_20250825"] },
  },
});

  model: anthropic("claude-sonnet-4-5"),
  tools: {
    code_execution: anthropic.tools.codeExecution_20250825(),
    getWeather,
  },
  prepareStep: forwardAnthropicContainerIdFromLastStep,
});
```

要了解更多信息，请查看 [Anthropic 文档](https://sdk.vercel.ai/docs/ai-sdk-providers/anthropic)。

### OpenAI 供应商工具
**Shell 工具**：执行具有超时和输出限制的 shell 命令
**应用补丁工具**：使用结构化差异创建、更新和删除文件
**MCP 工具**：连接到远程模型上下文协议服务器

```javascript
import { openai } from "@ai-sdk/openai";

// Shell 工具 - 执行 shell 命令
const shell = openai.tools.shell({
  execute: async ({ action }) => {
    // action.commands: string[] - 要执行的命令
    // action.timeoutMs: 可选超时时间
    // action.maxOutputLength: 可选返回的最大字符数
  },
});

// 应用补丁工具 - 使用差异进行文件操作
const applyPatch = openai.tools.applyPatch({
  execute: async ({ callId, operation }) => {
    // operation.type: 'create_file' | 'update_file' | 'delete_file'
    // operation.path: 文件路径
    // operation.diff: 差异内容（用于创建/更新）
  },
});

// MCP 工具 - 连接到 MCP 服务器
const mcp = openai.tools.mcp({
  serverLabel: "my-mcp-server",
  serverUrl: "https://mcp.example.com",
  allowedTools: ["tool1", "tool2"],
});
```

要了解更多信息，请查看 [OpenAI 文档](https://sdk.vercel.ai/docs/ai-sdk-providers/openai)。

### Google 供应商工具
**Google 地图工具**：通过地图基础信息实现位置感知响应（Gemini 2.0+）
**Vertex RAG 存储工具**：从 Vertex AI RAG Engine 语料库检索上下文（Gemini 2.0+）
**文件搜索工具**：在文件搜索存储中进行语义和关键词搜索（Gemini 2.5+）

```javascript
import { google } from "@ai-sdk/google";

// Google 地图工具 - 位置感知基础信息
const googleMaps = google.tools.googleMaps();

// Vertex RAG 存储工具 - 从 RAG 语料库检索
const vertexRagStore = google.tools.vertexRagStore({
  ragCorpus: "projects/{project}/locations/{location}/ragCorpora/{rag_corpus}",
  topK: 5, // 可选：要检索的上下文数量
});

// 文件搜索工具 - 在文件存储中搜索
const fileSearch = google.tools.fileSearch({
  fileSearchStoreNames: ["fileSearchStores/my-store-123"],
  topK: 10, // 可选：要检索的块数量
  metadataFilter: "author=John Doe", // 可选：AIP-160 过滤器
});
```

要了解更多信息，请查看 [Google 文档](https://sdk.vercel.ai/docs/ai-sdk-providers/google)。

### xAI 供应商工具
**网络搜索**：支持域名过滤和图像理解的网络搜索
**X 搜索**：支持用户句柄和日期过滤的 X（Twitter）帖子搜索
**代码执行**：在沙盒环境中运行代码
**查看图像**：分析和描述图像
**查看 X 视频**：分析 X 视频内容

```javascript
import { xai } from "@ai-sdk/xai";

// 网络搜索工具 - 搜索网络
const webSearch = xai.tools.webSearch({
  allowedDomains: ["wikipedia.org", "github.com"], // 可选：最多 5 个
  excludedDomains: ["example.com"], // 可选：最多 5 个
  enableImageUnderstanding: true, // 可选
});

// X 搜索工具 - 搜索 X 帖子
const xSearch = xai.tools.xSearch({
  allowedXHandles: ["elonmusk", "xai"], // 可选：最多 10 个
  fromDate: "2025-01-01", // 可选
  toDate: "2025-12-31", // 可选
  enableVideoUnderstanding: true, // 可选
});

// 代码执行工具 - 运行代码
const codeExecution = xai.tools.codeExecution();

// 查看图像工具 - 分析图像
const viewImage = xai.tools.viewImage();

// 查看 X 视频工具 - 分析 X 视频
const viewXVideo = xai.tools.viewXVideo();
```

要了解更多信息，请查看 [xAI 文档](https://sdk.vercel.ai/docs/ai-sdk-providers/xai)。

### 图像编辑
图像生成模型的能力已远不止文本到图像生成。许多模型现在支持图像到图像操作，如修复、扩展、风格迁移等。

AI SDK 6 扩展了 `generateImage` 以支持图像编辑，允许在文本提示词之外接受参考图像：

```javascript
import { generateImage } from "ai";
import { blackForestLabs } from "@ai-sdk/black-forest-labs";

const { images } = await generateImage({
  model: blackForestLabs.image("flux-2-pro"),
  prompt: {
    text: "编辑此图像，使其成为两只狸猫在约会",
    images: ["https://www.example.com/tanuki.png"],
  },
});
```

参考图像可以作为 URL 字符串、base64 编码字符串、Uint8Array、ArrayBuffer 或 Buffer 提供。

注意：`experimental_generateImage` 已升级为稳定版并重命名为 `generateImage`。

查看 [图像生成文档](https://sdk.vercel.ai/docs/ai-sdk-core/generate-image) 以了解更多信息。

### 原始完成原因和扩展使用情况
AI SDK 6 通过原始完成原因和重构的使用情况信息，提高了模型响应的可见性。

#### 原始完成原因
当供应商添加 AI SDK 无法识别的新完成原因时，它们以前会显示为 `'other'`。

现在，rawFinishReason
会直接暴露来自提供商的原始字符串，让您能够在 AI SDK 更新之前处理特定于提供商的情况。
const { finishReason, rawFinishReason } = await generateText({ model: 'anthropic/claude-sonnet-4.5', prompt: 'What is love?',});
// finishReason: 'other' (已映射)// rawFinishReason: 'end_turn' (提供商特定)
当提供商有多个完成原因映射到同一个 AI SDK 值时，或者当您需要区分特定的提供商行为时，这非常有用。
链接到标题扩展使用信息
使用情况报告现在包含输入和输出 Token 的详细细分：
const { usage } = await generateText({ model: 'anthropic/claude-sonnet-4.5', prompt: 'What is love?',});
// 输入 Token 详情usage.inputTokenDetails.noCacheTokens; // 非缓存的输入 Tokenusage.inputTokenDetails.cacheReadTokens; // 从缓存读取的 Tokenusage.inputTokenDetails.cacheWriteTokens; // 写入缓存的 Token
// 输出 Token 详情usage.outputTokenDetails.textTokens; // 文本生成 Tokenusage.outputTokenDetails.reasoningTokens; // 推理 Token（在支持的情况下）
// 原始提供商使用情况usage.raw; // 完整的提供商特定使用情况对象
这些详细的细分数据为您提供了所需的可见性，以便优化成本并跨提供商调试 Token 使用情况。
链接到标题LangChain 适配器重写
@ai-sdk/langchain
包已重写，以支持现代 LangChain 和 LangGraph 功能。新的 API 包括 toBaseMessages()
用于将 UI 消息转换为 LangChain 格式，toUIMessageStream()
用于转换 LangGraph 事件流，以及 LangSmithDeploymentTransport
用于浏览器端连接到 LangSmith 部署。该适配器现在支持带有部分输入流、推理块以及通过 LangGraph 中断实现的人机协同工作流的工具调用。
import { toBaseMessages, toUIMessageStream } from '@ai-sdk/langchain';import { createUIMessageStreamResponse } from 'ai';
const langchainMessages = await toBaseMessages(messages);const stream = await graph.stream({ messages: langchainMessages });
return createUIMessageStreamResponse({ stream: toUIMessageStream(stream),});
此版本完全向后兼容。要了解更多信息，请查看 LangChain 适配器文档。
链接到标题迁移到 AI SDK 6
AI SDK 6 是一个主要版本，原因是引入了 v3 语言模型规范，该规范为 Agent（智能体）和工具批准等新功能提供了支持。然而，与 AI SDK 5 不同，此版本预计不会对大多数用户造成重大的破坏性变更。
版本号的提升反映了规范的改进，而不是 SDK 的完全重新设计。如果您正在使用 AI SDK 5，迁移到 v6 应该很简单，只需最少的代码更改。
npx @ai-sdk/codemod upgrade v6
有关所有变更以及可能需要的手动步骤的详细概述，请参阅我们的 AI SDK 6 迁移指南。该指南包含分步说明和示例，以确保顺利更新。
链接到标题开始使用
我对 v6 感到非常兴奋。从 streamText 转向可组合的 Agent（智能体）非常精妙，围绕类型安全、MCP 和 Agent（智能体）准备的新 API 也是如此。团队在 API 设计上投入的精力令人惊叹。
凭借 ToolLoopAgent
、人机协同工具批准、带有工具调用的稳定结构化输出以及用于调试的 DevTools 等强大的新功能，现在正是使用 AI SDK 构建 AI 应用程序的最佳时机。
开始一个新的 AI 项目：通过我们最新的 Next.js、React、Svelte 等指南快速上手。查看我们的最新指南。
探索我们的模板：访问我们的模板库，获取可用于生产环境的入门项目。
迁移到 v6：使用我们的自动化代码修改工具实现平稳过渡。我们全面的迁移指南涵盖了所有破坏性变更。
试用 DevTools：通过完全可见的 LLM（大语言模型）调用来调试您的 AI 应用程序。查看 DevTools 文档。
加入社区：在我们的 GitHub Discussions 中分享您正在构建的内容、提问并与其他开发者交流。
链接到标题贡献者
AI SDK 6 是 Vercel 核心团队（Gregor, Lars, Aayush, Josh, Nico）和我们出色的贡献者社区共同努力的成果：
viktorlarsson, shaper, AVtheking, SamyPesse, firemoonai, seldo, R-Taneja, ZiuChen, gaspar09, christian-bromann, jeremyphilemon, DaniAkash, a-tokyo, rohrz4nge, EwanTauran, codicecustode, shubham-021, kkawamu1, mclenhard, gdaybrice, dyh-sjtu, blurrah, EurFelux, AryanBagade, Omcodes23, jeffcarbs, codeyogi911, zirkelc, qkdreyer, tsuzaki430, qchuchu, karthikscale3, alex-deneuvillers, kesku, yorkeccak, guy-hartstein, Und3rf10w, siwachabhi, homanp, tengis617, SalvatoreAmoroso, ericciarla, baturyilmaz, chentsulin, kovereduard, yaonyan, mwln, IdoBouskila, wangyedev, rubnogueira, Emmaccen, priyanshusaini105, dpmishler, yilinjuang, JulioPeixoto, DeJeune, BangDori, shadowssdt, efantasia, kevinjosethomas, lukehrucker, Mohammedsinanpk, danielamitay, davidsonsns, teeverc, MQ37, jephal, TimPietrusky, theishangoswami, juliettech13, shelleypham, tconley1428, goyalshivansh2805, KirschX, neallseth, jltimm, rahulbhadja, tayyab3245, cwtuan, titouv, dylan-duan-aai, bel0v, josh-williams, amyegan, samjbobb, teunlao, dylanmoz, 0xlakshan, patelvivekdev, nvie, nlaz, drew-foxall, dannyroosevelt, Diluka, AlexKer, YosefLm, YutoKitano13, SarityS, jonaslalin, tobiasbueschel, dhofheinz, ethshea, ellis-driscoll, marcbouchenoire, shin-sakata, ellispinsky, DDU1222, ci, tomsseisums, kpman, juanuicich, A404coder, tamarshe-dev, crishoj, kevint-cerebras, arjunkmrm, Barbapapazes, nimeshnayaju, lewwolfe, sergical, tomerigal, huanshenyi, horita-yuya, rbadillap, syeddhasnainn, Dhravya, jagreehal, Mintnoii, mhodgson, amardeeplakshkar, aron, TooTallNate, Junyi-99, princejoogie, iiio2, MonkeyLeeT, joshualipman123, andrewdoro, fveiraswww, HugoRCD, rockingrohit9639
您在 GitHub 上的反馈、错误报告和拉取请求对塑造此版本起到了关键作用。我们很期待看到您将利用这些新功能构建出什么。

> 本文由AI自动翻译，原文链接：[AI SDK 6 - Vercel](https://vercel.com/blog/ai-sdk-6)
> 
> 翻译时间：2026-01-05 13:33
