---
title: 让AI像人类一样“看见”：重组视觉表征提升鲁棒性
title_original: Teaching AI to See the World More Like Humans Do
date: '2025-11-11'
source: Google DeepMind
source_url: https://deepmind.google/blog/teaching-ai-to-see-the-world-more-like-we-do/
author: Andrew Lampinen; Klaus Greff
summary: 《自然》新研究揭示AI与人类视觉认知的系统性差异：AI模型常依赖表层特征（如颜色、纹理），而人类更关注高级概念。研究者提出一种三阶段对齐方法，利用人类相似度判断数据重组AI模型的内部表征，使其更贴合人类知识层级结构。实验表明，对齐后的模型不仅在异类识别等认知任务上与人类判断更一致，还在少样本学习、分布偏移等实际AI任务中表现出更强的鲁棒性和泛化能力，标志着向更直观、可靠AI系统迈出重要一步。
categories:
- AI研究
tags:
- 计算机视觉
- 人机对齐
- 表征学习
- 认知科学
- 模型鲁棒性
draft: false
translated_at: '2026-01-06T00:49:01.667Z'
---

新研究表明，重组模型的视觉表征可使其更具实用性、鲁棒性和可靠性
"视觉"人工智能（AI）无处不在。我们用它来整理照片、识别未知花卉、操控汽车。但这些强大的系统并不总是像人类一样"看见"世界，有时会表现出令人意外的行为。例如，能识别数百个汽车制造商和型号的AI系统，可能仍无法捕捉汽车与飞机的共性——即两者都是由金属制成的大型交通工具。

为深入理解这些差异，我们今日在《自然》杂志发表新论文，系统分析了AI系统与人类在组织视觉世界方式上的重要区别。我们提出了一种使AI系统更贴合人类认知的方法，并证明解决这些差异能提升其鲁棒性与泛化能力。

这项研究是构建更直观、可信赖AI系统的重要一步。

当你看见一只猫时，大脑会形成心理表征，涵盖从颜色、毛发质感等基础特征到"猫科属性"等高级概念的所有信息。AI视觉模型同样会生成表征——将图像映射到高维空间中的坐标点，相似物体（如两只绵羊）位置相近，不同物体（绵羊与蛋糕）则相距甚远。

为探究人类与模型表征组织的差异，我们采用认知科学经典的"异类识别"任务，要求人类与模型从三张给定图像中选出最不匹配的选项。这项测试能揭示二者认为哪两个物体"最相似"。

某些情况下双方判断一致。面对貘、绵羊和生日蛋糕的图像，人类与模型都会选择蛋糕作为异类。但有时正确答案并不明确，人与模型会产生分歧。

值得注意的是，我们发现许多人类高度共识的案例中，AI模型却做出错误判断。如下方第三组示例，大多数人认为海星是异类，但多数视觉模型更关注背景颜色、纹理等表层特征，反而选择了猫。

这个案例揭示了人类与AI之间系统性的认知偏差。我们在各类视觉模型（从图像分类器到无监督模型）中都观察到了这种现象。

该问题在AI内部表征的二维投影（PCA）中清晰可见。

下方左图显示某视觉模型的内部表征图呈现无序状态，动物、食物、家具等不同类别混杂分布。右图则是应用对齐方法后的改进表征图，各类别呈现出清晰的组织结构。

认知科学家收集的THINGS数据集包含数百万条人类异类识别判断，本可用于解决视觉对齐问题。但该数据集仅涵盖数千张图像，信息量不足以直接微调强大的视觉模型——模型会立即对这小规模图像过拟合，遗忘先前掌握的多数技能。

为此，我们提出三阶段解决方案：

如下图所示，学生模型（AI）的表征从无序混沌转变为层次清晰的结构，动物（蓝色）与食物（绿色）等高级概念与其他物体类别明确分离。

人类知识按相似度层级进行组织。当我们将模型与人类知识对齐时，模型表征会依据这些相似度层级进行重组。这种重组遵循认知科学中已知的人类知识层级结构。

在对齐过程中，表征的分离与聚合程度与其在人类分类层级中的"概念距离"成正比。例如，两只狗（相同子类别）会相互靠近（距离减小），而猫头鹰与卡车（不同父类别）则会彼此远离（距离增大）。

由此可得出结论：我们的方法能依据人类概念层级重组AI学生模型的表征图，且无需显式监督即可实现。

我们在多项认知科学任务（包括多图像相似度排序等）及自行收集的新异类识别数据集Levels上测试了对齐模型。所有测试中，对齐模型都展现出显著提升的人类对齐度，在各类视觉任务中与人类判断的一致性大幅提高。

我们的模型甚至学会了某种"类人类"不确定性。测试中，模型决策的不确定性与人类做出选择所需时长高度相关——后者是衡量不确定性的常用代理指标。

研究还发现，提升模型的人类对齐度能使其整体上成为更优秀的视觉模型。对齐模型在多项挑战性任务中表现更佳，例如通过单张图像学习新类别（"少样本学习"），或在测试图像类型变化时仍能保持可靠决策（"分布偏移"）。

两组柱状图显示：在涉及异类识别与多图像排序的认知科学任务（上图），以及涉及少样本学习与分布偏移的AI任务（下图）中，我们的对齐模型（深蓝色）均显著优于原始模型（浅灰色）。

现有许多视觉模型未能捕捉人类知识的高级结构。本研究提出了解决该问题的可行方法，并证明模型可以更好地与人类判断对齐，在各种标准AI任务中表现更可靠。

尽管对齐工作仍需持续推进，但我们的研究标志着向更鲁棒、可靠AI系统迈出了重要一步。

了解更多研究成果
我们要感谢论文第一作者Lukas Muttenthaler，以及合作者Frieda Born、Bernhard Spitzer、Simon Kornblith、Michael C. Mozer、Klaus-Robert Müller和Thomas Unterthiner。


> 本文由AI自动翻译，原文链接：[Teaching AI to See the World More Like Humans Do](https://deepmind.google/blog/teaching-ai-to-see-the-world-more-like-we-do/)
> 
> 翻译时间：2026-01-06 00:49
