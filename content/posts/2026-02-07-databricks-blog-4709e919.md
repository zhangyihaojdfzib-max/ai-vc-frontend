---
title: 基于Databricks的SAP与Salesforce零拷贝数据集成实现供应商分析
title_original: SAP and Salesforce Data Integration for Supplier Analytics on Databricks
date: '2026-02-07'
source: Databricks Blog
source_url: https://www.databricks.com/blog/sap-and-salesforce-data-integration-supplier-analytics-databricks
author: ''
summary: 本文介绍了如何利用Databricks平台，通过Lakeflow Connect和SAP BDC Connect实现Salesforce与SAP
  S/4HANA系统的零拷贝数据集成。该方法避免了传统ETL的多副本和延迟问题，在Unity Catalog的统一治理下，将分散的供应商CRM与ERP数据融合，构建起支持分析与AI洞察的单一可信视图，从而优化采购、财务和供应链管理。
categories:
- AI基础设施
tags:
- 数据集成
- Databricks
- SAP
- Salesforce
- 供应商分析
draft: false
translated_at: '2026-02-07T04:10:29.987767'
---

## 如何通过 Databricks 上的 Salesforce SAP 集成构建供应商分析

供应商数据几乎触及组织的每个部分——从采购和供应链管理到财务和分析。然而，这些数据通常分散在彼此不通信的系统中。例如，Salesforce 保存着供应商档案、联系人和账户详情，而 SAP S/4HANA 则管理发票、付款和总账条目。由于这些系统独立运行，团队缺乏对供应商关系的全面了解。结果是核对缓慢、记录重复，并错失了优化支出的机会。

Databricks 通过在统一治理的数据与 AI 平台上连接这两个系统来解决此问题。使用 **Lakeflow Connect for Salesforce** 进行数据摄取，并结合 **SAP Business Data Cloud (BDC) Connect**，团队可以统一 CRM 和 ERP 数据而无需复制。其结果是获得一个关于供应商、付款和绩效指标的单一可信视图，支持采购和财务用例以及分析。

在本操作指南中，您将学习如何连接这两个数据源，构建混合数据管道，并创建一个支持通过 AI/BI 仪表板和 Genie 进行分析和对话式洞察的黄金层。

## 为何零拷贝 SAP Salesforce 数据集成有效

大多数企业尝试通过传统的 ETL 或第三方工具连接 SAP 和 Salesforce。这些方法会创建多个数据副本，引入延迟，并使治理变得困难。Databricks 采取了不同的方法。

*   **零拷贝 SAP 访问：** **Databricks 的 SAP BDC 连接器** 通过 Delta Sharing 为您提供受治理的、对 SAP S/4HANA 数据产品的实时访问。无需导出或复制。
*   **快速的 Salesforce 增量摄取：** Lakeflow 持续连接并摄取 Salesforce 数据，确保您的数据集保持新鲜和一致。
*   **统一治理：** **Unity Catalog** 在 SAP 和 Salesforce 源上强制执行权限、血缘和审计。
*   **声明式管道：** **Lakeflow Spark Declarative Pipelines** 简化了 ETL 设计和编排，并具有自动优化功能以获得更好的性能。

**零拷贝 SAP 访问：** **Databricks 的 SAP BDC 连接器** 通过 Delta Sharing 为您提供受治理的、对 SAP S/4HANA 数据产品的实时访问。无需导出或复制。

![图：SAP BDC 连接器到原生 Databricks（双向）](/images/posts/0a4ea7f3d1a2.png)

这些功能共同使数据工程师能够在一个平台上融合 SAP 和 Salesforce 数据，在保持企业级治理的同时降低复杂性。

## Databricks 上的 SAP Salesforce 数据集成架构

在构建管道之前，了解这些组件如何在 Databricks 中协同工作是有帮助的。

从高层次来看，SAP S/4HANA 将业务数据作为经过整理的、业务就绪的 SAP 管理数据产品发布到 SAP Business Data Cloud (BDC) 中。**Databricks 的 SAP BDC Connect** 使用 Delta Sharing 实现对那些数据产品的安全、零拷贝访问。同时，Lakeflow Connect 处理 Salesforce 摄取——通过增量管道捕获账户、联系人和商机数据。

所有传入的数据，无论是来自 SAP 还是 Salesforce，都在 Unity Catalog 中进行治理，包括治理、血缘和权限。然后，数据工程师使用 **Lakeflow Declarative Pipelines** 将这些数据集连接并转换到奖牌架构（青铜层、白银层和黄金层）中。最后，黄金层作为在 AI/BI 仪表板和 Genie 中进行分析和探索的基础。

这种架构确保来自两个系统的数据保持同步、受治理，并准备好用于分析和 AI——无需复制或外部 ETL 工具的开销。

## 如何构建统一的供应商分析

以下步骤概述了如何在 Databricks 上连接、融合和分析 SAP 与 Salesforce 数据。

### 步骤 1：使用 Lakeflow Connect 摄取 Salesforce 数据

使用 **Lakeflow Connect** 将 Salesforce 数据引入 Databricks。您可以通过 UI 或 API 配置管道。这些管道自动管理增量更新，确保数据保持最新而无需手动刷新。

![图：设置从 Salesforce 摄取数据](/images/posts/1518aaae69d0.png)

该连接器与 Unity Catalog 治理、用于 ETL 的 Lakeflow Spark Declarative Pipelines 以及用于编排的 Lakeflow Jobs 完全集成。

以下是我们计划从 Salesforce 摄取的表格：

*   **Account：** 供应商详情（字段包括：AccountId、Name、Industry、Type、BillingAddress）
*   **Contact：** 供应商联系人（字段包括：ContactId、AccountId、FirstName、LastName、Email）

### 步骤 2：使用 SAP BDC 连接器访问 SAP S/4HANA 数据

**SAP BDC Connect** 提供对 SAP S/4HANA **供应商付款** 数据的实时、受治理的访问，直接进入 Databricks——通过利用 SAP BDC 数据产品 `sap_bdc_working_capital.entryviewjournalentry.operationalacctgdocitem`（**通用日记账行项目** 视图），消除了传统的 ETL。

此 BDC 数据产品直接映射到 SAP S/4HANA CDS 视图 `I_JournalEntryItem`（运营会计凭证项目），基于 `ACDOCA`。

对于 ECC 环境，最接近的物理结构是 `BSEG`（FI 行项目），其表头在 `BKPF` 中，CO 过账在 `COEP` 中，以及未清/已清索引 `BSIK`/`BSAK`（供应商）和 `BSID`/`BSAD`（客户）。在 SAP S/4HANA 中，这些 BS** 对象是简化数据模型的一部分，其中供应商和总账行项目集中在通用日记账 (`ACDOCA`) 中，取代了 ECC 中通常需要连接多个独立财务表的方法。

这些是在 SAP BDC 驾驶舱中需要执行的步骤。

1.  登录 SAP BDC 驾驶舱，并在系统环境中查看 SAP BDC 形态。通过 SAP BDC **delta sharing** 连接器连接到原生 Databricks。有关如何将原生 Databricks 连接到 SAP BDC 以使其成为其形态一部分的更多信息。
    ![图：SAP BDC 形态](/images/posts/848edc5b3891.png)
2.  转到目录，查找数据产品 **Entry View Journal Entry**，如下所示
    ![图：SAP BDC 目录](/images/posts/1671109c1927.png)
3.  在数据产品上，选择 **Share**，然后选择目标系统，如下图所示。
    ![图：SAP BDC 目录数据产品共享](/images/posts/09f2b0255d6c.png)
4.  数据产品共享后，它将作为 delta share 出现在 Databricks 工作区中，如下所示。确保您拥有“Use Provider”访问权限才能看到这些提供者。
    ![图：Databricks 中 Catalog Explorer 的 Delta Sharing](/images/posts/ea5603a35e60.png)
5.  然后，您可以将该共享挂载到目录，并创建一个新目录或将其挂载到现有目录。
6.  共享挂载后，它将反映在目录中。
    ![图 10：Databricks 工作区，它将作为 delta share 落地](/images/posts/7a4b3a5c84aa.png)

### 步骤 3：使用 Lakeflow Declarative Pipelines 在 Databricks 中融合 ETL 管道

两个数据源都可用后，使用 **Lakeflow Declarative Pipelines** 构建一个包含 Salesforce 和 SAP 数据的 ETL 管道。

Salesforce 的 **Account** 表通常包含字段 `SAP_ExternalVendorId__c`，它与 SAP 中的供应商 ID 匹配。这成为您白银层的主要连接键。

Lakeflow Spark Declarative Pipelines 允许您用 SQL 定义转换逻辑，而 Databricks 自动处理优化并编排管道。

![图 8：Lakeflow Declarative Pipelines](/images/posts/6f0084e9b4f9.png)

#### 示例：构建经过整理的业务级表

此查询创建一个 **经过整理的业务级物化视图**，将来自 SAP 的供应商付款记录与来自 Salesforce 的供应商详情统一起来，为分析和报告做好准备。

### 步骤 4：使用 AI/BI 仪表板和 Genie 进行分析

物化视图创建后，您可以直接在AI/BI仪表板中进行探索，让团队能够可视化供应商付款、未结余额和按区域划分的支出。它们支持动态筛选、搜索和协作，所有这些都由Unity Catalog统一管理。Genie则支持使用自然语言探索相同的数据。

![图：基于混合数据的AI/BI仪表板](/images/posts/0b3f92c308bd.png)

您可以基于此混合数据创建Genie空间并提出问题，如果数据孤立在Salesforce和SAP中，这是无法实现的：

- “我付款最多的前3家供应商是谁？我还需要他们的联系信息。”
- “前3家供应商的账单地址是什么？”
- “我的前5家供应商中哪些不是来自美国？”

![图：Genie基于混合黄金层数据回答问题](/images/posts/8425799754f2.png)

**业务成果**

通过在Databricks上整合SAP和Salesforce数据，企业能够获得关于供应商绩效、付款和关系的完整可信视图。这种统一方法带来了运营和战略双重效益：

- **更快的争议解决**：团队可以并排查看付款详情和供应商联系信息，从而更轻松地调查问题并快速解决。
- **提前付款节省成本**：将付款条款、清算日期和净额集中在一处，财务团队可以轻松识别提前付款折扣的机会。
- **更清晰的供应商主数据**：通过`SAP_ExternalVendorId__c`字段进行关联，有助于识别和解决重复或不匹配的供应商记录，从而在系统间维护准确一致的供应商数据。
- **满足审计要求的治理**：Unity Catalog确保所有数据都通过一致的沿袭、权限和审计进行治理，因此分析、AI模型和报告都依赖于同一个可信源。

这些成果共同帮助企业简化供应商管理并提高财务效率，同时满足企业系统所需的治理和安全性。

### 结论：

统一SAP和Salesforce的供应商数据，并不意味着必须重建数据管道或管理重复的系统。

借助Databricks，团队可以在一个统一治理的基础上工作，实时无缝集成ERP和CRM数据。结合**零拷贝SAP BDC访问**、**增量Salesforce摄取**、**统一治理**和**声明式管道**，用洞察力取代了集成开销。

其结果不仅仅是更快的报告。它提供了一个关于供应商绩效的互联视图，从而改进采购决策、加强供应商关系并释放可量化的节省。由于它构建在**Databricks数据智能平台**之上，用于支付和发票的相同SAP数据也可以驱动仪表板、AI模型和对话式分析——全部来自同一个可信源。

SAP数据通常是企业运营的支柱。通过集成**SAP Business Data Cloud**、**Delta Sharing**和**Unity Catalog**，企业可以将此架构扩展到供应商分析之外——进入营运资本优化、库存管理和需求预测领域。

这种方法将SAP数据从记录系统转变为智能系统，其中每个数据集都是实时的、受治理的，并可供整个业务使用。

---

> 本文由AI自动翻译，原文链接：[SAP and Salesforce Data Integration for Supplier Analytics on Databricks](https://www.databricks.com/blog/sap-and-salesforce-data-integration-supplier-analytics-databricks)
> 
> 翻译时间：2026-02-07 04:10
