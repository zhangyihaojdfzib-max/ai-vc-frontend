---
title: Fara-7B：微软发布的高效计算机使用智能体小语言模型
title_original: 'Fara-7B: An efficient agentic small language model for computer use'
date: '2025-11-24'
source: Microsoft Research
source_url: https://www.microsoft.com/en-us/research/blog/fara-7b-an-efficient-agentic-model-for-computer-use/
author: Alyssa Hughes
summary: 微软发布了Fara-7B，这是一个专为计算机使用设计的智能体化小语言模型。该模型仅70亿参数，通过视觉感知网页并模拟鼠标键盘操作来代表用户完成自动化网络任务，如填写表格、搜索信息和预订旅行。Fara-7B实现了同规模类别中最先进的性能，支持在设备上本地运行以降低延迟和保护隐私。模型采用新颖的合成数据生成流程训练，现已在Microsoft
  Foundry和Hugging Face上以MIT许可证开源，旨在推动计算机使用智能体技术的发展。
categories:
- AI产品
tags:
- 小语言模型
- 智能体
- 计算机使用
- 微软
- 开源模型
draft: false
---

以开放权重、超紧凑模型推动计算机使用智能体的前沿，专为现实世界网络任务优化

2024年，微软开始向客户引入小语言模型（SLM），首先在 Microsoft Foundry（在新标签页中打开）上发布了 Phi（在新标签页中打开）系列模型，并在搭载 Windows 11 的 Copilot+ PC 上部署了 Phi Silica（在新标签页中打开）。今天，我们很高兴地宣布推出 Fara-7B，这是我们首个专为计算机使用设计的智能体化 SLM。

与生成基于文本回复的传统聊天模型不同，像 Fara-7B 这样的计算机使用智能体（CUA）模型利用计算机界面（如鼠标和键盘）来代表用户完成任务。Fara-7B 仅有 70 亿参数，在其规模类别中实现了最先进的性能，并且可与依赖提示多个大模型的、更大、更耗资源的智能体系统相媲美。Fara-7B 的小尺寸使得直接在设备上运行 CUA 模型成为可能。这降低了延迟并提升了隐私性，因为用户数据保留在本地。

Fara-7B 是一个实验性版本，旨在邀请社区进行实践探索和反馈。用户可以构建和测试超越纯研究的智能体体验——自动化日常网络任务，如填写表格、搜索信息、预订旅行或管理账户。我们建议在沙盒环境中运行 Fara-7B，监控其执行，并避免使用敏感数据或高风险领域。随着模型的持续演进，负责任的使用至关重要。

**聚焦：事件系列**

Fara-7B 通过视觉感知网页来操作，并执行滚动、键入和点击直接预测的坐标等动作。它不依赖单独的模型来解析屏幕，也不依赖任何额外信息（如无障碍功能树），因此使用与人类相同的模态与计算机交互。为了训练 Fara-7B，我们在先前工作（AgentInstruct）的基础上，开发了一种新颖的、用于多步骤网络任务的合成数据生成流程。该数据生成流程源自真实网页和来自人类用户的任务。

与现有模型相比，Fara-7B 在一系列多样化的基准测试中表现出强大的性能。这包括现有基准测试，以及我们发布的新评估，这些评估涵盖了常见基准测试中代表性不足的有用任务领域，例如查找招聘信息和比较不同零售商的价格。尽管 Fara-7B 展示了强大的基准测试结果，甚至面对更大的模型也是如此，但它也共享了它们的许多局限性，包括在更复杂任务上的准确性挑战、遵循指令时的错误以及易产生幻觉。这些都是活跃的研究领域，我们致力于在从现实世界使用中学习的过程中持续改进。

Fara-7B 现已在 Microsoft Foundry（在新标签页中打开）和 Hugging Face（在新标签页中打开）上根据 MIT 许可证提供，并与 Microsoft Research AI Frontiers（在新标签页中打开）的研究原型 Magentic-UI 集成。我们还分享了 Fara-7B 的量化及针对硅芯片优化的版本，可在搭载 Windows 11 的 Copilot+ PC 上安装和运行，以便进行开箱即用的实验。社区可以简单地下载预优化模型并在其环境中运行。

通过将 Fara-7B 设为开放权重，我们的目标是降低实验和改进 CUA 技术的门槛，以实现自动化常规网络任务，如搜索信息、购物和预订。

**开发 Fara-7B**

**CUA 多智能体合成数据生成**

构建 CUA 模型的一个关键瓶颈是缺乏大规模、高质量的计算机交互数据。通过人工标注员收集此类数据成本极其高昂，因为单个 CUA 任务可能涉及数十个步骤，每个步骤都需要标注。我们的数据生成流程（图 2）避免了手动标注，转而依赖来自公开可用网站和自定义任务提示词的可扩展合成数据。我们在 Magentic-One 框架之上构建了这个流程，它包含三个主要阶段：

1.  **任务提议**。我们生成一整套模拟网络上常见用户活动的合成任务。为确保覆盖面和多样性，任务由公共 URL 的网络索引“播种”，这些 URL 被分类到不同类别，例如购物、旅行、餐厅等。这使得任务生成能够针对特定技能，例如从分类为“电影”的 URL（如这个（在新标签页中打开））生成“预订 2 张在纽约 AMC Union Square 观看《唐顿庄园》大结局的票”。作为另一种策略，我们设计了一种从随机抽样的 URL 生成任务的方法。每个任务从一个通用提示词开始，并随着 LLM 智能体探索网站并收集更多相关信息而迭代细化。我们正在发布这些任务的一个保留子集作为基准测试（“WebTailBench”），将在下面的评估部分进行描述。
2.  **任务求解**。一旦生成合成任务，一个基于 Magentic-One 构建的多智能体系统会尝试完成它们，以生成用于监督微调的演示。该多智能体系统使用一个 Orchestrator 智能体来创建计划并指导一个 WebSurfer 智能体执行浏览器操作并报告结果。Orchestrator 监控进度，根据需要更新计划，并且可以结束任务或在需要用户输入时调用 UserSimulator 智能体，从而实现多轮次完成。每个任务及其对应的观察、动作和智能体思考序列形成一个“轨迹”。
3.  **轨迹验证**。在将任何任务用于训练之前，三个验证器智能体会评估任务是否“成功”：对齐验证器检查动作轨迹是否与任务意图匹配；标准验证器定义完成标准并根据这些标准对轨迹进行评分；多模态验证器审查屏幕截图和响应，以确认视觉证据支持成功完成。不符合这些标准的轨迹将被移除。

我们最终在包含 145,000 条轨迹、覆盖 100 万步骤的数据集上训练了这个版本的 Fara-7B，这些数据涵盖了多样化的网站、任务类型和难度级别。此外，我们还加入了几个辅助任务的训练数据，包括用于精确 UI 元素定位的基础数据、图像描述和视觉问答。

**训练 Fara-7B**

使用一个计算使用模型比多智能体系统更容易，特别是在部署方面。因此，我们将多智能体求解系统的复杂性提炼到一个可以执行任务的单一模型中。Fara-7B 是一个概念验证，表明小模型可以有效地从复杂、功能繁多的多智能体系统中学习。

如图 3 所示，Fara-7B 被训练为仅通过感知浏览器窗口截图（不依赖无障碍功能树）并预测单步动作来执行用户任务。对于每个步骤，用于进行预测的上下文包含所有用户消息、完整的动作历史以及最新的三张截图。

在其预测中，Fara-7B 输出一个推理消息（“思考”下一步动作），然后是一个工具调用。可用的工具包括标准的 Playwright（在新标签页中打开）鼠标和键盘动作，如 `click(x,y)` 和 `type()`，以及特定于浏览器的宏动作，如 `web_search()` 和 `visit_url()`。

Fara-7B 使用 Qwen2.5-VL-7B（在新标签页中打开）作为其基础模型，因为它在基础任务上表现出色，并且能够支持长上下文（高达 128k Token）。我们将求解流程的轨迹线性化为一系列“观察-思考-行动”步骤，这些步骤适合使用监督微调损失进行训练。

我们并未使用强化学习来达成下文报告的结果。

**评估**
我们在经典公共基准测试上评估了Fara-7B及可比基线模型，这些测试包括WebVoyager（在新标签页中打开）、Online-Mind2Web（在新标签页中打开）和Deepshop（在新标签页中打开），以及我们新开发的名为WebTailBench的基准测试。WebTailBench特别聚焦于11种在现有基准测试中代表性不足或缺失的真实世界任务类型，例如预订电影/活动票、餐厅订座、跨零售商比价、申请工作、寻找房地产，以及更复杂的多步骤任务。

评估网络Agent可能具有挑战性，因为网络环境不断变化，且许多网站甚至会屏蔽检测到的机器人。为此，我们开发了一个测试工具，该工具依赖Browserbase（在新标签页中打开）来标准化浏览器会话的管理方式。在下方的表1中，我们报告了由各基准测试官方LLM-as-judge评估器定义的任务成功率（%）；WebTailBench的成功率是使用筛选我们训练数据的相同任务验证流程来计算的。我们发现Fara-7B达到了最先进的水平，甚至超越了UI-TARS-1.5-7B这类原生计算机使用Agent，或像GPT-4o这样被提示扮演Set-Of-Marks（在新标签页中打开）（SoM Agent）计算机使用Agent的更大模型。

| | WebVoyager | Online-Mind2Web | DeepShop | WebTailBench |
|---|---|---|---|---|
| **SoM Agents** | SoM Agent (GPT-4o) | 65.1 | 34.6 | 16.0 | 30.0 |
| | GLM-4.1V-9B-Thinking | 66.8 | 33.9 | 32.0 | 22.4 |
| **Computer Use Models** | OpenAI computer-use-preview | 70.9 | 42.9 | 24.7 | 25.7 |
| | UI-TARS-1.5-7B | 66.4 | 31.3 | 11.6 | 19.5 |
| | **Fara-7B** | **73.5** | **34.1** | **26.2** | **38.4** |

在图1中，我们通过给予每个模型最多三次完成任务的机会并报告“pass@K”，进一步扩展了WebVoyager的结果。我们还在x轴上考虑了如果按市场费率支付输入/输出Token消耗时运行每个模型的成本。Fara-7B开创了一个新的帕累托前沿，表明设备端计算机使用Agent正在接近前沿模型的能力。

我们与可信的外部团队Browserbase合作，利用人工标注员独立评估了Fara-7B。该模型在WebVoyager上取得了62%的成绩（详见Browserbase博客中的详细报告（在新标签页中打开））。这些结果是在相同环境中、使用相同设置并对每项任务进行人工验证后生成的，因此具有直接可比性。请注意，Browserbase的标准WebVoyager评分在发生环境错误时不使用重试；此处引用的结果包含了重试，不应直接与非重试的分数进行比较。展望未来，我们正与Browserbase合作，托管WebTailBench的人工评估，以帮助社区为计算机使用Agent建立可靠且可复现的评估体系。

**安全性**
能够操作计算机的Agent带来了与纯聊天模型不同的挑战，包括用户误用的新途径、模型不当行为、行动的意外后果，以及提示词注入或网络诈骗等外部风险。计算机使用Agent（CUA）的行动会产生现实世界的后果，因此确保稳健的安全措施对于其负责任地部署至关重要。透明度和用户控制是Fara-7B设计的核心。尽管我们已经采取了多项安全措施，但Fara-7B仍是一个研究预览版，我们将继续推进计算机使用Agent的安全方法，这是整个AI社区一个活跃的工作领域。

Fara-7B处理浏览器截图、用户任务指令以及每次会话期间采取的行动历史，并且仅收集完成用户请求任务所必需的信息。它不会访问额外的网站数据（例如无障碍功能树或外部框架）；Fara-7B以与人类相同的方式与计算机交互，仅依赖于屏幕上可见的内容。

Agent采取的所有行动都会被记录并可审计，允许用户审查和监控每一步。为了增强安全性，Fara-7B设计为在沙盒环境中运行，使用户拥有完全的监督能力，并能够随时干预或停止行动。这些保障措施确保隐私、透明度和用户控制始终是每次交互的核心。

为了解决误用问题，我们使用公共安全数据和内部生成的任务混合数据对Fara-7B进行了训练，这些任务根据微软负责任AI政策是模型应当拒绝的。我们在WebTailBench-Refusals上评估了Fara-7B拒绝有害任务的能力，该基准包含111个红队任务，结果显示其拒绝率高达82%。该模型还经过了微软严格的红队测试流程，我们重点关注模型拒绝有害任务和风险任务的能力，例如有害内容、越狱尝试、无根据的回应和提示词注入。更多详细信息，请查看我们的技术报告（在新标签页中打开）。

为了降低Fara-7B采取意外行动的风险，Fara-7B的所有训练数据都强制要求在执行任务时识别并在“关键点”停止。关键点（参见操作员系统卡（在新标签页中打开））是指在进行交易或发送电子邮件等不可逆操作之前，需要用户个人数据或同意的任何情况。当到达关键点时，Fara-7B应通过告知用户未经其同意无法继续来做出回应。

关于如何安全使用我们的模型，以及使用模型时需注意的安全考虑事项，请参阅我们的模型卡（在新标签页中打开）。

**如何使用**
Fara-7B已在（在新标签页中打开）Microsoft Foundry（在新标签页中打开）和（在新标签页中打开）Hugging Face（在新标签页中打开）上提供。我们还在Magentic-UI中发布了Fara-7B的实现，以便用户可以通过提供的推理代码在受控环境中进行尝试。此外，用户可以从VSCode的AI工具包中下载适用于Windows 11驱动的Copilot+ PC的模型，并利用NPU硬件加速在设备端完全本地运行。

**展望未来**
我们当前的发布版本是一个实验性的计算机使用Agent模型，它仅使用监督微调就在其规模上取得了最先进的结果。我们相信，通过改进的多模态基础模型以及在实时和沙盒环境中的强化学习，能够实现更强大、可在设备端运行的计算机使用Agent模型。在早期阶段，我们致力于向社区学习并推动真实世界的实验，以塑造未来。如果您想加入我们并帮助塑造SLM的未来，请申请开放的职位。

**致谢：**
我们感谢Gustavo de Rosa、Adam Fourney、Michael Harrison、Rafah Hosn、Neel Joshi、Ece Kamar、John Langford、Maya Murad、Sidhartha Sen、Pratyusha Sharma和Lili Wu在整个工作中提供的宝贵帮助、富有洞察力的讨论和持续支持。

我们也感谢Pashmina Cameron、Karthik Vijayan、Vicente Rivera、Chris Dern、Sayan Shaw、Sunghoon Choi、Andrey Rybalchenko和Vivek Pradeep通过AI工具包使模型在Copilot+ PC上可用所付出的努力。

---

> 本文由AI自动翻译，原文链接：[Fara-7B: An efficient agentic small language model for computer use](https://www.microsoft.com/en-us/research/blog/fara-7b-an-efficient-agentic-model-for-computer-use/)
> 
> 翻译时间：2026-01-06 00:51
