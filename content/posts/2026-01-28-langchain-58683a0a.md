---
title: Deep Agents SDK：应对长任务上下文管理的三大压缩技术
title_original: Context Management for Deep Agents
date: '2026-01-28'
source: LangChain Blog
source_url: https://blog.langchain.com/context-management-for-deepagents/
author: ''
summary: 本文介绍了Deep Agents SDK为解决AI智能体处理长任务时面临的上下文窗口限制问题而设计的上下文管理方案。该框架通过三种核心压缩技术——卸载大型工具结果、卸载大型工具输入和总结——来有效管理上下文，防止上下文腐化。这些技术在不同频率下触发，结合文件系统抽象层，使智能体能在保留关键信息的同时减少工作内存负担，从而支持复杂、长期运行的任务执行。文章还通过实际运行数据展示了这些技术的有效性。
categories:
- AI基础设施
tags:
- AI智能体
- 上下文管理
- LangChain
- 大语言模型
- Agent框架
draft: false
translated_at: '2026-02-04T04:19:08.439621'
---

作者：Chester Curme 与 Mason Daugherty

随着AI Agent（智能体）可处理的任务长度持续增长，有效的上下文管理变得至关重要，以防止**上下文腐化**并应对LLM（大语言模型）有限的内存限制。

**Deep Agents SDK** 是 LangChain 开源、功能完备的**Agent（智能体）框架**。它提供了一条便捷的路径来构建具备规划、生成子智能体以及与文件系统交互以执行复杂、长期运行任务能力的智能体。由于这类任务通常可能超出模型的**上下文窗口**，该SDK实现了多种功能以促进**上下文压缩**。

上下文压缩指的是在保留完成任务所需相关细节的同时，减少智能体工作内存中信息量的技术。这可能涉及总结先前的交互、过滤过时信息，或策略性地决定保留与丢弃哪些内容。

Deep Agents 实现了一个**文件系统抽象层**，允许智能体执行诸如列出、读取、写入文件，以及搜索、模式匹配和文件执行等操作。智能体利用文件系统来按需搜索和检索已卸载的内容。

Deep Agents 实现了三种主要的压缩技术，在不同频率下触发：

1.  **卸载大型工具结果**：每当出现大型工具响应时，我们将其卸载到文件系统。
2.  **卸载大型工具输入**：当上下文大小超过阈值时，我们将工具调用中旧的写入/编辑参数卸载到文件系统。
3.  **总结**：当上下文大小超过阈值，且没有更多符合条件的上下文可供卸载时，我们执行总结步骤以压缩消息历史记录。

为了管理上下文限制，Deep Agents SDK 在模型**上下文窗口**大小的阈值比例处触发这些压缩步骤。（在底层，我们使用 LangChain 的**模型配置文件**来获取给定模型的**Token**阈值。）

## 卸载大型工具结果

工具调用（例如，读取大文件或API调用的结果）的响应可能超出模型的**上下文窗口**。当 Deep Agents 检测到工具响应超过 20,000 个 **Token** 时，它会将响应卸载到文件系统，并用文件路径引用和前10行的预览内容替换它。智能体随后可以根据需要重新读取或搜索该内容。

![](/images/posts/e6cf274dc85a.png)

## 卸载大型工具输入

文件写入和编辑操作会在智能体的对话历史中留下包含完整文件内容的工具调用记录。由于这些内容已经持久化到文件系统，它们通常是冗余的。当会话上下文超过模型可用窗口的85%时，Deep Agents 将截断较早的工具调用，用指向磁盘上文件的指针替换它们，从而减小活动上下文的大小。

![](/images/posts/44d687847eac.png)

## 总结

当卸载操作不再能释放足够空间时，Deep Agents 会转而采用总结。此过程包含两个部分：

1.  **上下文内总结**：LLM（大语言模型）生成对话的结构化摘要——包括会话意图、创建的工件以及后续步骤——用以替换智能体工作内存中的完整对话历史记录。（参见 Deep Agents 的**总结提示词**。）
2.  **文件系统保存**：完整、原始的对话消息作为规范记录写入文件系统。

这种双重方法确保智能体保持对其目标和进度的认知（通过摘要），同时保留在需要时恢复特定细节的能力（通过文件系统搜索）。参见**此跟踪记录**中的示例，其中模型使用 `read_file` 工具来获取先前卸载的消息。

![](/images/posts/67f7887d104e.png)

## 实践中的表现

虽然上述技术提供了上下文管理的机制，但我们如何知道它们确实有效呢？在真实世界任务上的运行（如在 **terminal-bench** 等基准测试中捕获的）可能零星地触发上下文压缩，使得难以孤立地评估其影响。

我们发现，通过在基准数据集上更积极地启用框架的各个功能来增强其信号是有益的。例如，虽然在可用**上下文窗口**的10-20%处触发总结可能导致整体性能次优，但它会产生显著更多的总结事件。这使得可以比较不同的配置（例如，您实现方案的变体）。举例来说，通过强制智能体频繁总结，我们能够识别对 **deepagents** **总结提示词**的简单**更改**（我们在其中为会话意图和后续步骤添加了专用字段）如何帮助提升性能。

![](/images/posts/f59add64f9bf.png)

图：Claude Sonnet 4.5 在 terminal-bench-2 上样本运行中随时间变化的 **Token** 使用情况（灰线显示所有运行；彩色线突出显示两个具体示例）。绿线显示在第20轮左右，当总结事件压缩对话历史时，**Token** 使用量急剧下降。橙线显示在第40轮左右，当一个大型文件写入工具调用从上下文中被移除时，出现了较小的减少。通过在**上下文窗口**的25%处触发压缩（而非 Deep Agents 默认的85%），我们生成了更多可供研究的事件。

### 针对性评估

Deep Agents SDK 维护了一套针对性评估，旨在隔离和验证各个上下文管理机制。这些是刻意设计的小型测试，使特定的故障模式显而易见且易于调试。

这些评估的目的不是衡量广泛的任务解决能力，而是确保智能体框架不会妨碍某些任务的执行。例如：

*   **总结是否保留了智能体的目标？** 一些评估有意在任务中途触发总结，然后检查智能体是否继续执行。这确保了总结不仅保留了智能体状态，也保留了其执行轨迹。
*   **智能体能否恢复被总结掉的信息？** 这里我们在对话早期嵌入一个“大海捞针”式的事实，强制触发总结事件，然后要求智能体稍后回忆该事实以完成任务。该事实在总结后不存在于活动上下文中，必须通过文件系统搜索来恢复。

这些针对性评估充当了上下文管理的集成测试：它们不取代完整的基准测试运行，但能显著减少迭代时间，并使故障可归因于特定的压缩机制，而非智能体的整体行为。

### 指导建议

在评估您自己的上下文压缩策略时，我们强调：

*   **从真实世界基准开始，然后对单个功能进行压力测试。** 首先在代表性任务上运行您的框架以建立基线性能。然后，人为地更积极地触发压缩（例如，在上下文的10-20%处而非85%处），以在每次运行中生成更多的压缩事件。这放大了来自单个功能的信号，使得更容易比较不同的方法（例如，您的**总结提示词**的变体）。
*   **测试可恢复性。** 上下文压缩只有在关键信息保持可访问时才有用。应包含针对性测试，以验证智能体在压缩后既能继续朝着其原始目标前进，又能在需要时恢复特定细节（例如，“大海捞针”场景，其中关键事实被总结掉但必须在稍后检索）。
*   **监控目标漂移。** 最隐蔽的故障模式是智能体在总结后失去了对用户意图的追踪。这可能表现为智能体在总结后的回合中停下来请求澄清，或错误地宣布任务完成。与预期任务更微妙的偏离可能更难归因于总结；在样本数据集上强制频繁总结可能有助于暴露这些故障。

Deep Agent 工具包的所有功能均已开源。试用最新版本，并告诉我们哪种压缩策略最适合您的使用场景！

---

> 本文由AI自动翻译，原文链接：[Context Management for Deep Agents](https://blog.langchain.com/context-management-for-deepagents/)
> 
> 翻译时间：2026-02-04 04:19
