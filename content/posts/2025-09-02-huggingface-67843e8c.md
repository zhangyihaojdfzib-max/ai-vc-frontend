---
title: åˆ©ç”¨é¢„ç¼–è¯‘æŠ€æœ¯å¤§å¹…æå‡ZeroGPU Spaceæ€§èƒ½
title_original: Make your ZeroGPU Spaces go brrr with ahead-of-time compilation
date: '2025-09-02'
source: Hugging Face Blog
source_url: https://huggingface.co/blog/zerogpu-aoti
author: ''
summary: æœ¬æ–‡ä»‹ç»äº†å¦‚ä½•é€šè¿‡PyTorché¢„ç¼–è¯‘æŠ€æœ¯ä¼˜åŒ–Hugging Face ZeroGPU Spaceçš„æ€§èƒ½ã€‚ZeroGPUé‡‡ç”¨æŒ‰éœ€åˆ†é…GPUèµ„æºçš„æ–¹å¼ï¼Œé¿å…äº†é—²ç½®æµªè´¹ï¼Œä½†åˆå§‹è¿è¡Œæ—¶å­˜åœ¨ç¼–è¯‘å¼€é”€ã€‚æ–‡ç« è¯¦ç»†é˜è¿°äº†é€šè¿‡é¢„ç¼–è¯‘æ¨¡åž‹ã€FP8é‡åŒ–ã€åŠ¨æ€å½¢çŠ¶ä¼˜åŒ–ç­‰æ–¹æ³•ï¼Œåœ¨Fluxã€Wanç­‰æ¨¡åž‹ä¸Šå®žçŽ°1.3è‡³1.8å€çš„åŠ é€Ÿæ•ˆæžœï¼Œä½¿æ¼”ç¤ºåº”ç”¨å“åº”æ›´è¿…é€Ÿã€‚åŒæ—¶æä¾›äº†å…·ä½“å®žæ–½æ­¥éª¤ã€æ³¨æ„äº‹é¡¹ä»¥åŠå®žé™…æ¼”ç¤ºæ¡ˆä¾‹ï¼Œå¸®åŠ©ç”¨æˆ·å……åˆ†åˆ©ç”¨Nvidia
  H200ç¡¬ä»¶æ½œåŠ›ã€‚
categories:
- AIåŸºç¡€è®¾æ–½
tags:
- ZeroGPU
- é¢„ç¼–è¯‘
- PyTorch
- GPUä¼˜åŒ–
- Hugging Face
draft: false
translated_at: '2026-02-14T04:13:12.501865'
---

# é€šè¿‡é¢„ç¼–è¯‘è®©ä½ çš„ ZeroGPU Space é£žé€Ÿè¿è¡Œ

ZeroGPU è®©ä»»ä½•äººéƒ½èƒ½åœ¨ Hugging Face Space ä¸­è½»æ¾å¯åŠ¨å¼ºå¤§çš„ Nvidia H200 ç¡¬ä»¶ï¼Œè€Œæ— éœ€ä¸ºé—²ç½®æµé‡é”å®š GPUã€‚
å®ƒé«˜æ•ˆã€çµæ´»ï¼Œéžå¸¸é€‚åˆæ¼”ç¤ºï¼Œä½†æœ‰æ—¶å¹¶ä¸èƒ½å……åˆ†åˆ©ç”¨ GPU å’Œ CUDA å †æ ˆçš„å…¨éƒ¨æ½œåŠ›ã€‚
ç”Ÿæˆå›¾åƒæˆ–è§†é¢‘å¯èƒ½éœ€è¦å¤§é‡æ—¶é—´ã€‚åœ¨è¿™ç§æƒ…å†µä¸‹ï¼Œèƒ½å¤Ÿæ¦¨å–æ›´å¤šæ€§èƒ½ã€å……åˆ†åˆ©ç”¨ H200 ç¡¬ä»¶å°±æ˜¾å¾—å°¤ä¸ºé‡è¦ã€‚

è¿™å°±æ˜¯ PyTorch é¢„ç¼–è¯‘çš„ç”¨æ­¦ä¹‹åœ°ã€‚ä¸Žå³æ—¶ç¼–è¯‘ä¸åŒï¼ˆè¿™ä¸Ž ZeroGPU çš„çŸ­ç”Ÿå‘½å‘¨æœŸè¿›ç¨‹ä¸å¤ªå…¼å®¹ï¼‰ï¼Œé¢„ç¼–è¯‘è®©ä½ å¯ä»¥ä¸€æ¬¡æ€§ä¼˜åŒ–æ¨¡åž‹ï¼Œç„¶åŽå³æ—¶é‡æ–°åŠ è½½ã€‚

ç»“æžœå°±æ˜¯ï¼šæ¼”ç¤ºå“åº”æ›´è¿…é€Ÿï¼Œä½“éªŒæ›´æµç•…ï¼Œåœ¨ Fluxã€Wan å’Œ LTX ç­‰æ¨¡åž‹ä¸Šå¯èŽ·å¾— **1.3 å€è‡³ 1.8 å€** çš„åŠ é€Ÿ ðŸ”¥

åœ¨è¿™ç¯‡æ–‡ç« ä¸­ï¼Œæˆ‘ä»¬å°†å±•ç¤ºå¦‚ä½•åœ¨ ZeroGPU Space ä¸­è®¾ç½®é¢„ç¼–è¯‘ã€‚æˆ‘ä»¬å°†æŽ¢ç´¢ FP8 é‡åŒ–ã€åŠ¨æ€å½¢çŠ¶ç­‰é«˜çº§æŠ€å·§ï¼Œå¹¶åˆ†äº«ä½ å¯ä»¥ç«‹å³è¯•ç”¨çš„å·¥ä½œæ¼”ç¤ºã€‚å¦‚æžœä½ ç­‰ä¸åŠäº†ï¼Œæˆ‘ä»¬é‚€è¯·ä½ æŸ¥çœ‹ `zerogpu-aoti` ç»„ç»‡ä¸‹ä¸€äº›ç”± ZeroGPU é©±åŠ¨çš„æ¼”ç¤ºã€‚

**Pro ç”¨æˆ·** å’Œ **Team / Enterprise** ç»„ç»‡æˆå‘˜å¯ä»¥åˆ›å»º ZeroGPU Spaceï¼Œè€Œä»»ä½•äººéƒ½å¯ä»¥è‡ªç”±ä½¿ç”¨å®ƒä»¬ï¼ˆProã€Team å’Œ Enterprise ç”¨æˆ·å¯èŽ·å¾— **8 å€** çš„ ZeroGPU é…é¢ï¼‰ã€‚

-   ZeroGPU æ˜¯ä»€ä¹ˆ
-   PyTorch ç¼–è¯‘
-   åœ¨ ZeroGPU ä¸Šè¿›è¡Œé¢„ç¼–è¯‘
-   æ³¨æ„äº‹é¡¹
    -   é‡åŒ–
    -   åŠ¨æ€å½¢çŠ¶
    -   å¤šç¼–è¯‘ / å…±äº«æƒé‡
    -   FlashAttention-3
    -   åŒºåŸŸç¼–è¯‘
    -   ä½¿ç”¨ Hub ä¸Šçš„ç¼–è¯‘å›¾
-   AoT ç¼–è¯‘çš„ ZeroGPU Space æ¼”ç¤º
-   ç»“è®º
-   èµ„æº

## ZeroGPU æ˜¯ä»€ä¹ˆ

**Space** æ˜¯ç”± Hugging Face æä¾›æ”¯æŒçš„ä¸€ä¸ªå¹³å°ï¼Œå…è®¸æœºå™¨å­¦ä¹ ä»Žä¸šè€…è½»æ¾å‘å¸ƒæ¼”ç¤ºåº”ç”¨ã€‚

Space ä¸Šå…¸åž‹çš„æ¼”ç¤ºåº”ç”¨å¦‚ä¸‹æ‰€ç¤ºï¼š

```python
import gradio as gr
from diffusers import DiffusionPipeline

pipe = DiffusionPipeline.from_pretrained(...).to('cuda')

def generate(prompt):
    return pipe(prompt).images

gr.Interface(generate, "text", "gallery").launch()

```

è¿™å·¥ä½œå¾—å¾ˆå¥½ï¼Œä½†æœ€ç»ˆä¼šåœ¨ Space çš„æ•´ä¸ªç”Ÿå‘½å‘¨æœŸå†…ä¸ºå…¶ä¿ç•™ä¸€ä¸ª GPUâ€”â€”å³ä½¿å®ƒæ²¡æœ‰ä»»ä½•ç”¨æˆ·æ´»åŠ¨ã€‚

å½“æ‰§è¡Œè¿™è¡Œä»£ç çš„ `.to('cuda')` æ—¶ï¼š

```python
pipe = DiffusionPipeline.from_pretrained(...).to('cuda')

```

PyTorch ä¼šåˆå§‹åŒ– NVIDIA é©±åŠ¨ç¨‹åºï¼Œè¿™ä¼šå°†è¿›ç¨‹æ°¸ä¹…è®¾ç½®åœ¨ CUDA ä¸Šã€‚è€ƒè™‘åˆ°åº”ç”¨æµé‡å¹¶éžå®Œå…¨å¹³ç¨³ï¼Œè€Œæ˜¯æžå…¶ç¨€ç–å’Œçªå‘çš„ï¼Œè¿™ç§æ–¹å¼åœ¨èµ„æºåˆ©ç”¨ä¸Šæ•ˆçŽ‡ä¸é«˜ã€‚

ZeroGPU é‡‡ç”¨äº†ä¸€ç§å³æ—¶ GPU åˆå§‹åŒ–çš„æ–¹æ³•ã€‚å®ƒä¸ä¼šåœ¨ä¸»è¿›ç¨‹ä¸Šè®¾ç½® CUDAï¼Œè€Œæ˜¯è‡ªåŠ¨ fork è¿›ç¨‹ï¼Œåœ¨ CUDA ä¸Šè®¾ç½®å®ƒï¼Œè¿è¡Œ GPU ä»»åŠ¡ï¼Œæœ€åŽåœ¨éœ€è¦é‡Šæ”¾ GPU æ—¶ç»ˆæ­¢è¯¥ forkã€‚

è¿™æ„å‘³ç€ï¼š

-   å½“åº”ç”¨æ²¡æœ‰æ”¶åˆ°æµé‡æ—¶ï¼Œå®ƒä¸ä½¿ç”¨ä»»ä½• GPU
-   å½“å®ƒå®žé™…æ‰§è¡Œä»»åŠ¡æ—¶ï¼Œå®ƒå°†ä½¿ç”¨ä¸€ä¸ª GPU
-   å®ƒå¯ä»¥æ ¹æ®éœ€è¦åŒæ—¶ä½¿ç”¨å¤šä¸ª GPU æ¥æ‰§è¡Œä»»åŠ¡

å¾—ç›ŠäºŽ Python çš„ `spaces` åŒ…ï¼Œè¦èŽ·å¾—æ­¤è¡Œä¸ºï¼Œå”¯ä¸€éœ€è¦çš„ä»£ç æ›´æ”¹å¦‚ä¸‹ï¼š

```diff
  import gradio as gr
+ import spaces
  from diffusers import DiffusionPipeline

  pipe = DiffusionPipeline.from_pretrained(...).to('cuda')

+ @spaces.GPU
  def generate(prompt):
      return pipe(prompt).images

  gr.Interface(generate, "text", "gallery").launch()

```

é€šè¿‡å¯¼å…¥ `spaces` å¹¶æ·»åŠ  `@spaces.GPU` è£…é¥°å™¨ï¼Œæˆ‘ä»¬ï¼š

-   æ‹¦æˆª PyTorch API è°ƒç”¨ä»¥æŽ¨è¿Ÿ CUDA æ“ä½œ
-   ä½¿è¢«è£…é¥°çš„å‡½æ•°åœ¨ç¨åŽè°ƒç”¨æ—¶åœ¨ fork ä¸­è¿è¡Œ
-   ï¼ˆè°ƒç”¨å†…éƒ¨ API ä»¥ä½¿æ­£ç¡®çš„è®¾å¤‡å¯¹ fork å¯è§ï¼Œä½†è¿™ä¸åœ¨æœ¬æ–‡çš„è®¨è®ºèŒƒå›´å†…ï¼‰

ZeroGPU ç›®å‰åˆ†é…çš„æ˜¯ H200 çš„ä¸€ä¸ª **MIG åˆ‡ç‰‡**ï¼ˆ`3g.71gb` é…ç½®ï¼‰ã€‚åŒ…æ‹¬å®Œæ•´åˆ‡ç‰‡ï¼ˆ`7g.141gb` é…ç½®ï¼‰åœ¨å†…çš„å…¶ä»– MIG å°ºå¯¸å°†äºŽ 2025 å¹´åº•æŽ¨å‡ºã€‚

## PyTorch ç¼–è¯‘

åƒ PyTorch å’Œ JAX è¿™æ ·çš„çŽ°ä»£æœºå™¨å­¦ä¹ æ¡†æž¶å…·æœ‰**ç¼–è¯‘**çš„æ¦‚å¿µï¼Œå¯ç”¨äºŽä¼˜åŒ–æ¨¡åž‹å»¶è¿Ÿæˆ–æŽ¨ç†æ—¶é—´ã€‚åœ¨å¹•åŽï¼Œç¼–è¯‘åº”ç”¨ä¸€ç³»åˆ—ï¼ˆé€šå¸¸æ˜¯ç¡¬ä»¶ç›¸å…³çš„ï¼‰ä¼˜åŒ–æ­¥éª¤ï¼Œä¾‹å¦‚ç®—å­èžåˆã€å¸¸é‡æŠ˜å ç­‰ã€‚

PyTorchï¼ˆä»Ž 2.0 ç‰ˆæœ¬å¼€å§‹ï¼‰ç›®å‰æœ‰ä¸¤ä¸ªä¸»è¦çš„ç¼–è¯‘æŽ¥å£ï¼š

-   å³æ—¶ç¼–è¯‘ï¼Œä½¿ç”¨ `torch.compile`
-   é¢„ç¼–è¯‘ï¼Œä½¿ç”¨ `torch.export` + `AOTInductor`

`torch.compile` åœ¨æ ‡å‡†çŽ¯å¢ƒä¸­æ•ˆæžœå¾ˆå¥½ï¼šå®ƒåœ¨æ¨¡åž‹é¦–æ¬¡è¿è¡Œæ—¶è¿›è¡Œç¼–è¯‘ï¼Œå¹¶åœ¨åŽç»­è°ƒç”¨ä¸­é‡ç”¨ä¼˜åŒ–åŽçš„ç‰ˆæœ¬ã€‚

ç„¶è€Œï¼Œåœ¨ ZeroGPU ä¸Šï¼Œè€ƒè™‘åˆ°è¿›ç¨‹å‡ ä¹Žæ˜¯ä¸ºæ¯ä¸ª GPU ä»»åŠ¡å…¨æ–°å¯åŠ¨çš„ï¼Œè¿™æ„å‘³ç€ `torch.compile` æ— æ³•æœ‰æ•ˆåœ°é‡ç”¨ç¼–è¯‘ç»“æžœï¼Œå› æ­¤è¢«è¿«ä¾èµ–å…¶**æ–‡ä»¶ç³»ç»Ÿç¼“å­˜**æ¥æ¢å¤å·²ç¼–è¯‘çš„æ¨¡åž‹ã€‚æ ¹æ®è¢«ç¼–è¯‘çš„æ¨¡åž‹ï¼Œè¿™ä¸ªè¿‡ç¨‹éœ€è¦å‡ åç§’åˆ°å‡ åˆ†é’Ÿï¼Œè¿™å¯¹äºŽ Space ä¸­çš„å®žé™… GPU ä»»åŠ¡æ¥è¯´å¤ªé•¿äº†ã€‚

è¿™å°±æ˜¯**é¢„ç¼–è¯‘**å¤§æ”¾å¼‚å½©çš„åœ°æ–¹ã€‚

é€šè¿‡é¢„ç¼–è¯‘ï¼Œæˆ‘ä»¬å¯ä»¥ä¸€æ¬¡æ€§å¯¼å‡ºç¼–è¯‘å¥½çš„æ¨¡åž‹ï¼Œä¿å­˜å®ƒï¼Œç„¶åŽåœ¨ä»»ä½•è¿›ç¨‹ä¸­å³æ—¶é‡æ–°åŠ è½½ï¼Œè¿™æ­£æ˜¯ ZeroGPU æ‰€éœ€è¦çš„ã€‚è¿™æœ‰åŠ©äºŽæˆ‘ä»¬å‡å°‘æ¡†æž¶å¼€é”€ï¼Œå¹¶æ¶ˆé™¤å³æ—¶ç¼–è¯‘ä¸­é€šå¸¸å‡ºçŽ°çš„å†·å¯åŠ¨æ—¶é—´ã€‚

ä½†æ˜¯æˆ‘ä»¬å¦‚ä½•åœ¨ ZeroGPU ä¸Šè¿›è¡Œé¢„ç¼–è¯‘å‘¢ï¼Ÿè®©æˆ‘ä»¬æ·±å…¥æŽ¢è®¨ã€‚

## åœ¨ ZeroGPU ä¸Šè¿›è¡Œé¢„ç¼–è¯‘

è®©æˆ‘ä»¬å›žåˆ° ZeroGPU çš„åŸºç¡€ç¤ºä¾‹ï¼Œå¹¶æ‹†è§£å¯ç”¨é¢„ç¼–è¯‘æ‰€éœ€çš„å†…å®¹ã€‚ä¸ºäº†æœ¬æ¬¡æ¼”ç¤ºï¼Œæˆ‘ä»¬å°†ä½¿ç”¨ `black-forest-labs/FLUX.1-dev` æ¨¡åž‹ï¼š

```python
import gradio as gr
import spaces
import torch
from diffusers import DiffusionPipeline

MODEL_ID = 'black-forest-labs/FLUX.1-dev'

pipe = DiffusionPipeline.from_pretrained(MODEL_ID, torch_dtype=torch.bfloat16)
pipe.to('cuda')

@spaces.GPU
def generate(prompt):
    return pipe(prompt).images

gr.Interface(generate, "text", "gallery").launch()

```

åœ¨ä¸‹é¢çš„è®¨è®ºä¸­ï¼Œæˆ‘ä»¬åªç¼–è¯‘ `pipe` çš„ **transformer** ç»„ä»¶ï¼Œå› ä¸ºåœ¨ç”Ÿæˆæ¨¡åž‹ä¸­ï¼Œtransformerï¼ˆæˆ–æ›´ä¸€èˆ¬åœ°è¯´ï¼ŒåŽ»å™ªå™¨ï¼‰æ˜¯è®¡ç®—é‡æœ€å¤§çš„ç»„ä»¶ã€‚

ä½¿ç”¨ PyTorch é¢„ç¼–è¯‘æ¨¡åž‹æ¶‰åŠå¤šä¸ªæ­¥éª¤ï¼š

### 1. èŽ·å–ç¤ºä¾‹è¾“å…¥

å›žæƒ³ä¸€ä¸‹ï¼Œæˆ‘ä»¬è¦**æå‰**ç¼–è¯‘æ¨¡åž‹ã€‚å› æ­¤ï¼Œæˆ‘ä»¬éœ€è¦ä¸ºæ¨¡åž‹æŽ¨å¯¼å‡ºç¤ºä¾‹è¾“å…¥ã€‚è¯·æ³¨æ„ï¼Œè¿™äº›è¾“å…¥ç±»åž‹ä¸Žæˆ‘ä»¬æœŸæœ›åœ¨å®žé™…è¿è¡Œä¸­çœ‹åˆ°çš„ç›¸åŒã€‚ä¸ºäº†æ•èŽ·è¿™äº›è¾“å…¥ï¼Œæˆ‘ä»¬å°†åˆ©ç”¨ `spaces` åŒ…ä¸­çš„ `spaces.aoti_capture` è¾…åŠ©å‡½æ•°ï¼š

```python
with spaces.aoti_capture(pipe.transformer) as call:
    pipe("arbitrary example prompt")

```

å½“ç”¨ä½œä¸Šä¸‹æ–‡ç®¡ç†å™¨æ—¶ï¼Œ`aoti_capture` ä¼šæ‹¦æˆªå¯¹ä»»ä½•å¯è°ƒç”¨å¯¹è±¡ï¼ˆåœ¨æˆ‘ä»¬çš„ä¾‹å­ä¸­æ˜¯ `pipe.transformer`ï¼‰çš„è°ƒç”¨ï¼Œé˜»æ­¢å…¶æ‰§è¡Œï¼Œæ•èŽ·åŽŸæœ¬è¦ä¼ é€’ç»™å®ƒçš„è¾“å…¥å‚æ•°ï¼Œå¹¶å°†å…¶å€¼å­˜å‚¨åœ¨ `call.args` å’Œ `call.kwargs` ä¸­ã€‚

### 2. å¯¼å‡ºæ¨¡åž‹

çŽ°åœ¨æˆ‘ä»¬æœ‰äº† transformer ç»„ä»¶çš„ç¤ºä¾‹ args å’Œ kwargsï¼Œæˆ‘ä»¬å¯ä»¥ä½¿ç”¨ `torch.export.export` å·¥å…·å°†å…¶å¯¼å‡ºä¸º PyTorch `ExportedProgram`ï¼š

```python
exported_transformer = torch.export.export(
    pipe.transformer,
    args=call.args,
    kwargs=call.kwargs,
)

```

å¯¼å‡ºçš„ PyTorch ç¨‹åºæ˜¯ä¸€ä¸ªè®¡ç®—å›¾ï¼Œå®ƒè¡¨ç¤ºå¼ é‡è®¡ç®—ä»¥åŠåŽŸå§‹æ¨¡åž‹çš„å‚æ•°å€¼ã€‚

### 3. ç¼–è¯‘å¯¼å‡ºçš„æ¨¡åž‹

ä¸€æ—¦æ¨¡åž‹è¢«å¯¼å‡ºï¼Œç¼–è¯‘å®ƒå°±ç›¸å½“ç®€å•äº†ã€‚

PyTorch ä¸­ä¼ ç»Ÿçš„é¢„ç¼–è¯‘é€šå¸¸éœ€è¦å°†æ¨¡åž‹ä¿å­˜åˆ°ç£ç›˜ä¸Šï¼Œä»¥ä¾¿ç¨åŽé‡æ–°åŠ è½½ã€‚åœ¨æˆ‘ä»¬çš„ä¾‹å­ä¸­ï¼Œæˆ‘ä»¬å°†åˆ©ç”¨ `spaces` åŒ…ä¸­çš„ä¸€ä¸ªè¾…åŠ©å‡½æ•°ï¼š`spaces.aoti_compile`ã€‚å®ƒæ˜¯ `torch._inductor.aot_compile` çš„ä¸€ä¸ªå°åŒ…è£…å™¨ï¼Œæ ¹æ®éœ€è¦ç®¡ç†æ¨¡åž‹çš„ä¿å­˜å’Œå»¶è¿ŸåŠ è½½ã€‚å®ƒçš„ç”¨æ³•å¦‚ä¸‹ï¼š

```python
compiled_transformer = spaces.aoti_compile(exported_transformer)

```

çŽ°åœ¨ï¼Œè¿™ä¸ª `compiled_transformer` å°±æ˜¯ä¸€ä¸ªå·²é¢„ç¼–è¯‘å¥½çš„äºŒè¿›åˆ¶æ–‡ä»¶ï¼Œå¯ä»¥ç”¨äºŽæŽ¨ç†äº†ã€‚

### 4. åœ¨æµç¨‹ä¸­ä½¿ç”¨ç¼–è¯‘åŽçš„æ¨¡åž‹

çŽ°åœ¨æˆ‘ä»¬éœ€è¦å°†ç¼–è¯‘å¥½çš„Transformerç»‘å®šåˆ°åŽŸå§‹æµæ°´çº¿ï¼Œå³`pipeline`ã€‚

ä¸€ç§ç®€å•ä¸”è¿‘ä¹Žå¯è¡Œçš„æ–¹æ³•æ˜¯ç›´æŽ¥ä¿®è¡¥æµæ°´çº¿ï¼Œä¾‹å¦‚`pipe.transformer = compiled_transformer`ã€‚ä¸å¹¸çš„æ˜¯ï¼Œè¿™ç§æ–¹æ³•è¡Œä¸é€šï¼Œå› ä¸ºå®ƒä¼šåˆ é™¤é‡è¦çš„å±žæ€§ï¼Œå¦‚`dtype`ã€`config`ç­‰ã€‚ä»…ä¿®è¡¥`forward`æ–¹æ³•æ•ˆæžœä¹Ÿä¸å¥½ï¼Œå› ä¸ºè¿™æ ·æˆ‘ä»¬ä¼šåœ¨å†…å­˜ä¸­ä¿ç•™åŽŸå§‹æ¨¡åž‹å‚æ•°ï¼Œå¸¸å¸¸å¯¼è‡´è¿è¡Œæ—¶å‡ºçŽ°OOMé”™è¯¯ã€‚

`spaces`åŒ…ä¹Ÿä¸ºæ­¤æä¾›äº†ä¸€ä¸ªå®žç”¨å·¥å…·â€”â€”`spaces.aoti_apply`ï¼š

```python
spaces.aoti_apply(compiled_transformer, pipe.transformer)

```

çž§ï¼å®ƒä¼šè´Ÿè´£ç”¨æˆ‘ä»¬ç¼–è¯‘å¥½çš„æ¨¡åž‹ä¿®è¡¥`pipe.transformer.forward`ï¼ŒåŒæ—¶æ¸…ç†æŽ‰å†…å­˜ä¸­çš„æ—§æ¨¡åž‹å‚æ•°ã€‚

### 5. æ•´åˆæ‰€æœ‰æ­¥éª¤

è¦æ‰§è¡Œå‰ä¸‰ä¸ªæ­¥éª¤ï¼ˆæ‹¦æˆªè¾“å…¥ç¤ºä¾‹ã€å¯¼å‡ºæ¨¡åž‹ã€ä½¿ç”¨PyTorch inductorç¼–è¯‘ï¼‰ï¼Œæˆ‘ä»¬éœ€è¦ä¸€ä¸ªçœŸå®žçš„GPUã€‚åœ¨`@spaces.GPU`å‡½æ•°ä¹‹å¤–èŽ·å¾—çš„CUDAæ¨¡æ‹Ÿæ˜¯ä¸å¤Ÿçš„ï¼Œå› ä¸ºç¼–è¯‘ç¡®å®žä¾èµ–äºŽç¡¬ä»¶ï¼Œä¾‹å¦‚ï¼Œå®ƒä¾èµ–äºŽå¾®åŸºå‡†æµ‹è¯•è¿è¡Œæ¥è°ƒæ•´ç”Ÿæˆçš„ä»£ç ã€‚è¿™å°±æ˜¯ä¸ºä»€ä¹ˆæˆ‘ä»¬éœ€è¦å°†æ‰€æœ‰å†…å®¹åŒ…è£…åœ¨ä¸€ä¸ª`@spaces.GPU`å‡½æ•°ä¸­ï¼Œç„¶åŽå°†ç¼–è¯‘å¥½çš„æ¨¡åž‹è¿”å›žåˆ°æˆ‘ä»¬åº”ç”¨çš„æ ¹ç›®å½•ã€‚ä»Žæˆ‘ä»¬åŽŸå§‹çš„æ¼”ç¤ºä»£ç å¼€å§‹ï¼Œå¾—åˆ°å¦‚ä¸‹ä¿®æ”¹ï¼š

```diff
  import gradio as gr
  import spaces
  import torch
  from diffusers import DiffusionPipeline
  
  MODEL_ID = 'black-forest-labs/FLUX.1-dev'
  
  pipe = DiffusionPipeline.from_pretrained(MODEL_ID, torch_dtype=torch.bfloat16)
  pipe.to('cuda')
  
+ @spaces.GPU(duration=1500) # å¯åŠ¨æœŸé—´å…è®¸çš„æœ€å¤§æŒç»­æ—¶é—´
+ def compile_transformer():
+     with spaces.aoti_capture(pipe.transformer) as call:
+         pipe("arbitrary example prompt")
+ 
+     exported = torch.export.export(
+         pipe.transformer,
+         args=call.args,
+         kwargs=call.kwargs,
+     )
+     return spaces.aoti_compile(exported)
+ 
+ compiled_transformer = compile_transformer()
+ spaces.aoti_apply(compiled_transformer, pipe.transformer)
  
  @spaces.GPU
  def generate(prompt):
      return pipe(prompt).images
  
  gr.Interface(generate, "text", "gallery").launch()

```

ä»…ä»…å¢žåŠ äº†åå‡ è¡Œä»£ç ï¼Œæˆ‘ä»¬å°±æˆåŠŸåœ°è®©æˆ‘ä»¬çš„æ¼”ç¤ºå¿«äº†å¾ˆå¤šï¼ˆåœ¨FLUX.1-devçš„æƒ…å†µä¸‹å¿«äº†1.7å€ï¼‰ã€‚

å¦‚æžœä½ æƒ³äº†è§£æ›´å¤šå…³äºŽAoTç¼–è¯‘çš„ä¿¡æ¯ï¼Œå¯ä»¥é˜…è¯»PyTorchçš„AOTInductoræ•™ç¨‹

## æ³¨æ„äº‹é¡¹

æ—¢ç„¶æˆ‘ä»¬å·²ç»å±•ç¤ºäº†åœ¨ZeroGPUçº¦æŸä¸‹å¯ä»¥å®žçŽ°çš„åŠ é€Ÿï¼ŒæŽ¥ä¸‹æ¥æˆ‘ä»¬å°†è®¨è®ºåœ¨ä½¿ç”¨æ­¤è®¾ç½®æ—¶é‡åˆ°çš„ä¸€äº›æ³¨æ„äº‹é¡¹ã€‚

### é‡åŒ–

AoTå¯ä»¥ä¸Žé‡åŒ–ç»“åˆä½¿ç”¨ï¼Œä»¥æä¾›æ›´å¤§çš„åŠ é€Ÿã€‚
å¯¹äºŽå›¾åƒå’Œè§†é¢‘ç”Ÿæˆï¼ŒFP8è®­ç»ƒåŽåŠ¨æ€é‡åŒ–æ–¹æ¡ˆæä¾›äº†è‰¯å¥½çš„é€Ÿåº¦-è´¨é‡æƒè¡¡ã€‚
ç„¶è€Œï¼ŒFP8è¦æ±‚CUDAè®¡ç®—èƒ½åŠ›è‡³å°‘ä¸º9.0æ‰èƒ½å·¥ä½œã€‚
å¹¸è¿çš„æ˜¯ï¼Œå¯¹äºŽZeroGPUï¼Œç”±äºŽå®ƒä»¬åŸºäºŽH200ï¼Œæˆ‘ä»¬å·²ç»å¯ä»¥åˆ©ç”¨FP8é‡åŒ–æ–¹æ¡ˆã€‚

è¦åœ¨æˆ‘ä»¬çš„AoTç¼–è¯‘å·¥ä½œæµä¸­å¯ç”¨FP8é‡åŒ–ï¼Œæˆ‘ä»¬å¯ä»¥åƒè¿™æ ·åˆ©ç”¨`torchao`æä¾›çš„APIï¼š

```diff
+ from torchao.quantization import quantize_, Float8DynamicActivationFloat8WeightConfig

+ # åœ¨å¯¼å‡ºæ­¥éª¤ä¹‹å‰é‡åŒ–transformerã€‚
+ quantize_(pipe.transformer, Float8DynamicActivationFloat8WeightConfig())

exported_transformer = torch.export.export(
    pipe.transformer,
    args=call.args,
    kwargs=call.kwargs,
)

```

ï¼ˆä½ å¯ä»¥åœ¨æ­¤å¤„æ‰¾åˆ°å…³äºŽTorchAOçš„æ›´å¤šç»†èŠ‚ã€‚ï¼‰

ç„¶åŽæˆ‘ä»¬å¯ä»¥æŒ‰ç…§ä¸Šé¢æ¦‚è¿°çš„æ­¥éª¤ç»§ç»­ã€‚ä½¿ç”¨é‡åŒ–æä¾›äº†é¢å¤–çš„1.2å€åŠ é€Ÿã€‚

### åŠ¨æ€å½¢çŠ¶

å›¾åƒå’Œè§†é¢‘å¯ä»¥æœ‰ä¸åŒå½¢çŠ¶å’Œå°ºå¯¸ã€‚å› æ­¤ï¼Œåœ¨æ‰§è¡ŒAoTç¼–è¯‘æ—¶ï¼Œè€ƒè™‘å½¢çŠ¶åŠ¨æ€æ€§ä¹Ÿå¾ˆé‡è¦ã€‚`torch.export.export`æä¾›çš„åŽŸè¯­ä½¿å…¶æ˜“äºŽé…ç½®ï¼Œä»¥æŒ‡å®šå“ªäº›è¾“å…¥åº”ç›¸åº”å¤„ç†ä¸ºåŠ¨æ€å½¢çŠ¶ï¼Œå¦‚ä¸‹æ‰€ç¤ºã€‚

å¯¹äºŽFlux.1-Dev transformerï¼Œä¸åŒå›¾åƒåˆ†è¾¨çŽ‡çš„å˜åŒ–ä¼šå½±å“å…¶`forward`çš„ä¸¤ä¸ªå‚æ•°ï¼š

- `hidden_states`ï¼šå™ªå£°è¾“å…¥æ½œåœ¨è¡¨ç¤ºï¼Œtransformeréœ€è¦å¯¹å…¶è¿›è¡ŒåŽ»å™ªã€‚å®ƒæ˜¯ä¸€ä¸ª3Då¼ é‡ï¼Œä»£è¡¨`batch_size`ã€`flattened_latent_dim`ã€`embed_dim`ã€‚å½“æ‰¹æ¬¡å¤§å°å›ºå®šæ—¶ï¼Œ`flattened_latent_dim`ä¼šéšç€å›¾åƒåˆ†è¾¨çŽ‡çš„ä»»ä½•æ”¹å˜è€Œå˜åŒ–ã€‚
- `img_ids`ï¼šç¼–ç çš„åƒç´ åæ ‡çš„2Dæ•°ç»„ï¼Œå½¢çŠ¶ä¸º`height * width, 3`ã€‚åœ¨è¿™ç§æƒ…å†µä¸‹ï¼Œæˆ‘ä»¬å¸Œæœ›ä½¿`height * width`åŠ¨æ€ã€‚

æˆ‘ä»¬é¦–å…ˆå®šä¹‰å¸Œæœ›ï¼ˆæ½œåœ¨ï¼‰å›¾åƒåˆ†è¾¨çŽ‡å˜åŒ–çš„èŒƒå›´ã€‚
ä¸ºäº†æŽ¨å¯¼è¿™äº›å€¼èŒƒå›´ï¼Œæˆ‘ä»¬æ£€æŸ¥äº†æµæ°´çº¿ä¸­`hidden_states`ç›¸å¯¹äºŽä¸åŒå›¾åƒåˆ†è¾¨çŽ‡çš„å½¢çŠ¶ã€‚ç¡®åˆ‡çš„å€¼å–å†³äºŽæ¨¡åž‹ï¼Œéœ€è¦æ‰‹åŠ¨æ£€æŸ¥å’Œä¸€äº›ç›´è§‰ã€‚å¯¹äºŽFlux.1-Devï¼Œæˆ‘ä»¬æœ€ç»ˆå¾—åˆ°ï¼š

```python
transformer_hidden_dim = torch.export.Dim('hidden', min=4096, max=8212)

```

ç„¶åŽæˆ‘ä»¬å®šä¹‰ä¸€ä¸ªå‚æ•°åç§°æ˜ å°„ï¼Œä»¥åŠæˆ‘ä»¬æœŸæœ›å…¶è¾“å…¥å€¼ä¸­å“ªäº›ç»´åº¦æ˜¯åŠ¨æ€çš„ï¼š

```python
transformer_dynamic_shapes = {
    "hidden_states": {1: transformer_hidden_dim}, 
    "img_ids": {0: transformer_hidden_dim},
}

```

ç„¶åŽæˆ‘ä»¬éœ€è¦è®©æˆ‘ä»¬çš„åŠ¨æ€å½¢çŠ¶å¯¹è±¡å¤åˆ¶ç¤ºä¾‹è¾“å…¥çš„ç»“æž„ã€‚ä¸éœ€è¦åŠ¨æ€å½¢çŠ¶çš„è¾“å…¥å¿…é¡»è®¾ç½®ä¸º`None`ã€‚è¿™å¯ä»¥å¾ˆå®¹æ˜“åœ°ä½¿ç”¨PyTorchçš„`tree_map`å·¥å…·å®Œæˆï¼š

```python
from torch.utils._pytree import tree_map

dynamic_shapes = tree_map(lambda v: None, call.kwargs)
dynamic_shapes |= transformer_dynamic_shapes

```

çŽ°åœ¨ï¼Œåœ¨æ‰§è¡Œå¯¼å‡ºæ­¥éª¤æ—¶ï¼Œæˆ‘ä»¬åªéœ€å°†`transformer_dynamic_shapes`æä¾›ç»™`torch.export.export`ï¼š

```python
exported_transformer = torch.export.export(
    pipe.transformer,
    args=call.args,
    kwargs=call.kwargs,
    dynamic_shapes=dynamic_shapes,
)

```

æŸ¥çœ‹æ­¤Spaceï¼Œå®ƒå±•ç¤ºäº†å¦‚ä½•åœ¨å¯¼å‡ºæ­¥éª¤ä¸­åŒæ—¶ä½¿ç”¨é‡åŒ–å’ŒåŠ¨æ€å½¢çŠ¶ã€‚

### å¤šç¼–è¯‘ / å…±äº«æƒé‡

å½“åŠ¨æ€æ€§éžå¸¸é‡è¦æ—¶ï¼ŒåŠ¨æ€å½¢çŠ¶æœ‰æ—¶æ˜¯ä¸å¤Ÿçš„ã€‚

ä¾‹å¦‚ï¼Œå¯¹äºŽWanç³»åˆ—è§†é¢‘ç”Ÿæˆæ¨¡åž‹ï¼Œå¦‚æžœä½ å¸Œæœ›ç¼–è¯‘åŽçš„æ¨¡åž‹èƒ½ç”Ÿæˆä¸åŒåˆ†è¾¨çŽ‡ï¼Œå°±ä¼šå‡ºçŽ°è¿™ç§æƒ…å†µã€‚
åœ¨è¿™ç§æƒ…å†µä¸‹å¯ä»¥åšä¸€ä»¶äº‹ï¼šä¸ºæ¯ä¸ªåˆ†è¾¨çŽ‡ç¼–è¯‘ä¸€ä¸ªæ¨¡åž‹ï¼ŒåŒæ—¶ä¿æŒæ¨¡åž‹å‚æ•°å…±äº«ï¼Œå¹¶åœ¨è¿è¡Œæ—¶åˆ†æ´¾æ­£ç¡®çš„æ¨¡åž‹

è¿™æ˜¯è¿™ç§æ–¹æ³•çš„ä¸€ä¸ªæœ€å°ç¤ºä¾‹ï¼šzerogpu-aoti-multi.pyã€‚ä½ ä¹Ÿå¯ä»¥åœ¨Wan 2.2 Spaceä¸­çœ‹åˆ°æ­¤èŒƒå¼çš„å®Œæ•´å·¥ä½œå®žçŽ°ã€‚

### FlashAttention-3

ç”±äºŽZeroGPUç¡¬ä»¶å’ŒCUDAé©±åŠ¨ç¨‹åºä¸ŽFlash-Attention 3ï¼ˆFA3ï¼‰å®Œå…¨å…¼å®¹ï¼Œæˆ‘ä»¬å¯ä»¥åœ¨ZeroGPU Spaceä¸­ä½¿ç”¨å®ƒæ¥è¿›ä¸€æ­¥åŠ é€Ÿã€‚FA3é€‚ç”¨äºŽæå‰ç¼–è¯‘ã€‚æ‰€ä»¥ï¼Œè¿™å¯¹æˆ‘ä»¬çš„æƒ…å†µæ¥è¯´æ˜¯ç†æƒ³çš„ã€‚

ä»Žæºä»£ç ç¼–è¯‘å’Œæž„å»ºFA3å¯èƒ½éœ€è¦å‡ åˆ†é’Ÿï¼Œå¹¶ä¸”è¿™ä¸ªè¿‡ç¨‹ä¾èµ–äºŽç¡¬ä»¶ã€‚ä½œä¸ºç”¨æˆ·ï¼Œæˆ‘ä»¬ä¸æƒ³æµªè´¹å®è´µçš„ZeroGPUè®¡ç®—æ—¶é—´ã€‚è¿™å°±æ˜¯Hugging Faceçš„`kernels`åº“å‘æŒ¥ä½œç”¨çš„åœ°æ–¹ã€‚å®ƒæä¾›äº†å¯¹ä¸Žç»™å®šç¡¬ä»¶å…¼å®¹çš„é¢„æž„å»ºå†…æ ¸çš„è®¿é—®ã€‚ä¾‹å¦‚ï¼Œå½“æˆ‘ä»¬å°è¯•è¿è¡Œï¼š

```python
from kernels import get_kernel

vllm_flash_attn3 = get_kernel("kernels-community/vllm-flash-attn3")

```

å®ƒä¼šå°è¯•ä»Ž`kernels-community/vllm-flash-attn3`ä»“åº“åŠ è½½ä¸€ä¸ªä¸Žå½“å‰è®¾ç½®å…¼å®¹çš„å†…æ ¸ã€‚å¦åˆ™ï¼Œç”±äºŽå…¼å®¹æ€§é—®é¢˜ï¼Œå®ƒä¼šå‡ºé”™ã€‚å¹¸è¿çš„æ˜¯ï¼Œè¿™å¯¹æˆ‘ä»¬æ¥è¯´ï¼Œåœ¨ZeroGPU Spaceä¸Šå¯ä»¥æ— ç¼å·¥ä½œã€‚è¿™æ„å‘³ç€æˆ‘ä»¬å¯ä»¥åˆ©ç”¨`kernels`åº“ï¼Œåœ¨ZeroGPUä¸Šå‘æŒ¥FA3çš„å¼ºå¤§åŠŸèƒ½ã€‚

è¿™æ˜¯ä¸€ä¸ªç”¨äºŽQwen-Imageæ¨¡åž‹çš„FA3æ³¨æ„åŠ›å¤„ç†å™¨çš„å®Œæ•´å·¥ä½œç¤ºä¾‹ã€‚

### åŒºåŸŸç¼–è¯‘

åˆ°ç›®å‰ä¸ºæ­¢ï¼Œæˆ‘ä»¬ä¸€ç›´åœ¨ç¼–è¯‘æ•´ä¸ªæ¨¡åž‹ã€‚æ ¹æ®æ¨¡åž‹çš„ä¸åŒï¼Œå…¨æ¨¡åž‹ç¼–è¯‘å¯èƒ½å¯¼è‡´ç›¸å½“é•¿çš„å†·å¯åŠ¨æ—¶é—´ã€‚é•¿çš„å†·å¯åŠ¨æ—¶é—´ä¼šä½¿å¼€å‘ä½“éªŒä¸æ„‰å¿«ã€‚

æˆ‘ä»¬ä¹Ÿå¯ä»¥é€‰æ‹©ç¼–è¯‘æ¨¡åž‹å†…çš„ç‰¹å®šåŒºåŸŸï¼Œè¿™èƒ½åœ¨ä¿ç•™å…¨æ¨¡åž‹ç¼–è¯‘å‡ ä¹Žæ‰€æœ‰ä¼˜åŠ¿çš„åŒæ—¶ï¼Œæ˜¾è‘—é™ä½Žå†·å¯åŠ¨æ—¶é—´ã€‚å½“æ¨¡åž‹åŒ…å«é‡å¤çš„è®¡ç®—æ¨¡å—æ—¶ï¼ŒåŒºåŸŸç¼–è¯‘å°±å˜å¾—æžå…·å‰æ™¯ã€‚ä¾‹å¦‚ï¼Œæ ‡å‡†è¯­è¨€æ¨¡åž‹é€šå¸¸åŒ…å«å¤šä¸ªç»“æž„ç›¸åŒçš„Transformeræ¨¡å—ã€‚

åœ¨æˆ‘ä»¬çš„ç¤ºä¾‹ä¸­ï¼Œæˆ‘ä»¬å¯ä»¥é¢„å…ˆç¼–è¯‘Flux transformerä¸­çš„é‡å¤æ¨¡å—ï¼Œå¹¶å°†ç¼–è¯‘åŽçš„è®¡ç®—å›¾ä¼ æ’­åˆ°å…¶ä½™é‡å¤æ¨¡å—ä¸­ã€‚Flux TransformeråŒ…å«ä¸¤ç±»é‡å¤æ¨¡å—ï¼šFluxTransformerBlockå’ŒFluxSingleTransformerBlockã€‚

æ‚¨å¯ä»¥é€šè¿‡æ­¤SpaceæŸ¥çœ‹å®Œæ•´ç¤ºä¾‹ã€‚

ðŸ’¡ å¯¹äºŽFlux.1-Devæ¨¡åž‹ï¼Œé‡‡ç”¨åŒºåŸŸç¼–è¯‘å¯å°†ç¼–è¯‘æ—¶é—´ä»Ž**6åˆ†é’Ÿ**ç¼©çŸ­è‡³ä»…**30ç§’**ï¼ŒåŒæ—¶å®žçŽ°å®Œå…¨ç›¸åŒçš„åŠ é€Ÿæ•ˆæžœã€‚

### ä½¿ç”¨æ¥è‡ªHubçš„é¢„ç¼–è¯‘è®¡ç®—å›¾

å½“æ¨¡åž‹ï¼ˆç”šè‡³å•ä¸ªæ¨¡åž‹æ¨¡å—ï¼‰è¢«é¢„å…ˆç¼–è¯‘åŽï¼Œæˆ‘ä»¬å¯ä»¥å°†ç¼–è¯‘å¥½çš„è®¡ç®—å›¾æ¨¡å—åºåˆ—åŒ–ä¸ºå·¥ä»¶ä¾›åŽç»­å¤ç”¨ã€‚åœ¨Spacesçš„ZeroGPUé©±åŠ¨æ¼”ç¤ºåœºæ™¯ä¸­ï¼Œè¿™å°†é€šè¿‡è·³è¿‡ç¼–è¯‘æ—¶é—´å¤§å¹…ç¼©çŸ­æ¼”ç¤ºå¯åŠ¨æ—¶é—´ã€‚

ä¸ºä¿æŒå­˜å‚¨è½»é‡åŒ–ï¼Œæˆ‘ä»¬å¯ä»¥ä»…ä¿å­˜ç¼–è¯‘åŽçš„æ¨¡åž‹è®¡ç®—å›¾ï¼Œè€Œæ— éœ€åœ¨å·¥ä»¶ä¸­åŒ…å«ä»»ä½•æ¨¡åž‹å‚æ•°ã€‚

è¯·æŸ¥çœ‹æ­¤åˆé›†ï¼Œå…¶ä¸­å±•ç¤ºäº†èŽ·å–ç¼–è¯‘æ¨¡åž‹è®¡ç®—å›¾ã€å°†å…¶æŽ¨é€è‡³Hubï¼Œå¹¶ç”¨äºŽæž„å»ºæ¼”ç¤ºçš„å®Œæ•´å·¥ä½œæµç¨‹ã€‚

## é‡‡ç”¨AoTç¼–è¯‘çš„ZeroGPU Spacesæ¼”ç¤º

### åŠ é€Ÿæ•ˆæžœå¯¹æ¯”

- æœªä½¿ç”¨AoTIçš„FLUX.1-dev
- ä½¿ç”¨AoTIå’ŒFA3çš„FLUX.1-devï¼ˆ**1.75å€åŠ é€Ÿ**ï¼‰

### ç‰¹è‰²AoTI Spaces

- FLUX.1 Kontext
- QwenImage Edit
- Wan 2.2

- åŒºåŸŸç¼–è¯‘æ–¹æ¡ˆ
- ç»“åˆAOTçš„åŒºåŸŸç¼–è¯‘
- DiffusersåŽŸç”Ÿé›†æˆ
- æ›´å¤šæ€§èƒ½æ•°æ®

## ç»“è®º

Hugging Face Spacesä¸­çš„ZeroGPUæ˜¯ä¸€é¡¹å¼ºå¤§åŠŸèƒ½ï¼Œé€šè¿‡æä¾›é«˜æ€§èƒ½è®¡ç®—èµ„æºèµ‹èƒ½AIå¼€å‘è€…ã€‚æœ¬æ–‡å±•ç¤ºäº†ç”¨æˆ·å¦‚ä½•åˆ©ç”¨PyTorchçš„æå‰ç¼–è¯‘æŠ€æœ¯æ¥åŠ é€ŸåŸºäºŽZeroGPUçš„åº”ç”¨ç¨‹åºã€‚

æˆ‘ä»¬ä»¥Flux.1-Devæ¨¡åž‹å±•ç¤ºäº†åŠ é€Ÿæ•ˆæžœï¼Œä½†è¿™äº›æŠ€æœ¯å¹¶ä¸å±€é™äºŽè¯¥æ¨¡åž‹ã€‚å› æ­¤ï¼Œæˆ‘ä»¬é¼“åŠ±æ‚¨å°è¯•è¿™äº›æŠ€æœ¯ï¼Œå¹¶åœ¨æ­¤ç¤¾åŒºè®¨è®ºä¸­å‘æˆ‘ä»¬æä¾›åé¦ˆã€‚

## èµ„æº

- è®¿é—®æˆ‘ä»¬åœ¨Hubä¸Šçš„ZeroGPU-AOTIç»„ç»‡ï¼ŒæŸ¥çœ‹è¿ç”¨æœ¬æ–‡æŠ€æœ¯çš„æ¼”ç¤ºåˆé›†
- æµè§ˆspaces.aoti_* APIsæºä»£ç ä»¥æ·±å…¥äº†è§£æŽ¥å£
- æŸ¥çœ‹Hubä¸Šçš„Kernels Communityç»„ç»‡
- ä»Žæ­¤å¤„äº†è§£æ›´å¤šå…³äºŽåŒºåŸŸç¼–è¯‘çš„ä¿¡æ¯
- å‡çº§è‡³Hugging Face Proç‰ˆä»¥åˆ›å»ºæ‚¨è‡ªå·±çš„ZeroGPU Spacesï¼ˆæ¯æ—¥å¯èŽ·å¾—25åˆ†é’ŸH200ä½¿ç”¨æ—¶é•¿ï¼‰

è‡´è°¢ï¼šæ„Ÿè°¢ChunTe Leeä¸ºæœ¬æ–‡åˆ¶ä½œäº†ç²¾ç¾Žçš„å°é¢å›¾ã€‚æ„Ÿè°¢Pedroå’ŒVaibhavå¯¹æœ¬æ–‡æå‡ºçš„åé¦ˆæ„è§ã€‚æ„Ÿè°¢PyTorchå›¢é˜Ÿçš„Angela Yiåœ¨AOTæŠ€æœ¯æ–¹é¢ç»™äºˆçš„æŒ‡å¯¼ã€‚

---

> æœ¬æ–‡ç”±AIè‡ªåŠ¨ç¿»è¯‘ï¼ŒåŽŸæ–‡é“¾æŽ¥ï¼š[Make your ZeroGPU Spaces go brrr with ahead-of-time compilation](https://huggingface.co/blog/zerogpu-aoti)
> 
> ç¿»è¯‘æ—¶é—´ï¼š2026-02-14 04:13
