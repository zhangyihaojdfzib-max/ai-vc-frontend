---
title: 中国开源AI架构选择：超越DeepSeek的构建之路
title_original: 'Architectural Choices in China''s Open-Source AI Ecosystem: Building
  Beyond DeepSeek'
date: '2026-01-27'
source: Hugging Face Blog
source_url: https://huggingface.co/blog/huggingface/one-year-since-the-deepseek-moment-blog-2
author: ''
summary: 本文探讨了自“DeepSeek时刻”以来中国开源AI生态的架构演进。文章指出，中国社区正从模型优先转向硬件优先，混合专家模型成为默认选择，多模态竞赛加剧，小模型更受青睐，且开源许可证趋于宽松。这些趋势共同指向一个目标：在现实约束下实现可持续运营、灵活部署与最佳性价比，并推动国产硬件的广泛采用。
categories:
- 技术趋势
tags:
- 开源AI
- AI架构
- 混合专家模型
- 国产硬件
- 多模态AI
draft: false
translated_at: '2026-01-28T04:39:42.016834'
---

# 中国开源AI生态的架构选择：超越DeepSeek的构建之路

这是关于2025年1月"DeepSeek时刻"以来中国开源社区历史性进展的三部曲系列博客的第二篇。第一篇博客可在此处查阅。

在这第二篇文章中，我们将焦点从模型转向了随着开源成为常态，中国企业在架构和硬件方面做出的选择。

对于为开源生态系统做出贡献并依赖其的AI研究者和开发者，以及对于需要理解快速变化环境的政策制定者而言，**架构偏好、模态多样化、许可证宽松度、小模型流行度以及中国硬件日益增长的采用率**，都指向了跨越多种路径的领导力策略。DeepSeek R1自身的特性激发了重叠与竞争，并促使中国更加关注国产硬件。

### 混合专家模型成为默认选择

过去一年，中国社区的主流模型几乎一致转向了混合专家架构，包括Kimi K2、MiniMax M2和Qwen3。虽然R1本身并非MoE模型，但它证明了一个关键点：**强大的推理能力可以是开放的、可复现的，并且能够在实践中被工程化实现**。在中国现实的约束条件下，要在保持高能力的同时控制成本，并确保模型能够被训练、部署和广泛采用，MoE成为了一个自然的解决方案。

MoE就像一个可控的计算资源分配系统；在单一能力框架下，根据任务复杂度和价值，通过动态激活不同数量的专家，将计算资源分配到不同的请求和部署环境中。更重要的是，它不需要每次推理都消耗全部资源，也不假设所有部署环境都具备相同的硬件条件。

2025年中国开源模型的总体方向很明确：**不一定是追求最强的性能，而是追求可持续运营、灵活部署和持续演进的能力，实现最佳的性价比平衡**。

### 多模态领域的争先竞赛

从2025年2月开始，开源活动不再仅仅聚焦于文本模型。它迅速扩展到多模态和基于Agent的方向：**任意到任意模型、文生图、图生视频、文生视频、TTS、3D以及智能体**都在并行发展。社区推动的不仅仅是模型权重，而是一整套工程资产，包括推理部署、数据集与评估、工具链、工作流以及边云协同。视频生成工具、3D组件、蒸馏数据集和Agent框架的并行涌现，指向了比孤立突破更大的东西——它指向了可复用的系统级能力。

在非文本模态领域，争夺类似DeepSeek领导地位的竞争日益激烈。阶跃星辰发布了高性能多模态模型，在**音频、视频和图像的生成、处理或编辑**方面表现出色。他们最新的语音到语音模型Step-Audio-R1.1拥有最先进的性能，超越了闭源模型。腾讯也通过其在视频和3D领域的开源工作反映了这一转变。其**混元视频模型**以及如**混元3D**等项目，反映了超越以文本为中心的模型的竞争日益加剧。

### 对小模型的强烈偏好

参数量在0.5B到30B范围内的模型更容易在本地运行、微调，并集成到业务系统和Agent工作流中。例如：在Qwen系列中，**Qwen 1.5-0.5B**拥有最多的衍生模型。在计算资源有限或合规要求严格的环境中，这些模型更适合长期运营。同时，领先的参与者通常将100B到700B范围的大型MoE模型作为能力上限或"教师模型"，然后将这些能力蒸馏到许多更小的模型中。这形成了一个清晰的结构：顶层是少数几个非常大的模型，下面则是许多实用的模型。月度总结中小模型份额的增长反映了社区真实的用需。

https://huggingface.co/spaces/cfahlgren1/hub-model-tree-stats

### 更宽松的开源许可证

在R1之后，Apache 2.0几乎成为中国社区开源模型的默认选择。**更宽松的许可证降低了在生产中使用、修改和部署模型的摩擦**，使得企业将开源模型引入实际系统变得容易得多。对Apache 2.0和MIT等标准许可证的熟悉同样简化了使用；而规定性强的、定制的许可证则因不熟悉和新的法律障碍增加了摩擦，这导致了如下图所示的下滑趋势。

基于中国开源热图中所示所有组织的发布情况

### 从模型优先到硬件优先

2025年，模型发布越来越多地与推理框架、量化格式、服务引擎和边缘运行时对齐。一个突出的目标不再仅仅是让权重可下载，而是要确保模型能够直接在目标国产硬件上运行——并且是可靠、高效地运行。这一变化在推理侧最为明显。例如，对于**DeepSeek-V3.2-Exp**，华为昇腾和寒武纪芯片都实现了发布当天的支持，不是作为云端演示，而是作为与权重一同发布的可复现推理流水线，使开发者能够直接验证实际性能。

与此同时，训练侧的信号也开始出现。蚂蚁集团的**Lingopen**模型通过在国产AI芯片上的优化训练，实现了接近NVIDIA H800的性能，将训练1万亿Token的成本降低了约20%。百度的开源**Qianfan-VL**模型明确记录了该模型是在超过5000个百度昆仑P800加速器（其旗舰AI芯片）的集群上训练的，并提供了并行化和效率的细节。2026年初，智谱的**GLM-Image**和中国电信的最新开源模型**TeleChat3**，均宣布完全在国产芯片上训练完成。这些披露表明，国产计算设备不再局限于推理，而是已经开始进入训练流水线的关键阶段。

在服务和基础设施方面，工程能力正在被系统地开源。月之暗面发布了其服务系统：**Mooncake**，并明确支持了预填充/解码分离等功能。通过开源生产级经验，这些努力显著提高了整个社区的部署和运维基线，使得大规模可靠运行模型变得更加容易。这一方向在整个生态系统中得到了呼应。百度的**FastDeploy 2.0**强调极致的量化和集群级优化，以在紧张的计算预算下降低推理成本。阿里巴巴的**Qwen**生态系统追求全栈集成，将模型、推理框架、量化策略和云部署工作流紧密结合，以最小化从开发到生产的摩擦。尽管如此，关于中国计算资源受限的报道威胁着扩张；据报道，智谱AI正在计算紧缩中限制使用。

当模型、工具和工程能力一同交付时，生态系统不再是通过增加项目来增长，而是在共享的基础上进行结构性分化——并开始自主演进。随着英伟达销售H200，中国将如何应对美国的硬件销售和出口管制，仍然是一个**悬而未决的问题**。更多关于全球计算格局变化的信息可在此处查阅。

### 重构进行时

2025年1月的"DeepSeek时刻"所做的不仅仅是引发了一波新的开源模型浪潮。它迫使人们更深入地重新思考：当开源不再是可选项而是基础时，AI系统应该如何构建，以及为什么这些底层选择现在具有战略分量。

中国企业已不再局限于优化单一模型，而是正沿着独特的架构路径推进，致力于构建适应开源世界的完整生态系统。在模型日益商品化的格局下，这些决策标志着竞争焦点已从模型性能明显转向系统设计。

我们的下一篇博客将深入探讨组织层面的成功案例，并分享我们对2026年行业发展的部分展望。

---

> 本文由AI自动翻译，原文链接：[Architectural Choices in China's Open-Source AI Ecosystem: Building Beyond DeepSeek](https://huggingface.co/blog/huggingface/one-year-since-the-deepseek-moment-blog-2)
> 
> 翻译时间：2026-01-28 04:39
