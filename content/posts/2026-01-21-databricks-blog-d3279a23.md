---
title: Databricks的高可用性功能标志实践
title_original: High-Availability Feature Flagging at Databricks
date: '2026-01-21'
source: Databricks Blog
source_url: https://www.databricks.com/blog/high-availability-feature-flagging-databricks
author: ''
summary: 本文介绍了Databricks平台如何实现高可用性的功能标志（Feature Flagging）技术。功能标志是一种允许团队在不部署新代码的情况下，动态控制功能开启或关闭的技术，常用于灰度发布、A/B测试和快速回滚。Databricks作为统一的数据、分析和AI平台，其高可用性架构确保了功能标志服务的稳定性和可靠性，即使在复杂的生产环境中也能实现无缝的功能管理，支撑其数据工程、机器学习、商业智能等多种服务的灵活迭代与安全发布。
categories:
- AI基础设施
tags:
- 功能标志
- 高可用性
- Databricks
- 灰度发布
- 云原生
draft: false
translated_at: '2026-01-22T04:57:50.989629'
---

-   为何选择 Databricks
探索
面向高管
面向初创企业
湖仓一体架构
Mosaic 研究
客户
客户案例
合作伙伴
云服务提供商
Databricks 在 AWS、Azure、GCP 和 SAP 上的服务
咨询与系统集成商
构建、部署和迁移至 Databricks 的专家
技术合作伙伴
将现有工具连接至您的湖仓一体
C&SI 合作伙伴计划
构建、部署或迁移至湖仓一体
数据合作伙伴
接入数据消费者生态系统
合作伙伴解决方案
寻找定制化行业与迁移解决方案
基于 Databricks 构建
构建、推广和发展您的业务

-   产品
Databricks 平台
平台概览
面向数据、分析和 AI 的统一平台
数据管理
数据可靠性、安全性与性能
共享
面向所有数据的开放、安全、零拷贝共享
数据仓库
用于 SQL 分析的无服务器数据仓库
治理
面向所有数据、分析和 AI 资产的统一治理
数据工程
批处理和流式数据的 ETL 与编排
人工智能
构建和部署机器学习与生成式 AI 应用
数据科学
大规模协作式数据科学
商业智能
面向真实世界数据的智能分析
应用开发
快速构建安全的数据与 AI 应用
数据库
面向数据应用和 AI Agent（智能体）的 Postgres
集成与数据
市场
面向数据、分析和 AI 的开放市场
IDE 集成
在您喜爱的 IDE 中基于湖仓一体进行开发
合作伙伴连接
发现并与 Databricks 生态系统集成
定价
Databricks 定价
探索产品定价、DBU 等更多信息
成本计算器
估算您在任意云上的计算成本
开源
开源技术
深入了解平台背后的创新

-   解决方案
面向行业的 Databricks
通信
媒体与娱乐
金融服务
公共部门
医疗保健与生命科学
零售
制造业
查看所有行业
跨行业解决方案
AI Agent（智能体）
网络安全
市场营销
迁移与部署
数据迁移
专业服务
解决方案加速器
探索加速器
更快地实现关键成果

-   资源
学习
培训
发现为您量身定制的课程
Databricks 学院
登录 Databricks 学习平台
认证
获得认可与差异化优势
免费版
免费学习专业的数据与 AI 工具
大学联盟
想要教授 Databricks？了解详情。
活动
Data + AI 峰会
Data + AI 全球巡演
数据智能日
活动日历
博客与播客
Databricks 博客
探索新闻、产品发布等更多内容
Databricks Mosaic 研究博客
发现我们生成式 AI 研究的最新进展
Data Brew 播客
让我们聊聊数据！
Champions of Data + AI 播客
来自推动创新的数据领导者的见解
获取帮助
客户支持
文档
社区
深入探索
资源中心
演示中心
架构中心

-   关于
公司
我们是谁
我们的团队
Databricks Ventures
联系我们
招聘
在 Databricks 工作
开放职位
新闻
奖项与认可
新闻中心
安全与信任
安全与信任

-   探索
面向高管
面向初创企业
湖仓一体架构
Mosaic 研究

-   客户
客户案例

-   合作伙伴
云服务提供商
Databricks 在 AWS、Azure、 GCP 和 SAP 上的服务
咨询与系统集成商
构建、部署和迁移至 Databricks 的专家
技术合作伙伴
将现有工具连接至您的湖仓一体
C&SI 合作伙伴计划
构建、部署或迁移至湖仓一体
数据合作伙伴
接入数据消费者生态系统
合作伙伴解决方案
寻找定制化行业与迁移解决方案
基于 Databricks 构建
构建、推广和发展您的业务

-   面向高管
-   面向初创企业
-   湖仓一体架构
-   Mosaic 研究

-   客户案例

-   云服务提供商
Databricks 在 AWS、Azure、 GCP 和 SAP 上的服务
-   咨询与系统集成商
构建、部署和迁移至 Databricks 的专家
-   技术合作伙伴
将现有工具连接至您的湖仓一体
-   C&SI 合作伙伴计划
构建、部署或迁移至湖仓一体
-   数据合作伙伴
接入数据消费者生态系统
-   合作伙伴解决方案
寻找定制化行业与迁移解决方案
-   基于 Databricks 构建
构建、推广和发展您的业务

-   Databricks 平台
平台概览
面向数据、分析和 AI 的统一平台
数据管理
数据可靠性、安全性与性能
共享
面向所有数据的开放、安全、零拷贝共享
数据仓库
用于 SQL 分析的无服务器数据仓库
治理
面向所有数据、分析和 AI 资产的统一治理
数据工程
批处理和流式数据的 ETL 与编排
人工智能
构建和部署机器学习与生成式 AI 应用
数据科学
大规模协作式数据科学
商业智能
面向真实世界数据的智能分析
应用开发
快速构建安全的数据与 AI 应用
数据库
面向数据应用和 AI Agent（智能体）的 Postgres

-   集成与数据
市场
面向数据、分析和 AI 的开放市场
IDE 集成
在您喜爱的 IDE 中基于湖仓一体进行开发
合作伙伴连接
发现并与 Databricks 生态系统集成

-   定价
Databricks 定价
探索产品定价、DBU 等更多信息
成本计算器
估算您在任意云上的计算成本

-   开源
开源技术
深入了解平台背后的创新

-   平台概览
面向数据、分析和 AI 的统一平台
-   数据管理
数据可靠性、安全性与性能
-   共享
面向所有数据的开放、安全、零拷贝共享
-   数据仓库
用于 SQL 分析的无服务器数据仓库
-   治理
面向所有数据、分析和 AI 资产的统一治理
-   数据工程
批处理和流式数据的 ETL 与编排
-   人工智能
构建和部署机器学习与生成式 AI 应用
-   数据科学
大规模协作式数据科学
-   商业智能
面向真实世界数据的智能分析
-   应用开发
快速构建安全的数据与 AI 应用
-   数据库
面向数据应用和 AI Agent（智能体）的 Postgres

-   市场
面向数据、分析和 AI 的开放市场
-   IDE 集成
在您喜爱的 IDE 中基于湖仓一体进行开发
-   合作伙伴连接
发现并与 Databricks 生态系统集成

-   Databricks 定价
探索产品定价、DBU 等更多信息
-   成本计算器
估算您在任意云上的计算成本

-   开源技术
深入了解平台背后的创新

-  面向行业的Databricks通信媒体与娱乐金融服务公共部门医疗与生命科学零售制造业查看所有行业跨行业解决方案AI Agent（智能体）网络安全营销迁移与部署数据迁移专业服务解决方案加速器探索加速器更快实现关键成果

-   面向行业的Databricks通信媒体与娱乐金融服务公共部门医疗与生命科学零售制造业查看所有行业
-   跨行业解决方案AI Agent（智能体）网络安全营销
-   迁移与部署数据迁移专业服务
-   解决方案加速器探索加速器更快实现关键成果

-   通信
-   媒体与娱乐
-   金融服务
-   公共部门
-   医疗与生命科学
-   零售
-   制造业
-   查看所有行业

-   AI Agent（智能体）
-   网络安全
-   营销

-   数据迁移
-   专业服务

-   探索加速器更快实现关键成果


-   培训发现满足您需求的定制课程
-   Databricks Academy登录Databricks学习平台
-   认证获得认可与区分
-   免费版免费学习专业的数据与AI工具
-   大学联盟想教授Databricks？了解详情。

-   Data + AI 峰会
-   Data + AI 全球巡展
-   数据智能日
-   活动日历

-   Databricks 博客探索新闻、产品公告等
-   Databricks Mosaic 研究博客发现我们生成式AI研究的最新进展
-   Data Brew 播客让我们聊聊数据！
-   Champions of Data + AI 播客来自推动创新的数据领导者的洞见

-   客户支持
-   文档
-   社区

-   资源中心
-   演示中心
-   架构中心

-   安全与信任

-   安全与信任

-   关于我们
-   我们的团队
-   Databricks Ventures
-   联系我们

-   在Databricks工作
-   开放职位

-   奖项与认可
-   新闻中心

-   安全与信任

-   准备开始了吗？
-   获取演示

-   登录
-   联系我们
-   试用 Databricks

1.  博客
2.  /工程
3.  /文章

# Databricks 的高可用性功能开关

## 我们如何为 Databricks 的全球基础设施构建零停机功能开关系统

![Databricks 的高可用性功能开关](/images/posts/21f3d24e04d2.png)

![Databricks 的高可用性功能开关](/images/posts/21f3d24e04d2.png)

![Databricks 的高可用性功能开关](/images/posts/21f3d24e04d2.png)

发布日期：2026年1月21日

-   SAFE 是 Databricks 内部的功能开关平台，它使工程师能够将代码部署与功能启用解耦，从而在数百个服务中实现更安全的发布和更快的事件缓解。
-   本文描述了 SAFE 的架构，该系统通过静态维度预评估和多层全局交付等技术，处理超过 25,000 个活跃开关，每秒进行超过 3 亿次评估，且延迟在微秒级别。
-   该系统通过分层弹性机制实现高可靠性，包括故障静态行为、带外交付路径和冷启动配置包，确保即使在交付管道故障期间服务也能持续运行。

-   SAFE 是 Databricks 内部的功能开关平台，它使工程师能够将代码部署与功能启用解耦，从而在数百个服务中实现更安全的发布和更快的事件缓解。
-   本文描述了 SAFE 的架构，该系统通过静态维度预评估和多层全局交付等技术，处理超过 25,000 个活跃开关，每秒进行超过 3 亿次评估，且延迟在微秒级别。
-   该系统通过分层弹性机制实现高可靠性，包括故障静态行为、带外交付路径和冷启动配置包，确保即使在交付管道故障期间服务也能持续运行。

在保持可靠性的同时快速交付软件，始终是一个持续的张力。随着 Databricks 的发展，在数百个服务、多个云平台和数千个客户工作负载中安全推出变更的复杂性也随之增加。功能开关通过将部署代码的决策与启用功能的决策分开，帮助我们管理这种复杂性。这种分离使工程师能够隔离故障并更快地缓解事件，同时不牺牲交付速度。

Databricks 稳定性态势的关键组成部分之一是我们内部的功能开关和实验平台，称为 "SAFE"。Databricks 工程师每天使用 SAFE 来发布功能、动态控制服务行为，并通过 A/B 实验衡量其功能的有效性。

SAFE 启动时的"北极星"目标是完全将服务二进制发布与功能启用解耦，允许团队独立于其二进制部署来发布功能。这带来了许多附带好处，例如能够可靠地将功能逐步推广给越来越多的用户群体，并快速缓解由发布引起的事件。

在 Databricks 的规模下，服务于跨多个云的数千家企业客户，且产品覆盖范围快速增长，我们需要一个能够满足我们独特要求的功能开关系统：

-   对安全性和变更管理的高标准。SAFE 的主要价值主张是改善 Databricks 的稳定性和运营态势，因此几乎所有其他要求都源于此。
-   跨 Azure、AWS 和 GCP 的多云、无缝全局交付，具有亚毫秒级的开关评估延迟，以支持高吞吐量和延迟敏感的生产服务。
-   透明支持 Databricks 工程师编写代码的所有地方，包括我们的控制平面、Databricks UI、Databricks 运行时环境和 Databricks 的无服务器数据平面。
-   一个对 Databricks 发布实践有足够见解的界面，使常见的开关发布"默认安全"，同时又足够灵活以支持大量更特殊的用例。
-   极其严格的可用性要求，因为服务在没有加载开关定义的情况下无法安全启动。

在仔细考量这些需求后，我们最终选择构建一套自定义的内部功能开关系统。我们需要一个能够与我们的架构共同演进、并能提供必要治理控制能力的解决方案，以便安全地管理横跨数百个服务和数千名工程师的功能开关。要成功实现我们的扩展性和安全性目标，需要与我们的基础设施数据模型、服务框架和CI系统进行深度集成。

截至2025年底，SAFE系统拥有约2.5万个活跃功能开关，每周进行4000次开关状态切换。在峰值时，SAFE每秒执行超过3亿次开关评估，同时将开关评估的p95延迟维持在约10微秒。

本文将探讨我们如何构建SAFE以满足这些要求，以及在此过程中获得的经验教训。

## 功能开关实战

首先，我们将讨论SAFE功能开关的典型用户使用流程。功能开关的核心是一个可以在服务控制流中访问的变量，其取值取决于由外部配置控制的特定条件。功能开关一个极其常见的用例是：以可控的方式逐步启用新的代码路径，首先从一小部分流量开始，逐步扩展到全局启用。

SAFE用户首先在服务代码中定义他们的功能开关，并将其作为新功能逻辑的条件控制门：

```scala
if (safe.enabled("my-new-feature")) {
  // 新功能逻辑
} else {
  // 旧逻辑
}
```

随后，用户前往内部的SAFE用户界面注册此开关，并选择一个模板来部署他们的开关。该模板定义了一个由一系列有序阶段组成的渐进式推广计划。每个阶段都按百分比缓慢增加流量。开关创建后，用户会看到如下所示的界面：

![SAFE UI示例](/images/posts/example-ui.png)

在此之后，用户可以手动地逐个阶段推广他们的开关，或者设置一个时间表来自动创建开关切换任务。在内部，功能开关配置的单一事实来源是一个签入Databricks单体代码库的Jsonnet文件，该文件使用一种轻量级的领域特定语言来管理开关配置：

```jsonnet
{
  flag: 'my-new-feature',
  rollout: {
    template: 'gradual-ramp',
    stages: [
      { percentage: 1 },
      { percentage: 5 },
      { percentage: 25 },
      { percentage: 100 }
    ]
  }
}
```

当用户通过UI更改开关时，该更改的输出是一个需要至少由另一名工程师审查的拉取请求。SAFE还会运行各种预合并检查，以防止不安全或非预期的更改。一旦更改被合并，用户的服务将在PR合并后的2-5分钟内获取到更改并开始输出新值。

除了上述功能发布用例外，SAFE还用于动态服务配置的其他方面，例如：长期动态配置（如超时或速率限制）、基础设施迁移的状态机控制，或传递小型配置数据块（如定向日志记录策略）。

![客户端库](/images/posts/c8a4603efb5d.png)

SAFE以多种内部支持的语言提供客户端“SDK”，其中Scala SDK最为成熟且应用最广。该SDK本质上是一个条件评估库，结合了一个配置加载组件。对于每个功能开关，都有一套控制SDK在运行时应返回哪个值的评估标准。SDK负责加载最新的配置集，并需要在运行时快速返回评估这些标准的结果。

用伪代码表示，其内部评估标准大致如下：

```python
def evaluate(flag, context):
    for rule in flag.rules:
        if matches(rule.conditions, context):
            return rule.value
    return flag.default_value
```

评估标准可以建模为类似于一系列布尔表达式树的结构。每个条件表达式都需要高效评估以快速返回结果。

为了满足性能要求，SAFE SDK设计体现了几项架构原则：(1) 配置交付与评估分离，(2) 静态维度与运行时评估维度分离。

1.  **交付与评估分离**：SAFE客户端库始终将配置交付视为异步过程，绝不因配置交付而阻塞功能开关评估的“热路径”。一旦客户端获取了功能开关配置的快照，它将基于该快照返回结果，直到异步后台进程将该快照原子性地更新为更新的快照。
2.  **维度类型分离**：SAFE中的功能开关评估基于两种类型的维度：
    *   **静态维度**：代表运行中二进制文件本身的特征，例如云提供商、云区域和环境（开发/预发布/生产）。这些值在进程的生命周期内保持不变。
    *   **运行时维度**：捕获请求特定的上下文，如工作区ID、账户ID、应用程序提供的值，以及其他随每次评估而变化的每个请求属性。

为了在大规模下可靠地实现亚毫秒级的评估延迟，SAFE采用了布尔表达式树中静态部分的预评估。当SAFE配置包交付给服务时，SDK会立即根据内存中的功能开关配置表示对所有静态维度进行评估。这会生成一个简化的配置树，其中仅包含与该特定服务实例相关的逻辑。

当在请求处理过程中需要进行功能开关评估时，SDK只需根据这个预编译的配置评估剩余的运行时维度。这显著降低了每次评估的计算成本。由于许多功能开关的布尔表达式树中只使用静态维度，因此许多功能开关实际上可以完全进行预评估。

为了可靠地将配置交付给Databricks的所有服务，SAFE与我们内部的动态配置交付平台Zippy协同工作。关于Zippy架构的深入描述留待其他文章讨论，简而言之，Zippy采用多层全球/区域架构以及每个云的Blob存储，将任意配置数据块从中央源传输到（包括）在Databricks控制平面中运行的所有Kubernetes Pod。

![](/images/posts/aca9a950cccf.png)

已交付功能开关的生命周期如下：

1.  用户创建并合并一个针对其某个功能开关配置Jsonnet文件的PR，该文件随后被合并到Github中的Databricks单体代码库。
2.  大约1分钟内，一个合并后的CI作业会拾取修改后的文件并将其发送到SAFE后端，后端随后将新配置的副本存储到数据库中。
3.  SAFE后端定期（约1分钟间隔）将所有SAFE功能开关配置打包并发送给Zippy Global后端。
4.  Zippy Global在大约30秒内将这些配置分发到其各个Zippy Regional实例。
5.  在每个服务Pod中运行的SAFE SDK，通过基于推送和拉取相结合的交付方式，定期接收新版本的配置包。
6.  一旦交付完成，SAFE SDK即可在评估时使用新配置。

端到端来看，功能开关的更改通常在PR合并后的3-5分钟内传播到所有服务。

### 功能开关配置流水线

在功能开关交付流水线中，配置会呈现多种形式——随着功能开关越来越接近被评估，它会从高级的、人类可读的语义配置逐步转换为紧凑的机器可读版本。

在面向用户的界面中，功能开关使用Jsonnet和自定义DSL定义，以支持任意复杂的功能开关配置。该DSL为常见用例提供了便利，例如使用预定义模板配置功能开关的推广，或为特定流量片段设置特定的覆盖规则。

一旦完成登记，该DSL会被转换为等效的内部protobuf格式，以捕获配置的语义意图。随后，SAFE后端进一步将此语义配置转换为布尔表达式树。该布尔表达式树的protobuf描述会被传递给SAFE SDK，SDK将其加载为更紧凑的内存配置表示形式。

![](/images/posts/f83ee8e29d6c.png)

大多数标志切换操作都通过一个用于管理SAFE标志的内部UI发起。该UI允许用户通过一个工作流来创建、修改和停用标志，该工作流为简单变更抽象掉了Jsonnet的大部分复杂性，同时仍为高级用例提供对DSL大部分完整功能的访问。

丰富的UI还使我们能够提供额外的便利功能，例如安排标志切换、支持合并后健康检查，以及用于确定影响特定区域或服务的近期标志切换的调试工具。

所有SAFE标志变更都以普通的Github PR形式创建，并通过一系列广泛的预合并验证器进行验证。随着我们对如何最好地防范潜在不安全标志变更的了解加深，这套验证器已发展到包含数十项独立检查。在SAFE最初引入期间，对由SAFE标志切换引发或通过其缓解的事故进行事后审查，为其中许多检查提供了依据。例如，我们现在拥有以下检查：要求对大范围变更进行专门审查、要求在启用标志前必须部署特定的服务二进制版本、防止微妙的常见错误配置模式等等。

团队还可以定义自己特有的、针对特定标志或团队的预合并检查，以强制执行其配置的不变性。

### 处理故障模式

鉴于SAFE在服务稳定性中的关键作用，该系统设计有多层弹性，以确保即使在交付管道的某些部分发生故障时也能持续运行。

最常见的故障场景涉及配置交付路径的中断。如果交付路径中的任何环节导致配置更新失败，服务将简单地继续使用其最后已知的配置，直到交付路径恢复。这种"静态故障"方法确保即使在发生上游中断时，现有服务行为也能保持稳定。

对于更严重的场景，我们维护了多种备用机制：

1.  带外交付：如果CI或Github推送路径的任何部分不可用，操作员可以使用紧急工具将配置直接推送到SAFE后端。
2.  区域故障转移：如果SAFE后端或Zippy Global宕机，操作员可以暂时将配置直接推送到Zippy Regional实例。服务也可以跨区域轮询，以减轻单个Zippy Regional中断的影响。
3.  冷启动包：为了处理服务启动期间Zippy本身不可用的情况，SAFE会通过制品注册表定期向服务分发配置包。虽然这些包可能滞后几个小时，但它们为服务安全启动提供了足够的备份，而不是阻塞在实时交付上。

![](/images/posts/923f11e11eec.png)

在SAFE SDK内部，防御性设计确保配置错误的影响范围有限。如果某个特定标志的配置格式错误，只有该单个标志会受到影响。SDK还坚持永不抛出异常的约定，并且始终故障开放到代码默认值，因此应用程序开发人员无需将标志评估视为可能出错的操作。当发生任何配置解析或评估故障时，SDK还会立即提醒值班工程师。由于SAFE的成熟度和广泛的预合并验证，此类故障在生产环境中现已极为罕见。

这种分层的弹性方法确保了SAFE能够优雅降级，并最大限度地降低了其成为单点故障的风险。

最小化依赖和分层冗余备用机制减少了运维负担。尽管SAFE几乎部署在Databricks的每个计算表面并被广泛使用，但维护SAFE的运维负担一直相当可控。增加分层冗余，例如冷启动包和SDK的"静态故障"行为，使得SAFE架构的大部分能够自我修复。

开发者体验至关重要。扩展一个健壮的标志系统的"人员方面"需要强烈的用户体验关注。SAFE是一个关键任务系统，常用于缓解事故。因此，构建一个用户友好的界面以便在紧急情况下切换标志具有很高的杠杆效应。采用以产品为中心的思维方式减少了小问题、降低了混淆，并最终降低了公司范围内事故的平均恢复时间。

让"最佳实践"成为低摩擦路径。我们最大的收获之一是，不能仅仅记录最佳实践并期望工程师遵循它们。工程师在交付功能时有许多相互竞争的优先事项。SAFE使安全路径成为简单路径：与风险更高的启用模式相比，渐进式推出需要更少的努力，并提供更多便利功能。当系统激励更安全的行为时，平台可以推动工程师形成负责任的变更管理文化。

## 现状与未来工作

SAFE现已成为Databricks内部一个成熟的平台，并被广泛使用。我们在可用性和开发者体验方面的投入取得了回报，我们看到通过使用SAFE标志，平均解决时间和影响范围生产事故持续减少。

随着Databricks产品覆盖面的不断扩大，支撑这些产品的基础设施原语在广度和复杂性上都在扩展。因此，我们持续投入大量资源，以确保SAFE支持Databricks工程师编写和部署代码的所有场景。

如果您对扩展此类关键任务基础设施感兴趣，请探索Databricks的开放职位！


## 不错过任何Databricks文章

![Booting Databricks VMs 7x Faster for Serverless Compute](/images/posts/6ee6ae17dfac.png)

![Booting Databricks VMs 7x Faster for Serverless Compute](/images/posts/6ee6ae17dfac.png)

![Booting Databricks VMs 7x Faster for Serverless Compute](/images/posts/6ee6ae17dfac.png)

2024年11月26日 / 9分钟阅读

#### 为无服务器计算实现Databricks虚拟机启动速度提升7倍

![Mosaic AI Model Serving dashboard for deploying and managing fine-tuned LLaMA models.](/images/posts/c17c6300ff0c.png)

![Mosaic AI Model Serving dashboard for deploying and managing fine-tuned LLaMA models.](/images/posts/c17c6300ff0c.png)

![Mosaic AI Model Serving dashboard for deploying and managing fine-tuned LLaMA models.](/images/posts/c17c6300ff0c.png)

2024年12月10日 / 7分钟阅读

#### 使用Mosaic AI Model Serving对微调后的Llama模型进行批量推理

![databricks logo](/images/posts/443a5359ee28.png)

![databricks logo](/images/posts/443a5359ee28.png)

![databricks logo](/images/posts/443a5359ee28.png)

-   面向高管
-   面向初创公司
-   Lakehouse架构
-   Mosaic研究

-   客户案例

-   云提供商
-   技术合作伙伴
-   数据合作伙伴
-   基于Databricks构建
-   咨询与系统集成商
-   C&SI合作伙伴计划
-   合作伙伴解决方案

-   面向高管
-   面向初创公司
-   Lakehouse架构
-   Mosaic研究

-   客户案例

-   云提供商
-   技术合作伙伴
-   数据合作伙伴
-   基于Databricks构建
-   咨询与系统集成商
-   C&SI合作伙伴计划
-   合作伙伴解决方案

-   平台概览
-   共享
-   治理
-   人工智能
-   商业智能
-   数据库
-   数据管理
-   数据仓库
-   数据工程
-   数据科学
-   应用开发

-   定价概览
-   定价计算器

-   市场
-   IDE集成
-   合作伙伴连接

- 平台概览
- 共享
- 治理
- 人工智能
- 商业智能
- 数据库
- 数据管理
- 数据仓库
- 数据工程
- 数据科学
- 应用开发

- 定价概览
- 定价计算器

- 市场
- IDE 集成
- 合作伙伴连接

- 通信
- 金融服务
- 医疗保健与生命科学
- 制造业
- 媒体与娱乐
- 公共部门
- 零售
- 查看全部

- 网络安全
- 市场营销

- 通信
- 金融服务
- 医疗保健与生命科学
- 制造业
- 媒体与娱乐
- 公共部门
- 零售
- 查看全部

- 网络安全
- 市场营销

- 培训
- 认证
- 免费版
- 大学联盟
- Databricks 学院登录

- Data + AI 峰会
- Data + AI 全球巡展
- 数据智能日
- 活动日历

- Databricks 博客
- Databricks Mosaic 研究博客
- Data Brew 播客
- 数据与 AI 冠军播客

- 培训
- 认证
- 免费版
- 大学联盟
- Databricks 学院登录

- Data + AI 峰会
- Data + AI 全球巡展
- 数据智能日
- 活动日历

- Databricks 博客
- Databricks Mosaic 研究博客
- Data Brew 播客
- 数据与 AI 冠军播客

- 关于我们
- 我们的团队
- Databricks Ventures
- 联系我们

- 开放职位
- 在 Databricks 工作

- 奖项与认可
- 新闻中心

- 关于我们
- 我们的团队
- Databricks Ventures
- 联系我们

- 开放职位
- 在 Databricks 工作

- 奖项与认可
- 新闻中心

![databricks logo](/images/posts/443a5359ee28.png)

![databricks logo](/images/posts/443a5359ee28.png)

![databricks logo](/images/posts/443a5359ee28.png)

Databricks Inc.160 Spear Street, 15th FloorSan Francisco, CA 941051-866-330-0121


查看 Databricks 的职位


© Databricks2026. 保留所有权利。Apache、Apache Spark、Spark、Spark 徽标、Apache Iceberg、Iceberg 以及 Apache Iceberg 徽标是 Apache Software Foundation 的商标。

- 隐私声明
- |使用条款
- |现代奴隶制声明
- |加州隐私
- |您的隐私选择

---

> 本文由AI自动翻译，原文链接：[High-Availability Feature Flagging at Databricks](https://www.databricks.com/blog/high-availability-feature-flagging-databricks)
> 
> 翻译时间：2026-01-22 04:57
