---
title: LangSmith Fetch：终端调试智能体的CLI工具
title_original: 'Introducing LangSmith Fetch: Debug agents from your terminal'
date: '2025-12-10'
source: LangChain Blog
source_url: https://www.blog.langchain.com/introducing-langsmith-fetch/
author: ''
summary: 本文介绍了LangSmith新推出的CLI工具LangSmith Fetch，它允许开发者直接从终端访问LangSmith的追踪数据，无需切换至Web界面。该工具支持即时获取最新追踪记录和批量导出功能，特别适用于终端优先的开发者、使用编码智能体（如Claude
  Code）进行调试的场景，以及构建评估数据集的需求。通过将追踪数据直接集成到命令行工作流中，LangSmith Fetch提升了智能体调试的效率和编程访问的便捷性。
categories:
- AI产品
tags:
- LangSmith
- 智能体调试
- CLI工具
- 可观测性
- AI开发工具
draft: false
translated_at: '2026-01-15T04:40:17.931595'
---

# 介绍 LangSmith Fetch：从终端调试智能体

今天，我们推出 **LangSmith Fetch**，这是一个 CLI 工具，它将 LangSmith 追踪的全部功能直接带到了您的终端和 IDE 中。

如果您正在使用 Claude Code 或 Cursor 等编码工具构建智能体，或者您只是更喜欢在命令行中工作，您可能遇到过这种摩擦：您的智能体运行了，但出了问题，现在您必须切换到 LangSmith 的 Web 界面才能弄清楚发生了什么。您需要找到正确的追踪记录，点击界面，并设法将这些数据带回您的工作流程中。

LangSmith Fetch 彻底消除了这种摩擦。只需一个命令，您就可以将任何追踪记录或线程直接拉取到您的终端，将其提供给您的编码智能体，或通过管道传输到您的分析脚本中。请在此处查看代码仓库。

## 适应各种工作流程的可观测性

LangSmith 是一个智能体工程平台，可帮助您快速交付可靠的智能体。它能捕获您的智能体所做的一切：每一次 LLM 调用、每一次工具执行、每一个决策点。成千上万的开发者依赖它来调试生产环境中的智能体。

然而，并非每个人都想在 Web 界面中进行调试。如果您是终端优先的开发者，切换到浏览器会打断您的工作流。如果您使用 Claude Code 或其他编码智能体来帮助调试，您需要以您的智能体可以使用的格式获取追踪数据。如果您正在根据生产环境的追踪记录构建评估数据集，您需要批量导出功能。

LangSmith 的 Web 界面功能强大，但对于这些工作流程，您需要一些不同的东西：**从命令行直接以编程方式访问您的追踪数据**。

## LangSmith Fetch 的功能

LangSmith Fetch 围绕两个核心开发者工作流程设计：

### “我刚运行了某个东西”的工作流程

您在本地执行您的智能体。发生了奇怪的事情。您立即运行：

```
langsmith-fetch traces --project-uuid <your-uuid> --format json

```

砰！您项目中最新的追踪记录，就在您的终端里。无需打开浏览器，无需寻找追踪 ID，无需复制粘贴。只需即时访问刚刚发生的事情。

您可以进一步缩小范围：

```
# 获取过去 30 分钟的追踪记录
langsmith-fetch traces --project-uuid <your-uuid> --last-n-minutes 30

# 获取最后 5 条追踪记录
langsmith-fetch traces --project-uuid <your-uuid> --limit 5

```

### 批量导出的工作流程

当您需要用于评估、分析或构建测试套件的数据集时：

```
# 将 50 个线程导出为单独的 JSON 文件
langsmith-fetch threads ./my-data --limit 50

# 使用时间过滤器导出追踪记录
langsmith-fetch traces ./traces --project-uuid <your-uuid> --after 2025-12-01

```

每个线程或追踪记录都会保存为单独的文件，非常适合批处理、提供给 LLM 进行分析或构建回归测试套件。

## 专为编码智能体打造

这才是它真正强大的地方：**LangSmith Fetch 让您的编码智能体成为专家级的智能体调试器**。

当您使用 Claude Code、Cursor 或其他 AI 编码助手时，它们现在可以直接访问您完整的智能体执行数据。只需运行 `langsmith-fetch` 并将其输出通过管道传输给您的编码智能体。突然间，您的编码智能体可以：

*   分析您的智能体为何做出特定决策
*   识别跨多个追踪记录的效率低下模式
*   根据实际执行数据建议提示词改进
*   从生产环境故障中构建测试用例

与 Claude Code 配合的工作流程示例：

```
claude-code "使用 langsmith-fetch 分析 <project-uuid> 中的追踪记录，并告诉我智能体失败的原因"

```

现在，您的编码智能体拥有了关于所发生事情的完整上下文，而无需您手动解释或四处复制数据。

## 与您现有的 LangSmith 设置协同工作

无需新的配置。如果您已经在向 LangSmith 发送追踪记录，LangSmith Fetch 可以立即工作。只需通过 pip 安装：

```
pip install langsmith-fetch

```

设置您的 API 密钥（如果您尚未设置）：

```
export LANGSMITH_API_KEY=your_api_key

```

然后您就可以开始了。LangSmith Fetch 使用与您其他 LangSmith 设置相同的身份验证和项目。

您可能想知道：为什么要构建 CLI 工具而不是 MCP 服务器？MCP 是一个优秀的协议，用于让 LLM 结构化地访问外部数据源，许多开发者直接在他们的调试工作流程中使用它，尤其是在 Cursor 或 Claude Code 等工具内部。

但 MCP 和 CLI 解决的是不同的需求。当您调试智能体时，您需要灵活性：

*   有时您想在终端中快速检查一条追踪记录
*   有时您想将数据通过管道传输给 `jq` 或其他 Unix 工具
*   有时您想将追踪记录保存到文件以供稍后分析
*   有时您想将数据提供给编码智能体
*   有时您想构建处理数百条追踪记录的脚本

CLI 工具为您提供了所有这些功能。您可以独立使用它，将其输出传输到任何地方，将其集成到任何工作流程中，并与您生态系统中的任何工具结合使用。它是一个基础的构建模块。

相比之下，MCP 将您锁定在兼容 MCP 的工具和实时请求/响应模式中。它非常适合其设计目的（让 Claude 或其他 MCP 客户端访问您的数据），但对于开发者所需的各种工作流程来说，它限制性太强。

CLI 更灵活、更具组合性，也更符合 Unix 哲学。**您仍然可以将 LangSmith Fetch 的输出提供给您的编码智能体（无论是否兼容 MCP），但您还可以用它做一百件其他事情。**

我们并不反对 MCP。我们只是认为并非每个开发者工具都需要是 MCP。有时，一个精心设计的 CLI 正是您所需要的。

LangSmith Fetch 现已在 PyPI 上提供。安装它，运行您的第一次获取，体验无需离开终端的智能体调试。

```
# 安装

# 获取您最近的追踪记录
langsmith-fetch threads --project-uuid <your-uuid>

```

有关完整的文档、示例和高级用法，请查看 GitHub 代码仓库。

如需动手教程，请观看我们的视频演练。

无论您是终端优先的开发者、使用编码智能体进行构建，还是只想更快地访问您的追踪数据，LangSmith Fetch 都将 LangSmith 可观测性的强大功能直接带入您的工作流程。

开始使用 LangSmith Fetch。

来自 LangChain 团队和社区的更新

正在处理您的申请...

成功！请检查您的收件箱并点击链接确认订阅。

抱歉，出错了。请重试。

> 本文由AI自动翻译，原文链接：[Introducing LangSmith Fetch: Debug agents from your terminal](https://www.blog.langchain.com/introducing-langsmith-fetch/)
> 
> 翻译时间：2026-01-15 04:40
