---
title: Agent Lightning：无需重写代码，为AI智能体添加强化学习能力
title_original: Agent Lightning adds RL to AI agents without code rewrites
date: '2025-12-11'
source: Microsoft Research
source_url: https://www.microsoft.com/en-us/research/blog/agent-lightning-adding-reinforcement-learning-to-ai-agents-without-code-rewrites/
author: Alyssa Hughes
summary: 微软亚洲研究院-上海团队推出开源框架Agent Lightning，解决了AI智能体难以通过强化学习（RL）进行训练的问题。该框架将智能体执行与模型训练解耦，通过捕捉智能体行为并将其转化为RL可用的标准化格式，允许开发者在几乎不修改现有代码的情况下，为智能体添加强化学习能力。其分层强化学习算法LightningRL能有效分配奖励，并作为中间件协调智能体运行器、训练算法和数据存储，在文本到SQL、检索增强生成等真实场景中均实现了性能提升。
categories:
- AI工程
tags:
- AI智能体
- 强化学习
- 开源框架
- 微软亚洲研究院
- Agent Lightning
draft: false
translated_at: '2026-01-04T23:52:12.611Z'
---

AI Agent（智能体）正在重塑软件开发，从编写代码到执行复杂指令。然而，基于LLM（大语言模型）的智能体容易出错，在处理复杂、多步骤任务时往往表现不佳。强化学习是一种方法，AI系统通过其行为获得奖励或惩罚来学习做出最优决策，通过试错不断改进。强化学习可以帮助智能体提升，但这通常需要开发者大量重写代码。这阻碍了其采用，尽管这些智能体生成的数据通过强化学习训练本可以显著提升性能。

为了解决这个问题，微软亚洲研究院-上海的一个研究团队推出了Agent Lightning。这个开源框架通过将智能体执行任务的方式与模型训练分离，使得AI智能体可以通过强化学习进行训练，允许开发者几乎无需修改代码即可添加强化学习能力。

**为训练捕捉智能体行为**
Agent Lightning将智能体的经验转化为强化学习可用的格式，其方法是将智能体的执行视为一系列状态和动作，其中每个状态捕捉智能体的状态，每次LLM调用都是一个将智能体转移到新状态的动作。

这种方法适用于任何工作流，无论多么复杂。无论是涉及多个协作智能体还是动态工具使用，Agent Lightning都能将其分解为一系列转换。每次转换都捕捉LLM的输入、输出和奖励（图1）。这种标准化格式意味着数据无需任何额外步骤即可用于训练。

**分层强化学习**
对于需要进行多次LLM请求的智能体，传统的强化学习训练涉及将所有内容拼接成一个长序列，然后在训练中识别哪些部分应该学习、哪些部分应该忽略。这种方法难以实现，并且可能产生过长的序列，从而降低模型性能。

相反，Agent Lightning的LightningRL算法采用分层方法。任务完成后，一个信用分配模块会确定每次LLM请求对结果的贡献程度，并为其分配相应的奖励。这些独立的步骤现在与它们自己的奖励分数配对，可以与任何现有的单步强化学习算法一起使用，例如近端策略优化或组相对策略优化（图2）。

这种设计有几个好处。它与广泛使用的单步强化学习算法完全兼容，允许直接应用现有的训练方法而无需修改。将数据组织为一系列独立的转换，使开发者可以根据需要灵活构建LLM输入，支持复杂行为，例如使用多个工具或与其他智能体协作的智能体。此外，通过保持序列简短，该方法可以清晰地扩展并保持训练效率。

**Agent Lightning作为中间件**
Agent Lightning充当强化学习算法和智能体环境之间的中间件，提供模块化组件，通过标准化协议和定义良好的接口实现可扩展的强化学习。

一个智能体运行器在智能体完成任务时管理它们。它分配工作，并收集和存储结果与进度数据。它与LLM分开运行，使得LLM可以在不同的资源上运行，并能扩展以支持多个智能体并发运行。

一个算法负责训练模型，并托管用于推理和训练的LLM。它协调整个强化学习循环，管理分配哪些任务、智能体如何完成它们，以及如何根据智能体学习到的内容更新模型。它通常在GPU资源上运行，并通过共享协议与智能体运行器通信。

LightningStore作为系统内所有数据交换的中心存储库。它提供标准化接口和共享格式，确保不同组件可以协同工作，并使算法和智能体运行器能够有效通信。

所有强化学习循环都遵循两个步骤：（1）Agent Lightning收集智能体执行数据（称为“跨度”）并将其存储在数据存储中；（2）然后检索所需数据并将其发送给算法进行训练。通过这种设计，算法可以异步地将任务委托给智能体运行器，运行器完成任务后将结果报告回来（图4）。

这种方法的一个关键优势是其算法灵活性。该系统使开发者能够轻松定制智能体的学习方式，无论是定义不同的奖励、捕捉中间数据，还是尝试不同的训练方法。

另一个优势是资源效率。智能体强化学习系统很复杂，集成了智能体系统、LLM推理引擎和训练框架。通过分离这些组件，Agent Lightning使这种复杂性变得可管理，并允许每个部分独立优化。

解耦设计允许每个组件使用最适合其的硬件。智能体运行器可以使用CPU，而模型训练可以使用GPU。每个组件也可以独立扩展，从而提高效率并使系统更易于维护。在实践中，开发者可以保留他们现有的智能体框架，并将模型调用切换到Agent Lightning API，而无需更改其智能体代码（图5）。

**在三个真实场景中的评估**
Agent Lightning在三个不同的任务上进行了测试，在所有场景中都取得了一致的性能提升（图6）：

*   **文本到SQL（LangChain）：** 在一个由三个智能体分别处理SQL生成、检查和重写的系统中，Agent Lightning同时优化了其中两个智能体，显著提高了从自然语言查询生成可执行SQL的准确性。
*   **检索增强生成（OpenAI Agents SDK实现）：** 在需要查询大型维基百科数据库的多跳问答数据集MuSiQue上，Agent Lightning帮助智能体生成更有效的搜索查询，并更好地根据检索到的内容进行推理。
*   **数学问答和工具使用（AutoGen实现）：** 对于复杂的数学问题，Agent Lightning训练LLM更准确地确定何时以及如何调用工具，并将结果整合到其推理中，从而提高了准确性。

**实现智能体的持续改进**
通过简化强化学习集成，Agent Lightning可以使开发者更容易地构建、迭代和部署高性能智能体。我们计划扩展Agent Lightning的能力，包括自动提示词优化和额外的强化学习算法。

该框架旨在作为一个开放平台，任何AI智能体都可以通过真实世界的实践得到改进。通过桥接现有的智能体系统与强化学习，Agent Lightning旨在帮助创建能够从经验中学习并随时间不断改进的AI系统。

---

> 本文由AI自动翻译，原文链接：[Agent Lightning adds RL to AI agents without code rewrites](https://www.microsoft.com/en-us/research/blog/agent-lightning-adding-reinforcement-learning-to-ai-agents-without-code-rewrites/)
> 
> 翻译时间：2026-01-04 23:52
