---
title: 领域智能制胜：生产环境中AI“高质量”的真正含义
title_original: 'Domain Intelligence Wins: What “High-Quality” Actually Means in Production
  AI'
date: '2026-02-12'
source: Databricks Blog
source_url: https://www.databricks.com/blog/domain-intelligence-wins-what-high-quality-actually-means-production-ai
author: ''
summary: 本文通过对话Databricks首席AI官Maria Zervou，探讨了企业将生成式AI从实验转向生产部署时的关键转变。核心观点指出，AI Agent的成功不在于模型本身的“聪明”，而在于围绕其构建的可靠系统——包括数据质量、工程规范、可追溯性和问责制。文章强调，特定领域Agent通过限定范围、利用专有数据和业务知识，能比通用模型更可靠地创造价值，而构建有效的评估系统和对齐不同利益相关者的质量定义，是项目成功投入生产的关键。
categories:
- AI产品
tags:
- AI Agent
- 生产部署
- AI治理
- 领域智能
- AI评估
draft: false
translated_at: '2026-02-12T04:24:13.623496'
---

随着企业从生成式AI的实验阶段转向在生产环境中部署Agent（智能体）系统，讨论的重点正在发生变化。高管们提出的问题不再是“这个模型能推理吗？”，而是“这个系统值得信赖吗？”

为了探究这一转变的真正含义，我与Databricks EMEA地区首席人工智能官Maria Zervou进行了对话。Maria与受监管行业和快速变化行业的客户密切合作，她的工作聚焦于AI架构、治理和实际执行的交叉领域。

在整个对话中，Maria反复强调同一点：Agent AI的成功不在于模型本身，而在于围绕它的系统——数据、工程规范和清晰的问责制。

**Catherine Brown:** 与我交谈过的许多高管仍然将AI质量等同于模型看起来有多出色。您认为这是错误的观点。为什么？

**Maria Zervou:** 我遇到的最大误解是，人们将模型的聪明程度或感知到的推理能力与质量混为一谈。这两者不是一回事。

质量，尤其是在Agent系统中，关乎的是可靠性的复合效应。你不再评估单个响应，而是在评估一个可能包含数百个步骤的系统——检索数据、调用工具、做出决策、上报问题。即使是微小的错误也可能以不可预测的方式被放大。

因此，问题也随之改变。Agent使用了正确的数据吗？它找到了正确的资源吗？它知道何时停止或上报吗？这才是质量真正所在之处。

重要的是，质量对不同利益相关者意味着不同的事情。技术团队通常关注成本、延迟或吞吐量等KPI。最终用户关心的是品牌合规性、语气和法律约束。因此，如果这些视角没有对齐，你最终优化的可能就是错误的东西。

**Catherine:** 这很有趣，尤其是因为许多领导者认为AI系统必须是“完美的”才能使用，特别是在受监管的环境中。高度监管行业的公司应如何开展AI计划？

**Maria:** 在高度监管的行业，你确实需要非常高的准确度，但第一个基准应该是**人类的表现**。人类今天也一直在犯错。如果你不将期望锚定在现实中，就永远无法前进。

更重要的是可追溯性和问责制。当出现问题时，你能追溯决策是如何做出的吗？谁对结果负责？使用了什么数据？如果你无法回答这些问题，那么无论输出看起来多么出色，这个系统都还没有为生产环境做好准备。

**Catherine:** 您经常谈到特定领域Agent与通用模型的区别。高管们应该如何思考这种区别？

**Maria:** 通用模型本质上是一个能力非常强的推理引擎，在庞大而多样的数据集上进行训练。但它不理解你的业务。特定领域Agent使用相同的基础模型，但通过上下文变得更强大。你将其限定在预定义的用例中，限制其可搜索的空间，并教会它你的KPI意味着什么、你的术语意味着什么，以及允许它采取哪些行动。

这种约束实际上使其变得更好。通过缩小领域范围，你可以减少幻觉并提高输出的可靠性。大部分价值并非来自模型本身，而是来自其能够安全访问的专有数据、定义含义的语义层以及允许它使用的工具。本质上，它可以在你的数据上进行推理。这就是竞争优势所在。

**Catherine:** 当组织试图从原型转向生产时，您通常在AI Agent工作流的哪个环节看到问题？

**Maria:** 主要有三个故障点。第一是**节奏不匹配**。技术的发展速度比大多数组织快。团队在完成数据访问、安全和结构的基础工作之前，就急于构建Agent。

第二是**隐性知识**。员工高效工作的很多知识存在于人们的头脑中或分散的文档里。如果这些知识没有以Agent可以使用的形式进行编码，系统就永远不会按照业务预期的方式运行。

第三是**基础设施**。许多团队没有为规模或实际使用情况做规划。他们构建的东西在演示中能运行一次，但在生产负载下就会崩溃。

这三个问题往往同时出现。

**Catherine:** 您之前说过，捕获业务知识与选择正确的模型同样重要。您如何看待组织在这方面做得好的？

**Maria:** 首先要认识到AI系统不是一次性项目，它们是活的系统。一个实用的方法是记录和转录会议，并将其视为原材料。然后，你对这些信息进行结构化、总结和标记，以便系统日后检索。随着时间的推移，你就在建立一个反映业务实际思维方式的知识库。

同样重要的是你如何设计评估。Agent的早期版本应该由业务利益相关者使用，而不仅仅是工程师。他们的反馈——什么感觉对，什么感觉不对，为什么错了——会成为训练数据。

构建一个**有效的评估系统**，专门针对该Agent的具体目的，对于确保高质量输出至关重要，而这最终对任何生产环境中的AI项目都至关重要。**我们自己的使用数据**显示，使用AI评估工具的客户投入生产的AI项目数量是未使用者的近6倍。

实际上，你正在将业务思维编码到评估标准中。

**Catherine:** 这听起来既昂贵又耗时。您如何平衡严谨性与速度？

**Maria:** 这就是我谈论**最低可行治理**的地方。你不会在第一天就解决整个企业的治理问题。你为你正在处理的特定领域和用例解决它。你要确保数据对该Agent是受控、可追溯和可审计的。然后，随着系统被证明有价值，你再进行扩展。

有帮助的是拥有可重复的构建模块——那些已经编码了良好工程和治理实践的模式。这就是像Agent Bricks这类方法背后的思路，团队可以从精炼的基础开始，而不是每次都从头开始重新设计工作流、评估和控制。

高管们在一开始仍应坚持一些不容妥协的原则：清晰的业务KPI、指定的高管负责人、与业务用户共同构建的评估，以及扎实的软件工程基础。第一个项目会很痛苦——但它为后续一切设定了模式，并使后续Agent的部署速度大大加快。

如果你跳过这一步，最终就会得到我所说的“演示疲劳”：令人印象深刻但从未真正成为现实的原型。

**Catherine:** 您能分享一些Agent实质性改变了工作方式的例子吗？

**Maria:** 在Databricks内部，我们在几个地方看到了这种情况。在专业服务部门，Agent被用于在迁移期间扫描客户环境。Agent根据最佳实践生成推荐的工作流，而不是由工程师手动审查每个模式和系统。这极大地减少了花在重复性分析上的时间。

在现场工程部门，Agent能自动生成根据客户行业和用例定制的演示环境。过去需要数小时手动准备的工作，现在完成得更快，且一致性更高。

在这两种情况下，Agent并没有取代专业知识——而是增强了它。

**Catherine:** 如果您必须为刚刚踏上这条路的CIO或CDO提炼一下，他们首先应该关注什么？

Maria：从数据开始。可信的Agent（智能体）需要一个统一、可控且可审计的数据基础。如果您的数据是碎片化的或无法访问，那么无论模型多么优秀，Agent（智能体）都将失败。其次，要明确所有权。谁对质量负责？谁对结果负责？谁来决定Agent（智能体）何时“足够好”？最后，请记住，Agentic AI（智能体人工智能）的目的不在于展示系统有多聪明，而在于系统是否能可靠地帮助企业更快地做出更好的决策，同时不引入新的风险。

**结语**

Agentic AI（智能体人工智能）代表了一个真正的转变——从辅助人类的工具转变为代表人类行事的系统。但正如Maria所明确指出的，成功与否远非取决于模型的复杂程度，而更取决于纪律：数据管理、治理和工程实践方面的纪律。

对于高管而言，挑战不在于Agent（智能体）是否会到来，而在于他们的组织是否准备好构建出在Agent（智能体）到来时能够被信赖的系统。

要了解更多关于构建有效运营模式的信息，请下载Databricks AI成熟度模型。

## 下一步是什么？

---

> 本文由AI自动翻译，原文链接：[Domain Intelligence Wins: What “High-Quality” Actually Means in Production AI](https://www.databricks.com/blog/domain-intelligence-wins-what-high-quality-actually-means-production-ai)
> 
> 翻译时间：2026-02-12 04:24
