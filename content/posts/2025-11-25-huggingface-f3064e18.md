---
title: Diffusers å–œè¿Žå…¨æ–°å¼€æºå›¾åƒç”Ÿæˆæ¨¡åž‹ FLUX-2
title_original: Diffusers welcomes FLUX-2
date: '2025-11-25'
source: Hugging Face Blog
source_url: https://huggingface.co/blog/flux-2
author: null
summary: æœ¬æ–‡ä»‹ç»äº† Black Forest Labs å‘å¸ƒçš„å…¨æ–°å¼€æºå›¾åƒç”Ÿæˆæ¨¡åž‹ FLUX-2ã€‚æ–‡ç« é‡ç‚¹é˜è¿°äº† FLUX-2 ç›¸è¾ƒäºŽå‰ä»£ FLUX.1
  çš„å…³é”®æž¶æž„å˜åŒ–ï¼ŒåŒ…æ‹¬æ”¹ç”¨å•ä¸ª Mistral Small 3.1 æ–‡æœ¬ç¼–ç å™¨ã€å¯¹ DiT æž¶æž„çš„ä¼˜åŒ–ï¼ˆå¦‚å…±äº«è°ƒåˆ¶å‚æ•°ã€ç§»é™¤åç½®ã€èžåˆæ›´å¤šæŠ•å½±å±‚ï¼‰ä»¥åŠé‡‡ç”¨æ–°çš„è‡ªåŠ¨ç¼–ç å™¨ã€‚æ­¤å¤–ï¼Œæ–‡ç« è¿˜æä¾›äº†å¦‚ä½•åœ¨
  Diffusers åº“ä¸­ä½¿ç”¨è¯¥æ¨¡åž‹è¿›è¡ŒæŽ¨ç†çš„åˆæ­¥ä»£ç ç¤ºä¾‹ï¼Œå¹¶æŒ‡å‡ºäº†å…¶è¾ƒé«˜çš„æ˜¾å­˜éœ€æ±‚ã€‚
categories:
- AIç ”ç©¶
tags:
- å›¾åƒç”Ÿæˆ
- æ‰©æ•£æ¨¡åž‹
- FLUX-2
- Diffusers
- å¼€æºæ¨¡åž‹
draft: false
translated_at: '2026-01-06T01:04:04.973Z'
---

æ¬¢è¿Ž FLUX.2 - BFL çš„å…¨æ–°å¼€æºå›¾åƒç”Ÿæˆæ¨¡åž‹ ðŸ¤—
FLUX.2 æ˜¯ Black Forest Labs è¿‘æœŸæŽ¨å‡ºçš„å›¾åƒç”Ÿæˆæ¨¡åž‹ç³»åˆ—ï¼Œå…¶å‰èº«ä¸º Flux.1 ç³»åˆ—ã€‚è¿™æ˜¯ä¸€ä¸ªæ‹¥æœ‰å…¨æ–°æž¶æž„ã€å®Œå…¨ä»Žå¤´å¼€å§‹é¢„è®­ç»ƒçš„å…¨æ–°æ¨¡åž‹ï¼åœ¨æœ¬æ–‡ä¸­ï¼Œæˆ‘ä»¬å°†è®¨è®º FLUX.2 å¼•å…¥çš„å…³é”®å˜åŒ–ï¼Œåœ¨ä¸åŒè®¾ç½®ä¸‹ç”¨å®ƒè¿›è¡ŒæŽ¨ç†ï¼Œä»¥åŠè¿›è¡Œ LoRA å¾®è°ƒã€‚
ðŸš¨ FLUX.2 å¹¶éžæ—¨åœ¨ç›´æŽ¥æ›¿ä»£ FLUX.1ï¼Œè€Œæ˜¯ä¸€ä¸ªå…¨æ–°çš„å›¾åƒç”Ÿæˆä¸Žç¼–è¾‘æ¨¡åž‹ã€‚
FLUX.2ï¼šç®€ä»‹
FLUX.2 å¯ç”¨äºŽå›¾åƒå¼•å¯¼å’Œæ–‡æœ¬å¼•å¯¼çš„å›¾åƒç”Ÿæˆã€‚æ­¤å¤–ï¼Œå®ƒèƒ½å¤ŸæŽ¥æ”¶å¤šå¼ å›¾åƒä½œä¸ºå‚è€ƒè¾“å…¥ï¼ŒåŒæ—¶ç”Ÿæˆæœ€ç»ˆçš„è¾“å‡ºå›¾åƒã€‚ä¸‹é¢ï¼Œæˆ‘ä»¬ç®€è¦è®¨è®º FLUX.2 å¼•å…¥çš„å…³é”®å˜åŒ–ã€‚
æ–‡æœ¬ç¼–ç å™¨
é¦–å…ˆï¼Œå®ƒä¸å†åƒ Flux.1 é‚£æ ·ä½¿ç”¨ä¸¤ä¸ªæ–‡æœ¬ç¼–ç å™¨ï¼Œè€Œæ˜¯ä½¿ç”¨å•ä¸ªæ–‡æœ¬ç¼–ç å™¨â€”â€”Mistral Small 3.1ã€‚ä½¿ç”¨å•ä¸ªæ–‡æœ¬ç¼–ç å™¨æžå¤§åœ°ç®€åŒ–äº†è®¡ç®—æç¤ºè¯åµŒå…¥çš„è¿‡ç¨‹ã€‚è¯¥æµç¨‹å…è®¸çš„æœ€å¤§åºåˆ—é•¿åº¦ä¸º 512ã€‚FLUX.2 ä¸å†ä½¿ç”¨å•å±‚è¾“å‡ºæ¥ç”Ÿæˆæç¤ºè¯åµŒå…¥ï¼Œè€Œæ˜¯å †å ä¸­é—´å±‚çš„è¾“å‡ºï¼Œå·²çŸ¥è¿™ç§æ–¹å¼æ›´ä¸ºæœ‰ç›Šã€‚
DiT
FLUX.2 éµå¾ªä¸Ž Flux.1 ç›¸åŒçš„é€šç”¨å¤šæ¨¡æ€æ‰©æ•£ Transformer æž¶æž„å’Œå¹¶è¡Œ DiT æž¶æž„ã€‚ç®€å•å›žé¡¾ä¸€ä¸‹ï¼ŒMM-DiT æ¨¡å—é¦–å…ˆåœ¨ç‹¬ç«‹çš„æµä¸­å¤„ç†å›¾åƒæ½œåœ¨è¡¨ç¤ºå’Œæ¡ä»¶æ–‡æœ¬ï¼Œä»…åœ¨æ³¨æ„åŠ›æ“ä½œæ—¶æ‰å°†ä¸¤è€…ç»“åˆï¼Œå› æ­¤è¢«ç§°ä¸ºâ€œåŒæµâ€æ¨¡å—ã€‚éšåŽçš„å¹¶è¡Œæ¨¡å—åˆ™å¯¹æ‹¼æŽ¥åŽçš„å›¾åƒå’Œæ–‡æœ¬æµè¿›è¡Œæ“ä½œï¼Œå¯è¢«è§†ä¸ºâ€œå•æµâ€æ¨¡å—ã€‚
ä»Ž Flux.1 åˆ° FLUX.2ï¼ŒDiT çš„å…³é”®å˜åŒ–å¦‚ä¸‹ï¼š
æ—¶é—´å’Œå¼•å¯¼ä¿¡æ¯ä»¥ AdaLayerNorm-Zero è°ƒåˆ¶å‚æ•°çš„å½¢å¼ï¼Œåˆ†åˆ«åœ¨æ‰€æœ‰åŒæµå’Œå•æµ Transformer æ¨¡å—ä¹‹é—´å…±äº«ï¼Œè€Œä¸æ˜¯åƒ Flux.1 é‚£æ ·æ¯ä¸ªæ¨¡å—æ‹¥æœ‰ç‹¬ç«‹çš„è°ƒåˆ¶å‚æ•°ã€‚
æ¨¡åž‹ä¸­æ²¡æœ‰ä»»ä½•å±‚ä½¿ç”¨åç½®å‚æ•°ã€‚å…·ä½“æ¥è¯´ï¼Œæ— è®ºæ˜¯å“ªç§ Transformer æ¨¡å—ï¼Œå…¶æ³¨æ„åŠ›å­æ¨¡å—æˆ–å‰é¦ˆç½‘ç»œå­æ¨¡å—çš„ä»»ä½•å±‚ä¸­éƒ½ä¸ä½¿ç”¨åç½®å‚æ•°ã€‚
åœ¨ Flux.1 ä¸­ï¼Œå•æµ Transformer æ¨¡å—èžåˆäº†æ³¨æ„åŠ›è¾“å‡ºæŠ•å½±å’Œå‰é¦ˆç½‘ç»œè¾“å‡ºæŠ•å½±ã€‚FLUX.2 çš„å•æµæ¨¡å—è¿˜å°†æ³¨æ„åŠ› QKV æŠ•å½±ä¸Žå‰é¦ˆç½‘ç»œè¾“å…¥æŠ•å½±èžåˆï¼Œåˆ›å»ºäº†ä¸€ä¸ªå®Œå…¨å¹¶è¡Œçš„ Transformer æ¨¡å—ï¼š
è¯·æ³¨æ„ï¼Œä¸Žä¸Šå›¾æ‰€ç¤ºçš„ ViT-22B æ¨¡å—ç›¸æ¯”ï¼ŒFLUX.2 ä½¿ç”¨ SwiGLU é£Žæ ¼çš„ MLP æ¿€æ´»å‡½æ•°ï¼Œè€Œéž GELU æ¿€æ´»å‡½æ•°ï¼ˆå¹¶ä¸”ä¹Ÿä¸ä½¿ç”¨åç½®å‚æ•°ï¼‰ã€‚
FLUX.2 ä¸­æ›´å¤§æ¯”ä¾‹çš„ Transformer æ¨¡å—æ˜¯å•æµæ¨¡å—ï¼ˆ8 ä¸ªåŒæµæ¨¡å—å¯¹åº” 48 ä¸ªå•æµæ¨¡å—ï¼Œè€Œ Flux.1 æ˜¯ 19 ä¸ªåŒæµæ¨¡å—å¯¹åº” 38 ä¸ªå•æµæ¨¡å—ï¼‰ã€‚è¿™ä¹Ÿæ„å‘³ç€å•æµæ¨¡å—åœ¨ DiT å‚æ•°ä¸­å æ®äº†æ›´å¤§æ¯”ä¾‹ï¼šFlux.1[dev]-12B çš„æ€»å‚æ•°ä¸­çº¦æœ‰ 54% ä½äºŽåŒæµæ¨¡å—ï¼Œè€Œ FLUX.2[dev]-32B çš„æ€»å‚æ•°ä¸­çº¦æœ‰ 24% ä½äºŽåŒæµæ¨¡å—ï¼ˆçº¦ 73% ä½äºŽå•æµæ¨¡å—ï¼‰ã€‚
å…¶ä»–
- æ–°çš„è‡ªåŠ¨ç¼–ç å™¨ï¼Œå³ AutoencoderKLFlux2
ä½¿ç”¨ Diffusers è¿›è¡ŒæŽ¨ç†
FLUX.2 ä½¿ç”¨äº†æ›´å¤§çš„ DiT å’Œ Mistral3 Small ä½œä¸ºå…¶æ–‡æœ¬ç¼–ç å™¨ã€‚åœ¨ä¸è¿›è¡Œä»»ä½•å¸è½½çš„æƒ…å†µä¸‹ä¸€èµ·ä½¿ç”¨ï¼ŒæŽ¨ç†éœ€è¦è¶…è¿‡ 80GB çš„æ˜¾å­˜ã€‚åœ¨ä»¥ä¸‹éƒ¨åˆ†ï¼Œæˆ‘ä»¬å°†å±•ç¤ºå¦‚ä½•åœ¨å„ç§ç³»ç»Ÿçº§é™åˆ¶ä¸‹ï¼Œä»¥æ›´æ˜“å®žçŽ°çš„æ–¹å¼ä½¿ç”¨ FLUX.2 è¿›è¡ŒæŽ¨ç†ã€‚
å®‰è£…ä¸Žè®¤è¯
åœ¨å°è¯•ä»¥ä¸‹ä»£ç ç‰‡æ®µä¹‹å‰ï¼Œè¯·ç¡®ä¿æ‚¨å·²ä»Žä¸»åˆ†æ”¯å®‰è£… diffusers å¹¶å·²è¿è¡Œ hf auth loginã€‚
```
pip uninstall diffusers -y && pip install git+https://github.com/huggingface/diffusers -U
```
å¸¸è§„æŽ¨ç†
```
from diffusers import Flux2Pipeline
import torch
repo_id = "black-forest-labs/FLUX.2-dev"
pipe = Flux2Pipeline.from_pretrained(repo_id, torch_dtype=torch.bfloat16)
pipe.enable_model_cpu_offload()
image = pipe(
prompt="dog dancing near the sun",
num_inference_steps=50, # 28 is a good trade-off
guidance_scale=4,
height=1024,
width=1024
).images[0]
```
ä¸Šè¿°ä»£ç ç‰‡æ®µåœ¨ H100 ä¸Šè¿›è¡Œäº†æµ‹è¯•ï¼Œè‹¥ä¸å¯ç”¨ CPU å¸è½½ï¼Œåˆ™ä¸è¶³ä»¥åœ¨å…¶ä¸Šè¿è¡ŒæŽ¨ç†ã€‚å¯ç”¨ CPU å¸è½½åŽï¼Œæ­¤è®¾ç½®è¿è¡Œéœ€è¦çº¦ 62GB æ˜¾å­˜ã€‚
èƒ½å¤Ÿä½¿ç”¨ Hopper ç³»åˆ— GPU çš„ç”¨æˆ·å¯ä»¥åˆ©ç”¨ Flash Attention 3 æ¥åŠ é€ŸæŽ¨ç†ï¼š
```
import torch
pipe = Flux2Pipeline.from_pretrained(path, torch_dtype=torch.bfloat16)
+ pipe.transformer.set_attention_backend("_flash_3_hub")
image = pipe(
num_inference_steps=50,
guidance_scale=2.5,
height=1024,
width=1024
).images[0]
```
æ‚¨å¯ä»¥åœ¨æ­¤å¤„æŸ¥çœ‹æ”¯æŒçš„æ³¨æ„åŠ›åŽç«¯ï¼ˆæˆ‘ä»¬æœ‰å¾ˆå¤šï¼ï¼‰ã€‚
èµ„æºå—é™æƒ…å†µ
ä½¿ç”¨ 4 ä½é‡åŒ–
ä½¿ç”¨ bitsandbytesï¼Œæˆ‘ä»¬å¯ä»¥å°† Transformer å’Œæ–‡æœ¬ç¼–ç å™¨æ¨¡åž‹ä»¥ 4 ä½ç²¾åº¦åŠ è½½ï¼Œä½¿å¾—æ‹¥æœ‰ 24GB GPU çš„ç”¨æˆ·èƒ½å¤Ÿåœ¨æœ¬åœ°ä½¿ç”¨è¯¥æ¨¡åž‹ã€‚æ‚¨å¯ä»¥åœ¨æ‹¥æœ‰çº¦ 20 GB ç©ºé—²æ˜¾å­˜çš„ GPU ä¸Šè¿è¡Œæ­¤ä»£ç ç‰‡æ®µã€‚
```
import torch
from transformers import Mistral3ForConditionalGeneration
from diffusers import Flux2Pipeline, Flux2Transformer2DModel
repo_id = "diffusers/FLUX.2-dev-bnb-4bit"
device = "cuda:0"
torch_dtype = torch.bfloat16
transformer = Flux2Transformer2DModel.from_pretrained(
repo_id, subfolder="transformer", torch_dtype=torch_dtype, device_map="cpu"
)
text_encoder = Mistral3ForConditionalGeneration.from_pretrained(
repo_id, subfolder="text_encoder", dtype=torch_dtype, device_map="cpu"
)
pipe = Flux2Pipeline.from_pretrained(
repo_id, transformer=transformer, text_encoder=text_encoder, torch_dtype=torch_dtype
)
prompt = "Realistic macro photograph of a hermit crab using a soda can as its shell, partially emerging from the can, captured with sharp detail and natural colors, on a sunlit beach with soft shadows and a shallow depth of field, with blurred ocean waves in the background. The can has the text `BFL Diffusers` on it and it has a color gradient that start with #FF5733 at the top and transitions to #33FF57 at the bottom."
image = pipe(
prompt=prompt,
generator=torch.Generator(device=device).manual_seed(42),
guidance_scale=4,
).images[0]
image.save("flux2_t2i_nf4.png")
```
è¯·æ³¨æ„ï¼Œæˆ‘ä»¬ä½¿ç”¨çš„ä»“åº“åŒ…å«äº† FLUX.2 DiT å’Œ Mistral æ–‡æœ¬ç¼–ç å™¨çš„ NF4 é‡åŒ–ç‰ˆæœ¬ã€‚
æœ¬åœ° + è¿œç¨‹
ç”±äºŽ Diffusers æµç¨‹çš„æ¨¡å—åŒ–è®¾è®¡ï¼Œæˆ‘ä»¬å¯ä»¥éš”ç¦»å„ä¸ªæ¨¡å—å¹¶æŒ‰é¡ºåºå¤„ç†å®ƒä»¬ã€‚æˆ‘ä»¬å°†æ–‡æœ¬ç¼–ç å™¨è§£è€¦å¹¶éƒ¨ç½²åˆ°æŽ¨ç†ç«¯ç‚¹ã€‚è¿™æœ‰åŠ©äºŽæˆ‘ä»¬ä»…ä¸º DiT å’Œ VAE é‡Šæ”¾æ˜¾å­˜ä½¿ç”¨ã€‚
âš ï¸ è¦ä½¿ç”¨è¿œç¨‹æ–‡æœ¬ç¼–ç å™¨ï¼Œæ‚¨éœ€è¦æ‹¥æœ‰æœ‰æ•ˆçš„ä»¤ç‰Œã€‚å¦‚æžœæ‚¨å·²ç»é€šè¿‡è®¤è¯ï¼Œåˆ™æ— éœ€è¿›ä¸€æ­¥æ“ä½œã€‚
ä¸‹é¢çš„ç¤ºä¾‹ç»“åˆä½¿ç”¨äº†æœ¬åœ°å’Œè¿œç¨‹æŽ¨ç†ã€‚

æ­¤å¤–ï¼Œæˆ‘ä»¬é€šè¿‡ bitsandbytes ä½¿ç”¨ NF4 é‡åŒ–æ–¹æ³•å¯¹ DiT è¿›è¡Œäº†é‡åŒ–ã€‚

æ‚¨å¯ä»¥åœ¨æ‹¥æœ‰ 18 GB æ˜¾å­˜çš„ GPU ä¸Šè¿è¡Œä»¥ä¸‹ä»£ç ç‰‡æ®µï¼š

å±•å¼€
from diffusers import BitsAndBytesConfig as DiffBitsAndBytesConfig
from huggingface_hub import get_token
import requests
import torch
import io
def remote_text_encoder(prompts: str | list[str]):
    def _encode_single(prompt: str):
        response = requests.post(
            "https://remote-text-encoder-flux-2.huggingface.co/predict",
            json={"prompt": prompt},
            headers={
                "Authorization": f"Bearer {get_token()}",
                "Content-Type": "application/json"
            }
        )
        assert response.status_code == 200, f"{response.status_code=}"
        return torch.load(io.BytesIO(response.content))
    if isinstance(prompts, (list, tuple)):
        embeds = [_encode_single(p) for p in prompts]
        return torch.cat(embeds, dim=0)
    return _encode_single(prompts).to("cuda")

quantized_dit_id = "diffusers/FLUX.2-dev-bnb-4bit"
dit = Flux2Transformer2DModel.from_pretrained(
    quantized_dit_id, subfolder="transformer", torch_dtype=torch_dtype, device_map="cpu"
)
    repo_id,
    text_encoder=None,
    transformer=dit,
    torch_dtype=torch.bfloat16,
)
print("Running remote text encoder â˜ï¸")
prompt1 = "a photo of a forest with mist swirling around the tree trunks. The word 'FLUX.2' is painted over it in big, red brush strokes with visible texture"
prompt2 = "a photo of a dense forest with rain. The word 'FLUX.2' is painted over it in big, red brush strokes with visible texture"
prompt_embeds = remote_text_encoder([prompt1, prompt2])
print("Done âœ…")
out = pipe(
    prompt_embeds=prompt_embeds,
    generator=torch.Generator(device="cuda").manual_seed(42),
    guidance_scale=4,
    height=1024,
    width=1024,
)
for idx, image in enumerate(out.images):
    image.save(f"flux_out_{idx}.png")

å¯¹äºŽæ˜¾å­˜æ›´ä½Žçš„ GPUï¼Œæˆ‘ä»¬æä¾›äº†ç»„å¸è½½åŠŸèƒ½ï¼Œå®ƒå…è®¸ä»…éœ€ 8GB ç©ºé—²æ˜¾å­˜çš„ GPU ä¹Ÿèƒ½ä½¿ç”¨æ­¤æ¨¡åž‹ã€‚ä½†æ˜¯ï¼Œæ‚¨å°†éœ€è¦ 32GB çš„ç©ºé—²å†…å­˜ã€‚æˆ–è€…ï¼Œå¦‚æžœæ‚¨æ„¿æ„ç‰ºç‰²ä¸€äº›é€Ÿåº¦ï¼Œå¯ä»¥è®¾ç½® `low_cpu_mem_usage=True` æ¥å°†å†…å­˜éœ€æ±‚é™ä½Žåˆ°ä»… 10GBã€‚

å±•å¼€
import io
import os
import requests
import torch

device = "cuda"

            headers={"Authorization": f"Bearer {os.environ['HF_TOKEN']}", "Content-Type": "application/json"},
        )

)
    repo_id,
    text_encoder=None,
    transformer=transformer,
    torch_dtype=torch_dtype,
)
pipe.transformer.enable_group_offload(
    onload_device=device,
    offload_device="cpu",
    offload_type="leaf_level",
    use_stream=True,
    # low_cpu_mem_usage=True # å–æ¶ˆæ³¨é‡Šä»¥é™ä½Žå†…å­˜ä½¿ç”¨
)
pipe.to(device)

prompt = "a photo of a forest with mist swirling around the tree trunks. The word 'FLUX.2' is painted over it in big, red brush strokes with visible texture"
prompt_embeds = remote_text_encoder(prompt)
image = pipe(
    guidance_scale=4,
    height=1024,
    width=1024,
).images[0]

æ‚¨å¯ä»¥åœ¨æ­¤å¤„æŸ¥çœ‹å…¶ä»–æ”¯æŒçš„é‡åŒ–åŽç«¯ï¼Œä»¥åŠåœ¨æ­¤å¤„æŸ¥çœ‹å…¶ä»–èŠ‚çœå†…å­˜çš„æŠ€æœ¯ã€‚

è¦æ£€æŸ¥ä¸åŒé‡åŒ–æ–¹æ³•å¦‚ä½•å½±å“å›¾åƒï¼Œæ‚¨å¯ä»¥åœ¨ä¸‹é¢çš„ playground ä¸­è¿›è¡Œå°è¯•ï¼Œæˆ–é€šè¿‡ FLUX.2 é‡åŒ–å®žéªŒ Space ä½œä¸ºç‹¬ç«‹åº”ç”¨è®¿é—®ã€‚

**å¤šå¼ å›¾åƒä½œä¸ºå‚è€ƒ**
FLUX.2 æ”¯æŒä½¿ç”¨å¤šå¼ å›¾åƒä½œä¸ºè¾“å…¥ï¼Œæœ€å¤šå…è®¸ä½¿ç”¨ 10 å¼ å›¾åƒã€‚ä½†æ˜¯ï¼Œè¯·æ³¨æ„æ¯å¢žåŠ ä¸€å¼ å›¾åƒéƒ½éœ€è¦æ›´å¤šçš„æ˜¾å­˜ã€‚æ‚¨å¯ä»¥é€šè¿‡ç´¢å¼•ï¼ˆä¾‹å¦‚ï¼Œå›¾åƒ 1ï¼Œå›¾åƒ 2ï¼‰æˆ–è‡ªç„¶è¯­è¨€ï¼ˆä¾‹å¦‚ï¼Œè¢‹é¼ ï¼Œä¹Œé¾Ÿï¼‰æ¥å¼•ç”¨è¿™äº›å›¾åƒã€‚

ä¸ºèŽ·å¾—æœ€ä½³æ•ˆæžœï¼Œæœ€ä½³æ–¹æ³•æ˜¯ç»“åˆä½¿ç”¨ä¸¤ç§æ–¹æ³•ã€‚
å±•å¼€
import torch
from diffusers.utils import load_image
repo_id = "diffusers-internal-dev/new-model-image-final-weights"
device = "cuda:0"
repo_id, torch_dtype=torch_dtype
)
image_one = load_image("https://huggingface.co/datasets/huggingface/documentation-images/resolve/main/flux2_blog/kangaroo.png")
image_two = load_image("https://huggingface.co/datasets/huggingface/documentation-images/resolve/main/flux2_blog/turtle.png")
prompt = "the boxer kangaroo from image 1 and the martial artist turtle from image 2 are fighting in an epic battle scene at a beach of a tropical island, 35mm, depth of field, 50mm lens, f/3.5, cinematic lighting"
image = pipe(
prompt=prompt,
image=[image_one, image_two],
guidance_scale=2.5,
width=1024,
height=768,
).images[0]
image.save(f"./flux2_t2i.png")
é«˜çº§æç¤ºè¯
FLUX.2 æ”¯æŒé«˜çº§æç¤ºè¯æŠ€æœ¯ï¼Œå¦‚ç»“æž„åŒ– JSON æç¤ºè¯ã€ç²¾ç¡®çš„åå…­è¿›åˆ¶é¢œè‰²æŽ§åˆ¶ä»¥åŠå¤šå‚è€ƒå›¾åƒç¼–è¾‘ã€‚
é™¤äº†å¢žå¼ºæŽ§åˆ¶åŠ›ä¹‹å¤–ï¼Œè¿™è¿˜å…è®¸åœ¨ä¿æŒå…¶ä»–å±žæ€§æ€»ä½“ä¸å˜çš„æƒ…å†µä¸‹çµæ´»æ›´æ”¹ç‰¹å®šå±žæ€§ã€‚
ä¾‹å¦‚ï¼Œè®©æˆ‘ä»¬ä»¥è¿™ä¸ª json ä½œä¸ºåŸºç¡€æ¨¡å¼ï¼ˆå–è‡ªå®˜æ–¹ FLUX.2 æç¤ºè¯æŒ‡å—ï¼‰ï¼š
{
"scene": "overall scene description",
"subjects": [
{
"description": "detailed subject description",
"position": "where in frame",
"action": "what they're doing"
}
],
"style": "artistic style",
"color_palette": ["#hex1", "#hex2", "#hex3"],
"lighting": "lighting description",
"mood": "emotional tone",
"background": "background details",
"composition": "framing and layout",
"camera": {
"angle": "camera angle",
"lens": "lens type",
"depth_of_field": "focus behavior"
}
}
åœ¨æ­¤åŸºç¡€ä¸Šï¼Œè®©æˆ‘ä»¬å°†å…¶è½¬åŒ–ä¸ºä¸€ä¸ªå…³äºŽåœ°æ¯¯ä¸Šç»å…¸éšèº«å¬ï¼ˆWalkmanï¼‰é•œå¤´çš„æç¤ºè¯ï¼ˆåªéœ€å°†æ­¤æç¤ºè¯ä¼ é€’ç»™æ‚¨ä»Žä¸Šé¢é€‰æ‹©çš„ diffusers æŽ¨ç†ç¤ºä¾‹ï¼‰ï¼š
prompt = """
{
"scene": "Professional studio product photography setup with soft-textured carpet surface",
"subjects": [
{
"description": "Old silver Walkman placed on a carpet in the middle of an empty room",
"pose": "Stationary, lying flat",
"position": "Center foreground on carpeted surface",
"color_palette": ["brushed silver", "dark gray accents"]
}
],
"style": "Ultra-realistic product photography with commercial quality",
"color_palette": ["brushed silver", "neutral beige", "soft white highlights"],
"lighting": "Three-point softbox setup creating soft, diffused highlights with no harsh shadows",
"mood": "Clean, professional, minimalist",
"background": "Soft-textured carpet surface with subtle studio backdrop suggesting an empty room",
"composition": "rule of thirds",
"camera": {
"angle": "high angle",
"distance": "medium shot",
"focus": "Sharp focus on metallic Walkman textures and physical controls",
"lens-mm": 85,
"f-number": "f/5.6",
"ISO": 200
}
}
"""
çŽ°åœ¨ï¼Œè®©æˆ‘ä»¬å°†åœ°æ¯¯é¢œè‰²æ›´æ”¹ä¸ºç‰¹å®šçš„è“ç»¿è‰²è°ƒï¼ˆ#367588ï¼‰ï¼Œå¹¶æ·»åŠ æ’å…¥éšèº«å¬çš„æœ‰çº¿è€³æœºï¼š
prompt = """
{
"subjects": [
{
"description": "Old silver Walkman placed on a teal-blue carpet (#367588) in the middle of an empty room, with wired headphones plugged in",
"color_palette": ["brushed silver", "dark gray accents", "#367588"]
},
{
"description": "Wired headphones connected to the Walkman, cable loosely coiled on the carpet",
"pose": "Stationary",
"position": "Next to and partially in front of the Walkman on the carpet",
"color_palette": ["dark gray", "soft black", "#367588"]
}
],
"color_palette": ["brushed silver", "#367588", "neutral beige", "soft white highlights"],
"background": "Soft-textured teal-blue carpet surface (#367588) with subtle studio backdrop suggesting an empty room",
"camera": {
"focus": "Sharp focus on metallic Walkman textures, wired headphones, and carpet fibers",
"lens-mm": 85,
"f-number": "f/5.6",
"ISO": 200
}
}
"""
çŽ°åœ¨åœ°æ¯¯é¢œè‰²ä¸Žæä¾›çš„åå…­è¿›åˆ¶ä»£ç åŒ¹é…ï¼Œå¹¶ä¸”è€³æœºå·²æ·»åŠ ï¼ŒåŒæ—¶å¯¹æ•´ä½“åœºæ™¯è¿›è¡Œäº†å¾®å°çš„æ”¹åŠ¨ã€‚
è¯·æŸ¥çœ‹å®˜æ–¹æç¤ºè¯æŒ‡å—ä»¥èŽ·å–æ›´å¤šç¤ºä¾‹å’Œè¯¦ç»†ä¿¡æ¯ã€‚
LoRA å¾®è°ƒ
FLUX.2 æ—¢æ˜¯æ–‡ç”Ÿå›¾æ¨¡åž‹ä¹Ÿæ˜¯å›¾ç”Ÿå›¾æ¨¡åž‹ï¼Œä½¿å…¶æˆä¸ºè®¸å¤šç”¨ä¾‹çš„å®Œç¾Žå¾®è°ƒå€™é€‰è€…ï¼ç„¶è€Œï¼Œç”±äºŽä»…æŽ¨ç†å°±éœ€è¦è¶…è¿‡ 80GB çš„æ˜¾å­˜ï¼Œåœ¨æ¶ˆè´¹çº§ GPU ä¸Šè¿è¡Œ LoRA å¾®è°ƒæ›´å…·æŒ‘æˆ˜æ€§ã€‚ä¸ºäº†å°½å¯èƒ½èŠ‚çœå†…å­˜ï¼Œæˆ‘ä»¬åœ¨è®­ç»ƒä¸­ä¹Ÿä½¿ç”¨äº†ä¸Šè¿°éƒ¨åˆ†æŽ¨ç†ä¼˜åŒ–æŠ€æœ¯ï¼Œå¹¶ç»“åˆå…±äº«å†…å­˜èŠ‚çœæŠ€æœ¯ï¼Œä»¥å¤§å¹…å‡å°‘å†…å­˜æ¶ˆè€—ã€‚è¦è¿›è¡Œè®­ç»ƒï¼Œæ‚¨å¯ä»¥ä½¿ç”¨ä¸‹é¢çš„ diffusers ä»£ç æˆ– Ostris çš„ AI å·¥å…·åŒ…ã€‚
æˆ‘ä»¬æä¾›äº†æ–‡ç”Ÿå›¾å’Œå›¾ç”Ÿå›¾ä¸¤ç§è®­ç»ƒè„šæœ¬ï¼Œå‡ºäºŽæœ¬åšå®¢çš„ç›®çš„ï¼Œæˆ‘ä»¬å°†é‡ç‚¹ä»‹ç»ä¸€ä¸ªæ–‡ç”Ÿå›¾è®­ç»ƒç¤ºä¾‹ã€‚
å¾®è°ƒçš„å†…å­˜ä¼˜åŒ–æŠ€æœ¯
è®¸å¤šè¿™äº›æŠ€æœ¯å¯ä»¥ç›¸äº’è¡¥å……ï¼Œç»“åˆä½¿ç”¨ä»¥è¿›ä¸€æ­¥å‡å°‘å†…å­˜æ¶ˆè€—ã€‚ç„¶è€Œï¼ŒæŸäº›æŠ€æœ¯å¯èƒ½äº’æ–¥ï¼Œå› æ­¤åœ¨å¯åŠ¨è®­ç»ƒè¿è¡Œå‰è¯·åŠ¡å¿…æ£€æŸ¥ã€‚
å±•å¼€ä»¥æŸ¥çœ‹æ‰€ç”¨å†…å­˜èŠ‚çœæŠ€æœ¯çš„è¯¦ç»†ä¿¡æ¯ï¼š
- è¿œç¨‹æ–‡æœ¬ç¼–ç å™¨ï¼šè¦åœ¨è®­ç»ƒä¸­åˆ©ç”¨è¿œç¨‹æ–‡æœ¬ç¼–ç ï¼Œåªéœ€ä¼ é€’ `--remote_text_encoder`ã€‚è¯·æ³¨æ„ï¼Œæ‚¨å¿…é¡»ç™»å½•æ‚¨çš„ Hugging Face è´¦æˆ·ï¼ˆ`hf auth login`ï¼‰æˆ–é€šè¿‡ `--hub_token` ä¼ é€’ä»¤ç‰Œã€‚
- CPU å¸è½½ï¼šé€šè¿‡ä¼ é€’ `--offload`ï¼Œå˜åˆ†è‡ªç¼–ç å™¨å’Œæ–‡æœ¬ç¼–ç å™¨å°†è¢«å¸è½½åˆ° CPU å†…å­˜ï¼Œä»…åœ¨éœ€è¦æ—¶ç§»åŠ¨åˆ° GPUã€‚
- æ½œåœ¨ç¼“å­˜ï¼šä½¿ç”¨å˜åˆ†è‡ªç¼–ç å™¨é¢„ç¼–ç è®­ç»ƒå›¾åƒï¼Œç„¶åŽåˆ é™¤å®ƒä»¥é‡Šæ”¾ä¸€äº›å†…å­˜ã€‚è¦å¯ç”¨ `latent_caching`ï¼Œåªéœ€ä¼ é€’ `--cache_latents`ã€‚
- QLoRAï¼šä½¿ç”¨é‡åŒ–çš„ä½Žç²¾åº¦è®­ç»ƒ - ä½¿ç”¨ 8 ä½æˆ– 4 ä½é‡åŒ–ã€‚æ‚¨å¯ä»¥ä½¿ç”¨ä»¥ä¸‹æ ‡å¿—ï¼š
    - ä½¿ç”¨ `torchao` è¿›è¡Œ FP8 è®­ç»ƒï¼šé€šè¿‡ä¼ é€’ `--do_fp8_training` å¯ç”¨ FP8 è®­ç»ƒã€‚ç”±äºŽæˆ‘ä»¬åˆ©ç”¨ FP8 å¼ é‡æ ¸å¿ƒï¼Œæˆ‘ä»¬éœ€è¦è®¡ç®—èƒ½åŠ›è‡³å°‘ä¸º 8.9 æˆ–æ›´é«˜çš„ CUDA GPUã€‚å¦‚æžœæ‚¨å¸Œæœ›åœ¨ç›¸å¯¹è¾ƒæ—§çš„æ˜¾å¡ä¸Šè¿›è¡Œå†…å­˜é«˜æ•ˆçš„è®­ç»ƒï¼Œæˆ‘ä»¬å»ºè®®æ‚¨æŸ¥çœ‹å…¶ä»–è®­ç»ƒå™¨ï¼Œå¦‚ `SimpleTuner`ã€`ai-toolkit` ç­‰ã€‚
    - ä½¿ç”¨ `bitsandbytes` è¿›è¡Œ NF4 è®­ç»ƒï¼šæˆ–è€…ï¼Œæ‚¨å¯ä»¥é€šè¿‡ä¼ é€’ `--bnb_quantization_config_path` å¹¶é™„å¸¦æŒ‡å‘åŒ…å«æ‚¨é…ç½®çš„ json æ–‡ä»¶çš„ç›¸åº”è·¯å¾„ï¼Œä½¿ç”¨ `bitsandbytes` è¿›è¡Œ 8 ä½æˆ– 4 ä½é‡åŒ–ã€‚æœ‰å…³æ›´å¤šè¯¦ç»†ä¿¡æ¯ï¼Œè¯·å‚è§ä¸‹æ–‡ã€‚
- æ¢¯åº¦æ£€æŸ¥ç‚¹ä¸Žç´¯ç§¯ï¼š
    - `--gradient accumulation` æŒ‡çš„æ˜¯åœ¨æ‰§è¡Œåå‘ä¼ æ’­/æ›´æ–°æ­¥éª¤ä¹‹å‰ç´¯ç§¯çš„æ›´æ–°æ­¥æ•°ã€‚é€šè¿‡ä¼ é€’å¤§äºŽ 1 çš„å€¼ï¼Œæ‚¨å¯ä»¥å‡å°‘åå‘ä¼ æ’­/æ›´æ–°ä¼ é€’çš„æ¬¡æ•°ï¼Œä»Žè€Œä¹Ÿé™ä½Žå†…å­˜éœ€æ±‚ã€‚
    - é€šè¿‡ `--gradient checkpointing`ï¼Œæˆ‘ä»¬å¯ä»¥é€šè¿‡ä¸åœ¨å‰å‘ä¼ æ’­æœŸé—´å­˜å‚¨æ‰€æœ‰ä¸­é—´æ¿€æ´»æ¥èŠ‚çœå†…å­˜ã€‚ç›¸åï¼Œåªå­˜å‚¨è¿™äº›æ¿€æ´»çš„ä¸€ä¸ªå­é›†ï¼ˆæ£€æŸ¥ç‚¹ï¼‰ï¼Œå…¶ä½™çš„åœ¨åå‘ä¼ æ’­æœŸé—´æ ¹æ®éœ€è¦é‡æ–°è®¡ç®—ã€‚è¯·æ³¨æ„ï¼Œè¿™ä¼šä»¥åå‘ä¼ æ’­é€Ÿåº¦å˜æ…¢ä¸ºä»£ä»·ã€‚
- 8 ä½ Adam ä¼˜åŒ–å™¨ï¼šå½“ä½¿ç”¨ `AdamW` è®­ç»ƒæ—¶ï¼ˆä¸é€‚ç”¨äºŽ `prodigy`ï¼‰ï¼Œæ‚¨å¯ä»¥ä¼ é€’ `--use_8bit_adam` æ¥é™ä½Žè®­ç»ƒçš„å†…å­˜éœ€æ±‚ã€‚

å¦‚æžœæ‚¨æƒ³è¿›è¡ŒFP8è®­ç»ƒï¼Œè¯·åŠ¡å¿…å®‰è£…bitsandbytesã€‚
å¼€å§‹è®­ç»ƒå‰ï¼Œè¯·åŠ¡å¿…æŸ¥é˜…READMEæ–‡ä»¶äº†è§£å…ˆå†³æ¡ä»¶ã€‚

åœ¨æœ¬ç¤ºä¾‹ä¸­ï¼Œæˆ‘ä»¬å°†ä½¿ç”¨multimodalart/1920-raider-waite-tarot-public-domainæ•°æ®é›†ï¼Œå¹¶é‡‡ç”¨ä»¥ä¸‹é…ç½®è¿›è¡ŒFP8è®­ç»ƒã€‚æ¬¢è¿Žæ‚¨å°è¯•è°ƒæ•´æ›´å¤šè¶…å‚æ•°å¹¶åˆ†äº«æ‚¨çš„ç»“æžœ ðŸ¤—

```
accelerate launch train_dreambooth_lora_flux2.py \
--pretrained_model_name_or_path="black-forest-labs/FLUX.2-dev" \
--mixed_precision="bf16" \
--gradient_checkpointing \
--remote_text_encoder \
--cache_latents \
--caption_column="caption"\
--do_fp8_training \
--dataset_name="multimodalart/1920-raider-waite-tarot-public-domain" \
--output_dir="tarot_card_Flux2_LoRA" \
--instance_prompt="trcrd tarot card" \
--resolution=1024 \
--train_batch_size=2 \
--guidance_scale=1 \
--gradient_accumulation_steps=1 \
--optimizer="adamW" \
--use_8bit_adam\
--learning_rate=1e-4 \
--report_to="wandb" \
--lr_scheduler="constant_with_warmup" \
--lr_warmup_steps=200 \
--checkpointing_steps=250\
--max_train_steps=1000 \
--rank=8\
--validation_prompt="a trtcrd of a person on a computer, on the computer you see a meme being made with an ancient looking trollface, 'the shitposter' arcana, in the style of TOK a trtcrd, tarot style" \
--validation_epochs=25 \
--seed="0"\
--push_to_hub
```

å·¦ä¾§å›¾åƒæ˜¯ä½¿ç”¨é¢„è®­ç»ƒçš„FLUX.2æ¨¡åž‹ç”Ÿæˆçš„ï¼Œå³ä¾§å›¾åƒåˆ™æ˜¯ä½¿ç”¨LoRAç”Ÿæˆçš„ã€‚

å¦‚æžœæ‚¨çš„ç¡¬ä»¶ä¸æ”¯æŒFP8è®­ç»ƒï¼Œå¯ä»¥ä½¿ç”¨bitsandbytesè¿›è¡ŒQLoRAè®­ç»ƒã€‚æ‚¨é¦–å…ˆéœ€è¦å®šä¹‰ä¸€ä¸ªå¦‚ä¸‹çš„`config.json`æ–‡ä»¶ï¼š

```json
{
"load_in_4bit": true,
"bnb_4bit_quant_type": "nf4"
}
```

ç„¶åŽå°†å…¶è·¯å¾„ä¼ é€’ç»™`--bnb_quantization_config_path`å‚æ•°ï¼š

```
--cache_latents \
**--bnb_quantization_config_path="config.json" \**
--instance_prompt="a tarot card" \
--resolution=1024 \
--guidance_scale=1 \
--use_8bit_adam\
--rank=8\
--seed="0"
```

**èµ„æº**
- FLUX.2 å…¬å‘Šæ–‡ç« 
- Diffusers æ–‡æ¡£
- FLUX.2 å®˜æ–¹æ¼”ç¤º
- Hubä¸Šçš„ FLUX.2
- FLUX.2 åŽŸå§‹ä»£ç åº“

> æœ¬æ–‡ç”±AIè‡ªåŠ¨ç¿»è¯‘ï¼ŒåŽŸæ–‡é“¾æŽ¥ï¼š[Diffusers welcomes FLUX-2](https://huggingface.co/blog/flux-2)
> 
> ç¿»è¯‘æ—¶é—´ï¼š2026-01-06 01:04
