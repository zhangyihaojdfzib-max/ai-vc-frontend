---
title: 编程的可能性：从Copilot看AI如何重塑开发与责任
title_original: Programming Possibility | Greylock
date: '2024-08-19'
source: Greylock Partners
source_url: https://greylock.com/reid-hoffman/kevin-scott-ai-programming-possibility/
author: ''
summary: 本文基于微软首席技术官凯文·斯科特在Greylock峰会上的访谈，探讨了以GitHub Copilot为代表的人工智能工具如何通过自动化认知工作释放生产力，并改变软件开发范式。斯科特强调，开发者在享受AI带来的效率提升时，必须肩负起应对安全、公平等潜在风险的责任。他认为，AI不仅应推动经济增长，更需为所有人创造机会，而Copilot的成功模式可复制到众多其他认知工作领域。
categories:
- AI产品
tags:
- GitHub Copilot
- 人工智能伦理
- 软件开发
- 生产力工具
- 凯文·斯科特
draft: false
translated_at: '2026-01-07T16:31:05.478784'
---

## 人工智能技术的潜力让我们有充分的理由保持乐观。那些能够自动化日常任务并扩展人类专业技能的工具，将释放出巨大的生产力，推动几乎所有行业实现跨越式发展。

然而，这种热情也伴随着担忧：人工智能可能会取代人类工作，加剧现有的不平等，并进一步分裂社会。目前可用的产品主要影响认知或知识工作，极大地扩展了能够开发和设计软件、进行科学实验等任务的人群规模。因此，微软首席技术官凯文·斯科特认为，创造和部署这些工具的人负有诚信行事的责任。

"这些工具意味着，将有一大批人能够利用新能力构建复杂的事物，"斯科特说，"你必须确保以相当严谨的方式处理所有安全和保障问题。"

斯科特的公司开发了编程辅助工具 GitHub Copilot，他建议围绕人工智能构建机器学习系统（或整个公司）的人们，要保持清晰的责任感，并意识到潜在的负面影响。

除了在企业组织中构思、开发和采用新技术的经验外，斯科特还以其致力于探索人工智能如何为社会创造公平竞争环境而闻名。

这源于他在弗吉尼亚州农村社区成长的独特视角。他的个人背景和职业生涯经历汇聚在他2020年出版的著作《重编美国梦：从美国乡村到硅谷，让人工智能为我们所有人服务》中。书中提出，人工智能可以（也应该）被开发来促进所有行业和个人的经济增长。

本次采访发生在 Greylock 的"智能未来"活动期间，这是一个为期一天的峰会，汇集了人工智能领域的专家和企业家。您可以通过下方链接或在您获取播客的任何地方收听本次采访，也可以在我们的 YouTube 频道观看本次采访的视频。

**里德·霍夫曼：** 欢迎大家。感谢各位的到来。

我只简单说一句：凯文是我见过的极少数人之一，当他加入 LinkedIn 时，他提升了 LinkedIn 工程团队的整体质量、工程战略以及规模，在这三个维度上都有所建树。这是一项非常罕见的成就。当然，当萨提亚和比尔第一次见到他时，他们立即打电话给我说："你不觉得他应该成为微软的 CTO 吗？"我当时就说："是的，这是个好主意。"

那么，现在让我们从 Copilot 的相关经验开始，因为大家可能已经知道 Copilot 的进展，但事实上，它是观察编码和工程开发整体范式如何变化的一个窗口。我们何不从这里开始？请先描述一下 Copilot 的现状，然后谈谈这将如何改变开发方式。

**凯文·斯科特：** 是的，我认为从 Copilot 的经验中至少可以学到几件事，这些对于围绕人工智能构建机器学习系统或公司的人来说是相关的。

对于那些不了解的人，GitHub Copilot 是一个编程辅助工具，它可以接收自然语言提示词，比如你可以描述你希望存在的程序，它会为你生成代码。令人惊讶的是，该系统的性能正在以相当稳定的速度提升。几个月前当我们正式发布它时，它生成的代码量已超过其用户总体编写代码量的 40%。从定性角度看，这是那种一旦有人用上（并非所有人，也有人不喜欢 Copilot，这没关系），许多许多用户会说"这对我太有价值了，你休想把它从我手中夺走"的工具。

关于 Copilot，有两件有趣的事。第一是当我们开始开发它时，我们有证据表明大语言模型实际上能够完成这种从自然语言到代码的转换。即使当我们向微软内部人员展示这可能实现时，我们得到的反应也各不相同，从"不，这不真实，这不可能，永远行不通"，到"也许能行，但我高度怀疑"。

因此，我们必须做的一项重要工作就是克服那种消极偏见，真正开始行动，因为我们不仅有证据表明它会成功，而且我们有一个非常具体的计划，知道如何随着时间的推移让它变得越来越好。我认为这是我们在这些基础模型中普遍看到的情况。人们看着它们，当然它们周围存在一定程度的炒作，但也有人怀疑它们是否真的能对人们想要构建的东西有用。

我认为第二件事，也许是 GitHub Copilot 更深刻的一点，是它只是众多潜在 Copilot 中的一员。我们通过 Copilot 实现的这种自动化特定类型的认知工作（甚至不是完全自动化，只是辅助人们进行特定类型的认知工作），将可以直接应用并复制到一大堆其他领域。因此，未来任何重复性的认知工作都可能有一个 Copilot。而为 GitHub Copilot 提供动力的模型，即 OpenAI 的 Codex 模型，确实让你能够以不同的方式思考软件开发。现在有一种你可以采用的软件开发模式，即通过迭代对话，将一个应用程序描述出来。

所以，并不是一个话语或一个提示词就能生成整个程序。但如果你说"我想要这样"，它会生成一些东西。然后你说"好的，这不错，但请以这种方式增强它，这样修改一下。"因此，你与这个系统进行多轮对话来得到一个应用程序。我在微软内部使用 API 构建了数十个这样的演示。随着越来越多的人能够访问 Codex API 本身，许多人正在看到它的威力。

**里德·霍夫曼：** 那么，首先，这对于软件开发的质量意味着什么？错误率、安全性以及进行新型工作的能力。请从你在 Copilot 中看到的这些维度以及其他方面，给我们一些视角。

**凯文·斯科特：** 是的，我的意思是现在还处于早期阶段，我们拭目以待。关于 GitHub Copilot 和 Codex，需要记住的一点是，使用它生成代码并不能免除你确保产品高质量、无缺陷且安全的责任。因此，开发者和企业家仍然承担着巨大的责任，要确保他们构建的东西是可靠的。

也许构建 GitHub Copilot 最困难的部分不是将自然语言转换为代码的 AI 部分，而是位于基础模型之上的安全层。这个安全层会查看输入的提示词和模型的输出，并努力确保它处理模型中的不当偏见，处理安全问题，处理如果模型恰好模仿了受版权保护的内容，或者处于某种可能使其输出内容非法的许可下的情况。因此，我们不得不投入大量工作来构建这一层，而且我认为随着时间的推移，我们还需要做更多的工作。

令人兴奋的是，它实现了两件事。一方面，它服务于那些在软件需求无限的世界中备受追捧的开发者，成为提升生产力的绝佳工具。但更有趣的是，我认为它拓宽了成为开发者的门槛——这既可能是好事也可能是坏事。我站在积极的一方，但也清醒地认识到，将会有大量普通人能够借助这项新能力构建复杂事物。我们必须确保以相当严谨的方式处理所有安全和保障问题。

"开发者和创业者仍肩负着重大责任，必须确保他们构建的产品具有诚信。"

RH：围绕所有这些基础大语言模型，一个核心问题是其规模及运作方式。显然我们选择构建大型模型而非小型模型，稍后我会就此提问。此外，未来还会涌现大量其他模型，毕竟你们正在构建的是数千亿参数的模型，对吧？

RH：但即便如此，人们用60亿参数或200亿参数的模型也能做出相当惊人的成果。

我们首先探讨：仅有少数公司能构建这种超大规模模型意味着什么？这对开发者生态和世界可能性将产生哪些影响？

KS：是的，这些模型——无论是基础模型、语言模型，还是今年我们将越来越多看到的多模态模型——正在构建跨多个领域的世界表征。由于需要海量计算基础设施，它们的构建成本只会越来越高。而且目前看来，规模扩张的边际收益递减点尚未显现。

因此，当你扩大模型规模（这听起来比实际容易得多），它们不仅在执行原有任务时变得更强大，同时能力范围也更广泛。相比之前的小型版本，它们能应用于更广泛的场景。这自然激励着人们不断投资构建更庞大的模型迭代，确保基础模型随时间推移日益强大。

我们的思考方式，以及我们的合作伙伴OpenAI的思考方式是：希望通过API开放这些模型，从而培育出建立在模型之上的丰富第三方开发者生态。很难想象任何单个公司——即使是市值万亿、一万五千亿甚至两万亿美元的大企业——能仅凭自身的想象力和资源，构建出所有能服务公共利益、造福人类并创造巨大价值的事物。因此这种开放模式令人振奋。

我昨天浏览新闻时，看到大量关于人们用GPT-3创造成果的激动人心的报道。GPT-3现在已相对普及，问世两年半以来，人们基于它构建应用的热情依然高涨，这非常令人兴奋，且未来会越来越好。

RH：一些创业者提出的问题是：既然通过API提供的超大规模模型数量相对有限，他们应如何思考构建差异化业务？您认为有哪些值得关注的思路和视角？

KS：在我看来，这正是最有趣的地方。虽然计算机科学和系统挑战领域存在诸多兴趣点，比如构建超大型模型，但我不认为最终需要15或20个功能基本相同的平台。保留少数几个是好事，因为竞争能促进进步，也能确保价格符合实际。但有趣之处在于，商业构建的永恒法则依然适用：你需要对客户需求有独到见解，可能比大公司更懂客户，在捕捉机会时更敏捷，并能快速迭代对客户高价值的功能。

因此我认为机遇巨大。应当将大模型视为技术赋能者，而非你正在构建的产品本身。

RH：目前仍处早期阶段，我们还不清楚真正的路线图会如何展开。但显然很多时候你会说："应该尽可能获取最好的资源，即由顶尖团队精心训练的最大规模模型，这需要巨额资金投入。"那么在哪些情况下，自行构建较小模型更有意义？有哪些可能的判断视角或原则？

KS：当前阶段的微妙之处在于，我们的直觉正受到挑战。微软内部也面临这种情况：我们正在重构架构，越来越多地使用这些基础模型，而自行构建端到端大型产品的团队越来越少。

默认的直觉往往是："如果拥有自己的数据，能自主选择模型架构，并以定制化方式训练和微调，我就能超越这个通用大模型。"这种想法有时正确，有时错误。我建议的思考起点是："我能否接入这个大模型？是否可以通过提示词工程或基于自身数据（针对具体用例）对大模型进行微调来提升性能？"

如果可行，那么你的架构设计将具备优势：当基础模型变得更强大时，你可以直接替换升级，你的应用也会随之增强。你实际上继承了分摊到众多不同应用中的改进成果。但有时你确实需要构建高度定制化的方案，比如当大型基础模型完全无法覆盖你的特定需求时。

一个很好的例子是：我们正在为科学领域构建一系列模型，那些擅长语言应用的模型架构和数据，对于分子动力学模拟几乎没有帮助。例如当你需要快速建立原子相互作用的量子精确模型时。

"应当将大模型视为技术赋能者，而非你正在构建的产品本身。"

RH：让我们再稍微谈谈科学。这实际上属于我认为在座大多数人都有所感知的加速领域之一，但这里有一个极其重要的观点：工具对科学的放大作用惊人地强大。通常人们想到工具时会认为，“哦，是新望远镜或是新这个新那个。”但实际上，我们获得的部分进展正是通过新工具、软件以及这些模型实现的调优。我们显然已经看到了AlphaFold、BakerFold等成果。在科学工具和加速方面，还有哪些即将到来的进展？

KS：请允许我先说些技术细节。对在座的计算机科学家而言，科学领域存在两类真正的难题。一类是组合优化问题，即处理离散系统并寻求其最优解；另一类是数值优化问题，通常涉及描述物理或自然世界运行规律的高度非线性偏微分方程组。这两类问题都需要对极其复杂的系统进行建模——事实上复杂到我们只能通过做出大量艰难妥协来寻求问题的最优或近似解。

在组合优化中，我们通常采用大量启发式方法，盯着问题域琢磨：“如果我用这种取巧方式或那种变通方法，就能让这个原本NP完全或NP难的问题更快收敛。”而在数值优化系统中，我们则要做出一系列假设，比如：“我将对求解这个波动方程的方法进行近似处理，在系统分辨率上妥协，在时间步数或步长设置上让步。”

现在我们在这两类系统中都观察到（随便翻开一期《自然》或《科学》杂志都能看到相关应用）：可以将AI自监督系统嵌入仿真循环，让它从全粒度系统中学习。只需以全分辨率缓慢运行系统，就能训练出掌握该领域知识的模型。一旦获得模型，将其置入优化循环的核心，整个进程就会加速。

这方面有很多研究论文，加州理工学院团队的一篇尤为出色。他们的神经微分算子论文获得了最佳奖项。他们基本提出了一种求解纳维-斯托克斯方程（计算流体动力学的偏微分方程）的方法，并将其应用于翼型设计，在保持同等质量的前提下，相比之前最优系统实现了10万倍的加速。这非常了不起。

我认为这里存在大量机遇。这意味着更好的药物，或许还能发现目前未知的固碳催化剂。相比未来拥有50个以上量子比特的实用量子计算机可能带来的突破，我对这些进展同样兴奋，甚至更加期待。

RH：没错，是超过50个逻辑量子比特。

RH：这是大家常讨论的话题。关于AI加速在生物学等领域的应用（如AlphaFold）已有不少报道。你认为还有哪些尚未受到足够关注但同样能获得加速的科学领域？

KS：我认为范围很广。即使在生物学领域，也不要低估这对材料设计的意义。要实现零碳经济转型，不仅需要淘汰内燃机，还涉及大量材料问题——有些材料的生产过程消耗大量碳密集型能源，有些材料本身（如塑料）需要碳氢化合物。我认为AI系统将加速解决大量极具挑战性的材料难题。

RH：我最近听到的一个例子是关于某些聚变反应的模拟，相较于使用碳氢化合物作为能量链的方案。这种模拟实际上提高了我们实现可控核聚变的可能性，对吗？

KS：没错。即使是当前几家非常有前景的聚变能源公司（我密切关注着其中两家），它们正在取得极其快速的进展。如果其中任何一家成功，我们有望在几十年内规模化部署大量廉价可持续的能源。这些公司快速推进的关键在于能够进行高保真度的模拟。AI系统彻底改变了他们的迭代速度，否则就会陷入必须投入500亿美元建造单个原型机才能验证可行性的困境。

RH：在这个问题之后，我会请观众提问。我本可以和你聊到明天，但最后这个问题算是承上启下——我知道你对此的观点，也可以从你之前的回答延伸出来：知识和专业工作领域将如何变革？哪些部分会被取代，哪些会被增强，哪些会被改造？当然这个问题足以讨论数小时。基于你的著作《重建美国梦》及其他思考，你会从哪些视角来解读即将到来的变化？

KS：这只是我的个人观点，存在多种不同见解。我认为——尽管有Nuro、Aurora等即将呈现的成果——过去十年我们可能高估了AI对工业应用、制造业及现实世界技术接口带来的变革程度，却低估了它对认知工作的影响。

具体来说，任何重复性认知工作，无论多么复杂——无论是编程、物理学的实验设计，还是合同审阅、疾病诊断——大部分都将被AI系统覆盖。我认为今年人们将震惊于我们再次迈出的巨大步伐。每年我们都会对AI的进展感到惊讶。你我都是德米斯（哈萨比斯）的朋友，尽管DeepMind属于谷歌而非微软，但他们通过AlphaFold取得的成就以及对科学的贡献确实令人敬畏。

我们去年有了Copilot，有了AlphaFold的蛋白质数据库。我认为今年即将到来的事物将更加重大，其中大部分将直接影响认知工作。但这并不意味着会出现一大批……我不认为会出现一大批能完全替代律师或程序员工作的AI律师或AI程序员。而是意味着知识工作的生产力将获得真正的提升，其程度可能是自互联网诞生以来前所未有的，甚至可能超越互联网的影响。

"我认为过去十年里我们犯的一个错误是，高估了AI在工业应用、制造业以及现实世界技术接口方面将带来的变革程度。同时，我们低估了它对认知工作将产生的影响。"

RH：是的，我完全同意。好的，那么这里有个问题。

观众提问：谢谢Reid和Kevin。我很好奇，当你们提到并非所有应用和创新都将来自少数几家大公司时，我完全赞同。你们还提到了一些通过API开放可能促进的举措。你们认为还有哪些想法可以帮助生态系统蓬勃发展？根据你们漫长的职业生涯，从过去的历史中你们看到了哪些可借鉴的经验？这是第一个问题。

其次，我很好奇的是，对于你们组织内部描述的所有举措，你们目前是否在考虑任何优化效率的方案？如果有任何想法可以分享？谢谢。

KS：我认为这两个都是非常好的问题。我想说，我持有的'大公司无法独自完成一切'这个观点，部分是现实，部分是期望。我真心希望，为了这个世界着想，不应该由两三家位于沿海都市创新中心的超级富裕公司来决定全球实质性生产力提升的来源，决定哪些问题值得解决而哪些不重要。这在我看来太可怕了，这是我的个人偏见。

所以，我认为在座的各位创业者，你们的机会在于——尽管由于资本密集，可能不会看到很多人去训练成本高达十亿美元的模型（不过鉴于目前的发展速度，在不久的将来我们终将到达那个阶段）——我认为有大量像基础设施一样的东西需要建设。这不仅仅是"嘿，你建好模型，用API包装起来，然后让别人能用"那么简单。我认为需要围绕大模型构建一整套机器学习开发生态系统。因此，帮助人们进行提示词工程、微调、管理数据隐私和来源版本控制、微调数据、管理实验等等。我的意思是，我们需要为上一代机器学习构建的整套东西，我认为都需要为基础模型和那个应用栈重新构思，并且还需要构建一大堆全新的东西。

我们大家可能都在构建但尚未共同向公众开放的东西之一，就是安全和内容审核层。那个位于用户、Codex和GitHub Copilot之间或之上的组件，可以有人将其转化为每个人都需要的基础设施。

我们需要为所有这些事物提供安全、保障和责任管理，尤其是随着应用和模型变得更加强大。所以，我认为存在大量的机会。这很有趣，很令人兴奋，需要被构建出来。即使是这些东西，我也不认为会完全由谷歌、微软、阿里巴巴或其他任何公司来构建。

关于你的第二个问题：当然，我们正在考虑效率问题。当你像我们一样消耗大量计算资源时，不考虑效率才是愚蠢的。而且，效率问题本身就很有趣。我可能无法具体透露太多我们在做什么，但一件非常有趣的事情是：有很多关于训练大模型碳足迹的讨论。有趣的是，训练一个大模型的碳足迹，相对于大型云服务提供商整体的云计算碳足迹而言，是微不足道的。而云计算的碳足迹，鉴于我们优化能源消耗的能力相对于全球碳足迹而言，也是微不足道的。

但令人兴奋的是，当你能够构建一个基础模型时——这与我们过去端到端构建事物的方式不同，过去公司内部可能有上百个不同的垂直机器学习技术栈——如果你能把一大堆这样的东西整合到一个组件中，那将是一个非常有趣的优化领域。因此，我们认为我们已经从中获益，我们可以将训练成本分摊到众多不同的事物上。目前在公司内部，我们正基于大模型构建数百个功能。其中每一个功能，要么是以前因为成本太高或不可能实现而不会存在的，要么是如果拥有自己的垂直技术栈，其消耗的总资源量将远超我们现在的做法。

RH：我想补充一点，因为我认为那种"做这些大模型的碳足迹很愚蠢"的整个思维方式是错误的，那就是这些模型在节能方面的应用。例如，DeepMind所做的工作之一就是研究数据中心，并找出如何更具创新性，从而实际上产生了巨大的净正面效益。

KS：哦，百分之百同意。我们现在就用这些大模型来优化我们数据中心的能源足迹……

RH：而且效果是实实在在的。

KS：是的，我的意思是，我们甚至在做这样的事情，比如将不间断电源基础设施中多余的储存能源卖回电网，并使用AI系统在能源现货市场上进行电力投标，这就是一个例子。

RH：好的。正如你们所见，我可以轻松愉快地和Kevin聊上几个小时。谢谢你，Kevin。

KS：谢谢你的邀请。

Reid作为企业家和投资者，致力于构建网络以发展具有全球影响力的标志性企业。

---

> 本文由AI自动翻译，原文链接：[Programming Possibility | Greylock](https://greylock.com/reid-hoffman/kevin-scott-ai-programming-possibility/)
> 
> 翻译时间：2026-01-07 16:31
