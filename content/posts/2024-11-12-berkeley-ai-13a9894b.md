---
title: 通过背景故事集构建语言模型的虚拟角色
title_original: Virtual Personas for Language Models via an Anthology of Backstories
date: '2024-11-12'
source: Berkeley AI Research (BAIR)
source_url: http://bair.berkeley.edu/blog/2024/11/12/virutal-persona-llm/
author: Ritwik Gupta
summary: 本文提出了一种名为Anthology的新方法，通过为大型语言模型生成包含丰富个人价值观与生活经历的背景故事，使其能够模拟具有代表性、一致且多样化的虚拟角色。该方法利用LLM自身生成大量覆盖广泛人口统计学特征的背景故事，并将条件化的虚拟角色与现实调查样本匹配。评估显示，相较于仅使用人口统计学变量的传统方法，Anthology在模拟人类回应分布与一致性方面表现更优，为社会科学研究和用户调研提供了一种可扩展的潜在替代方案。
categories:
- AI研究
tags:
- 大语言模型
- 虚拟角色
- 条件化生成
- 社会科学模拟
- 背景故事
draft: false
translated_at: '2026-01-05T17:17:48.877Z'
---

我们介绍一种名为Anthology的方法，该方法通过生成并利用包含个人价值观与经历丰富细节的自然主义背景故事，使LLM（大语言模型）能够适配于具有代表性、一致且多样化的虚拟角色。

大语言模型在由数百万乃至数十亿独特人类作者共同产出的大规模文本语料上进行训练，这意味着什么？

在《作为智能体模型的语言模型》一文中，有力的证据表明，近期的语言模型可被视为智能体模型：在给定文本上下文的情况下，LLM能够生成代表可能产生该上下文的智能体特征的条件性文本。这表明，通过适当的条件设定，可以引导LLM近似模拟特定人类个体的回应，而非通常呈现的混合声音。若能实现，LLM的这种能力将对用户研究和社会科学产生重大影响——作为人类受试者虚拟角色的条件化语言模型，可成为具有成本效益的试点研究工具，并支持人类研究中的最佳实践，例如遵循贝尔蒙特原则中的公正与有利原则。

在这项工作中，我们介绍Anthology，一种通过向模型提供包含丰富细节的个人生活叙事作为条件上下文，从而引导LLM生成具有代表性、一致且多样化的虚拟角色的方法。在此过程中，我们还提出了利用LLM自身生成背景故事的方法，以此高效地生成覆盖广泛人口统计学特征的大规模数据集。通过将语言模型锚定在自然主义的背景故事中，Anthology使LLM能够以更高的保真度模拟个体人类样本，其衡量标准在于匹配人类回应的分布与一致性。

**我们的方法：Anthology**
**利用个人生活叙事条件化语言模型生成**

先前在引导LLM生成虚拟角色方法上的一个显著局限，是无法可靠地近似个体人类样本。以往的方法通常使用宽泛的人口统计学信息来提示LLM，例如“我是一名来自加利福尼亚州的25岁青年，我的最高教育水平低于高中”，这本质上是由一组人口统计学变量生成的文本内容。使用这些方法，我们只能在群体层面近似人类样本，而无法在个体层面实现，这导致：
*   回应容易使LLM默认采用刻板印象和/或原型化描述，因为它们仅以人口统计学变量（如种族和性别）为条件。
*   无法提供重要的关注指标，如协方差和统计显著性，因为此类计算需要个体层面的回应数据。

Anthology通过使用细节丰富的背景故事作为条件，实现了对个体受试者的近似模拟。通过这些背景故事，模型捕捉到个人身份的隐性和显性标记，包括人口统计学特征以及对文化、社会经济背景和生活哲学的自发性提及。我们的方法涉及通过语言模型生成大量代表广泛人口统计学属性的背景故事，这些模型使用不受限制的开放式提示词进行查询，例如“介绍一下你自己”。然后，我们将由每个背景故事条件化的虚拟角色与现实世界的调查样本进行匹配。

**结果：更接近地近似民意调查**

为进行评估，我们在近似三项皮尤研究中心美国趋势小组调查（第34、92和99波）的背景下，比较了不同条件化虚拟角色方法的有效性。

在近似皮尤研究中心美国趋势小组调查人类回应方面的结果。粗体和下划线结果分别表示最接近和次接近人类回应值的数值。

作为衡量使用虚拟角色近似人类样本成功程度的指标，我们考虑以下度量标准：
*   回应分布之间的平均Wasserstein距离，作为代表性的度量。
*   相关矩阵之间的Frobenius范数，作为一致性的度量。
*   Cronbach's alpha作为内部一致性的额外度量。

在分析虚拟受试者之前，我们通过将人类群体随机分成两个大小相等的子组，并计算子组之间的这些度量指标，来估计每个评估指标的下限。我们取100次迭代的平均值来代表下限估计值。

我们一致观察到，无论是对于Llama-3-70B还是Mixtral-8x22B模型，Anthology在所有指标上都优于其他条件化方法。在比较两种匹配方法时，贪婪匹配方法在所有调查波次上的平均Wasserstein距离方面往往表现更好。我们将匹配方法的差异归因于最大权重匹配的一一对应条件限制以及可用虚拟用户数量的有限性。具体而言，最大权重匹配中分配给匹配虚拟受试者的权重不可避免地低于贪婪匹配中的权重，因为后者放宽了一一对应的约束。与贪婪匹配相比，这种差异可能导致匹配的人类用户与虚拟用户之间的人口统计学相似性较低。这些结果表明，与基线方法相比，我们方法中生成的背景故事的丰富性能够引发更细致入微的回应。

**最终思考**

Anthology标志着在LLM中条件化虚拟角色的一个前景广阔的新方向，它通过提供一种可扩展的、有时更具伦理性的传统人类调查替代方案，可能重塑我们进行用户研究、民意调查和其他社会科学应用的方式。然而，如同语言模型在社会科学中的任何其他应用一样，使用Anthology也带来了几个需要首要考虑的问题：尽管生成的背景故事有助于创建更具代表性的角色，但仍存在延续偏见或侵犯隐私的风险，因此应谨慎使用和解释结果。

关于未来的步骤，我们设想我们的方法将受益于更广泛和多样化的背景故事集合，每个故事都代表个体一致的生活叙事。此外，一个有价值的工作延伸是考虑自由形式的回应生成，使得角色模拟能够超越多项选择等结构化调查格式，实现更自然和细致入微的模拟。最后，在行为研究中应用LLM的一个令人兴奋的下一维度，将涉及模拟长期效应，允许虚拟角色建模并回顾性地审视随时间发生的变化。

所有这些方向都提出了众多的技术挑战；如果您有兴趣合作或想进一步讨论我们的工作，请告知我们！

了解更多关于我们的工作：完整论文链接
@article{moon2024virtual,
title={Virtual personas for language models via an anthology of backstories},
author={Moon, Suhong and Abdulhai, Marwa and Kang, Minwoo and Suh, Joseph and Soedarmadji, Widyadewi and Behar, Eran Kohen and Chan, David M},
journal={arXiv preprint arXiv:2407.06576},
year={2024}
}

> 本文由AI自动翻译，原文链接：[Virtual Personas for Language Models via an Anthology of Backstories](http://bair.berkeley.edu/blog/2024/11/12/virutal-persona-llm/)
> 
> 翻译时间：2026-01-05 17:17
