---
title: 利用有效载荷日志增强WAF可见性
title_original: Get better visibility for the WAF with payload logging
date: '2025-11-24'
source: Cloudflare Blog
source_url: https://blog.cloudflare.com/waf-payload-logging/
author: Paschal Obba
summary: 本文介绍了Cloudflare Web应用程序防火墙（WAF）中有效载荷日志记录功能的工作原理与价值。针对WAF规则匹配可能产生的误报问题，传统的日志操作仅能确认规则触发，但无法揭示具体是请求中的哪个字段或转换后的值导致了匹配。有效载荷日志记录通过记录触发规则的特定请求字段及其值，减少了调试的模糊性，帮助客户精准识别误报、验证规则正确性，并优化WAF配置以提升安全效能。文章还简要说明了该功能基于Wirefilter引擎和抽象语法树（AST）的技术实现。
categories:
- 技术趋势
tags:
- Web应用防火墙
- 网络安全
- 日志分析
- Cloudflare
- 误报调试
draft: false
translated_at: '2026-01-05T17:26:56.021Z'
---

随着网络攻击面的扩大，Cloudflare的Web应用程序防火墙（WAF）提供了多种解决方案来缓解这些攻击。这对我们的客户来说非常有益，但我们所服务的数百万请求的工作负载基数意味着产生误报是不可避免的。这意味着我们必须为客户提供的默认配置进行微调。

微调并非一个不透明的过程：客户需要获取一些数据点，然后决定什么对他们有效。本文解释了我们所提供的技术，这些技术能让客户了解WAF采取某些操作的原因，以及为减少噪音、增强信号所做的改进。

**日志操作很棒——但我们能否做得更多？**

Cloudflare的WAF保护源服务器免受各种第7层攻击，即针对应用层的攻击。保护通过多种工具提供，例如：

这些工具构建在规则集引擎之上。当规则表达式匹配时，引擎会执行一个操作。

日志操作用于模拟规则的行为。此操作证明引擎匹配了规则表达式，并发出一个日志事件，可以通过安全分析、安全事件、Logpush或边缘日志交付进行访问。

日志非常擅长验证规则是否按预期在预期匹配的流量上工作，但仅显示规则匹配是不够的，特别是当规则表达式可能包含许多代码路径时。

在伪代码中，一个表达式可能如下所示：
> 如果任何HTTP请求头包含"authorization"键 **或者** HTTP主机头的小写表示以"cloudflare"开头，则记录日志。

规则语言语法将是：
> `any(http.request.headers[*] contains "authorization") or starts_with(lower(http.host), "cloudflare")`

调试这个表达式会带来几个问题。是上述OR表达式的左侧（LHS）还是右侧（RHS）匹配？像Base64解码、URL解码以及本例中的小写转换这样的函数，会对这些字段的原始表示形式进行转换，这进一步增加了不确定性，难以判断是请求的哪些特征导致了匹配。

更复杂的是，规则集中的许多规则都可能记录匹配。像Cloudflare OWASP这样的规则集使用不同规则的累积分数，当分数超过设定阈值时触发操作。

此外，Cloudflare托管规则和OWASP规则的表达式是私有的。这增强了我们的安全态势，但也意味着客户只能从标题、标签和描述中猜测这些规则的作用。例如，一个规则可能被标记为"SonicWall SMA - 远程代码执行 - CVE:CVE-2025-32819"。

这就引出了问题：是我的请求的哪一部分导致了规则集引擎的匹配？这些是误报吗？

这正是有效载荷日志记录发挥作用的地方。它可以帮助我们深入分析导致匹配的规则中，具体是哪些字段及其转换后的值。

有效载荷日志记录是一项功能，用于记录请求中哪些字段与导致WAF采取操作的规则相关联。这减少了模糊性，并提供了有用的信息，有助于发现误报、保证正确性，并帮助微调这些规则以获得更好的性能。

在上面的例子中，一个有效载荷日志条目将包含表达式的LHS或RHS，但不会同时包含两者。

**有效载荷日志记录如何工作？**

有效载荷日志记录和规则集引擎构建在Wirefilter之上，这已被广泛解释过。

从根本上说，这些引擎是用Rust编写的对象，它们实现了一个编译器特性。这个特性驱动着从这些表达式派生出的抽象语法树（ASTs）的编译。

```rust
struct PayloadLoggingCompiler {
    regex_cache: HashMap<String, Arc<Regex>>
}

impl wirefilter::Compiler for PayloadLoggingCompiler {
    type U = PayloadLoggingUserData;

    fn compile_logical_expr(&mut self, node: LogicalExpr) -> CompiledExpr<Self::U> {
        // ...
        let regex = self.regex_cache.entry(regex_pattern)
            .or_insert_with(|| Arc::new(regex));
        // ...
    }
}
```

规则集引擎执行一个表达式，如果其评估结果为真，则该表达式及其执行上下文将被发送到有效载荷日志记录编译器进行重新评估。执行上下文提供了评估表达式所需的所有运行时值。

重新评估完成后，将记录表达式中评估为真的分支所涉及的字段。

日志的结构是Wirefilter字段及其值的映射 `Map<Field, Value>`：
```json
{
    "http.host": "cloudflare.com",
    "http.method": "get",
    "http.user_agent": "mozilla"
}
```
注意：这些日志使用客户提供的公钥进行加密。

这些日志经过我们的日志管道，可以通过不同的方式读取。客户可以配置一个Logpush任务，将其写入我们构建的自定义Worker，该Worker使用客户的私钥自动解密这些日志。也可以使用有效载荷日志记录CLI工具、Worker或Cloudflare仪表板进行解密。

**我们发布了哪些改进？**

在Wirefilter中，有些字段是数组类型。字段 `http.request.headers.names` 是请求中所有头名称的数组。例如：
> `["content-type", "content-length", "authorization", "host"]`

一个读取 `any(http.request.headers.names[*] contains "c")` 的表达式将评估为真，因为至少有一个头包含字母"c"。在之前版本的有效载荷日志记录编译器中，`http.request.headers.names` 字段中的所有头都会被记录，因为它是评估为真的表达式的一部分。

**有效载荷日志（之前）**
> `http.request.headers.names[*] = ["content-type", "content-length", "authorization", "host"]`

现在，我们部分评估数组字段，并记录匹配表达式约束的索引。在这种情况下，将只记录包含"c"的头！

**有效载荷日志（新）**
> `http.request.headers.names[0,1] = ["content-type", "content-length"]`

这就引出了Wirefilter中的运算符。像"eq"这样的运算符会导致完全匹配，例如 `http.host eq "a.com"`。还有其他运算符会导致"部分"匹配，例如"in"、"contains"、"matches"，它们与正则表达式一起工作。

本例中的表达式：`any(http.request.headers[*] contains "c")` 使用了"contains"运算符，它产生部分匹配。它还使用了"any"函数，我们可以说它产生部分匹配，因为如果至少有一个头包含"c"，那么我们应该记录那个头，而不是像之前版本那样记录所有头。

随着有效载荷日志记录编译器的改进，当评估这些表达式时，我们只记录部分匹配。在这种情况下，新的有效载荷日志记录编译器处理"contains"运算符的方式类似于Rust标准库中字节的"find"方法。这将我们的有效载荷日志改进为：
> `http.request.headers.names[0,1] = ["c", "c"]`

这使得事情清晰得多。它也使我们的日志管道免于处理数百万字节。例如，一个经常被分析的字段是请求体 `http.request.body.raw`，它的大小可能达到几十千字节。有时表达式检查的正则表达式模式应该匹配三个字符。在这种情况下，我们将记录3个字节而不是几千字节！

我知道，我知道，`["c", "c"]` 并没有太大意义。即使我们已经提供了匹配的确切原因，并且显著节省了写入客户存储目的地的字节量，但关键目标是为客户提供有用的调试信息。作为有效载荷日志记录改进的一部分，编译器现在还会为部分匹配记录"之前"和"之后"（如果适用）的值。这些缓冲区的大小目前各为15字节。

这意味着我们的载荷日志现在看起来像这样：
http.request.headers[0,1] = [
{
before: null, // 不包含在最终日志中
content: âcâ,
after: âontent-lengthâ
},
{
content: âcâ,
after:âontent-typeâ
}
]
载荷日志示例（先前）
载荷日志示例（新）
在之前的日志中，我们拥有所有的头部值。在新的日志中，我们有一个第8个索引，它是HTTP头部中的一个恶意脚本。匹配发生在`<script>`标签上，其余部分是灰色文本显示的上下文。
托管规则严重依赖正则表达式来识别恶意请求。解析和编译这些表达式是CPU密集型任务。由于托管规则编写一次后部署到数百万个区域，我们通过编译这些正则表达式并将其缓存在内存中而受益。这为我们节省了CPU周期，因为在进程重启之前我们无需重新编译它们。
载荷日志编译器使用大量动态大小的数组或向量来存储这些日志的中间状态。同时也使用了像smallvec这样的crate来减少堆分配。
臭名昭著的"TRUNCATED"值
有时，客户会在其载荷日志中看到"truncated"。这是因为每个防火墙事件都有字节大小限制。当超过此限制时，载荷日志会被截断。
载荷日志（先前）
载荷日志（新）
我们看到载荷日志的p50字节大小从1.5千字节缩减到500字节——减少了67%！这意味着被截断的载荷日志数量大大减少。
我们目前使用有损的utf-8字符串表示法来表示值。这意味着像多媒体这样的非有效utf-8字符串会被表示为U+FFFD Unicode替换字符。对于需要处理二进制数据的规则，应使用字节数组或不同的序列化格式来保持这些值的完整性。
载荷日志的存储格式是JSON。我们将对此以及其他二进制格式（如CBOR、Cap'n Proto、Protobuf等）进行基准测试，以了解这能为我们的处理流水线节省多少时间。这将帮助我们更快地向客户交付日志，同时二进制格式还有一个额外优势，即有助于维护向后兼容的预定义模式。
最后，载荷日志目前仅适用于托管规则。它将逐步推广到其他Cloudflare WAF产品，如自定义规则、WAF攻击评分、内容扫描、AI防火墙等。
一个载荷日志示例，显示了由AI防火墙检测到的包含PII的提示词：
了解WAF所采取的行动将使客户确信他们的规则或配置正在按预期工作。提高载荷日志的针对性是朝着这个方向迈出的一步——并且正在规划中的还有对可靠性、延迟的进一步改进，以及扩展到更多WAF产品。
由于这是对JSON模式的一项重大变更，我们已通过充分的文档逐步向客户推出。
要开始使用并启用载荷日志，请访问我们的开发者文档。

> 本文由AI自动翻译，原文链接：[Get better visibility for the WAF with payload logging](https://blog.cloudflare.com/waf-payload-logging/)
> 
> 翻译时间：2026-01-05 17:26
