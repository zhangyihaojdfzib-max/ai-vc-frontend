---
title: 基于Databricks Agent Bricks构建监管风险Copilot（一）：信息提取
title_original: 'Building a Regulatory Risk Copilot with Databricks Agent Bricks (Part
  1: Information Extraction)'
date: '2026-01-21'
source: Databricks Blog
source_url: https://www.databricks.com/blog/building-regulatory-risk-copilot-databricks-agent-bricks-part-1-information-extraction
author: ''
summary: 本文是系列文章的第一部分，探讨如何利用Databricks的Agent Bricks技术构建一个监管风险Copilot（智能副驾），重点聚焦于信息提取环节。文章首先介绍了选择Databricks作为技术平台的原因，并详细列举了其平台架构、产品矩阵、行业解决方案及丰富的生态资源，为后续构建面向金融等强监管行业的智能风险分析工具奠定了技术基础。
categories:
- AI产品
tags:
- Databricks
- Agent Bricks
- 监管科技
- 信息提取
- AI Copilot
draft: false
translated_at: '2026-01-22T04:57:23.887564'
---

-   为何选择 Databricks
探索
面向高管
面向初创企业
湖仓一体架构
Mosaic 研究
客户
客户案例
合作伙伴
云服务提供商
Databricks 在 AWS、Azure、GCP 和 SAP 上的服务
咨询与系统集成商
构建、部署和迁移至 Databricks 的专家
技术合作伙伴
将现有工具连接到您的湖仓一体
C&SI 合作伙伴计划
构建、部署或迁移至湖仓一体
数据合作伙伴
接入数据消费者生态系统
合作伙伴解决方案
寻找定制行业与迁移解决方案
基于 Databricks 构建
构建、推广和发展您的业务

-   产品
Databricks 平台
平台概览
面向数据、分析与 AI 的统一平台
数据管理
数据可靠性、安全性与性能
共享
面向所有数据的开放、安全、零拷贝共享
数据仓库
用于 SQL 分析的无服务器数据仓库
治理
面向所有数据、分析与 AI 资产的统一治理
数据工程
批处理和流式数据的 ETL 与编排
人工智能
构建和部署机器学习与生成式 AI 应用
数据科学
大规模协作式数据科学
商业智能
面向真实世界数据的智能分析
应用开发
快速构建安全的数据与 AI 应用
数据库
用于数据应用和 AI Agent（智能体）的 Postgres
集成与数据
市场
面向数据、分析与 AI 的开放市场
IDE 集成
在您喜爱的 IDE 中基于湖仓一体进行开发
合作伙伴连接
发现并与 Databricks 生态系统集成
定价
Databricks 定价
探索产品定价、DBU 等
成本计算器
估算您在任意云上的计算成本
开源
开源技术
深入了解平台背后的创新

-   解决方案
面向行业的 Databricks
通信
媒体与娱乐
金融服务
公共部门
医疗保健与生命科学
零售
制造业
查看所有行业
跨行业解决方案
AI Agent（智能体）
网络安全
营销
迁移与部署
数据迁移
专业服务
解决方案加速器
探索加速器
更快实现重要成果

-   资源
学习
培训
发现为您量身定制的课程
Databricks 学院
登录 Databricks 学习平台
认证
获得认可与差异化优势
免费版
免费学习专业的数据与 AI 工具
大学联盟
想要教授 Databricks？了解详情。
活动
Data + AI 峰会
Data + AI 全球巡演
数据智能日
活动日历
博客与播客
Databricks 博客
探索新闻、产品发布等
Databricks Mosaic 研究博客
发现我们生成式 AI 研究的最新进展
Data Brew 播客
让我们聊聊数据！
Champions of Data + AI 播客
来自推动创新的数据领导者的见解
获取帮助
客户支持
文档
社区
深入探索
资源中心
演示中心
架构中心

-   关于
公司
我们是谁
我们的团队
Databricks Ventures
联系我们
招聘
在 Databricks 工作
开放职位
新闻
奖项与认可
新闻中心
安全与信任
安全与信任

-   探索
面向高管
面向初创企业
湖仓一体架构
Mosaic 研究

-   客户
客户案例

-   合作伙伴
云服务提供商
Databricks 在 AWS、Azure、 GCP 和 SAP 上的服务
咨询与系统集成商
构建、部署和迁移至 Databricks 的专家
技术合作伙伴
将现有工具连接到您的湖仓一体
C&SI 合作伙伴计划
构建、部署或迁移至湖仓一体
数据合作伙伴
接入数据消费者生态系统
合作伙伴解决方案
寻找定制行业与迁移解决方案
基于 Databricks 构建
构建、推广和发展您的业务

-   面向高管
-   面向初创企业
-   湖仓一体架构
-   Mosaic 研究

-   客户案例

-   云服务提供商
Databricks 在 AWS、Azure、 GCP 和 SAP 上的服务
-   咨询与系统集成商
构建、部署和迁移至 Databricks 的专家
-   技术合作伙伴
将现有工具连接到您的湖仓一体
-   C&SI 合作伙伴计划
构建、部署或迁移至湖仓一体
-   数据合作伙伴
接入数据消费者生态系统
-   合作伙伴解决方案
寻找定制行业与迁移解决方案
-   基于 Databricks 构建
构建、推广和发展您的业务

-   Databricks 平台
平台概览
面向数据、分析与 AI 的统一平台
数据管理
数据可靠性、安全性与性能
共享
面向所有数据的开放、安全、零拷贝共享
数据仓库
用于 SQL 分析的无服务器数据仓库
治理
面向所有数据、分析与 AI 资产的统一治理
数据工程
批处理和流式数据的 ETL 与编排
人工智能
构建和部署机器学习与生成式 AI 应用
数据科学
大规模协作式数据科学
商业智能
面向真实世界数据的智能分析
应用开发
快速构建安全的数据与 AI 应用
数据库
用于数据应用和 AI Agent（智能体）的 Postgres

-   集成与数据
市场
面向数据、分析与 AI 的开放市场
IDE 集成
在您喜爱的 IDE 中基于湖仓一体进行开发
合作伙伴连接
发现并与 Databricks 生态系统集成

-   定价
Databricks 定价
探索产品定价、DBU 等
成本计算器
估算您在任意云上的计算成本

-   开源
开源技术
深入了解平台背后的创新

-   平台概览
面向数据、分析与 AI 的统一平台
-   数据管理
数据可靠性、安全性与性能
-   共享
面向所有数据的开放、安全、零拷贝共享
-   数据仓库
用于 SQL 分析的无服务器数据仓库
-   治理
面向所有数据、分析与 AI 资产的统一治理
-   数据工程
批处理和流式数据的 ETL 与编排
-   人工智能
构建和部署机器学习与生成式 AI 应用
-   数据科学
大规模协作式数据科学
-   商业智能
面向真实世界数据的智能分析
-   应用开发
快速构建安全的数据与 AI 应用
-   数据库
用于数据应用和 AI Agent（智能体）的 Postgres

-   市场
面向数据、分析与 AI 的开放市场
-   IDE 集成
在您喜爱的 IDE 中基于湖仓一体进行开发
-   合作伙伴连接
发现并与 Databricks 生态系统集成

-   Databricks 定价
探索产品定价、DBU 等
-   成本计算器
估算您在任意云上的计算成本

-   开源技术
深入了解平台背后的创新


-   通信
-   媒体与娱乐
-   金融服务
-   公共部门
-   医疗保健与生命科学
-   零售
-   制造业
-   查看所有行业

-   AI Agent（智能体）
-   网络安全
-   营销

-   数据迁移
-   专业服务

-   探索加速器更快实现重要成果


-   培训发现满足您需求的定制课程
-   Databricks Academy登录Databricks学习平台
-   认证获得认可与区分
-   免费版免费学习专业的Data和AI工具
-   大学联盟想教授Databricks？了解详情。

-   Data + AI Summit
-   Data + AI World Tour
-   Data Intelligence Days
-   活动日历

-   Databricks博客探索新闻、产品公告等
-   Databricks Mosaic研究博客发现我们Gen AI研究的最新进展
-   Data Brew播客让我们聊聊数据！
-   Champions of Data + AI播客来自推动创新的数据领导者的洞见

-   客户支持
-   文档
-   社区

-   资源中心
-   演示中心
-   架构中心

-   安全与信任

-   安全与信任

-   关于我们
-   我们的团队
-   Databricks Ventures
-   联系我们

-   在Databricks工作
-   开放职位

-   奖项与认可
-   新闻中心

-   安全与信任

-   准备开始了吗？
-   获取演示

-   登录
-   联系我们
-   试用Databricks

1.  博客
2.  /行业
3.  /文章

# 使用 Databricks Agent Bricks 构建监管风险 Copilot（第一部分：信息提取）

## 了解如何使用 Databricks AI 函数和 Agent Bricks 将非结构化的 FDA 拒绝信转化为可操作的见解。

![使用 Databricks Agent Bricks 构建监管风险 Copilot（第一部分：信息提取）](/images/posts/9e395015ecc4.png)

![使用 Databricks Agent Bricks 构建监管风险 Copilot（第一部分：信息提取）](/images/posts/9e395015ecc4.png)

![使用 Databricks Agent Bricks 构建监管风险 Copilot（第一部分：信息提取）](/images/posts/9e395015ecc4.png)

发布日期：2026年1月21日

作者：Guanyu Chen 和 Diego Malaver

-   -   -

-   解析复杂PDF：与传统方法需要团队和数千行代码不同，只需使用 ai_parse_document() 函数即可可靠地从复杂的PDF文档（如FDA完全回应函）中解析文本和图像。
-   协作提取见解：了解如何使用信息提取 Agent Bricks，让业务专家和AI工程师能够实时协作定义、测试和完善结构化数据的提取。
-   使用SQL实现生产化：一键将完善的Agent部署为无服务器端点，并使用 ai_query() 函数构建可扩展、可用于生产的流水线，直接在您的Lakehouse中处理新文档。

-   解析复杂PDF：与传统方法需要团队和数千行代码不同，只需使用 ai_parse_document() 函数即可可靠地从复杂的PDF文档（如FDA完全回应函）中解析文本和图像。
-   协作提取见解：了解如何使用信息提取 Agent Bricks，让业务专家和AI工程师能够实时协作定义、测试和完善结构化数据的提取。
-   使用SQL实现生产化：一键将完善的Agent部署为无服务器端点，并使用 ai_query() 函数构建可扩展、可用于生产的流水线，直接在您的Lakehouse中处理新文档。

2025年7月，美国FDA公开发布了首批 **200多封完全回应函**，这些是解释药物和生物制品申请为何未能在首次提交时获得批准的决策信函，标志着透明度的重大转变。这是首次，申办方、临床医生和数据团队可以通过集中、可下载的公开FDA PDF文件，分析该机构关于临床、CMC、安全性、标签和生物等效性等方面缺陷的官方表述，从而洞察整个行业。

随着FDA持续发布新的CRL，能够从此类及其他非结构化数据中快速生成见解，并添加到其内部情报/数据中，将成为一项重要的竞争优势。能够有效利用这些以PDF、文档、图像等形式存在的非结构化数据见解的组织，可以降低自身提交的风险，识别常见陷阱，并最终加速其上市进程。挑战在于，这些数据与许多其他监管数据一样，被锁定在PDF中，众所周知，大规模处理PDF非常困难。

这正是Databricks旨在解决的那类挑战。本博客将演示如何使用Databricks最新的AI工具来加速提取困在PDF中的关键信息——将这些关键信函转化为可操作情报的来源。

## 成功应用AI的关键要素

鉴于所需的技术深度，工程师通常孤立地主导开发，导致AI构建与业务需求之间存在巨大鸿沟。当领域专家最终看到结果时，往往并非他们所需。反馈循环太慢，项目失去了动力。

在早期测试阶段，建立基准至关重要。许多情况下，替代方案会浪费数月时间却缺乏真实基准，只能依赖主观观察和“感觉”。这种缺乏实证证据的情况会阻碍进展。相反，Databricks 工具提供开箱即用的评估功能，让客户能立即聚焦质量——通过迭代框架获得提取结果的数学置信度。AI 的成功需要一种建立在快速、协作迭代基础上的新方法。

Databricks 提供了一个统一的平台，业务领域专家和 AI 工程师可以在此实时协作，构建、测试和部署生产就绪的智能体。该框架建立在三个关键原则之上：

- **紧密的业务与技术对齐**：领域专家和技术负责人在同一用户界面中协作，获得即时反馈，取代缓慢的邮件循环。
- **真实基准评估**：业务定义的“真实基准”标签直接内置于工作流中，用于正式评分。
- **完整的平台方案**：这不是一个沙盒或单点解决方案；它与自动化流水线、LLM-as-a-Judge 评估、生产级可靠的 GPU 吞吐量以及端到端的 Unity Catalog 治理完全集成。

这种统一的平台方法，正是将原型转变为可信赖、生产就绪的 AI 系统的关键。让我们来逐步了解构建它的四个步骤。

## 从 PDF 到生产：四步指南

在非结构化数据上构建生产级 AI 系统，不仅需要一个好模型，更需要一个无缝、迭代且协作的工作流。信息提取智能体模块，结合 Databricks 内置的 AI 函数，使得解析文档、提取关键信息并使整个过程可操作化变得容易。这种方法使团队能够更快地推进并交付更高质量的结果。下面分解构建过程的四个关键步骤。

### 步骤 1：使用 `ai_parse_document()` 将非结构化 PDF 解析为文本

第一个障碍是从 PDF 中获取干净的文本。CRL 可能具有复杂的布局，包含页眉、页脚、表格、图表，跨越多页和多栏。简单的文本提取通常会失败，产生不准确且无法使用的输出。

与那些难以处理布局的脆弱单点解决方案不同，`ai_parse_document()` 利用最先进的多模态 AI 来理解文档结构——准确地按阅读顺序提取文本，保留不规则的表格层级结构，并为图表生成标题。

此外，Databricks 在文档智能方面提供了一项优势：能够可靠地扩展以处理企业级体量的复杂 PDF，成本比主要竞争对手低 3-5 倍。团队无需担心文件大小限制，其底层的 OCR 和 VLM 确保能准确解析历史上那些包含密集、不规则图表及其他挑战性结构的“问题 PDF”。

过去需要众多数据科学家跨多个供应商配置和维护定制化解析堆栈的工作，现在只需一个原生的 SQL 函数即可完成——让团队能够并行处理数百万份文档，而不会出现困扰那些可扩展性较差的解析器的故障模式。

开始使用，首先将 UC Volume 指向包含 PDF 的云存储。在我们的示例中，我们将 SQL 函数指向由 Volume 管理的 CRL PDF：

```sql
SELECT ai_parse_document(content) FROM pdf_volume;
```

这一条命令处理所有 PDF，并创建一个包含解析内容和合并文本的结构化表，为下一步做好准备。

请注意，我们无需配置任何基础设施、网络或外部 LLM 或 GPU 调用——Databricks 托管 GPU 和模型后端，无需额外配置即可实现可靠、可扩展的吞吐量。与收取许可费的平台不同，Databricks 采用基于计算的定价模式——意味着您只需为使用的资源付费。这允许通过生产流水线中的并行化和函数级定制实现强大的成本优化。

### 步骤 2：使用智能体模块进行迭代式信息提取

一旦获得文本，下一个目标就是提取特定的结构化字段。例如：缺陷是什么？NDA ID 是什么？拒绝引文是什么？这正是 AI 工程师和业务领域专家需要紧密协作的地方。领域专家知道要查找什么，可以与工程师合作，快速指导模型如何找到它。

**智能体模块：信息提取** 为此工作流提供了一个实时协作的用户界面。

如下图所示，该界面允许技术负责人和业务领域专家协同工作：

1.  **业务领域专家** 提供需要提取的特定字段（例如，`deficiency_summary_paragraphs`、`NDA_ID`、`FDA_Rejection_Citing`）。
2.  **信息提取智能体** 将这些需求转化为有效的提示词——这些可编辑的指南位于右侧面板。
3.  **技术负责人和业务领域专家** 都可以立即在中央面板看到 JSON 输出，并验证模型是否从左边的文档中正确提取了信息。在此，任何一方都可以重新表述提示词以确保提取的准确性。

这种即时反馈循环是成功的关键。如果某个字段提取不正确，团队可以调整提示词、添加新字段或优化指令，并在几秒钟内看到结果。这种多位专家在单一界面中协作的迭代过程，正是成功的 AI 项目与那些在孤岛中失败的项目之间的区别。

### 步骤 3：评估和验证智能体

在步骤 2 中，我们构建了一个智能体，从“感觉检查”来看，在迭代开发过程中似乎是正确的。但是，当处理新数据时，如何确保高准确性和可扩展性？修复一个文档的提示词更改可能会破坏其他十个文档。这时，正式评估——智能体模块工作流中一个关键且内置的部分——就派上用场了。

此步骤是您的质量关卡，它提供了两种强大的验证方法：

**方法 A：使用真实基准标签进行评估（黄金标准）**

与任何数据科学项目一样，缺乏适当的领域知识，AI 也会在真空中失败。领域专家投入精力提供一个“黄金集”（即真实基准、带标签的数据集），其中包含人工提取并经过人工验证的正确相关信息，这对于确保该解决方案能推广到新文件和格式大有裨益。这是因为带标签的键值对能快速帮助智能体调整出高质量的提示词，从而产生与业务相关且准确的提取结果。让我们深入了解智能体模块如何使用这些标签来正式评估您的智能体。

在智能体模块用户界面中，提供真实基准测试集，后台的智能体模块会在测试文档上运行。用户界面将并排显示您的智能体提取的输出与“正确”的标签答案。

用户界面为**每个提取字段提供清晰的准确度分数**，让您能在更改提示词时**立即发现性能倒退**。通过智能体模块，您能**获得业务层面的信心**，确信智能体**表现达到或超过人类水平的准确度**。

**方法 B：没有标签？使用 LLM-as-a-Judge**

但是，如果您是从零开始，没有任何真实基准标签怎么办？这是一个常见的“冷启动”问题。

智能体模块评估套件提供了一个强大的解决方案：**LLM-as-a-Judge**。Databricks 提供了一套评估框架，智能体模块将利用评估模型作为公正的评估者。“法官”模型会接收到原始文档文本和每个文档的一组字段提示词。“法官”的角色是生成一个“预期”响应，然后将其与智能体提取的输出进行对比评估。

LLM-as-a-Judge 让您能够获得可扩展、高质量的评估分数，并且请注意，它也可以在生产中使用，以确保智能体在面对生产环境的变化和规模时保持可靠性和泛化能力。更多相关内容将在未来的博客中介绍。

### 步骤四：在您的ETL流水线中集成Agent与ai_query()

至此，您已在步骤二中构建了您的Agent（智能体），并在步骤三中验证了其准确性，现在可以放心地将提取功能集成到您的工作流中。只需单击一下，您就可以将Agent部署为无服务器模型端点——您的提取逻辑即刻成为一个简单、可扩展的函数。

为此，您可以在SQL中使用`ai_query()`函数，将此逻辑应用于新到达的文档。`ai_query()`函数允许您在端到端的ETL数据流水线中直接、无缝地调用任何模型服务端点。

这样一来，Databricks Lakeflow Jobs确保您拥有一个完全自动化、生产级的ETL流水线。您的Databricks作业会处理到达云存储的原始PDF文件，解析它们，使用您的高质量Agent提取结构化见解，并将其存入表中，以供分析、报告或在下游Agent应用程序的检索中引用。

Databricks是下一代AI平台——它打破了深度技术团队与掌握构建有意义AI所需背景知识的领域专家之间的壁垒。AI的成功不仅仅是模型或基础设施；它更是工程师与领域专家之间紧密、迭代的协作，双方相互完善彼此的想法。Databricks为团队提供了一个共同开发、快速实验、负责任治理并将科学带回数据科学的统一环境。

Agent Bricks正是这一愿景的体现。通过`ai_parse_document()`解析非结构化内容，通过Agent Bricks：信息提取的协作设计界面加速高质量提取，并通过`ai_query()`在生产级流水线中应用解决方案，团队能够比以往更快地将数百万混乱的PDF文件转化为经过验证的见解。

在我们的下一篇博客中，我们将展示如何利用这些提取的见解，构建一个生产级的聊天Agent，使其能够回答自然语言问题，例如：“肿瘤药物最常见的生产就绪问题是什么？”

- **了解更多**：阅读`ai_parse_document()`、Agent Bricks：信息提取和`ai_query()`的官方文档。
- **开始使用**：立即注册Databricks免费试用，构建您自己的AI驱动解决方案。


## 不错过任何Databricks动态

![自动化工作流如何革新制造业](/images/posts/40d9e92dd935.png)

![自动化工作流如何革新制造业](/images/posts/40d9e92dd935.png)

![自动化工作流如何革新制造业](/images/posts/40d9e92dd935.png)

2024年11月27日 / 阅读6分钟

#### 自动化工作流如何革新制造业

![通过Databricks与The Virtue Foundation提升全球健康水平](/images/posts/596b5527cd9c.png)

![通过Databricks与The Virtue Foundation提升全球健康水平](/images/posts/596b5527cd9c.png)

![通过Databricks与The Virtue Foundation提升全球健康水平](/images/posts/596b5527cd9c.png)

医疗保健与生命科学

2024年12月19日 / 阅读5分钟

#### 通过Databricks与The Virtue Foundation提升全球健康水平

![databricks logo](/images/posts/443a5359ee28.png)

![databricks logo](/images/posts/443a5359ee28.png)

![databricks logo](/images/posts/443a5359ee28.png)

- 面向高管
- 面向初创公司
- Lakehouse架构
- Mosaic研究

- 客户案例

- 云提供商
- 技术合作伙伴
- 数据合作伙伴
- 基于Databricks构建
- 咨询与系统集成商
- C&SI合作伙伴计划
- 合作伙伴解决方案

- 面向高管
- 面向初创公司
- Lakehouse架构
- Mosaic研究

- 客户案例

- 云提供商
- 技术合作伙伴
- 数据合作伙伴
- 基于Databricks构建
- 咨询与系统集成商
- C&SI合作伙伴计划
- 合作伙伴解决方案

- 平台概览
- 共享
- 治理
- 人工智能
- 商业智能
- 数据库
- 数据管理
- 数据仓库
- 数据工程
- 数据科学
- 应用开发

- 定价概览
- 定价计算器

- 市场
- IDE集成
- 合作伙伴连接

- 平台概览
- 共享
- 治理
- 人工智能
- 商业智能
- 数据库
- 数据管理
- 数据仓库
- 数据工程
- 数据科学
- 应用开发

- 定价概览
- 定价计算器

- 市场
- IDE集成
- 合作伙伴连接

- 通信
- 金融服务
- 医疗保健与生命科学
- 制造业
- 媒体与娱乐
- 公共部门
- 零售
- 查看全部

- 网络安全
- 市场营销

- 通信
- 金融服务
- 医疗保健与生命科学
- 制造业
- 媒体与娱乐
- 公共部门
- 零售
- 查看全部

- 网络安全
- 市场营销

- 培训
- 认证
- 免费版
- 大学联盟
- Databricks学院登录

- Data + AI峰会
- Data + AI全球巡展
- 数据智能日
- 活动日历

- Databricks博客
- Databricks Mosaic研究博客
- Data Brew播客
- 数据与AI冠军播客

- 培训
- 认证
- 免费版
- 大学联盟
- Databricks学院登录

- Data + AI峰会
- Data + AI全球巡展
- 数据智能日
- 活动日历

- Databricks博客
- Databricks Mosaic研究博客
- Data Brew播客
- 数据与AI冠军播客

- 关于我们
- 我们的团队
- Databricks Ventures
- 联系我们

- 开放职位
- 在Databricks工作

- 奖项与认可
- 新闻中心

- 关于我们
- 我们的团队
- Databricks Ventures
- 联系我们

- 开放职位
- 在Databricks工作

- 奖项与认可
- 新闻中心

![databricks logo](/images/posts/443a5359ee28.png)

![databricks logo](/images/posts/443a5359ee28.png)

![databricks logo](/images/posts/443a5359ee28.png)

Databricks Inc.160 Spear Street, 15th FloorSan Francisco, CA 941051-866-330-0121


查看Databricks的职业生涯


© Databricks 2026。保留所有权利。Apache、Apache Spark、Spark、Spark徽标、Apache Iceberg、Iceberg以及Apache Iceberg徽标是Apache Software Foundation的商标。

- 隐私声明
- |使用条款
- |现代奴隶制声明
- |加州隐私
- |您的隐私选择

---

> 本文由AI自动翻译，原文链接：[Building a Regulatory Risk Copilot with Databricks Agent Bricks (Part 1: Information Extraction)](https://www.databricks.com/blog/building-regulatory-risk-copilot-databricks-agent-bricks-part-1-information-extraction)
> 
> 翻译时间：2026-01-22 04:57
