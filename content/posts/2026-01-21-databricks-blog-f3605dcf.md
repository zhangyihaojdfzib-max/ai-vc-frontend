---
title: 基于Databricks Agent Bricks构建监管风险Copilot（一）：信息提取
title_original: 'Building a Regulatory Risk Copilot with Databricks Agent Bricks (Part
  1: Information Extraction)'
date: '2026-01-21'
source: Databricks Blog
source_url: https://www.databricks.com/blog/building-regulatory-risk-copilot-databricks-agent-bricks-part-1-information-extraction
author: ''
summary: 本文是系列文章的第一部分，探讨如何利用Databricks的Agent Bricks技术构建一个监管风险Copilot（智能副驾），重点聚焦于信息提取环节。文章首先介绍了选择Databricks作为技术平台的原因，并详细列举了其平台架构、产品矩阵、行业解决方案及丰富的生态资源，为后续构建面向金融等强监管行业的智能风险分析工具奠定了技术基础。
categories:
- AI产品
tags:
- Databricks
- Agent Bricks
- 监管科技
- 信息提取
- AI Copilot
draft: false
translated_at: '2026-01-22T04:57:23.887564'
---

# 使用 Databricks Agent Bricks 构建监管风险 Copilot（第一部分：信息提取）

## 了解如何使用 Databricks AI 函数和 Agent Bricks 将非结构化的 FDA 拒绝信转化为可操作的见解。

发布日期：2026年1月21日

作者：Guanyu Chen 和 Diego Malaver

-   -   -

-   协作提取见解：了解如何使用信息提取 Agent Bricks，让业务专家和AI工程师能够实时协作定义、测试和完善结构化数据的提取。


2025年7月，美国FDA公开发布了首批 **200多封完全回应函**，这些是解释药物和生物制品申请为何未能在首次提交时获得批准的决策信函，标志着透明度的重大转变。这是首次，申办方、临床医生和数据团队可以通过集中、可下载的公开FDA PDF文件，分析该机构关于临床、CMC、安全性、标签和生物等效性等方面缺陷的官方表述，从而洞察整个行业。

随着FDA持续发布新的CRL，能够从此类及其他非结构化数据中快速生成见解，并添加到其内部情报/数据中，将成为一项重要的竞争优势。能够有效利用这些以PDF、文档、图像等形式存在的非结构化数据见解的组织，可以降低自身提交的风险，识别常见陷阱，并最终加速其上市进程。挑战在于，这些数据与许多其他监管数据一样，被锁定在PDF中，众所周知，大规模处理PDF非常困难。

这正是Databricks旨在解决的那类挑战。本博客将演示如何使用Databricks最新的AI工具来加速提取困在PDF中的关键信息——将这些关键信函转化为可操作情报的来源。

## 成功应用AI的关键要素

鉴于所需的技术深度，工程师通常孤立地主导开发，导致AI构建与业务需求之间存在巨大鸿沟。当领域专家最终看到结果时，往往并非他们所需。反馈循环太慢，项目失去了动力。

在早期测试阶段，建立基准至关重要。许多情况下，替代方案会浪费数月时间却缺乏真实基准，只能依赖主观观察和“感觉”。这种缺乏实证证据的情况会阻碍进展。相反，Databricks 工具提供开箱即用的评估功能，让客户能立即聚焦质量——通过迭代框架获得提取结果的数学置信度。AI 的成功需要一种建立在快速、协作迭代基础上的新方法。

Databricks 提供了一个统一的平台，业务领域专家和 AI 工程师可以在此实时协作，构建、测试和部署生产就绪的智能体。该框架建立在三个关键原则之上：

- **紧密的业务与技术对齐**：领域专家和技术负责人在同一用户界面中协作，获得即时反馈，取代缓慢的邮件循环。
- **真实基准评估**：业务定义的“真实基准”标签直接内置于工作流中，用于正式评分。

这种统一的平台方法，正是将原型转变为可信赖、生产就绪的 AI 系统的关键。让我们来逐步了解构建它的四个步骤。

## 从 PDF 到生产：四步指南

在非结构化数据上构建生产级 AI 系统，不仅需要一个好模型，更需要一个无缝、迭代且协作的工作流。信息提取智能体模块，结合 Databricks 内置的 AI 函数，使得解析文档、提取关键信息并使整个过程可操作化变得容易。这种方法使团队能够更快地推进并交付更高质量的结果。下面分解构建过程的四个关键步骤。

### 步骤 1：使用 `ai_parse_document()` 将非结构化 PDF 解析为文本

第一个障碍是从 PDF 中获取干净的文本。CRL 可能具有复杂的布局，包含页眉、页脚、表格、图表，跨越多页和多栏。简单的文本提取通常会失败，产生不准确且无法使用的输出。

与那些难以处理布局的脆弱单点解决方案不同，`ai_parse_document()` 利用最先进的多模态 AI 来理解文档结构——准确地按阅读顺序提取文本，保留不规则的表格层级结构，并为图表生成标题。

此外，Databricks 在文档智能方面提供了一项优势：能够可靠地扩展以处理企业级体量的复杂 PDF，成本比主要竞争对手低 3-5 倍。团队无需担心文件大小限制，其底层的 OCR 和 VLM 确保能准确解析历史上那些包含密集、不规则图表及其他挑战性结构的“问题 PDF”。

过去需要众多数据科学家跨多个供应商配置和维护定制化解析堆栈的工作，现在只需一个原生的 SQL 函数即可完成——让团队能够并行处理数百万份文档，而不会出现困扰那些可扩展性较差的解析器的故障模式。

开始使用，首先将 UC Volume 指向包含 PDF 的云存储。在我们的示例中，我们将 SQL 函数指向由 Volume 管理的 CRL PDF：

```sql
SELECT ai_parse_document(content) FROM pdf_volume;
```

这一条命令处理所有 PDF，并创建一个包含解析内容和合并文本的结构化表，为下一步做好准备。

请注意，我们无需配置任何基础设施、网络或外部 LLM 或 GPU 调用——Databricks 托管 GPU 和模型后端，无需额外配置即可实现可靠、可扩展的吞吐量。与收取许可费的平台不同，Databricks 采用基于计算的定价模式——意味着您只需为使用的资源付费。这允许通过生产流水线中的并行化和函数级定制实现强大的成本优化。

### 步骤 2：使用智能体模块进行迭代式信息提取

一旦获得文本，下一个目标就是提取特定的结构化字段。例如：缺陷是什么？NDA ID 是什么？拒绝引文是什么？这正是 AI 工程师和业务领域专家需要紧密协作的地方。领域专家知道要查找什么，可以与工程师合作，快速指导模型如何找到它。

**智能体模块：信息提取** 为此工作流提供了一个实时协作的用户界面。

如下图所示，该界面允许技术负责人和业务领域专家协同工作：

1.  **业务领域专家** 提供需要提取的特定字段（例如，`deficiency_summary_paragraphs`、`NDA_ID`、`FDA_Rejection_Citing`）。
2.  **信息提取智能体** 将这些需求转化为有效的提示词——这些可编辑的指南位于右侧面板。
3.  **技术负责人和业务领域专家** 都可以立即在中央面板看到 JSON 输出，并验证模型是否从左边的文档中正确提取了信息。在此，任何一方都可以重新表述提示词以确保提取的准确性。

这种即时反馈循环是成功的关键。如果某个字段提取不正确，团队可以调整提示词、添加新字段或优化指令，并在几秒钟内看到结果。这种多位专家在单一界面中协作的迭代过程，正是成功的 AI 项目与那些在孤岛中失败的项目之间的区别。

### 步骤 3：评估和验证智能体

在步骤 2 中，我们构建了一个智能体，从“感觉检查”来看，在迭代开发过程中似乎是正确的。但是，当处理新数据时，如何确保高准确性和可扩展性？修复一个文档的提示词更改可能会破坏其他十个文档。这时，正式评估——智能体模块工作流中一个关键且内置的部分——就派上用场了。

此步骤是您的质量关卡，它提供了两种强大的验证方法：

**方法 A：使用真实基准标签进行评估（黄金标准）**

与任何数据科学项目一样，缺乏适当的领域知识，AI 也会在真空中失败。领域专家投入精力提供一个“黄金集”（即真实基准、带标签的数据集），其中包含人工提取并经过人工验证的正确相关信息，这对于确保该解决方案能推广到新文件和格式大有裨益。这是因为带标签的键值对能快速帮助智能体调整出高质量的提示词，从而产生与业务相关且准确的提取结果。让我们深入了解智能体模块如何使用这些标签来正式评估您的智能体。

在智能体模块用户界面中，提供真实基准测试集，后台的智能体模块会在测试文档上运行。用户界面将并排显示您的智能体提取的输出与“正确”的标签答案。

用户界面为**每个提取字段提供清晰的准确度分数**，让您能在更改提示词时**立即发现性能倒退**。通过智能体模块，您能**获得业务层面的信心**，确信智能体**表现达到或超过人类水平的准确度**。

**方法 B：没有标签？使用 LLM-as-a-Judge**

但是，如果您是从零开始，没有任何真实基准标签怎么办？这是一个常见的“冷启动”问题。

智能体模块评估套件提供了一个强大的解决方案：**LLM-as-a-Judge**。Databricks 提供了一套评估框架，智能体模块将利用评估模型作为公正的评估者。“法官”模型会接收到原始文档文本和每个文档的一组字段提示词。“法官”的角色是生成一个“预期”响应，然后将其与智能体提取的输出进行对比评估。

LLM-as-a-Judge 让您能够获得可扩展、高质量的评估分数，并且请注意，它也可以在生产中使用，以确保智能体在面对生产环境的变化和规模时保持可靠性和泛化能力。更多相关内容将在未来的博客中介绍。

### 步骤四：在您的ETL流水线中集成Agent与ai_query()

至此，您已在步骤二中构建了您的Agent（智能体），并在步骤三中验证了其准确性，现在可以放心地将提取功能集成到您的工作流中。只需单击一下，您就可以将Agent部署为无服务器模型端点——您的提取逻辑即刻成为一个简单、可扩展的函数。

为此，您可以在SQL中使用`ai_query()`函数，将此逻辑应用于新到达的文档。`ai_query()`函数允许您在端到端的ETL数据流水线中直接、无缝地调用任何模型服务端点。

这样一来，Databricks Lakeflow Jobs确保您拥有一个完全自动化、生产级的ETL流水线。您的Databricks作业会处理到达云存储的原始PDF文件，解析它们，使用您的高质量Agent提取结构化见解，并将其存入表中，以供分析、报告或在下游Agent应用程序的检索中引用。

Databricks是下一代AI平台——它打破了深度技术团队与掌握构建有意义AI所需背景知识的领域专家之间的壁垒。AI的成功不仅仅是模型或基础设施；它更是工程师与领域专家之间紧密、迭代的协作，双方相互完善彼此的想法。Databricks为团队提供了一个共同开发、快速实验、负责任治理并将科学带回数据科学的统一环境。

Agent Bricks正是这一愿景的体现。通过`ai_parse_document()`解析非结构化内容，通过Agent Bricks：信息提取的协作设计界面加速高质量提取，并通过`ai_query()`在生产级流水线中应用解决方案，团队能够比以往更快地将数百万混乱的PDF文件转化为经过验证的见解。

在我们的下一篇博客中，我们将展示如何利用这些提取的见解，构建一个生产级的聊天Agent，使其能够回答自然语言问题，例如：“肿瘤药物最常见的生产就绪问题是什么？”

- **开始使用**：立即注册Databricks免费试用，构建您自己的AI驱动解决方案。

##


> 本文由AI自动翻译，原文链接：[Building a Regulatory Risk Copilot with Databricks Agent Bricks (Part 1: Information Extraction)](https://www.databricks.com/blog/building-regulatory-risk-copilot-databricks-agent-bricks-part-1-information-extraction)
> 
> 翻译时间：2026-01-22 04:57
