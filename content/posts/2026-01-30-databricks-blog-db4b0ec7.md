---
title: 高效AI治理：平衡创新速度与风险管控
title_original: Getting AI Governance Right Without Slowing Everything Down
date: '2026-01-30'
source: Databricks Blog
source_url: https://www.databricks.com/blog/getting-ai-governance-right-without-slowing-everything-down
author: ''
summary: 本文基于Databricks高管的访谈，探讨企业在规模化应用AI时面临的治理挑战。核心观点认为，有效的AI治理不应成为创新的阻碍，而应通过强化技术可观测性、借鉴成熟的数据管理原则以及建立分散式指导体系来加速发展。文章强调将AI智能体视为工程规范而非全新概念，并指出成功的组织能在过度自由与过度管控之间找到平衡，通过统一治理数据与模型来维持长期价值。
categories:
- AI产品
tags:
- AI治理
- 可观测性
- 智能体
- 工程规范
- 风险管理
draft: false
translated_at: '2026-01-31T04:04:46.085664'
---

随着企业从AI实验迈向规模化应用，治理已成为董事会层面的重要议题。对管理者而言，挑战已不再是治理是否重要，而是如何设计治理体系，在保障速度、创新与信任之间取得平衡。

为探讨这种平衡在实践中的体现，我采访了Databricks产品高级副总裁David Meyer。通过与各行业、各地区客户的密切合作，David清晰地洞察到哪些领域正在取得实际进展，哪些环节遭遇瓶颈，以及当前的治理决策如何塑造未来的可能性。

我们对话中最突出的是他的务实态度。David没有将AI治理视为全新或抽象的概念，而是始终回归基本原则：工程规范、可见性与责任归属。

## 将AI治理作为加速发展的途径

**Catherine Brown：** 您与各行业客户有大量深入交流。在规划未来一两年时，领导者对治理的思考方式正在发生哪些变化？

**David Meyer：** 我观察到最明显的趋势是：治理挑战既是组织层面的，也是技术层面的，且两者紧密相连。在组织层面，领导者正试图找到让团队快速行动而不引发混乱的方法。

陷入困境的组织往往过度规避风险。他们集中所有决策权，增设繁重的审批流程，无意中拖慢了所有进程。讽刺的是，这通常会导致更糟的结果而非更安全。

有趣的是，强大的技术治理实际上能释放组织灵活性。当领导者能真正掌握正在使用的数据、模型和Agent（智能体）时，他们无需手动控制每个决策。由于了解整个系统的运行状况，他们可以给予团队更多自由。实践中，这意味着团队无需为每个模型或用例申请许可——访问权限、审计和更新由中央统一处理，治理通过设计而非特例来实现。

**Catherine Brown：** 许多组织似乎困在"行动过快"和"全面管控"之间。您看到哪些企业找到了平衡点？

**David Meyer：** 我通常看到两种极端。

一端是那些宣称"AI优先"并鼓励全员自由构建的公司。这在短期内有效——人们行动迅速，热情高涨。但转眼间，你会突然发现公司拥有成千上万个Agent（智能体），却没有真正的资产清单，不清楚它们的成本，也不了解生产环境中实际运行的情况。

另一端是试图预先控制一切的组织。他们设置单一的审批瓶颈，结果导致几乎没有任何有意义的项目得以部署。这些团队通常持续感到落后于人的压力。

做得好的企业往往介于两者之间。在每个业务部门内，他们识别出具备AI素养并能指导本地实验的人员。这些人员在组织内交流经验，分享有效方案，并精简推荐工具集。将工具从数十种减少到两三种，其效果远超人们预期。

## Agent（智能体）并非想象中那样全新

**Catherine：** 您之前提到的一个观点令人印象深刻：您认为Agent（智能体）并不像许多人假设的那样具有根本性差异。

**David：** 没错。Agent（智能体）感觉新颖，但其许多特性其实非常熟悉。

它们持续产生成本，扩大安全攻击面，并与其他系统连接——这些都是我们曾经处理过的问题。

我们已经知道如何治理数据资产和API，同样的原则在此同样适用。如果你不知道某个Agent（智能体）存在于何处，就无法关闭它。如果Agent（智能体）涉及敏感数据，就需要有人对此负责。许多组织误以为Agent（智能体）系统需要全新的规则手册。实际上，如果借鉴数据管理中经过验证的生命周期和治理实践，你就已经解决了大部分问题。

**Catherine：** 如果有高管向您咨询简单的切入点，您会如何建议？

**David：** 我会从可观测性入手。

有意义的AI几乎总是依赖于专有数据。你需要了解正在使用哪些数据、涉及哪些模型，以及这些组件如何组合形成Agent（智能体）。

许多公司跨不同云平台使用多个模型供应商。当这些模型被孤立管理时，理解成本、质量或性能就变得非常困难。当数据和模型被统一治理时，团队才能更有效地测试、比较和改进。

由于生态系统变化极快，这种可观测性显得尤为重要。领导者需要能够评估新模型和新方法，而无需在每次变化时重建整个技术栈。

**Catherine：** 组织在哪些方面进展迅速？又常在哪些环节陷入困境？

**David：** 基于知识的Agent（智能体）通常部署最快。将其指向一组文档，人们就能立即提问并获得答案，这很强大。但问题在于，许多这类系统会随时间推移而退化：内容变更、索引过时、质量下降——大多数团队没有为此制定计划。

维持价值意味着超越初始部署进行思考。你需要建立能持续更新数据、评估输出并随时间提升准确性的系统。缺乏这些，许多组织会经历最初几个月的活跃期，随后使用量和影响力逐渐下降。

## 将Agent（智能体）AI视为工程规范

**Catherine：** 在实践中，领导者如何平衡速度与信任、控制？

**David：** 做得好的组织将Agent（智能体）AI视为工程问题。他们运用与软件开发相同的规范：持续测试、监控和部署。故障是预期内的。目标不是防止所有问题，而是限制影响范围并快速修复。当团队能做到这些时，他们就能以更快的速度和更强的信心前进。如果从未出现任何问题，你可能过于保守了。

**Catherine：** 关于信任和透明度的期望如何演变？

**David：** 信任并非源于假设系统完美无缺，而是来自知晓问题发生后的处理过程。你需要可追溯性——使用了什么数据、涉及哪个模型、谁与系统交互。当具备这种可审计性时，你才能承担更多实验风险。

大型分布式系统一直是这样运行的：优化恢复能力而非追求零故障。随着AI系统自主性增强，这种思维方式变得更加重要。

## 构建AI治理战略

与其将Agent（智能体）AI视为与过去的彻底决裂，不如将其视为企业已掌握的管理规范的延伸。对于思考下一步关键举措的高管而言，三大主题浮出水面：

- **利用治理赋能速度，而非限制速度。** 最强大的组织建立基础控制措施，使团队能在不丧失可见性或问责制的情况下更快行动。
- **将熟悉的工程和数据实践应用于Agent（智能体）。** 资产清单、生命周期管理和可追溯性对Agent（智能体）的重要性不亚于对数据和API的重要性。
- **将AI视为生产系统，而非一次性发布。** 持续价值取决于持续评估、新鲜数据以及快速检测和纠正问题的能力。

这些观点共同指向一个清晰的结论：持久的AI价值并非来自追逐最新工具或全面管控，而是来自建立能让组织自信地学习、适应和扩展的基础。

要了解构建有效运营模式的更多信息，请下载[Databricks AI成熟度模型](https://www.databricks.com/resources/ebook/databricks-ai-maturity-model)。

## 下一步是什么？

---

> 本文由AI自动翻译，原文链接：[Getting AI Governance Right Without Slowing Everything Down](https://www.databricks.com/blog/getting-ai-governance-right-without-slowing-everything-down)
> 
> 翻译时间：2026-01-31 04:04
