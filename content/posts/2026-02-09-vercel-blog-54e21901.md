---
title: Vercel如何为编程智能体构建AEO追踪系统
title_original: How we built AEO tracking for coding agents - Vercel
date: '2026-02-09'
source: Vercel Blog
source_url: https://vercel.com/blog/how-we-built-aeo-tracking-for-coding-agents
author: ''
summary: 本文介绍了Vercel为追踪编程智能体（Coding Agent）的AI引擎优化（AEO）而构建的系统。文章指出，编程智能体与标准聊天模型不同，它们通常在完整的开发环境中运行，会执行网络搜索并调用工具，这带来了执行隔离和可观测性两大挑战。Vercel通过其沙箱（Sandbox）技术，为每个智能体运行创建临时的MicroVM，遵循从创建、安装CLI、注入凭证、运行、捕获日志到清理的六步生命周期，从而安全、统一地追踪和分析不同编程智能体如何发现、解释和引用其网站内容。
categories:
- AI基础设施
tags:
- AEO
- 编程智能体
- Vercel
- AI Gateway
- 沙箱
draft: false
translated_at: '2026-02-10T04:37:43.316772'
---

人工智能已经改变了人们获取信息的方式。对于企业而言，这意味着理解LLM（大语言模型）如何搜索和总结其网络内容至关重要。

我们正在构建一个AI引擎优化（AEO）系统，以追踪模型如何发现、解释和引用Vercel及我们的网站。

![对于我们营销团队的最终用户而言，不同编程Agent（智能体）的响应格式始终保持一致。](/images/posts/76ab9e650557.jpg)

这最初只是一个专注于标准聊天模型的雏形，但我们很快意识到这还不够。为了全面了解可见性，我们需要追踪编程Agent（智能体）。

对于标准模型，追踪相对直接。我们使用AI Gateway向数十个流行模型（例如GPT、Gemini和Claude）发送提示词，并分析它们的响应、搜索行为和引用的来源。

然而，编程Agent（智能体）的行为方式大不相同。许多Vercel用户在终端或IDE中处理项目时，会通过它们与AI交互。在早期抽样中，我们发现编程Agent（智能体）在大约20%的提示词中会执行网络搜索。由于这些搜索发生在真实的开发工作流程中，因此评估响应质量和来源准确性尤为重要。

衡量编程Agent（智能体）的AEO需要一种不同于纯模型测试的方法。编程Agent（智能体）并非设计为响应单个API调用。它们被构建为在项目内部运行，并期望一个完整的开发环境，包括文件系统、shell访问和包管理器。

这带来了一系列新的挑战：

1.  执行隔离：如何安全地运行一个可以执行任意代码的自主Agent（智能体）？
2.  可观测性：当每个Agent（智能体）都有自己的对话记录格式、工具调用约定和输出结构时，如何捕获Agent（智能体）的行为？

执行隔离：如何安全地运行一个可以执行任意代码的自主Agent（智能体）？

可观测性：当每个Agent（智能体）都有自己的对话记录格式、工具调用约定和输出结构时，如何捕获Agent（智能体）的行为？

## 编程Agent（智能体）的AEO生命周期

编程Agent（智能体）通常在一定程度上通过CLI而非API进行访问。即使你只是发送提示词和捕获响应，仍然需要在完整的运行时环境中安装和执行CLI。

Vercel Sandbox通过提供可在几秒钟内启动的临时Linux MicroVM来解决这个问题。无论使用何种CLI，每个Agent（智能体）运行都会获得自己的沙箱，并遵循相同的六步生命周期。

1.  创建沙箱。使用正确的运行时（Node 24、Python 3.13等）和超时时间启动一个新的MicroVM。超时时间是一个硬性上限，因此如果Agent（智能体）挂起或循环，沙箱会终止它。
2.  安装Agent（智能体）CLI。每个Agent（智能体）都作为一个npm包（例如`@anthropic-ai/claude-code`、`@openai/codex`等）提供。沙箱将其全局安装，使其可作为shell命令使用。
3.  注入凭证。我们不为每个Agent（智能体）提供直接的提供商API密钥，而是设置环境变量，将所有LLM（大语言模型）调用通过Vercel AI Gateway进行路由。这为我们提供了跨所有Agent（智能体）的统一日志记录、速率限制和成本跟踪，即使每个Agent（智能体）使用不同的底层提供商（尽管系统也允许使用直接的提供商密钥）。
4.  使用提示词运行Agent（智能体）。这是每个Agent（智能体）唯一不同的步骤。每个CLI都有自己的调用模式、标志和配置格式。但从沙箱的角度来看，它只是一个shell命令。
5.  捕获对话记录。Agent（智能体）完成后，我们提取其行为记录，包括它调用了哪些工具、是否搜索了网络以及在响应中推荐了什么。这是特定于Agent（智能体）的（下文会介绍）。
6.  清理。停止沙箱。如果出现任何问题，`catch`块确保无论如何都会停止沙箱，以免资源泄漏。

创建沙箱。使用正确的运行时（Node 24、Python 3.13等）和超时时间启动一个新的MicroVM。超时时间是一个硬性上限，因此如果Agent（智能体）挂起或循环，沙箱会终止它。

安装Agent（智能体）CLI。每个Agent（智能体）都作为一个npm包（例如`@anthropic-ai/claude-code`、`@openai/codex`等）提供。沙箱将其全局安装，使其可作为shell命令使用。

注入凭证。我们不为每个Agent（智能体）提供直接的提供商API密钥，而是设置环境变量，将所有LLM（大语言模型）调用通过Vercel AI Gateway进行路由。这为我们提供了跨所有Agent（智能体）的统一日志记录、速率限制和成本跟踪，即使每个Agent（智能体）使用不同的底层提供商（尽管系统也允许使用直接的提供商密钥）。

使用提示词运行Agent（智能体）。这是每个Agent（智能体）唯一不同的步骤。每个CLI都有自己的调用模式、标志和配置格式。但从沙箱的角度来看，它只是一个shell命令。

捕获对话记录。Agent（智能体）完成后，我们提取其行为记录，包括它调用了哪些工具、是否搜索了网络以及在响应中推荐了什么。这是特定于Agent（智能体）的（下文会介绍）。

清理。停止沙箱。如果出现任何问题，`catch`块确保无论如何都会停止沙箱，以免资源泄漏。

在代码中，生命周期如下所示。

```
1import { Sandbox } from "@vercel/sandbox";2
34sandbox = await Sandbox.create({5  resources: { vcpus: 2 },6  timeout:  10 * 60 * 10007});8
910for (const setupCmd of agent.setupCommands) {11  await sandbox.runCommand("sh", ["-c", setupCmd]);12}13
1415
1617const fullCommand = `AI_GATEWAY_API_KEY='${aiGatewayKey}' ${agent.command}`;18const result = await sandbox.runCommand("sh", ["-c", fullCommand]);19
20
2122
2324await sandbox.stop();
```

### 将Agent（智能体）定义为配置

由于生命周期是统一的，每个Agent（智能体）都可以定义为一个简单的配置对象。向系统添加新的Agent（智能体）意味着添加一个新条目，沙箱编排会处理其他所有事情。

```
1export const AGENTS: Agent[] = [2  {3    id: "anthropic/claude-code",4    name: "Claude Code",5    setupCommands: ["npm install -g @anthropic-ai/claude-code"],6    buildCommand: (prompt) => `echo '${prompt}' | claude --print`,7  },8  {9    id: "openai/codex",10    name: "OpenAI Codex",11    setupCommands: ["npm install -g @openai/codex"],12    buildCommand: (prompt) => `codex exec -y -S '${prompt}'`,13  },14];
```

`runtime`决定了MicroVM的基础镜像。大多数Agent（智能体）在Node上运行，但系统也支持Python运行时。

`setupCommands`是一个数组，因为有些Agent（智能体）需要的不仅仅是全局安装。例如，Codex还需要一个TOML配置文件写入`~/.codex/config.toml`。

`buildCommand`是一个函数，它接收提示词并返回要运行的shell命令。每个Agent（智能体）的CLI都有自己的标志和调用风格。

## 使用AI Gateway进行路由

我们希望使用AI Gateway来集中管理成本和日志。这需要通过沙箱内的环境变量覆盖提供商的基础URL。Agent（智能体）本身并不知道这种情况，它们就像直接与其提供商通信一样运行。

以下是Claude Code的示例：

```
1const claudeResult = await sandbox.runCommand(2  'claude',3  ['-p', '-m', options.model, '-y', options.prompt]4  {5    env: {6      ANTHROPIC_BASE_URL: AI_GATEWAY.baseUrl,7      ANTHROPIC_AUTH_TOKEN: options.apiKey,8      ANTHROPIC_API_KEY: '',  9    },10  }11);
```

`ANTHROPIC_BASE_URL`指向AI Gateway而不是`api.anthropic.com`。Agent（智能体）的HTTP调用会发送到Gateway，由Gateway代理到Anthropic。

`ANTHROPIC_API_KEY`被故意设置为空字符串——Gateway通过其自身的令牌进行身份验证，因此Agent（智能体）不需要（也没有）直接的提供商密钥。

同样的模式也适用于Codex（覆盖`OPENAI_BASE_URL`）以及任何其他尊重基础URL环境变量的Agent（智能体）。也可以直接使用提供商API凭证。

## 对话记录格式问题

当一个Agent（智能体）在其沙箱中运行结束后，我们会得到一份原始记录，其中记载了它执行的所有操作。

问题在于，每个Agent生成的记录格式各不相同。Claude Code将JSONL文件写入磁盘。Codex将JSON流式输出到stdout。OpenCode也使用stdout，但采用了不同的模式。它们对相同的工具使用不同的名称，对消息采用不同的嵌套结构，并遵循不同的约定。

我们需要将所有记录输入到统一的品牌分析流水线中，因此我们构建了一个包含四个阶段的标准化层：

1.  记录捕获：每个Agent存储其记录的方式不同，因此此步骤是特定于Agent的。
2.  解析：每个Agent都有其自己的解析器，用于规范化工具名称，并将Agent特定的消息结构扁平化为单一的统一事件类型。
3.  丰富：共享的后处理步骤，从工具参数中提取结构化元数据（URL、命令），并规范化每个Agent对其参数命名的差异。
4.  摘要与品牌提取：将统一的事件聚合成统计数据，然后输入到用于标准模型响应的同一品牌提取流水线中。

记录捕获：每个Agent存储其记录的方式不同，因此此步骤是特定于Agent的。

解析：每个Agent都有其自己的解析器，用于规范化工具名称，并将Agent特定的消息结构扁平化为单一的统一事件类型。

丰富：共享的后处理步骤，从工具参数中提取结构化元数据（URL、命令），并规范化每个Agent对其参数命名的差异。

摘要与品牌提取：将统一的事件聚合成统计数据，然后输入到用于标准模型响应的同一品牌提取流水线中。

### 阶段 1：记录捕获

此阶段发生在沙箱仍在运行时（即上一节生命周期中的第5步）。

Claude Code将其记录作为JSONL文件写入沙箱文件系统。我们必须在Agent运行结束后找到并读取它：

```
1async function captureTranscript(sandbox) {2  const workdir = sandbox.getWorkingDirectory();3  const projectPath = workdir.replace(/\\//g, '-');4  const claudeProjectDir = `~/.claude/projects/${projectPath}`;5
6  7  const findResult = await sandbox.runShell(8    `ls -t ${claudeProjectDir}/*.jsonl 2>/dev/null | head -1`9  );10
11  const transcriptPath = findResult.stdout.trim();12  return await sandbox.readFile(transcriptPath);13}
```

Codex 和 OpenCode 都将它们的记录输出到 stdout，因此捕获过程更简单——从输出中筛选出 JSON 行：

```
1function extractTranscriptFromOutput(output: string) {2  const lines = output.split('\\n').filter(line => {3    const trimmed = line.trim();4    return trimmed.startsWith('{') && trimmed.endsWith('}');5  });6  return lines.join('\\n');7}
```

此阶段的输出对所有Agent都是相同的：一个原始的JSONL字符串。但每个JSON行的结构仍然因Agent而异，而这正是下一阶段要处理的问题。

### 阶段 2：解析工具名称和消息结构

我们为每个Agent构建了一个专用的解析器，它同时完成两件事：规范化工具名称，并将Agent特定的消息结构扁平化为单一格式的事件类型。

工具名称规范化

相同的操作在不同Agent间有不同的名称：

| 操作 | Claude Code | Codex | OpenCode |
| :--- | :--- | :--- | :--- |
| 读取文件 | read\_file | | |
| 写入文件 | Write | write\_file | write |
| 编辑文件 | StrReplace | patch\_file | patch |
| 运行命令 | | shell | |
| 搜索网络 | WebFetch | (varies) | |

每个解析器维护一个查找表，将Agent特定的名称映射到约10个规范名称：

```
1export type ToolName =2  | 'file_read' | 'file_write' | 'file_edit'3  | 'shell' | 'web_fetch' | 'web_search'4  | 'glob' | 'grep' | 'list_dir'5  | 'agent_task' | 'unknown';6
7const claudeToolMap = {8  Read: 'file_read', Write: 'file_write', Bash: 'shell',9  WebFetch: 'web_fetch', Glob: 'glob', Grep: 'grep', 10};11
12const codexToolMap = {13  read_file: 'file_read', write_file: 'file_write', shell: 'shell',14  patch_file: 'file_edit', 15};16
17const opencodeToolMap = {18  read: 'file_read', write: 'file_write', bash: 'shell',19  rg: 'grep', patch: 'file_edit', 20};
```

消息结构扁平化

除了命名之外，事件的结构也因Agent而异：

*   Claude Code 将消息嵌套在 `message` 属性内，并将 `tool_use` 块混入内容数组中。
*   Codex 在工具事件之外，还有 Responses API 生命周期事件（`thread.started`、`turn.completed`、`output_text.delta`）。
*   OpenCode 通过 `part.tool` 和 `part.state` 将工具调用和结果捆绑在同一事件中。

每个Agent的解析器处理这些结构差异，并将所有内容压缩成单一的 `TranscriptEvent` 类型：

```
1export interface TranscriptEvent {2  timestamp?: string;3  type: 'message' | 'tool_call' | 'tool_result' | 'thinking' | 'error';4  role?: 'user' | 'assistant' | 'system';5  content?: string;6  tool?: {7    name: ToolName;           8    originalName: string;     9    args?: Record<string, unknown>;10    result?: unknown;11  };12}
```

此阶段的输出是一个扁平的 `TranscriptEvent[]` 数组，无论由哪个Agent产生，其形状都是相同的。

### 阶段 3：丰富

解析之后，一个共享的后处理步骤在所有事件上运行。这从工具参数中提取结构化元数据，以便下游代码无需知道 Claude Code 将文件路径放在 `args.path` 而 Codex 使用 `args.file`：

```
1if (['file_read', 'file_write', 'file_edit'].includes(event.tool.name)) {2  const path = extractFilePath(args);3  if (path) event.tool.args = { ...args, _extractedPath: path };4}5
6if (event.tool.name === 'web_fetch') {7  const url = extractUrl(args); 8  if (url) event.tool.args = { ...args, _extractedUrl: url };9}
```

### 阶段 4：摘要与品牌提取

经过丰富的 `TranscriptEvent[]` 数组被汇总成聚合统计数据（按类型统计的工具调用总数、网络抓取次数、错误数），然后输入到用于标准模型响应的同一品牌提取流水线中。从此刻起，系统不知道也不关心数据是来自编码Agent还是模型API调用。

## 使用 Vercel Workflow 进行编排

整个流水线作为 Vercel Workflow 运行。当一个提示词被标记为"agents"类型时，工作流会并行地扩展到所有已配置的Agent，每个Agent都获得自己的沙箱：

```
1export async function probeTopicWorkflow(topicId: string) {2  "use workflow";3
4  const agentPromises = AGENTS.map((agent, index) => {5    const command = agent.buildCommand(topicData.text);6    return queryAgentAndSave(topicData.text, run.id, {7      id: agent.id,8      name: agent.name,9      setupCommands: agent.setupCommands,10      command,11    }, index + 1, totalQueries);12  });13
14  const results = await Promise.all(agentPromises);15}
```

## 我们的收获

- 编程智能体贡献了相当一部分来自网络搜索的流量。对随机抽样的提示词进行的早期测试显示，编程智能体执行搜索的频率约为20%。随着收集更多数据，我们将对智能体搜索行为建立更全面的认知，但这些结果已明确表明，为编程智能体优化内容至关重要。
- 智能体推荐的形式与模型响应不同。当编程智能体推荐工具时，它倾向于生成包含该工具的可运行代码，例如import语句、配置文件或部署脚本。推荐内容直接嵌入在输出中，而非仅以文字形式提及。
- 日志格式混乱不堪。随着智能体命令行工具快速迭代更新，这种混乱状况日益加剧。早期构建标准化层使我们避免了持续的系统崩溃。
- 相同的品牌提取流程同时适用于模型和智能体。真正的难点在于所有上游环节：驱动智能体运行、捕获其行为、并将其标准化为可评估的结构。

编程智能体贡献了相当一部分来自网络搜索的流量。对随机抽样的提示词进行的早期测试显示，编程智能体执行搜索的频率约为20%。随着收集更多数据，我们将对智能体搜索行为建立更全面的认知，但这些结果已明确表明，为编程智能体优化内容至关重要。

智能体推荐的形式与模型响应不同。当编程智能体推荐工具时，它倾向于生成包含该工具的可运行代码，例如import语句、配置文件或部署脚本。推荐内容直接嵌入在输出中，而非仅以文字形式提及。

日志格式混乱不堪。随着智能体命令行工具快速迭代更新，这种混乱状况日益加剧。早期构建标准化层使我们避免了持续的系统崩溃。

相同的品牌提取流程同时适用于模型和智能体。真正的难点在于所有上游环节：驱动智能体运行、捕获其行为、并将其标准化为可评估的结构。

## 后续计划

- 工具开源化。我们计划发布系统的开源版本，以便其他团队能追踪其标准模型和编程智能体的AEO评估数据。
- 方法论深度解析。我们正在撰写后续文章，全面阐述AEO评估方法论：提示词设计、双模式测试（网络搜索 vs 训练数据）、查询即实体架构以及声量份额指标。
- 扩展智能体覆盖范围。随着生态系统发展增加更多智能体类型，并拓展测试提示词范畴（不仅限于"推荐工具"，还包括完整项目脚手架、调试等场景）。

工具开源化。我们计划发布系统的开源版本，以便其他团队能追踪其标准模型和编程智能体的AEO评估数据。

方法论深度解析。我们正在撰写后续文章，全面阐述AEO评估方法论：提示词设计、双模式测试（网络搜索 vs 训练数据）、查询即实体架构以及声量份额指标。

扩展智能体覆盖范围。随着生态系统发展增加更多智能体类型，并拓展测试提示词范畴（不仅限于"推荐工具"，还包括完整项目脚手架、调试等场景）。

---

> 本文由AI自动翻译，原文链接：[How we built AEO tracking for coding agents - Vercel](https://vercel.com/blog/how-we-built-aeo-tracking-for-coding-agents)
> 
> 翻译时间：2026-02-10 04:37
