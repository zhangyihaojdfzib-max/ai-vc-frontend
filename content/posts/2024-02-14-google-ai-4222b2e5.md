---
title: 概念漂移下训练数据的重要性与动态加权方法
title_original: Learning the importance of training data under concept drift
date: '2024-02-14'
source: Google AI Blog
source_url: http://blog.research.google/2024/02/learning-importance-of-training-data.html
author: null
summary: 本文探讨了在概念漂移（数据分布随时间变化）的挑战下，传统AI训练方法的局限性。作者提出了一种新颖的元学习方法，通过联合训练一个辅助模型，为每个训练实例动态分配重要性权重，旨在最大化模型在未来数据上的性能。该方法结合了离线学习（利用所有数据）和持续学习（侧重近期数据）的优势，在包含约3900万张照片的大规模非平稳学习基准上实现了高达15%的相对准确率提升，有效缓解了灾难性遗忘问题，并提升了模型对数据演变的适应性。
categories:
- AI研究
tags:
- 概念漂移
- 非平稳学习
- 元学习
- 灾难性遗忘
- 数据加权
draft: false
translated_at: '2026-01-06T14:49:02.036Z'
---

在概念漂移下认识训练数据的重要性  
2024年2月14日  
作者：Nishant Jain（谷歌研究院预博士研究员）、Pradeep Shenoy（谷歌研究院研究科学家）  
快速链接  

我们周围世界不断变化的本质为AI模型的开发带来了重大挑战。通常，模型会在纵向数据上进行训练，期望所用训练数据能准确代表模型未来可能接收的输入。更普遍地说，默认假设所有训练数据都同等相关在实践中往往不成立。例如，下图展示了来自CLEAR非平稳学习基准的图像，说明了物体的视觉特征在十年间如何显著演变（我们称之为**慢概念漂移**），这对物体分类模型构成了挑战。  

| CLEAR基准中的示例图像。（改编自Lin等人） |  

在线学习和持续学习等其他方法会使用少量近期数据反复更新模型以保持其时效性。这隐式地优先处理近期数据，因为过去数据的学习成果会逐渐被后续更新所覆盖。然而在现实世界中，不同类型的信息以不同速率失去相关性，因此存在两个关键问题：1) 这些方法设计上仅关注最新数据，会丢失被覆盖的旧数据中的任何信号；2) 数据实例的贡献随时间均匀衰减，与数据内容无关。  

在我们最近的研究《非平稳学习中实例条件化的衰减时间尺度》中，我们提出在训练期间为每个实例分配重要性分数，以最大化模型在未来数据上的性能。为实现这一目标，我们采用了一个辅助模型，该模型根据训练实例及其存在时长生成这些分数。该模型与主模型联合学习。我们解决了上述两个挑战，在一系列非平稳学习基准数据集上相比其他鲁棒学习方法取得了显著提升。例如，在近期一个大规模非平稳学习基准（约3900万张跨越十年的照片）上，我们通过训练数据的学习重加权实现了高达15%的相对准确率提升。  

**监督学习中概念漂移的挑战**  
为量化理解慢概念漂移，我们在一个近期照片分类任务上构建了分类器，该任务包含约3900万张从社交媒体网站获取的十年间照片。我们比较了**离线训练**（以随机顺序多次遍历所有训练数据）和**持续训练**（按时间顺序逐月多次遍历数据）。我们测量了模型在训练期间及后续冻结期间（即不再用新数据更新）的准确率（如下图所示）。在训练期结束时（左图，x轴=0），两种方法接触了相同数据量，但表现出巨大性能差距。这是由于**灾难性遗忘**——持续学习中模型对训练序列早期数据的知识以不受控方式衰减的问题。另一方面，遗忘也有其优势——在测试期间（右图所示），持续训练模型的性能衰减速度远低于离线模型，因为它对旧数据的依赖性更低。两个模型在测试期间准确率的下降证实了数据确实随时间演变，两个模型都变得越来越不相关。  

| 照片分类任务中离线训练与持续训练模型的比较 |  

**训练数据的时间敏感重加权**  
我们设计了一种结合离线学习（有效复用所有可用数据的灵活性）和持续学习（弱化旧数据影响的能力）优势的方法，以应对慢概念漂移。我们在离线学习基础上，添加了对过去数据影响的精细控制及优化目标，两者均旨在减少模型未来的性能衰减。  

假设我们希望基于随时间收集的训练数据训练模型M。我们提议同时训练一个辅助模型，该模型根据数据内容及其存在时长为每个数据点分配权重。该权重会缩放该数据点在M训练目标中的贡献。权重的目标是提升M在未来数据上的性能。  

在我们的工作中，我们描述了如何对辅助模型进行**元学习**，即与M共同学习，以促进模型M自身的学习。辅助模型的一个关键设计选择是：我们以因子分解方式分离了实例相关和时长相关的贡献。具体而言，我们通过组合多个不同固定衰减时间尺度的贡献来设置权重，并学习给定实例最适合时间尺度的近似“分配”。实验发现，这种形式的辅助模型因其简洁性与表达力的结合，优于我们考虑过的许多其他方案（包括无约束联合函数到单一衰减时间尺度（指数或线性））。完整细节可参阅论文。  

**实例权重评分**  
下图顶部显示，在CLEAR物体识别挑战中，我们学习的辅助模型确实为更现代外观的物体赋予了更高权重；较陈旧外观的物体则相应被降低权重。进一步分析（下图底部，基于梯度的特征重要性评估）显示，辅助模型关注图像中的主要物体，而非可能与实例存在时长虚假相关的背景特征。  

| 我们的辅助模型在CLEAR基准（相机和计算机类别）中分别赋予最高和最低权重的示例图像 |  
| 辅助模型在CLEAR基准示例图像上的特征重要性分析 |  

**结果**  
**大规模数据上的提升**  
我们首先在之前讨论的YFCC100M数据集上研究大规模照片分类任务（PCAT），使用前五年数据训练，后五年作为测试数据。我们的方法（下图红色所示）相比无重加权基线（黑色）及许多其他鲁棒学习技术有显著改进。有趣的是，我们的方法有意牺牲对遥远过去（未来不太可能再现的训练数据）的准确率，以换取测试期间的明显提升。同时，如预期那样，我们的方法在测试期间的衰减程度低于其他基线。  

| 我们的方法与相关基线在PCAT数据集上的比较 |  

**广泛适用性**  
我们在学术文献中广泛非平稳学习挑战数据集上验证了我们的发现（详见1、2、3、4），这些数据集涵盖多种数据源和模态（照片、卫星图像、社交媒体文本、医疗记录、传感器读数、表格数据）及规模（从1万到3900万个实例）。相比每个数据集最近发布的基准方法，我们在测试期间报告了显著提升（如下所示）。请注意，每个数据集先前已知的最佳方法可能不同。这些结果展示了我们方法的广泛适用性。  

| 我们的方法在研究自然概念漂移的各种任务上的性能提升。报告提升基于各数据集先前已知最佳方法。 |  

**向持续学习的扩展**  
最后，我们考虑一个有趣的工作延伸。上述工作描述了如何利用受持续学习启发的思想扩展离线学习以处理概念漂移。然而，有时离线学习不可行——例如，当可用训练数据量过大而无法存储或处理时。

我们以直接的方式调整了持续学习的方法，通过在用于顺序更新模型的每个数据桶的上下文中应用时间重加权。这一方案仍保留了持续学习的一些局限性，例如模型更新仅基于最新数据进行，且所有优化决策（包括我们的重加权）都仅基于该数据制定。尽管如此，在照片分类基准测试中（见下表），我们的方法始终优于常规持续学习以及多种其他持续学习算法。由于我们的方法与许多对比基线中的思路具有互补性，我们预计结合使用时将获得更大的提升。
| 我们的方法适配持续学习的结果，与最新基线的对比。 |
结论
我们通过结合先前方法的优势——离线学习对数据的有效复用，以及持续学习对近期数据的侧重——应对了学习中数据漂移的挑战。我们希望这项工作有助于在实践中提升模型对概念漂移的鲁棒性，并激发更多兴趣和新思路，以应对普遍存在的缓慢概念漂移问题。
致谢
我们感谢Mike Mozer在本工作早期阶段进行的多次有益讨论，以及在开发过程中提供的宝贵建议和反馈。

---

> 本文由AI自动翻译，原文链接：[Learning the importance of training data under concept drift](http://blog.research.google/2024/02/learning-importance-of-training-data.html)
> 
> 翻译时间：2026-01-06 02:08
