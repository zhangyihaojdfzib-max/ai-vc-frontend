---
title: Cappy：小型评分器提升大型多任务语言模型性能
title_original: 'Cappy: Outperforming and boosting large multi-task language models
  with a small scorer'
date: '2024-03-14'
source: Google AI Blog
source_url: http://blog.research.google/2024/03/cappy-outperforming-and-boosting-large.html
author: null
summary: 本文介绍了Google Research提出的Cappy，一个仅3.6亿参数的轻量级预训练评分器。Cappy基于RoBERTa构建，能够评估指令与候选响应的匹配度，输出0-1的正确性分数。它既可独立处理分类任务，也能作为辅助组件增强大型多任务语言模型的性能，同时避免对LLM参数进行反向传播，降低内存需求，并与闭源模型兼容。该方法在提升模型效率与可访问性方面提供了新思路。
categories:
- AI研究
tags:
- 大语言模型
- 多任务学习
- 模型优化
- 轻量级模型
- 自然语言处理
draft: false
translated_at: '2026-01-05T17:13:08.007Z'
---

Cappy：用小型评分器超越并增强大型多任务语言模型
2024年3月14日
作者：Google Research 软件工程师 Yun Zhu 和 Lijuan Liu
快速链接

大语言模型（LLM）的进步催生了一种新范式，它将各种自然语言处理（NLP）任务统一在一个遵循指令的框架内。最近的多任务LLM，如T0、FLAN和OPT-IML，就是这种范式的典范。首先，收集多任务数据，每个任务遵循一个特定于任务的模板，其中每个带标签的示例都被转换成一个指令（例如，“将这些概念组合成一个句子：滑雪、山、滑雪者”）与一个相应的响应（例如，“滑雪者滑下山”）配对。这些指令-响应对用于训练LLM，从而得到一个条件生成模型，该模型接收指令作为输入并生成响应。此外，多任务LLM展现出了卓越的任务泛化能力，因为它们可以通过理解和解决全新的指令来处理未见过的任务。

由于仅使用指令来理解和解决各种任务具有复杂性，多任务LLM的规模通常从数十亿参数到数千亿参数不等（例如，FLAN-11B、T0-11B和OPT-IML-175B）。因此，运行如此庞大的模型带来了重大挑战，因为它们需要大量的计算能力，并对GPU和TPU的内存容量提出了很高的要求，使得其训练和推理成本高昂且效率低下。为每个下游任务维护一个独特的LLM副本需要大量的存储空间。此外，最强大的多任务LLM（例如FLAN-PaLM-540B）是闭源的，无法进行适配。然而，在实际应用中，利用单个多任务LLM以零样本方式管理所有可想象的任务仍然很困难，尤其是在处理复杂任务、个性化任务以及那些无法用指令简洁定义的任务时。另一方面，下游训练数据的规模通常不足以在不融入丰富先验知识的情况下训练好一个模型。因此，人们长期以来一直希望在绕过存储、内存和访问问题的同时，利用下游监督来适配LLM。

某些参数高效的调优策略，包括提示词调优和适配器，大大降低了存储需求，但它们在调优过程中仍然需要通过LLM参数进行反向传播，从而使其内存需求保持在高位。此外，一些上下文学习技术通过将有限数量的监督示例整合到指令中来规避参数调优。然而，这些技术受到模型最大输入长度的限制，只允许使用少量样本来指导任务解决。

在NeurIPS 2023上发表的论文《Cappy：用小型评分器超越并增强大型多任务语言模型》中，我们提出了一种新颖的方法，以提升多任务LLM的性能和效率。我们引入了一个轻量级的预训练评分器Cappy，它基于RoBERTa进行持续预训练，仅有3.6亿参数。Cappy接收一个指令和一个候选响应作为输入，并输出一个介于0到1之间的分数，表示响应相对于指令的估计正确性。Cappy可以独立处理分类任务，也可以作为LLM的辅助组件，提升其性能。此外，Cappy能够高效地实现下游监督，无需任何微调，这避免了通过LLM参数进行反向传播的需求，并降低了内存要求。最后，使用Cappy进行适配不需要访问LLM参数，因为它与闭源的多任务LLM兼容，例如那些只能通过WebAPI访问的模型。

**预训练**
我们从相同的数据集收集开始，该集合包括来自PromptSource的39个不同数据集，这些数据集曾用于训练T0。这个集合涵盖了广泛的任务类型，如问答、情感分析和摘要生成。每个数据集都与一个或多个模板相关联，这些模板将原始数据集中的每个实例转换为一个指令与其真实响应配对。

Cappy的回归建模要求每个预训练数据实例包含一个指令-响应对以及该响应的正确性标注，因此我们生成了一个带有0到1范围正确性标注的数据集。对于生成任务中的每个实例，我们利用现有的多任务LLM，通过采样生成多个响应，条件是基于给定的指令。随后，我们使用响应与实例真实响应之间的相似性，为指令和每个响应组成的配对分配一个标注。具体来说，我们使用Rouge-L（一种常用于衡量整体多任务性能的指标，已被证明与人类评估高度一致）来计算这种相似性，作为一种弱监督形式。

最终，我们获得了一个包含1.6亿个实例的有效回归数据集，每个实例都配有正确性分数标注。最终的Cappy模型是在RoBERTa模型之上，使用该回归数据集进行持续预训练的结果。Cappy的预训练是在Google的TPU-v4上使用RedCoast（一个用于自动化分布式训练的轻量级工具包）进行的。

**应用Cappy**
> 本文由AI自动翻译，原文链接：[Cappy: Outperforming and boosting large multi-task language models with a small scorer](http://blog.research.google/2024/03/cappy-outperforming-and-boosting-large.html)
> 
> 翻译时间：2026-01-05 17:13
