---
title: 像图一样说话：为LLM编码图结构的方法与发现
title_original: 'Talk like a graph: Encoding graphs for large language models'
date: '2024-03-12'
source: Google AI Blog
source_url: http://blog.research.google/2024/03/talk-like-graph-encoding-graphs-for.html
author: null
summary: 本文介绍了如何将图结构有效地编码为文本，以便大型语言模型（LLM）能够理解和推理图信息。研究提出了GraphQA基准测试，用于评估LLM在不同图任务上的表现，并系统探索了节点编码、边编码和提示方法等多种技术。研究发现，LLM在图任务上的性能主要受三个因素影响：图编码方法、任务性质以及图结构本身。通过优化表示方法，LLM在图推理任务上的性能可提升高达60%。
categories:
- AI研究
tags:
- 大语言模型
- 图神经网络
- 图表示学习
- AI基准测试
- 图推理
draft: false
---

像图一样说话：为大型语言模型编码图结构
2024年3月12日
Bahare Fatemi，谷歌研究院研究科学家，与 Bryan Perozzi，谷歌研究院研究科学家
我们深入探究了如何以最佳方式将图表示为文本，以便LLM（大语言模型）能够理解它们——我们的调查发现了影响结果的三个主要因素。

快速链接
想象一下你周围的所有事物——你的朋友、厨房里的工具，甚至是你自行车的零件。它们都以不同的方式相互连接。在计算机科学中，术语“图”用于描述对象之间的连接。图由节点（对象本身）和边（两个节点之间的连接，表示它们之间的关系）组成。如今，图无处不在。互联网本身就是一个由相互链接的网站组成的巨型图。甚至搜索引擎所使用的知识也是以类似图的方式组织的。

此外，想想人工智能领域的显著进步——比如能在几秒钟内写出故事的聊天机器人，甚至能解读医疗报告的软件。这一令人兴奋的进展主要归功于大语言模型。针对不同用途的新LLM技术正在不断开发中。

既然图无处不在，而LLM技术又在兴起，我们在ICLR 2024上发表的论文《像图一样说话：为大型语言模型编码图结构》中，提出了一种方法，旨在教导强大的LLM如何更好地对图信息进行推理。图是组织信息的一种有用方式，但LLM主要是在常规文本上进行训练的。我们的目标是测试不同的技术，以了解什么方法最有效，并获得实用的见解。将图翻译成LLM能理解的文本是一项极其复杂的任务。其难度源于图结构固有的复杂性，包括多个节点以及连接它们的错综复杂的边网络。我们的工作研究如何获取一个图并将其转换为LLM能够理解的格式。我们还设计了一个名为GraphQA的基准测试，用于研究不同方法在不同图推理问题上的表现，并展示了如何以能使LLM解决图问题的方式来表述图相关问题。我们发现，LLM在图推理任务上的表现因三个基本层面而异：1）图编码方法，2）图任务本身的性质，以及3）有趣的是，所考虑的图的具体结构。这些发现为我们提供了关于如何为LLM最佳表示图的线索。选择正确的方法可以使LLM在图任务上的表现提升高达60%！

将图表示为文本
为了能够系统地找出将图转换为文本的最佳方法，我们首先设计了一个名为GraphQA的基准测试。可以将GraphQA视为一项旨在评估强大LLM在图特定问题上的考试。我们想看看LLM在不同设置下理解和解决涉及图的问题的能力如何。为了为LLM创建全面且真实的考试，我们不仅使用一种类型的图，而是混合使用多种图，确保连接数量的广度。这主要是因为不同的图类型会使解决此类问题变得更容易或更困难。这样，GraphQA有助于揭示LLM思考图时可能存在的偏见，并且整个考试更接近LLM在现实世界中可能遇到的实际设置。

GraphQA专注于与图相关的简单任务，例如检查边是否存在、计算节点或边的数量、查找连接到特定节点的节点以及检查图中是否存在环。这些任务可能看起来很基础，但它们需要理解节点和边之间的关系。通过涵盖从识别模式到创建新连接等不同类型的挑战，GraphQA帮助模型学习如何有效地分析图。这些基本任务对于更复杂的图推理至关重要，例如查找节点之间的最短路径、检测社区或识别有影响力的节点。此外，GraphQA包括使用各种算法（如Erdős-Rényi、无标度网络、Barabasi-Albert模型和随机块模型）生成随机图，以及更简单的图结构（如路径、完全图和星形图），从而为训练提供多样化的数据集。

在处理图时，我们还需要找到以LLM能够理解的方式提出图相关问题的方法。提示启发式方法是实现这一目标的不同策略。让我们分解一下常见的几种：
- 零样本：简单地描述任务（"这个图里有环吗？"）并让LLM去执行。不提供示例。
- 少样本：这就像在正式考试前给LLM一个迷你练习测试。我们提供几个示例图问题及其正确答案。
- 思维链：在这里，我们通过示例向LLM展示如何逐步分解问题。目标是教会它在面对新图时生成自己的“思维过程”。
- 零样本思维链：类似于思维链，但我们不提供训练示例，而是给LLM一个简单的提示，如“让我们逐步思考”，以触发它自己的问题解决分解过程。
- BAG（构建图）：这专门用于图任务。我们在描述中添加短语“让我们构建一个图……”，帮助LLM专注于图结构。

我们探索了将图转换为LLM可以处理的文本的不同方式。我们的关键问题是：
- 节点编码：我们如何表示单个节点？测试的选项包括简单整数、常见名称（人物、角色）和字母。
- 边编码：我们如何描述节点之间的关系？方法涉及括号表示法、“是朋友”之类的短语以及箭头等符号表示。

我们系统地组合了各种节点和边编码。这产生了如下图所示的一些函数：

分析与结果
我们进行了三个关键实验：一个测试LLM如何处理图任务，另外两个旨在理解LLM的规模大小和不同的图形状如何影响性能。我们所有的实验都在GraphQA上运行。

LLM如何处理图任务
在这个实验中，我们测试了预训练的LLM在处理图问题（如识别连接、环和节点度）方面的表现。以下是我们了解到的情况：
- LLM表现不佳：在大多数这些基本任务上，LLM的表现并不比随机猜测好多少。
- 编码至关重要：我们如何将图表示为文本对LLM性能有很大影响。“关联”编码在大多数任务上总体表现出色。

我们的结果总结在下图中。

越大（通常）越好
在这个实验中，我们想看看LLM的规模大小（就参数数量而言）是否会影响它们处理图问题的能力。为此，我们在PaLM 2的XXS、XS、S和L尺寸上测试了相同的图任务。以下是我们发现的总结：
- 一般来说，更大的模型在图推理任务上表现更好。似乎额外的参数为它们提供了学习更复杂模式的空间。
- 奇怪的是，对于“边存在性”任务（找出图中两个节点是否连接），模型大小的影响并不那么大。
- 即使在环检查问题（找出图是否包含环）上，最大的LLM也无法始终如一地击败一个简单的基线解决方案。这表明LLM在某些图任务上仍有改进空间。

不同的图形状会让LLM困惑吗？
我们想知道图的“形状”（节点如何连接）是否会影响LLM在其上解决问题的能力。将下图视为不同图形状的示例。

我们发现图结构对LLM性能有很大影响。例如，在一个询问是否存在环的任务中，LLM在紧密互连的图（环在那里很常见）上表现出色，但在路径图（环永远不会发生）上却表现不佳。有趣的是，提供一些混合示例有助于它适应。

例如，针对环路检测任务，我们在提示词中添加了包含环路的示例和不含环路的示例作为少样本示例。其他任务也采用了类似的处理模式。

结论
简而言之，我们深入探究了如何以最佳方式将图结构表示为文本，以便LLM（大语言模型）能够理解它们。我们发现三个关键因素会产生重要影响：
- 图结构转译方法：将图表示为文本的方式会显著影响LLM的性能。关联编码在多数任务中表现优异。
- 任务类型：某些类型的图问题对LLM而言更具挑战性，即使采用优质的图结构转译方法也是如此。
- 图结构：令人惊讶的是，进行推理时所依据的图"形态"（连接密集、稀疏等）会影响LLM的表现效果。

本研究揭示了为LLM准备图数据的关键见解。恰当的编码技术能显著提升LLM解决图问题的准确率（提升幅度约5%至60%以上）。我们提出的新基准测试集GraphQA将推动该领域的进一步研究。

致谢
我们衷心感谢合著者Jonathan Halcrow对本研究的宝贵贡献。特别感谢Anton Tsitsulin、Dustin Zelle、Silvio Lattanzi、Vahab Mirrokni以及谷歌研究院图挖掘团队的全体成员，他们富有洞见的评论、细致的校对和建设性反馈极大提升了本研究的质量。同时，我们特别感谢Tom Small为本文制作的动画。

---

> 本文由AI自动翻译，原文链接：[Talk like a graph: Encoding graphs for large language models](http://blog.research.google/2024/03/talk-like-graph-encoding-graphs-for.html)
> 
> 翻译时间：2026-01-05 17:13
