---
title: 生成式AI的坚实守护者：Robust Intelligence的转型之路
title_original: A Robust Safeguard for Generative AI
date: '2025-10-25'
source: 红杉资本 (Sequoia)
source_url: https://sequoiacap.com/article/robust-intelligence-spotlight/
author: ''
summary: 本文讲述了AI安全公司Robust Intelligence创始人亚伦·辛格在生成式AI浪潮冲击下的应对与转型。当大语言模型（LLM）兴起导致其传统AI防火墙业务面临危机时，辛格凭借早年对AI脆弱性的研究洞察——即机器学习模型的预测误差会系统性影响决策算法——迅速调整方向，立志成为生成式AI时代的关键守护者。文章回溯了其学术背景、创业初衷以及与联合创始人小柴宏仁的相遇，揭示了他们致力于解决AI安全根本问题的愿景。
categories:
- 创业
tags:
- AI安全
- 生成式AI
- 创业故事
- 大语言模型
- AI防火墙
draft: false
translated_at: '2026-02-01T20:43:22.746989'
---

2023年1月，亚伦·辛格在拉斯维加斯郊区的一间爱彼迎民宿中醒来，感觉他的公司Robust Intelligence终于迎来了转机。这家初创公司作为全球顶尖的AI安全公司之一正崭露头角，它开发了业界首个AI防火墙——一个能暴露AI安全缺陷与错误、保护AI技术免受外部恶意威胁及重大失误影响的模型引擎。

辛格相信，他即将与一家领先的咨询和系统集成公司敲定一笔七位数、为期多年的合作协议，这将是公司迄今最重要的客户之一。为表庆祝，他当晚准备请团队观看太阳马戏团的《O》秀，作为公司团建活动的一部分。然而不幸的是，那天与死亡擦肩而过的体验并不只存在于那些惊险的水上特技表演中。

走出房间时，辛格接到了那家咨询公司AI业务总经理的电话——他本以为只是处理一些收尾细节。但对方却告知，他们的CEO刚从达沃斯世界经济论坛归来，而论坛上最热门的话题是一项新技术：大语言模型（LLM）。AI正从预测性转向生成式的新方向，这位CEO担心Robust的产品可能已不再适用。

辛格立刻意识到，这不仅是失去一个客户的问题，而是可能失去所有客户。然而，尽管这对他的企业构成了生存威胁，辛格内心深处却涌动着兴奋。早在加州大学伯克利分校攻读研究生时，他就预见到AI将迎来这样的分水岭时刻。如果LLM即将改变世界，Robust Intelligence就有机会成为这项技术的重要守护者。

但要实现这一点，辛格和他的团队必须快速调整产品方向。

辛格出生在以色列一个学术世家，他是家里最年轻的一员——母亲、父亲和姐姐都拥有计算机科学博士学位。家人对他继承这条学术道路有着不言而喻的期待，以至于辛格记得自己六岁时曾问母亲：“我长大后也必须读博士吗？”（母亲笑着说不必，但他记得自己当时并未信服。）

直到本科阶段顿悟到学术研究的魅力，他才化解了这种矛盾心理。“我学习了从数学、理论到计算机科学等一系列精妙的体系构造，”辛格说，“想到自己能为这些领域做出永恒贡献——没有什么比这更令人向往了。”

辛格进入加州大学伯克利分校攻读计算机科学博士学位，并在此初次对创业文化产生兴趣。“我研究算法，但更想将其应用于现实世界，”辛格说，“作为学者，没人愿意与我交流，而我需要数据。所以我能想到的唯一途径就是创办公司，实施算法并收集大量数据。”

他的公司BIDWAVE运用机器学习和算法来确定用户通过社交媒体发布广告应获得的报酬。但系统建成后，却不断得出错误结果，这揭示了一个关于AI的棘手真相：“任何依赖AI输入进行算法决策的环节都极其脆弱，”辛格总结道，算法本身存在问题。

他以谷歌地图为例：输入目的地后，它会寻找最快路线。这个过程分为两步：首先通过机器学习预测到达各地点所需时间，然后基于这些信息运行算法。“问题在于，街道间的通行时间并非真实时间，而是某个AI模型的预测值，但算法却将其视为真理，”辛格指出。如果机器学习模型不够精确——“它们永远不可能完全精确”——就会损害决策算法的质量。

随着深入研究，辛格发现市场上不仅缺少能帮助企业防范此类问题的产品——这个市场根本尚未存在。

他的妻子梅罗米特·辛格——一位同样在加州大学伯克利分校获得计算机科学博士学位的计算生物学家——直白地总结了丈夫的洞察：“他最早意识到，众多公司运行机器学习时假设参数正确（实则并非完全准确）可能带来多大风险。误差必然存在，那么企业能获得什么保障？又存在哪些漏洞？”

对某些人而言，有此发现足以让其辍学并立即投身创业。但辛格仍受学术殿堂的吸引，选择前往东海岸的哈佛大学任教。颇具讽刺意味的是，在远离硅谷数千英里之外，他竟在此遇见了未来的联合创始人小柴宏仁——一位坐在他研究生研讨班第一排的本科生。

![](/images/posts/2812fde25850.jpg)

“作为学者，没人愿意与我交流，而我需要数据。所以我能想到的唯一途径就是创办公司，实施算法并收集大量数据。”

辛格成长于专注计算机科学的家庭，而小柴则在东京由两位资深书迷抚养长大：父亲是图书馆员，母亲在书店工作（事实上，小柴的名字源自小说《行人》——日文译作“Kōjin”——他母亲曾以该书为题完成论文）。

尽管童年经历迥异，小柴和辛格却有一个共同点：他们都是“第三文化儿童”。这个由美国社会学家露丝·尤西姆提出的术语，指在成长关键期长期生活在护照国之外的侨居儿童。辛格童年时曾随在科罗拉多州学术休假的父亲生活，小柴则因父亲在蒙特利尔大学东亚研究系工作，在加拿大度过了三年时光。

移居蒙特利尔的起步颇为艰难。“我刚去时完全不会英语，第一年过得相当挣扎，”小柴回忆道，“但三年后回国，我感觉自己已不完全适应日本社会。”在领略更广阔的世界后，小柴渴望更多——他决定赴美进入哈佛大学求学。

正如小说家格雷厄姆·格林的名言：“童年总有那么一刻，大门开启，未来涌入。”对小柴而言，这一刻就是他获得特别许可参加辛格的研究生研讨班，坐在第一排凝视着那位未来联合创始人的时刻——他们共同创立的企业估值已近5亿美元。

辛格最初注意到小柴，是因为他主持了一场关于TensorFlow（机器学习与人工智能的开源软件库）的精彩研讨会。此后不久，两人开始合作撰写并发表论文。在小柴看来，尽管经验存在差距，辛格始终将他视为真正的合作者。“我感觉自己是在与一位极其聪明、成就卓著的人共同解决问题，而不是被动接受指令，”小柴说，“我们更像是一起孵化创意，互相询问‘你怎么想？’‘我们何不尝试这个？’”

在辛格这边，他逐渐接受了学术之外的人生可能性。他早早获得了终身教职，当这个目标达成后，他意识到自己多么渴望看到研究的实际应用。他觉得创办公司的时机已经成熟。

学期末，辛格邀请大柴进入他的办公室，询问他是否愿意共同创立一家初创公司。大柴对合作的前景同样感到兴奋，无论这会将他们带向何方。"在询问任何细节之前，"大柴回忆道，"我说，我愿意。"合作关系确认后，辛格和大柴只剩下一个问题：他们到底想共同创立一家什么样的公司。

两人不断回到辛格多年前在伯克利偶然发现的那个关于算法的不便真相——人工智能并不可靠，这导致任何依赖它们的算法都存在漏洞和不准确性。这让他们对人工智能安全产生了一个简单而新颖的关注点："人工智能和机器学习，它们是经过美化的算法——就像是打了兴奋剂的算法，"大柴说。"因此，识别算法局限性的活动，就是在识别人工智能的局限性。"

他们着手创建了一系列他们认为能赋予公司使命的公理：第一，人工智能将继续以指数级速度增长；第二，根据他们对人工智能的所有了解，如果没有开发出保障其安全的方法，就没有负责任的方式来推动该领域的发展；第三，这些因素的必然结果将导致人工智能安全市场最终演变成一个价值数十亿美元的市场。

时间接近2019年底，辛格为摩根大通创建了一个集推介与试点于一体的项目，揭示了该银行在使用预测性人工智能方面的弱点。但大通银行拒绝了他们，原因是其团队的一名工程师得出结论，认为目前不需要他们这样的产品。

![](/images/posts/4f94dba7cf9c.jpg)

"人工智能和机器学习，它们是经过美化的算法——就像是打了兴奋剂的算法。因此，识别算法局限性的活动，就是在识别人工智能的局限性。"

大约在同一时间，辛格前往旧金山与投资者会面，其中包括红杉资本的合伙人比尔·考格兰，他曾是谷歌的工程副总裁。辛格希望，如果有人能理解他们想法的重要性，那可能就是比尔。"考虑到他在谷歌的角色，我觉得比尔对人工智能的了解比我更多，"辛格说，"他不需要我们去说服他相信‘人工智能将吞噬世界’以及‘它是一种存在脆弱性的技术’这些论断。"

辛格是对的。考格兰不仅成为了Robust的第一位投资者，还将辛格引荐给了大通银行的人工智能与量子安全负责人。这位负责人认识到，即使目前可能并不迫切需要一个人工智能防火墙，其需求的出现也会比大多数人预期的要早得多。2020年2月，他告诉辛格，他将在六个月内获得启动项目的预算。一个月后，新冠疫情席卷全球。

现在，除了让公司起步之外，辛格还在学习如何完全远程运营公司，并试图在一个被高利率和通胀困扰的市场中赢得第一批客户。最终，在2020年9月，Robust Intelligence通过在LinkedIn上的陌生推广，成功将其人工智能防火墙产品首次销售给了Expedia。

Expedia的数据科学副总裁被Robust产品在质量保证方面的应用前景所说服，甚至可能超过了其作为安全工具的价值。当时，他的组织里有很多出色的博士研究员，但缺乏编码专业知识，他认为Robust的技术可以帮助识别他们正在构建的模型中的问题。唯一的问题是——Robust实际上还没有产品。他们用Figma制作了一个看起来逼真的产品模型。尽管产品尚处萌芽阶段，Expedia仍愿意与Robust合作，因为市场上根本没有类似的产品。"我当时想，'糟糕，现在我们必须把这个东西做出来了，'"大柴回忆道。

Expedia提供了样本数据供Robust测试其技术，但数据量不足以支持大规模运行。这使得Robust开始期望一件其他初创公司很少会期望的事情：一个漫长的合同流程，以便他们的工程师有足够的时间来完善防火墙。

当时，Expedia的人工智能模型本质上是预测性或判别性的。它们会向消费者展示酒店或航班的价格，而预测消费者是否会购买房间或机票则是由人工智能驱动的。Robust的防火墙需要分析Expedia人工智能预测的准确性，同时测试其漏洞。经过一番密集努力，这家羽翼未丰的初创公司看起来有望在合同签署时交付一个可用的产品，但在计划向Expedia交付产品的三个月前，他们又遇到了另一个挫折。Robust的十二名员工中有七人离开了公司，原因是公司在成立一年半后只赢得了一个客户，这让他们感到沮丧。

其他创始人遭遇这样的挫折后可能会放弃，但辛格内心深处知道，人工智能革命即将到来。在Robust旧金山办公室附近的一张野餐桌旁，辛格与大柴坐下来确认，他们是希望重新致力于公司的愿景，还是打算将资金退还给投资者。两人都决定全力以赴。

于是，凭借一支仅剩五名员工的"精简"团队，Robust Intelligence继续推进，并成功按时向Expedia交付了产品。大通银行很快从疫情期间的谨慎中恢复过来，随后其他客户也纷纷跟进，包括德勤、Intuit、美国政府，以及一家有兴趣签署七位数合同的咨询和系统集成公司。辛格决定是时候带团队去拉斯维加斯庆祝一下了。

# 获取红杉社区的最佳故事。

那个决定性的拉斯维加斯电话终于证实了辛格一直在等待的人工智能拐点。人工智能的普及——以及随之而来的保障其安全的需求增长——终于到来了。直到那时，Robust一直在保障预测性人工智能的安全，就像他们为Expedia所做的工作一样。ChatGPT（以及更广泛意义上的LLM）不进行预测，而是进行生成——根据用户发出的提示词创建图像和文本。辛格认为，这最终以深刻的方式加深了人工智能的安全风险。"距离提取个人医疗记录或税务信息只有一步之遥，"辛格说。"这种隐私泄露是前所未有的。"

这种威胁也为Robust创造了前所未有的机遇，前提是他们能足够快地更新产品以维持公司运营。"所有客户都暂停了合作，因为他们不会在非生成式人工智能上投入任何资金，而且他们不知道自己的产品路线图会是什么样子，"辛格说。

他提议成立一个由两名工程师组成的攻坚小组，由大柴领导，目标是在六周内开发出一个可运行的生成式人工智能防火墙原型。然后他们将实施持续的六周发布周期，在每次新迭代中增加越来越多的测试用例、保护机制（和员工）。六个月内，整个公司都专注于构建护栏，以确保企业能够安全地部署LLM。

辛格在思科的一次会议上遇到了他们的第一个付费生成式人工智能客户——一家财富100强公司。他们因最新的AI防火墙而声名鹊起，受邀在会上发言。该公司签署了试点协议，试点揭示了其系统中的重大漏洞。这也带来一个发现：部署生成式人工智能应用的公司通常会微调现有的基础模型，以提高准确性和成本效益，但在这个过程中，它们使这些模型暴露于新的安全风险之下。在Robust展示了他们的发现后，该公司立即延长了合同。

2023年12月27日，《纽约时报》进一步印证了Robust的价值主张。他们起诉OpenAI和微软侵犯版权，指控其发布的作品被用于训练聊天机器人。2024年，Robust受邀为该诉讼提供咨询，并协助演示了如何轻松地利用互联网上的受版权保护材料训练LLM（大语言模型），进而使精通技术的恶意行为者能够获取这些内容。"我们团队的发现是，任何人都可以从ChatGPT这类模型中提取完整的文章，"Singer表示，"这不仅说明怀有恶意者能通过这些模型获取受版权保护的材料，还意味着他们能访问用于训练这些模型的数据，这进而引发了重大的隐私担忧。"

大约在同一时期，拜登总统签署了《关于安全、可靠和可信赖地开发与使用人工智能的行政命令》，这逐渐让更多人意识到Singer在过去近十年间早已洞悉的事实：要驾驭人工智能的力量，首先必须理解其风险并确保其安全性。

Robust Intelligence的2024年开局与2023年截然不同。他们不仅没有失去大客户并被迫彻底改变产品与技术，反而迎来了新的机遇。

尽管公司日益成功，Singer清醒地认识到LLM的发展速度远超其公司可能的成长速度。为实现他期望的影响力，必须与一家更大的企业合作。因此，在2024年夏季收到另外三份收购要约后，Singer接受了思科4亿美元的收购报价。

他认为思科正是那种能为Robust提供必要支持与基础设施、以保障不断扩张的人工智能生态安全的公司。依托两万五千名员工构建的基础设施，将为Robust的覆盖范围和机遇带来阶跃式变化。"人工智能现已成为思科关注的核心，"Singer说，"而Robust Intelligence正有机会引领这场变革。"

他们已看到合作带来的回报，成功赢得了宝马等新客户。宝马寻求Robust帮助保障其人工智能概念车Dee的安全性。这与保障旅游平台预测客户购票意向这类安全挑战完全不在一个量级。正如创始团队所言："我们最初关注的是AI模型产生的微小错误，这些错误虽对业务不利但并非灾难。但汽车撞墙——乃至企业用AI决定是否聘用某人——这些才真正影响人们的生活。"

对于这位曾梦想在领域内产生持久影响力（尽管最初是在更理论化的范畴）的人来说，思科在科技生态中的核心地位令Singer深感振奋。"思科支撑着互联网的运转，如果每个通过互联网运行的AI应用都能通过Robust Intelligence的AI防火墙获得安全保障，我们还能为世界带来比这更大的影响吗？"他补充道，"这正是梦想的定义。"

## 相关主题

![](/images/posts/95897e6f24cd.jpg)

## Wiz：其迅速崛起的背后故事

![](/images/posts/32dc8b65c64f.jpg)

## 以极速革新命令行

![](/images/posts/b04aaacf9f38.jpg)

## Arvind Jain进军AI驱动生产力领域

---

> 本文由AI自动翻译，原文链接：[A Robust Safeguard for Generative AI](https://sequoiacap.com/article/robust-intelligence-spotlight/)
> 
> 翻译时间：2026-02-01 20:43
