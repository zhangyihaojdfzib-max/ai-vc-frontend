---
title: AGENTS.md 完胜技能：Vercel 在编程智能体评估中的意外发现
title_original: AGENTS.md outperforms skills in our agent evals - Vercel
date: '2026-01-27'
source: Vercel Blog
source_url: https://vercel.com/blog/agents-md-outperforms-skills-in-our-agent-evals
author: ''
summary: Vercel 在教授 AI 编程智能体 Next.js 16 新 API 的评估中发现，将文档直接嵌入项目根目录的 AGENTS.md 文件（提供持久化上下文）实现了
  100% 的通过率。而采用按需调用的“技能”标准，即使明确指示使用，最高通过率也仅为 79%，且存在触发不可靠、指令措辞脆弱等问题。文章揭示了当前智能体在工具使用上的局限性，并指出对于框架文档，直接提供持久上下文比依赖智能体主动调用更有效、更稳健。
categories:
- AI产品
tags:
- AI编程助手
- 智能体评估
- Vercel
- Next.js
- 上下文管理
draft: false
translated_at: '2026-01-28T04:44:26.468822'
---

我们原本期望技能（Skills）是教授编程Agent特定框架知识的解决方案。但在构建了专注于Next.js 16 API的评估测试后，我们发现了意想不到的结果。

一个压缩至8KB的文档索引直接嵌入到`AGENTS.md`中，实现了100%的通过率；而技能（Skills）即使在明确指示Agent使用它们的情况下，最高通过率也只有79%。如果没有这些指示，技能的表现与完全没有文档时一样差。

以下是我们尝试的方法、学到的经验，以及你如何为自己的Next.js项目进行设置。

## 我们试图解决的问题

AI编程Agent依赖于可能过时的训练数据。Next.js 16引入了诸如`'use cache'`、`connection()`和`forbidden()`等API，这些并未包含在现有模型的训练数据中。当Agent不了解这些API时，它们会生成错误的代码或退回到旧的模式。

反之亦然，当你运行的是旧版Next.js，而模型却建议了项目中尚不存在的新API。我们希望通过为Agent提供版本匹配的文档来解决这个问题。

## 教授Agent框架知识的两种方法

在深入结果之前，先简要解释我们测试的两种方法：

*   **技能（Skills）** 是一种**开源标准**，用于打包编程Agent可以使用的领域知识。一个技能捆绑了提示词、工具和文档，Agent可以按需调用。其理念是，当Agent识别出需要特定框架帮助时，会调用该技能，从而获得相关文档的访问权限。
*   **`AGENTS.md`** 是项目根目录下的一个Markdown文件，为编程Agent提供持久化的上下文。无论你在`AGENTS.md`中放入什么内容，Agent在每一轮交互中都能获取到，而无需Agent决定是否加载它。Claude Code使用`CLAUDE.md`文件达到相同目的。

我们构建了一个Next.js文档技能和一个`AGENTS.md`文档索引，然后通过我们的评估套件运行它们，以比较哪个表现更好。

## 我们最初押注于技能

技能看起来像是正确的抽象方式。你将框架文档打包成一个技能，Agent在处理Next.js任务时调用它，然后你就能得到正确的代码。职责分离清晰，上下文开销最小，并且Agent只加载它需要的内容。甚至在`skills.sh`上还有一个不断增长的可复用技能目录。

我们期望Agent遇到Next.js任务时，会调用技能，读取版本匹配的文档，并生成正确的代码。

然后我们运行了评估测试。

## 技能未能被可靠地触发

在56%的评估案例中，技能从未被调用。Agent可以访问文档，但没有使用它。添加技能相比基线没有任何改进：

| 配置 | 通过率 | 与基线对比 |
| :--- | :--- | :--- |
| 基线（无文档） | 53% | — |
| 技能（默认行为） | 53% | 零改进 |

技能存在，Agent可以使用它，但Agent选择不使用。在详细的构建/代码检查/测试细分中，技能在某些指标上实际上比基线表现更差（测试通过率58% vs 63%），这表明环境中未使用的技能可能会引入噪音或干扰。

这并非我们设置独有的问题。Agent不能可靠地使用可用工具是当前模型的一个**已知限制**。

## 明确指示有帮助，但措辞很脆弱

我们尝试在`AGENTS.md`中添加明确指示，告诉Agent使用技能。

```
在编写代码之前，首先探索项目结构，然后调用nextjs-doc技能以获取文档。
```

添加到AGENTS.md中以触发技能使用的示例指令。

这将触发率提高到95%以上，并将通过率提升至79%。

| 配置 | 通过率 | 与基线对比 |
| :--- | :--- | :--- |
| 带有明确指示的技能 | 79% | +26个百分点 |

一个显著的改进。但我们发现指令措辞如何影响Agent行为方面，出现了一些意想不到的情况。

不同的措辞产生了截然不同的结果：

| 指令 | 行为 | 结果 |
| :--- | :--- | :--- |
| "你**必须**调用技能" | 先阅读文档，固守文档模式 | 忽略了项目上下文 |
| "先探索项目，然后调用技能" | 先建立心智模型，将文档作为参考 | 更好的结果 |

相同的技能。相同的文档。基于细微的措辞变化，产生了不同的结果。

在一次评估（`'use cache'`指令测试）中，"先调用"的方法写出了正确的`page.tsx`，但完全忽略了必需的`next.config.ts`更改。而"先探索"的方法则两者都做到了。

这种脆弱性让我们担忧。如果小的措辞调整会导致行为大幅波动，那么这种方法在生产环境中就显得不够稳健。

## 构建我们能够信任的评估

在下结论之前，我们需要能够信任的评估。我们最初的测试套件存在模糊的提示词、验证实现细节而非可观察行为的测试，并且关注点在于模型训练数据中已有的API。我们并没有衡量我们真正关心的东西。

我们通过移除测试泄漏、解决矛盾点以及转向基于行为的断言，来强化评估套件。最重要的是，我们添加了针对模型训练数据中不存在的Next.js 16 API的测试。

我们强化评估套件中的API包括：

*   `connection()` 用于动态渲染
*   `'use cache'` 指令
*   `cacheLife()` 和 `cacheTag()`
*   `forbidden()` 和 `unauthorized()`
*   `proxy.ts` 用于API代理
*   异步 `cookies()` 和 `headers()`
*   `after()`、`updateTag()`、`refresh()`

以下所有结果均来自这个强化后的评估套件。每种配置都根据相同的测试进行评判，并通过重试来排除模型方差的影响。

## 一个得到回报的直觉

如果我们完全移除这个决策过程会怎样？与其期望Agent调用技能，不如直接将文档索引嵌入到`AGENTS.md`中。不是完整的文档，只是一个索引，告诉Agent在哪里可以找到与你项目Next.js版本匹配的特定文档文件。然后Agent可以根据需要读取这些文件，无论你使用的是最新版本还是维护旧项目，都能获得版本准确的信息。

我们在注入的内容中添加了一个关键指令。

```
重要提示：对于任何Next.js任务，优先采用检索引导的推理，而非预训练引导的推理。
```

嵌入在文档索引中的关键指令

这告诉Agent查阅文档，而不是依赖可能过时的训练数据。

## 结果令我们惊讶

我们在所有四种配置上运行了强化后的评估套件：

![所有四种配置的评估结果。AGENTS.md（第三列）在构建、代码检查和测试上均达到了100%](/images/posts/408d79c1a433.jpg)

最终通过率：

| 配置 | 通过率 | 与基线对比 |
| :--- | :--- | :--- |
| 基线（无文档） | 53% | — |
| 技能（默认行为） | 53% | 零改进 |
| 带有明确指示的技能 | 79% | +26个百分点 |
| **`AGENTS.md` 文档索引** | **100%** | **+47个百分点** |

在详细细分中，`AGENTS.md`在构建、代码检查和测试上均取得了满分。

| 构建 | 基线 | 技能（默认） | 技能（有指示） | `AGENTS.md` |
| :--- | :--- | :--- | :--- | :--- |
| 通过率 | 53% | 53% | 79% | **100%** |

这并非我们预期的结果。"笨拙"的方法（一个静态的Markdown文件）胜过了更复杂的基于技能的检索，即使我们微调了技能触发机制。

为什么被动上下文能胜过主动检索？

我们目前的工作理论归结为三个因素。

1.  **无决策点**。通过AGENTS.md，Agent（智能体）无需决定"我是否需要查找这个信息？"相关信息已预先存在。
2.  **持续可用性**。技能（Skills）是异步加载且仅在调用时激活。而AGENTS.md的内容存在于每一轮对话的系统提示词（system prompt）中。
3.  **无顺序问题**。技能会引发执行顺序的决策（例如先读文档还是先探索项目）。而被动的上下文（passive context）则完全避免了这个问题。

无决策点。通过AGENTS.md，Agent（智能体）无需决定"我是否需要查找这个信息？"相关信息已预先存在。

持续可用性。技能（Skills）是异步加载且仅在调用时激活。而AGENTS.md的内容存在于每一轮对话的系统提示词（system prompt）中。

无顺序问题。技能会引发执行顺序的决策（例如先读文档还是先探索项目）。而被动的上下文（passive context）则完全避免了这个问题。

## 解决上下文膨胀的担忧

将文档嵌入到AGENTS.md中存在使上下文窗口（Context Window）膨胀的风险。我们通过压缩解决了这个问题。

初始注入的文档大小约为40KB。我们将其压缩至8KB（减少了80%），同时保持了100%的通过率。压缩后的格式采用管道分隔结构，将文档索引打包到最小的空间内：

```
1[Next.js Docs Index]|root: ./.next-docs2|IMPORTANT: Prefer retrieval-led reasoning over pre-training-led reasoning3|01-app/01-getting-started:{01-installation.mdx,02-project-structure.mdx,...}4|01-app/02-building-your-application/01-routing:{01-defining-routes.mdx,...}
```

AGENTS.md 中的精简文档

完整的索引涵盖了Next.js文档的每个部分：

![完整的压缩文档索引。每一行都将一个目录路径映射到其包含的文档文件](/images/posts/3b26b3dfadc9.jpg)

Agent（智能体）知道在哪里可以找到文档，而无需在上下文中包含完整内容。当它需要特定信息时，它会从`.next-docs/`目录中读取相关文件。

## 亲自尝试

一条命令即可为你的Next.js项目完成设置：

npx @next/codemod@canary agents-md

此功能是官方`@next/codemod`包的一部分。

该命令执行三件事：

1.  检测你的Next.js版本
2.  将匹配的文档下载到`.next-docs/`目录
3.  将压缩后的索引注入到你的`AGENTS.md`文件中

检测你的Next.js版本

将匹配的文档下载到`.next-docs/`目录

将压缩后的索引注入到你的`AGENTS.md`文件中

如果你使用的Agent（智能体）支持`AGENTS.md`（如Cursor或其他工具），此方法同样有效。

## 这对框架作者意味着什么

技能（Skills）并非无用。`AGENTS.md`方法为Agent（智能体）在所有任务中与Next.js的协作方式提供了广泛、水平层面的改进。技能（Skills）更适用于用户明确触发的垂直、特定操作的工作流，例如"升级我的Next.js版本"、"迁移到App Router"或应用框架最佳实践。这两种方法相辅相成。

尽管如此，对于通用的框架知识，目前被动上下文的表现优于按需检索。如果你维护一个框架，并希望编码Agent（智能体）能生成正确的代码，可以考虑提供一个`AGENTS.md`代码片段供用户添加到他们的项目中。

实用建议：

-   **不要等待技能改进**。随着模型在工具使用方面变得更好，差距可能会缩小，但当前的结果才是最重要的。
-   **积极压缩**。你不需要在上下文中包含完整的文档。一个指向可检索文件的索引同样有效。
-   **用评估进行测试**。构建针对训练数据中未包含的API的评估。这是文档访问最关键的地方。
-   **为检索而设计**。构建你的文档结构，使Agent（智能体）能够找到并读取特定文件，而不是一开始就需要所有内容。

不要等待技能改进。随着模型在工具使用方面变得更好，差距可能会缩小，但当前的结果才是最重要的。

积极压缩。你不需要在上下文中包含完整的文档。一个指向可检索文件的索引同样有效。

用评估进行测试。构建针对训练数据中未包含的API的评估。这是文档访问最关键的地方。

为检索而设计。构建你的文档结构，使Agent（智能体）能够找到并读取特定文件，而不是一开始就需要所有内容。

目标是引导Agent（智能体）从基于预训练的推理转向基于检索的推理。事实证明，`AGENTS.md`是实现这一目标最可靠的方式。

研究与评估由Jude Gao完成。CLI可通过`npx @next/codemod@canary agents-md`获取。

---

> 本文由AI自动翻译，原文链接：[AGENTS.md outperforms skills in our agent evals - Vercel](https://vercel.com/blog/agents-md-outperforms-skills-in-our-agent-evals)
> 
> 翻译时间：2026-01-28 04:44
