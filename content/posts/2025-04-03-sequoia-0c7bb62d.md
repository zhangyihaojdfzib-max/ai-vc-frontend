---
title: 反思AI：通往超级智能的竞赛
title_original: 'Reflection AI: The Race to Unlock Superintelligence'
date: '2025-04-03'
source: 红杉资本 (Sequoia)
source_url: https://sequoiacap.com/article/reflection-ai-spotlight/
author: ''
summary: 本文以AlphaGo战胜李世石为起点，回顾了DeepMind在强化学习领域的突破性进展，从AlphaGo Zero到MuZero，展示了AI从零开始、通过自我对弈达到超人类水平的能力。文章同时提及了研究者如约安尼斯和米沙的贡献与职业轨迹，揭示了AI研究如何吸引顶尖人才，并推动着通用人工智能与超级智能的探索。核心在于阐述强化学习如何通过不断迭代与创新，逐步解锁更复杂、更通用的智能系统。
categories:
- AI研究
tags:
- 强化学习
- AlphaGo
- 超级智能
- DeepMind
- 人工智能研究
draft: false
translated_at: '2026-02-09T04:22:05.841069'
---

"我从未因赢下一局棋而受到如此多的祝贺，"李世石在挤满人群的新闻发布会上面带微笑地说道，现场掌声热烈，闪光灯不断。这位伟大的围棋九段棋手刚刚在第四局中击败了DeepMind的AlphaGo，他使用了一手对手严重低估的意外楔入招法。两天后，AlphaGo将取得最终胜利，在五局比赛中赢得四局。真正抓住世界想象力的并非李世石的第78手，而是AlphaGo在更早两局比赛中的第37手。第37手极不寻常，以至于李世石和大部分观众起初都认为这是一步失误，后来才意识到它有多么"精妙"。人类棋手走出这步棋的概率仅有万分之一，它成为了人工智能具备超人类创造力的一次里程碑式展示。

在第五局比赛紧张的最后几分钟里，AlphaGo团队挤在首尔四季酒店的VIP套房内，这里已成为他们的指挥中心。团队负责人大卫·席尔瓦一侧是DeepMind创始人德米斯·哈萨比斯，另一侧是研究工程师约安尼斯·安东诺格鲁，正是他加速了驱动AlphaGo运行的神经网络。当李世石最终投子认输的那一刻，标志着一场为期两年的征程落下帷幕，这场征程将强化学习科学推向了新的高度，整个团队都为这一成就而欢欣鼓舞。

对约安尼斯而言，这证明了他当初看似冒险的职业选择是正确的——他于2012年作为第25号员工、第6号研究员加入了伦敦这家AI初创公司。"当时这里是世界上唯一一个人们认真考虑构建通用人工智能的地方，"他如今回忆道，并对强化学习在如此短时间内取得的成就感到惊叹。感到惊叹的不止他一人。在芝加哥，一位名叫米沙·拉斯金、刚获得量子物理学博士学位的人阅读了AlphaGo论文，并突然改变了自己的人生轨迹。他发现了一个与理论物理学一样精妙，却能产生现实世界影响力的领域。米沙意识到，"这让我们得以真正窥见与超级智能共存的未来景象。"

## AlphaGo及其后续发展

约安尼斯在DeepMind的第一位合作者是弗拉德·姆尼赫，这位研究员因构建了首个深度强化学习智能体DQN而闻名。他请约安尼斯编写一个简洁的DQN实现作为库，供DeepMind用于推进深度强化学习研究。"约安尼斯对细节的关注和学术上的严谨立刻脱颖而出，"弗拉德说，"他总是会问我们为什么做出特定的设计选择，为什么不更早地引入LSTM等组件。"

一年后，当大卫·席尔瓦开始研究AlphaGo时，DQN已经展示了如何在游戏中使用深度强化学习。AlphaGo在此基础上构建，包含了许多复杂的创新，例如使用蒙特卡洛树搜索——一种强大的搜索算法，通过模拟游戏结果来探索未来可能的走法。AlphaGo还采用了双网络架构，包含一个用于预测下一步走法的策略网络和一个用于评估棋盘局面的价值网络。

以当时的标准来看，这是一个庞大的系统。席尔瓦深知，最大化吞吐量和最小化延迟对于训练该系统并部署其进行实时对弈至关重要。他指派约安尼斯编写GPU内核代码，以加速他们正在训练的神经网络。DeepMind于2014年被谷歌收购，约安尼斯很快转而致力于在谷歌首批TPU上实现该系统。这些早期的芯片极不稳定且难以驾驭，但约安尼斯找到了驯服它们的方法。"如果我当时没能让它工作起来，"约安尼斯现在说，"那么我们就不可能取得AlphaGo所达成的那些成就。"

在首尔取得辉煌胜利后，约安尼斯继续与一个核心小团队合作，扩展这些游戏智能体的能力。"我们最早撰写的论文之一是AlphaGo Zero，"他回忆道。"我们证明了，你实际上可以从完全随机的行为开始，一路达到超智能行为，并获得与AlphaGo相同的性能——实际上比AlphaGo好得多。"这种白板方法结合自我对弈，对于证明强化学习能够扩展以解决新问题至关重要。

随后，团队构建了AlphaZero，它从随机走子开始，在除了游戏规则外没有任何领域知识的情况下，实现了超人水平的国际象棋和将棋对弈能力。这里的"Zero"也意味着该算法可以学会玩任何零和棋盘游戏。三年后，他们推出了MuZero，在其能力库中增加了雅达利游戏，并且不再提供游戏规则——只输入原始像素。在无法获得完美世界模拟器（如围棋或国际象棋中那样）的问题上使用强化学习，是一个长期存在的挑战，而MuZero解决了这个问题。"你实际上可以拥有一个既能学习世界动态，"约安尼斯说，"又能利用这个学习到的世界模型来对未来进行规划的系统。"

## 多伦多的Transformer

尽管米沙被DeepMind的研究所吸引，但他花了一些时间才找到通往那里的道路。他感染了创业热情，带着一家人工智能初创公司经历了Y Combinator的孵化，但人工智能研究的前沿领域始终在召唤他——他投身于伯克利皮特·阿比尔实验室的博士后研究，以磨练自己在AI研究方面的技能。就像一个优秀的强化学习智能体，他最大限度地从这个充满其他杰出研究者的环境中学习。作为一名前物理学家进入这个领域有一个额外的好处："因为我什么都不懂，所以我有一张白纸。我认为这让我能够尝试一些非常简单、以至于别人认为太显而易见而不会去尝试的东西。"他补充道，"正确地做简单的事情竟然如此困难，这让我感到惊讶。很多时候，当人们尝试简单的方法却没有成功时，是因为他们没有足够努力地去尝试。"

在接下来的两年半时间里，米沙追随通过自学培养的兴趣，在DeepMind Control Suite、雅达利游戏环境以及OpenAI Gym中改进强化学习方法。具体来说，他致力于数据增强策略和从原始像素中提取高级特征。他在伯克利合著的最受引用的论文是Decision Transformer，该论文将强化学习重新定义为序列建模问题，利用了Transformer架构的简洁性和可扩展性。

2021年，米沙接受了弗拉德的面试，后者当时正在多伦多为DeepMind组建一个新的通用智能体团队。"我立刻被米沙对强化学习和无监督方法力量的热情与信念所打动，所以当他决定加入团队时，真的非常令人兴奋，"弗拉德回忆道。"米沙从一开始就非常高效。他迅速熟悉了谷歌的基础设施，并在几周内就开始产出研究成果，这段时间也刚好够他找到多伦多所有好的咖啡店。"

弗拉德也很欣赏米沙从学术研究中带来的那种"白纸"状态，"他喜欢用非常简单的方法着手新问题。在研究中很容易把事情过度复杂化，但米沙似乎有一种天赋，能找到适用于某个问题的最简单方法。"

弗拉德和米沙后来在一个DeepMind黑客马拉松项目上合作，并在此基础上共同撰写了一篇题为《In-context reinforcement learning with algorithm distillation》的论文。"米沙和我决定训练一个Transformer来模仿一个强化学习算法，看看它是否能在未经训练的任务上表现出自我改进的能力，"弗拉德说。"我们在结对编程和让第一个原型运行起来的过程中获得了许多乐趣。这是情境中自我改进的一个早期例子，如今已成为大语言模型文献中一个非常活跃的研究领域。当我们发现Transformer学会了一个比它被训练模仿的算法高效得多的强化学习算法时，我们感到非常兴奋。"

Ioannis和Misha当时都在极力推动如何通过扩大规模和算法改进，让深度强化学习智能体变得更强大、更通用。但在2022年11月30日，人工智能的历史发生了突然的转折。“当ChatGPT问世时，一切都变了，”Ioannis回忆道。“我认为这对行业里的每个人来说都是一个重要时刻，让大家看到这些系统如此强大，它们可以成为通往更智能事物的起点。”

## 竞逐Gemini

ChatGPT的成功揭示了一个显而易见却曾被忽视的事实：深度强化学习的价值一直就在眼前。人类反馈强化学习（RLHF）是其训练的关键部分，它使模型的输出与人类的偏好和价值观保持一致。就像Transformer本身一样，OpenAI并没有发明深度强化学习，但却是第一个在这个规模上部署它的公司。

ChatGPT在两个月内用户数飙升至1亿，这在整个科技行业引发了冲击波——尤其是在谷歌内部。OpenAI不仅利用了Transformer架构，还在训练后增加了强化学习步骤，从而打造出一款现象级的消费级产品。2023年初，谷歌CEO Sundar Pichai宣布进入“红色警戒”状态，并请来联合创始人Larry Page和Sergey Brin帮助公司追赶OpenAI。几个月后，谷歌大脑团队与DeepMind合并，在Demis Hassabis的领导下成为Google DeepMind。

这次红色警戒也终结了Ioannis所从事的AlphaGo系列研究，他被选中领导谷歌新的大语言模型（LLM）Gemini的RLHF工作。Misha也希望加入Gemini团队，Ioannis让他负责奖励模型。在接下来的两年里，他们共同努力推出了Gemini 1和1.5。Misha起初对Ioannis有些敬畏，但很快对他的同事有了新的认识。“他领导的RLHF团队有趣的地方在于，他非常以人为本，并且非常努力地确保团队成员有自驱力。他会深刻理解每个人的驱动力，并找到引导他们的方向，以确保他们的工作对Gemini有影响力。我认为这是他作为领导者的一种超能力。”

到2023年12月，谷歌宣布了Gemini。当2024年2月v1.0版本发布时，在大多数基准测试中，其表现已与OpenAI的GPT-4相当甚至更优。这是一项巨大的成就，但团队并未松懈。几个月后，他们宣布了Gemini 1.5，这比OpenAI发布下一个重大升级GPT-4o早了三个月。Gemini 1.5通过混合专家架构提高了计算效率，增加了多模态能力和百万Token的上下文窗口。

对Misha而言，LLM的突然崛起是一个启示。“我们当时试图解决通用智能体的问题，但我们的思路完全错了，”他说。“因为我们当时认为通用性问题尚未解决。”尽管存在各种局限和幻觉，但LLM是有史以来发明的最通用的系统。“它们不是非常可靠，”Misha解释道。“它们不能自主为你完成任何工作。你不能像要求同事那样要求它们去做某事，但它们几乎能回答你提出的任何问题。”

将这种广泛的智能与可靠执行特定行动的能力结合起来，仍然是一个未解决的问题。“在AlphaGo中，奖励是明确的。你赢或输。在这些目标明确的系统中，强化学习的效果堪称神奇，”Misha说。然而，在大多数现实生活情境中，奖励是相当模糊的。你如何知道一项复杂任务是否完成？你如何知道人类是否会喜欢模型的回答？这正是他在DeepMind研究的、针对通用智能体的开放式奖励函数发挥作用的地方。“碰巧的是，我在语言模型之外专注研究的这个构建模块，恰恰是训练它们的核心构建模块之一，”Misha解释道。

用Misha的话说，他和Ioannis已经实现了成为“训练语言模型的最佳工匠”的目标。他们对这些系统了如指掌，但他们觉得，朝着他们热切的研究问题——如何构建能够自主行动的超级智能系统——前进的轨迹还不够快。

![Reflection联合创始人Ioannis Antonoglou和Misha Laskin](/images/posts/a7ecfd6d3685.jpg)

## 用Reflection拼合拼图

LLM在实现非常广泛的能力方面取得了成功，但它们的胜任力是肤浅的。正如Misha所说，它们解决了广度问题，但没有解决深度问题。“越来越清楚的是，这两股研究方向是构建超级智能的两个基石，”他说。“你从语言模型中获得通用性，从强化学习中获得能力。”Ioannis补充道：“确实，构建一个能在现实世界产生影响的超级智能体所需的所有必要组件都已齐备。”

当他们于2024年3月离开DeepMind创立Reflection时，他们的战略与行业大多数公司的方向背道而驰。一年后，每个主要实验室都在研究用强化学习增强LLM的推理模型，但这在当时并非一个显而易见的方向。同样，他们决定训练自己的模型，这对一家小型初创公司来说似乎是成本高昂得令人望而却步的举措，但现在看来，通过巧妙的工程，可以极大地改善模型训练的经济性。

“拥有算法是一回事，”Ioannis说，“但以可扩展的方式构建它们，并以最佳方式利用计算资源，这同样重要——甚至更重要。我们实际上已经在DeepSeek身上看到了工程的力量，他们通过出色的工程，以如此小的预算获得了如此卓越的性能。”

规模化对Reflection的方法至关重要，但具体而言，是关于在训练后阶段扩大数据和计算规模，这使得智能体在特定任务上能变得越来越好。正如Ioannis在AlphaGo工作中所学到的，你必须“在系统上真正下大力气”，才能获得超人的结果。但是，他承认：“这需要一点信念的飞跃。现在你有了扩展定律，但除非你真正投入资源，并亲眼看到随着计算量级提升，这些定律依然成立，否则你永远无法确定，对吧？”

预训练LLM的扩展定律开始趋于平缓，但在训练后阶段加入强化学习，增长曲线才刚刚开始攀升。与可能即将耗尽的LLM训练数据不同，强化学习训练的数据很大程度上是由强化学习智能体自身在与环境互动中产生的。“它有些事情做对了，有些事情做错了，”Ioannis解释道。“做对的事情应该多做，做错的事情应该少做。这就像是从错误中学习。如果正确地进行规模化，这种非常简单的机制就能催生超级智能行为。”

Misha对此有更精辟的阐述：“强化学习的根本在于——它是人工智能最具扩展性的形式。基本上，我们目前看不到它的上限。”

关于LLM，有一点是：并非所有任务对它们来说都是平等的。它们就像人类一样，能力分布不均，这主要是由于训练数据质量和数量的差异。Misha解释说，模型的智能并非均匀分布在人类所有知识领域，而是“一种参差不齐的智能”。他预测，第一批通用的超级智能系统将在某些方面表现出色，而在其他方面则不然。

事实证明，LLM能力最不均衡的领域，恰恰是它们目前在工作场景中最常用的领域：编程。“模型已经开始表现良好的领域，将会得到放大，”Misha说，“而这将是我们首先看到超级智能行为的地方。”

## 超级智能，即产品

"许多AI团队认为模型就是产品，"Misha表示。"通过与客户交流，我们对自己所构建之物的思考方式是：它并非仅仅是一个模型，而是一个系统。因此，这是一个模型与产品的结合体，旨在为我们的客户解决实际问题。"

Reflection创始人们看到的机遇，是创造真正自主的编码智能体，能够准确完成目前需要工程师处理的端到端任务。"如果说在自主编码领域，客户最关心什么，"Misha指出，"那就是可靠性。"

Misha以Waymo为例，类比了这在实践中可能呈现的样子。"产品的一部分，"他解释道，"是地理围栏。它不仅仅是一辆车，而是在确定边界及其优势区域。"Reflection的方法并非像当前大多数编码智能体那样，一开始就宣称能处理任何任务，而是划分出相当于大型都市区的软件领域，并在该地理范围内提供强有力的安全性和可靠性保证。

这种限制的积极一面在于，它能为用户提供更直观的界面。"最无摩擦的界面，就像你与人类交流时使用的界面，"Misha说。"例如，你给它一个工程任务，它返回给你的实现方案比你想象的还要好。这就是我们所认为的超级智能的样子。"

创始人们相信，解决自主编码问题是一个"根节点"问题，将解锁更通用的超级智能。"我们认为自主编码是AGI完备的。因此，如果你证明自己拥有一个超级智能的软件开发者，那就足够了，那就是一个AGI，"Ioannis说。"然后，只需采用相同的算法并将其应用于不同的垂直领域。但你已经掌握了如何构建超级智能系统的秘诀。在这个特定问题中，智能所需的所有要素都已具备。"

## 为何是代码，为何是现在？

智能有多种类型，不仅仅是编写代码所需的那种。但代码似乎是推动机器智能最易触及的表面积。"我们认为智能的进化速度将快于软件，"Misha预测道。"今天致力于软件工程的原因是，这是唯一已经为此做好准备的领域。整个软件工程领域都是为了对机器友好而构建的。"

用自主智能体实现编码自动化，将对软件本身产生深远影响。"在软件中，我们人类习惯使用的形态因素、在计算机上使用的用户界面，未必是AI最优的界面，"Misha说。图形用户界面的演变，是因为人类拥有基于眼睛和双手的先天先验知识。但对于LLM（大语言模型）而言，它们的先验知识是互联网上的语言。"但当涉及到与计算机交互时，与计算机交互的语言就是代码。因此，对于语言模型来说，代码就像三维物体操作对人类一样直观，"Misha继续说道。"代码对于语言模型来说是符合人体工程学的。"

这些变化的影响需要时间来展现。在这个过程中，生产软件的公司将创建对AI友好的用户界面，使得人类与软件产品的交互即使不是即时的，也能更快。Misha预见，"可能是GUI的部分功能被取代，其底层只是一个语言模型通过代码完成某些工作。"LLM可能只需编写一行代码来封装整个任务，而不是需要人类点击十次的工作流程。

Reflection团队对超级智能有一个务实的定义：它是一种通过在计算机上工作来创造价值的事物。"我们认为，编码智能体实际上将成为未来语言模型在任何软件上工作的方式，"Misha说。"因此，如果你解决了这个问题，你就解决了计算机上任何拥有AI友好界面的软件的超级智能问题。"最终，红杉资本合伙人Stephanie Zhan设想，这将引领我们走向"一个未来，在那里我们都成为超级智能智能体的主管，它们代表我们进行知识工作。"

实现这一目标不仅涉及训练模型，还需要构建对机器友好的界面——从浏览器、代码编辑器到任务类别的抽象表示——这些界面实际上为超级智能搭建了舞台。创始人们相信，当自主智能体拥有为其量身定制的环境（想想DeepMind的Atari环境或OpenAI Gym）时，它们才能发挥最佳作用，在这些环境中磨练其特定技能。对于代码而言，所需的环境和工具相对容易想象，但其他认知类别可能需要更大的跨越。

当前阶段的AI就像热力学发现之前的早期蒸汽机：理论的缺乏并未阻止发明家制造新的引擎。"我认为从理论层面深入理解模型为何有效，无疑将是非常有益的，"Misha说。"每当一个事物在理论上被深入理解时，至少在物理学中，它都会催生一个经验创新的新时代，因为科学家们知道该往哪里探索。但今天，你无需等待那一刻就能构建可靠的系统。"Richard Feynman是Misha早期的偶像，激励他学习物理学。在关于能量守恒的讲座中，Feynman说："重要的是要认识到，在今天的物理学中，我们并不知道能量是什么。"今天的AI和智能研究也是如此。在斯德哥尔摩的一次诺贝尔奖采访中，DeepMind创始人Demis Hassabis总结了我们在追求超级智能方面所处的位置："我认为AI科学是关于尝试探索和理解智能是什么，而理解某事物的最佳表达方式，实际上就是尝试构建它。"

## 相关主题

![](/images/posts/911108dfd753.jpg)

## 与Reflection合作

![](/images/posts/9f2aecc9f7a1.png)

## Reflection的Misha Laskin谈LLM后训练

![](/images/posts/f96ad7f0494e.png)

## Ioannis Antonoglou：从AlphaGo到AGI

![](/images/posts/a4c1b0a153dd.jpg)

## 生成式AI的Act o1

# 获取红杉社区的最佳故事。

---

> 本文由AI自动翻译，原文链接：[Reflection AI: The Race to Unlock Superintelligence](https://sequoiacap.com/article/reflection-ai-spotlight/)
> 
> 翻译时间：2026-02-09 04:22
