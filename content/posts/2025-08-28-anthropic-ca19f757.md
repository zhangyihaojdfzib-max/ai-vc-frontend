---
title: Claude开发计算机使用模型：AI直接操作软件的新突破
title_original: Developing a computer use model
date: '2025-08-28'
source: Anthropic
source_url: https://www.anthropic.com/news/developing-computer-use
author: ''
summary: 本文介绍了Anthropic公司为Claude 3.5 Sonnet模型开发的计算机使用能力，该能力允许AI通过观察屏幕截图、移动光标和模拟键盘输入来直接操作计算机软件。文章阐述了此项技术的重要性、研究过程（包括在OSWorld评估中取得14.9%的得分），以及为确保安全性而进行的风险分析（目前仍属AI安全等级2）。同时，文章也提及了应对提示词注入等潜在安全挑战的措施。
categories:
- AI研究
tags:
- Claude
- 计算机使用模型
- 人机交互
- AI安全
- 多模态AI
draft: false
translated_at: '2026-02-11T04:29:55.287546'
---

# 开发计算机使用模型

- 更新消费者条款与隐私政策 2025年8月28日

消费者条款与隐私政策

2025年8月28日

Claude 现已能够使用计算机。最新版本的 Claude 3.5 Sonnet 在通过适当的软件设置运行时，可以遵循用户的指令在计算机屏幕上移动光标、点击相关位置并通过虚拟键盘输入信息，模拟人类与计算机交互的方式。

我们认为这项目前处于公开测试阶段的能力，代表了人工智能发展的重大突破。下文，我们将分享在开发计算机使用模型以及使其更安全的研究过程中获得的一些见解。

## 为何需要计算机使用能力？

这项新能力为何重要？现代大量工作都是通过计算机完成的。让人工智能能够像人类一样直接与计算机软件交互，将解锁当前一代人工智能助手根本无法实现的海量应用场景。

过去几年，强大人工智能的发展已达成许多重要里程碑——例如执行复杂逻辑推理的能力，以及观察和理解图像的能力。下一个前沿领域就是计算机使用：人工智能模型无需通过定制工具进行交互，而是能够根据指令使用几乎任何软件。

## 研究过程

我们之前在工具使用和多模态方面的工作为这些新的计算机使用技能奠定了基础。操作计算机需要观察和解释图像的能力——在本例中，是计算机屏幕的图像。它还需要推理如何以及何时根据屏幕内容执行特定操作。结合这些能力，我们训练 Claude 解释屏幕上发生的情况，然后使用可用的软件工具来执行任务。

当开发者要求 Claude 使用某个计算机软件并给予必要访问权限时，Claude 会查看用户可见的屏幕截图，然后计算需要垂直或水平移动光标多少像素才能点击正确位置。训练 Claude 准确计算像素至关重要。没有这项技能，模型很难给出鼠标指令——类似于模型经常在看似简单的问题上遇到困难，比如“单词‘banana’中有多少个字母‘A’？”。

我们惊讶地发现，Claude 仅通过我们在少数简单软件（如计算器和文本编辑器）上进行的计算机使用训练，就迅速实现了泛化（出于安全考虑，我们在训练期间不允许模型访问互联网）。结合 Claude 的其他技能，这项训练赋予了它非凡的能力：将用户的书面提示词转化为一系列逻辑步骤，然后在计算机上执行操作。我们观察到，模型甚至在遇到障碍时会自我纠正并重试任务。

尽管在取得初步突破后进展迅速，但我们为此付出了大量的试错。一些研究人员指出，开发计算机使用能力的过程，接近他们刚进入该领域时设想的“理想化”人工智能研究过程：持续迭代，反复回到起点，直至取得进展。

研究取得了回报。目前，在像人类一样使用计算机（即观察屏幕并采取相应行动）的模型中，Claude 处于最先进水平。在用于测试开发者让模型使用计算机的尝试的评估平台 OSWorld 上，Claude 目前得分为 14.9%。这远未达到人类水平（通常为 70-75%），但远高于同类中次优人工智能模型获得的 7.7%。

## 确保计算机使用的安全性

人工智能的每一次进步都伴随着新的安全挑战。计算机使用主要是降低人工智能系统应用其现有认知技能的门槛，而非从根本上提升这些技能，因此我们对计算机使用的主要关注点在于当下的危害，而非未来的风险。我们通过评估计算机使用是否会增加《负责任扩展政策》中概述的前沿威胁风险来确认这一点。我们发现，更新后的 Claude 3.5 Sonnet（包括其新的计算机使用技能）仍处于人工智能安全等级 2——即，它不需要比我们目前已有的更高标准的安全保障措施。

当未来模型因存在灾难性风险而需要人工智能安全等级 3 或 4 的保障措施时，计算机使用可能会加剧这些风险。我们判断，现在引入计算机使用能力可能更好，因为模型目前仍只需要人工智能安全等级 2 的保障措施。这意味着我们可以在风险过高之前就开始应对任何安全问题，而不是首次将计算机使用能力添加到风险严重得多的模型中。

本着这种精神，我们的信任与安全团队对新计算机使用模型进行了广泛分析，以识别潜在漏洞。他们发现的一个担忧是“提示词注入”——一种网络攻击，向人工智能模型输入恶意指令，导致其覆盖先前的指令或执行偏离用户原始意图的意外操作。由于 Claude 可以解释连接到互联网的计算机的屏幕截图，它有可能接触到包含提示词注入攻击的内容。

在我们的公开测试中使用计算机使用版 Claude 的用户应采取相关预防措施，以最小化此类风险。作为开发者的资源，我们在参考实现中提供了进一步的指导。

与任何人工智能能力一样，用户也有可能故意滥用 Claude 的计算机技能。我们的团队已经开发了分类器和其他方法来标记和减轻此类滥用。鉴于即将到来的美国大选，我们对可能被视为破坏公众对选举过程信任的滥用企图保持高度警惕。虽然计算机使用能力尚不够先进，也无法大规模操作，从而相对于现有能力带来更高的风险，但我们已经制定了措施来监控 Claude 被要求参与选举相关活动的情况，以及引导 Claude 远离某些活动的系统，例如在社交媒体上生成和发布内容、注册网络域名或与政府网站交互。我们将持续评估并迭代这些安全措施，以在公开测试期间平衡 Claude 的能力与负责任的使用。

## 计算机使用的未来

计算机使用是一种完全不同的人工智能开发方法。迄今为止，LLM 开发者一直是让工具适应模型，创造出定制环境，让人工智能使用专门设计的工具来完成各种任务。现在，我们可以让模型适应工具——Claude 可以融入我们日常使用的计算机环境。我们的目标是让 Claude 能够使用现有的计算机软件，并像人一样简单地使用它们。

还有很多工作要做。尽管处于当前最先进水平，Claude 的计算机使用仍然缓慢且容易出错。人们用计算机常规执行的许多操作（如拖拽、缩放等），Claude 目前还无法尝试。Claude 对屏幕的“翻页式”视图（拍摄屏幕截图并将其拼凑起来，而非观察更细粒度的视频流）意味着它可能会错过短暂的动作或通知。

就在我们为今天的发布录制计算机使用演示时，我们遇到了一些有趣的错误。在一次演示中，Claude 不小心点击停止了长时间运行的屏幕录制，导致所有录像丢失。在另一次演示中，Claude 突然在我们的编码演示中暂停，开始浏览黄石国家公园的照片。

我们预计计算机使用功能将迅速改进，在处理用户想要完成的任务时变得更快、更可靠、更有用。对于软件开发经验较少的人来说，实现这一功能也将变得容易得多。在每一个阶段，我们的研究人员都将与安全团队紧密合作，确保 Claude 的新能力都伴随着相应的安全措施。

我们邀请在公开测试版中尝试计算机使用功能的开发者通过此表单联系我们并提供反馈，以便我们的研究人员能够持续改进这一新功能的实用性和安全性。

## 相关内容

### 介绍 Claude Opus 4.6

我们正在升级我们最智能的模型。在智能体编码、计算机使用、工具使用、搜索和金融领域，Opus 4.6 都是一个行业领先的模型，通常优势明显。

### Claude 是一个思考空间

我们做出了一个选择：Claude 将保持无广告。我们解释了为什么广告激励与真正有用的 AI 助手不相容，以及我们计划如何在扩展访问的同时不损害用户信任。

### Apple 的 Xcode 现已支持 Claude Agent SDK

---

> 本文由AI自动翻译，原文链接：[Developing a computer use model](https://www.anthropic.com/news/developing-computer-use)
> 
> 翻译时间：2026-02-11 04:29
