---
title: AI伦理问题的本质：是技术缺陷还是制度失责？
title_original: The problem of AI ethics — Benedict Evans
date: '2024-03-23'
source: Benedict Evans
source_url: https://www.ben-evans.com/benedictevans/2024/3/23/the-problem-of-ai-ethics-and-laws-about-ai
author: ''
summary: 本文以英国邮政局丑闻为例，指出当前关于AI伦理的讨论常陷入错误的抽象层级。作者认为，AI引发的各类问题（如偏见、安全、内容审核等）本质上是不同领域的具体制度与监管问题，而非单一技术伦理问题。将AI视为一个整体进行监管，如同设立“SQL监管机构”一样不切实际。真正的挑战在于针对不同应用场景（如司法、医疗、金融），由相应领域的专业人士制定具体规则，并承认技术快速演进带来的不确定性。
categories:
- 政策监管
tags:
- AI伦理
- 技术监管
- 制度失败
- 生成式AI
- 科技政策
draft: false
translated_at: '2026-01-09T04:29:33.606903'
---

# AI伦理问题

20世纪90年代末，英国邮政局部署了一套由富士通为其打造的新型销售点计算机系统。几乎立即，作为自雇者的小型独立零售商——邮政局长们——开始报告系统显示现金短缺；邮政局对此的反应是提起盗窃诉讼。随后的15年里，近千人被定罪，更多人被错误指控并被迫和解，还发生了至少四起自杀事件。

该系统充满可能导致虚假短缺显示的漏洞，富士通和邮政局内部的一些人知道这一点，但富士通和邮政局员工出庭作证称系统运行正常，盗窃是唯一解释。如今，这理所当然地演变成了一场巨大的丑闻。

每次听到关于AI伦理的讨论，每次人们谈及监管AI时，我都会想起这个案例。富士通当时构建的并非机器学习或LLM——那是1970年代的技术。但我们不会审视这场丑闻并声称需要"数据库伦理"，或认为解决方案是设立"SQL监管机构"。这是富士通内部、邮政局内部以及未能妥善检验证据的法庭系统的制度性失败。需要明确的是，失败不在于存在漏洞，而在于拒绝承认漏洞。无论如何，套用如今人们担忧AI时使用的语言：一台运行着难以诊断或理解的不确定软件的计算机，做出了毁掉人们生活的"决定"——它"判定"钱款缺失。邮政局员工只是盲目遵从了这些决定。

我们无法通过设立SQL监管机构来解决这个问题，同样地，当我们读到FTX拥有八份不同资产负债表的电子表格时，也不会呼吁设立"电子表格监管机构"，要求微软防止此类事件再次发生。那将是错误的抽象层级。

我认为，这正是讨论"AI伦理"或制定法律监管"AI"时的挑战所在。

坏人利用软件作恶的方式多种多样，人们搞砸软件的方式也层出不穷——我们既担心技术正常运作的后果，也忧虑技术失灵的影响。过去十年，机器学习创造了一系列新的出错或作恶方式，而生成式机器学习也将如此。

然而，这些问题会以截然不同的形式出现在完全不同的领域。人们将把AI用于从假释审理到抵押贷款审批，从批改中学试卷到商场抓贼（或试图抓贼），再到优化风力涡轮机叶片和规划自行车道等方方面面。其中一些应用涉及伦理问题或偏见问题（部分偏见问题甚至关乎人群偏见）。另一些则存在搞砸并致人死亡的潜在风险。但它们都是不同的问题，涉及不同的疑问、后果和专业知识。

最近几周关于谷歌Gemini的喧嚣就是一个很好的案例研究。我认为大多数人会同意：如果你向搜索引擎询问自杀的最佳方式，它不应仅仅告诉你绳套与安眠药的利弊；我们也理解Instagram和Pinterest或许不该向14岁女孩推送自残内容，即使她们似乎对此感兴趣。但我们已经花了十多年争论内容审核的真正含义以及如何划定界限，现在我们需要将这些争论应用于生成式搜索或生成式图像，而这绝不会更容易。许多聪明人将乐于在未来几年就此展开辩论——但与此同时，这与多发性硬化症药物研发中生成式AI的训练数据和测试协议毫无关系。这些都是不同的问题，很难想象存在一个能涵盖所有问题的伦理领域。正如拉里·特斯勒所言：AI就是任何尚未奏效的技术——一旦奏效，它就只是软件，而如今万物皆软件。

我常将科技监管与汽车监管相类比。汽车引发各种问题，我们拥有大量法规政策，当前这波消费科技监管浪潮有时看起来颇为相似。但我们没有一个政府部门、一部综合法律来涵盖通用汽车对待经销商的方式、碰撞安全标准、大城市拥堵收费、税法是否鼓励低密度开发、如何处理青少年酒后超速驾驶，以及国家石油供应安全等问题。这些都是重大问题，生成式AI也引发各种潜在问题，但它们都是不同性质的问题，最好由截然不同的专业人士来理解。

科技与汽车监管的最大区别在于：我们花了75年才为汽车安装安全带，却不愿等75年才监管科技；然而我们从小接触汽车并理解它们，而对某些科技问题往往缺乏直觉理解。生成式AI为此增添了新维度：Instagram或Tiktok可能相对新颖，但它们现在的形态与去年相差无几，而科技界无人真正知道今年年底生成式AI会是什么模样。关于其运作原理和发展轨迹的各种基础问题都悬而未决。延伸我的类比：我们就像在1910年撰写关于飞机和汽车的法律与论文。这需要保持谦逊，并预期你现在所说的大部分内容到明年此时可能已无关紧要。

---

> 本文由AI自动翻译，原文链接：[The problem of AI ethics — Benedict Evans](https://www.ben-evans.com/benedictevans/2024/3/23/the-problem-of-ai-ethics-and-laws-about-ai)
> 
> 翻译时间：2026-01-09 04:29
