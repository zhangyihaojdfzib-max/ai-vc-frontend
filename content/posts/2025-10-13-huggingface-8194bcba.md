---
title: Nemotron-Personas-India：面向印度主权AI的合成人物角色数据集
title_original: 'Nemotron-Personas-India: Synthesized Data for Sovereign AI'
date: '2025-10-13'
source: Hugging Face Blog
source_url: https://huggingface.co/blog/nvidia/nemotron-personas-india
author: ''
summary: 本文介绍了NVIDIA发布的Nemotron-Personas-India数据集，这是首个与印度真实世界人口、地理和文化分布对齐的开放合成数据集。该数据集包含2100万个人物角色，支持英语和印地语，涵盖印度所有邦和地区，采用CC
  BY 4.0许可。它基于官方统计数据生成，完全合成且无隐私风险，旨在填补现有数据集的西方偏向，为开发反映印度多语言、多文化环境的AI系统提供基础，支持从聊天机器人到专业助手等多种应用场景。
categories:
- AI产品
tags:
- 合成数据
- 主权AI
- 多语言AI
- 印度AI
- 数据集
draft: false
translated_at: '2026-01-27T04:38:26.094254'
---

# Nemotron-Personas-India：面向主权 AI 的合成数据

一种基于真实世界分布的印度人物角色复合 AI 方法

## 为印度 AI 未来提供开放数据

印度代表了世界上最大的 AI 机遇之一——拥有超过 7 亿互联网用户、多种语言以及快速发展的开发者生态系统。然而，大多数开放数据集反映的是西方规范和纯英语语境，造成了数据鸿沟，限制了 AI 在印度多语言、多文字环境中的应用。

今天，我们发布 **Nemotron-Personas-India**，这是首个与印度真实世界人口、地理和文化分布对齐的印度语系人物角色开放合成数据集。该数据集采用 **CC BY 4.0** 许可，为扩展反映印度社会的 AI 系统提供了一个保护隐私、符合法规要求的基础——无需依赖敏感的个人数据。

该数据集使用 **NeMo Data Designer**（NVIDIA 的企业级合成数据生成微服务）构建，是我们全球 **主权 AI** 数据集集合的扩展。它建立在我们美国和日本人物角色数据集成功的基础上，并包含了专为印度文化丰富性设计的新特性。

该数据集可与 **Nemotron 模型** 及其他开源 LLM（大语言模型）无缝集成，便于为印度应用场景微调 AI 系统——从多语言聊天机器人到基于文化的专业智能副驾。

此次发布是对我们早期印地语评估数据集套件（包括 **ChatRAG-Hi**、**IFEval-Hi**、**MT-Bench-Hi**、**GSM8K-Hi** 和 **BFCL-Hi**）的补充，支持为印度 AI 系统提供从合成数据生成到严格模型评估的完整流程。

## 数据集包含什么？

![image/png](/images/posts/4ed0de4881f8.png)

- **总计 2100 万个人物角色**（300 万条记录 × 每条记录 7 个角色）
- **多语言支持**：英语和印地语，均支持天城文和拉丁文字
- **每条记录 27 个字段**：基于官方人口普查和劳动力统计数据的人物角色特征 + 上下文属性，包括年龄、性别、教育程度、职业、邦、地区等
- **总计 77 亿 Token**，其中包含 29 亿人物角色 Token
    - 英语：总计 10 亿 Token，3.94 亿人物角色 Token
    - 印地语（天城文）：总计 47 亿 Token，18 亿人物角色 Token
    - 印地语（拉丁文）：总计 20 亿 Token，7.46 亿人物角色 Token
- **约 56 万个独特的全名**，反映了印度巨大的语言多样性
- **2900 个职业类别**，包括非正规、正规和传统行业
- **涵盖印度所有 36 个邦和 640 个地区**
- **自然语言字段**：文化背景、语言背景、技能与专长、爱好与兴趣
- **人物角色类型**：包括通用、专业、语言、烹饪、体育、艺术和旅行角色
- **采用 CC BY 4.0 许可**，可用于商业和非商业用途

## 我们如何构建它

### 数据生成流程

使用 **NeMo Data Designer**（NVIDIA 的合成数据生成微服务）生成。这个复合 AI 系统支持使用复杂的 Jinja 模板、Pydantic 验证、结构化输出、自动重试，并支持多个生成后端——这是扩展如此规模合成数据集所必需的工具。我们还利用了以下模型：

1.  **概率图模型（Apache-2.0）**：用于统计基础
2.  **GPT-OSS-120B（Apache-2.0）**：用于生成英语、印地语（天城文）和印地语（拉丁文）的叙述文本

### 嵌入的文化背景

该数据集与 2011 年人口普查的印度官方人口分布对齐，并扩展了对于可信 AI 训练至关重要的属性：

- **教育**：扩展了学位级别，以反映印度多样化的学术路径
- **职业**：包括正规、非正规和传统行业，如农业、裁缝和街头贩卖
- **人生阶段**：包括学生、家庭主妇、退休人员和失业类别
- **文化特征**：家庭结构、地区节日、婚姻传统和规范
- **数字鸿沟**：模拟了城乡、年龄和收入线之间的使用模式
- **语言多样性**：为每个合成人物角色包含了关于第一、第二和第三口语的惊人多样性

### 设计即隐私

没有真实姓名。没有重新识别风险。

所有人物角色都是完全合成的。虽然基于 **2011 年人口普查** 和 **解析的印度选民名册** 数据的真实世界分布，但没有任何数据与任何在世或已故的个人相关联。这确保了开发者可以安全地训练 AI 系统，而无需担心隐私风险或监管障碍。

## 面向对象

为印度构建，为世界准备

**Nemotron‑Personas‑India** 专为为 **印度市场** 构建 **主权 AI** 系统的开发者，以及希望使模型适应印度独特语言、文化和社会背景的全球团队而设计。

当今大多数开放数据集反映的是英语、西方规范——限制了 AI 在印度多语言、多文字和人口复杂环境中的表现。

## 实用的 AI 应用

借助 **Nemotron‑Personas‑India**，团队可以：

- 用 **印度语言和文字** 生成多样化、逼真的训练数据
- **微调** 模型以捕捉 **本地社会、职业和文化细微差别**
- 构建能够泛化到印度众多社区的 **区域感知 AI Agent（智能体）**
- 开发针对印度专业和公民工作流程的 **领域特定智能副驾**
- 创建能够处理 **复杂多轮对话** 和不同数字熟练程度的 **多语言系统**

## 为何重要

印度的 14 亿人口使用数百种语言，生活在巨大的文化、经济和地理鸿沟之中。印度国家 AI 门户网站估计有超过 **7000 家 AI 初创公司和研究机构** 正在努力构建本地相关的 AI 系统，而“数字印度”倡议和 IndiaAI 等政府计划正在加速采用。

但进展受到一个根本性差距的制约：反映印度人口现实的高质量、基于文化的训练数据。没有代表性的数据集，AI 系统难以处理英语和印地语之间的语码转换，无法理解地区性职业类别，并且会错失对于建立信任和采用至关重要的文化背景。

该数据集通过反映印度真实的地理和人口分布，提高了合成生成数据的多样性，减轻了偏见，并防止了 **模型崩溃**（因对另一个模型的输出进行未经筛选的训练而导致的性能退化）。

**Nemotron-Personas-India** 支持印度模型构建者开发包含重要地区特定人口统计和文化背景的主权 AI 系统。

## 开始使用 Nemotron-Personas-India 构建

想要构建理解印度文化、语言和人民的 AI 系统吗？

立即开始实验：

```python
from datasets import load_dataset


nemotron_personas_en = load_dataset("nvidia/Nemotron-Personas-India", "en_IN")

nemotron_personas_hi_deva = load_dataset("nvidia/Nemotron-Personas-India", "hi_Deva_IN")

nemotron_personas_hi_latn = load_dataset("nvidia/Nemotron-Personas-India", "hi_Latn_IN")

```

无论您是开发主权 AI 的印度模型构建者，还是寻求更好区域采用的全球开发者，**Nemotron-Personas-India** 都为您应用提供了真实、隐私安全的基础。

下载它。微调它。构建理解印度的 AI。如果您准备深入探索，**Nemotron-Personas-India** 的扩展版本（包含例如名/姓、宗教和合成地址）可在 **NeMo Data Designer** 中获取。

---

> 本文由AI自动翻译，原文链接：[Nemotron-Personas-India: Synthesized Data for Sovereign AI](https://huggingface.co/blog/nvidia/nemotron-personas-india)
> 
> 翻译时间：2026-01-27 04:38
