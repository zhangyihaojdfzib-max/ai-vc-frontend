---
title: 混合输入矩阵乘法性能优化：提升大模型效率
title_original: Mixed-input matrix multiplication performance optimizations
date: '2024-01-26'
source: Google AI Blog
source_url: http://blog.research.google/2024/01/mixed-input-matrix-multiplication.html
author: null
summary: 本文介绍了针对大语言模型（LLM）中混合输入矩阵乘法（如F16输入与U8权重）的性能优化技术。作者聚焦于NVIDIA安培架构，通过软件层面的数据类型转换和布局一致性处理，将硬件不直接支持的混合输入运算高效映射到Tensor
  Core上。这些方法在开源CUTLASS库中实现，能以极小开销实现接近硬件峰值的性能，有效应对LLM的内存与计算挑战。
categories:
- AI基础设施
tags:
- 矩阵乘法
- 性能优化
- 大语言模型
- GPU编程
- 模型量化
draft: false
---

混合输入矩阵乘法性能优化
2024年1月26日
作者：Manish Gupta，谷歌研究院高级软件工程师
快速链接

人工智能驱动技术正日益融入我们的日常生活，有望提升我们获取知识的能力并提高整体生产力。这些应用的支柱在于大语言模型（LLM）。LLM是内存密集型的，通常需要专门的硬件加速器来高效提供数十亿亿次浮点运算的计算能力。这篇博客展示了我们如何通过更有效地利用内存来着手应对这些计算挑战。

LLM的大部分内存和计算消耗都集中在矩阵乘法运算中的权重上。使用更窄的数据类型可以减少内存消耗。例如，以8位整数（即U8或S8）数据类型存储权重，相对于单精度（F32）可减少4倍内存占用，相对于半精度（F16）或bfloat16（BF16）可减少2倍。此外，先前的研究表明，LLM模型以S8权重和F16输入（保持用户输入的更高精度）运行矩阵乘法，是一种在可接受的精度权衡下提高效率的有效方法。这种技术被称为仅权重量化，需要高效实现混合输入的矩阵乘法，例如半精度输入乘以8位整数。包括GPU在内的硬件加速器支持一组固定的数据类型，因此，混合输入矩阵乘法需要通过软件转换来映射到硬件操作。

为此，在本博客中，我们专注于将混合输入矩阵乘法映射到NVIDIA安培架构上。我们提出了解决数据类型转换和布局一致性的软件技术，以高效地将混合输入矩阵乘法映射到硬件支持的数据类型和布局上。我们的结果表明，软件中额外工作的开销极小，并且能实现接近硬件峰值能力的性能。这里描述的软件技术已在开源NVIDIA/CUTLASS代码库中发布。

| 采用不同数据类型的1750亿参数LLM模型的内存占用情况。 |

矩阵乘积累加运算

现代AI硬件加速器，如谷歌的TPU和NVIDIA的GPU，通过针对Tensor Core在硬件中本地执行矩阵乘法。Tensor Core是专门用于加速矩阵运算的处理单元，尤其适用于AI工作负载。在本博客中，我们专注于NVIDIA安培Tensor Core，它提供矩阵乘积累加（mma）运算。在博客的其余部分，提及的mma均指安培Tensor Core。mma运算的两个输入矩阵（称为操作数）所支持的数据类型、形状和数据布局在硬件中是固定的。这意味着具有各种数据类型和更大形状的矩阵乘法需要通过软件实现，将问题分块映射到硬件支持的数据类型、形状和布局上。

Tensor Core mma运算通过指定两个输入矩阵（例如，如下所示的A和B）来生成结果矩阵C。mma运算原生支持混合精度。混合精度Tensor Core允许混合输入（A和B）数据类型与结果（C）数据类型。相比之下，混合输入矩阵乘法涉及混合输入数据类型，硬件不支持，因此需要在软件中实现。

| 对M-by-K的输入矩阵A和K-by-N的矩阵B执行M-by-N-by-K的Tensor Core运算，生成M-by-N的输出矩阵C。 |

混合输入矩阵乘法的挑战

为了简化讨论，我们限定一个混合输入矩阵乘法的具体示例：用户输入为F16，模型权重为U8（写作F16 * U8）。这里描述的技术适用于各种混合输入数据类型的组合。

GPU程序员可以访问一个内存层次结构，包括全局内存、共享内存和寄存器，这些内存按容量递减但速度递增的顺序排列。NVIDIA安培Tensor Core mma运算从寄存器中消耗输入矩阵。此外，输入和输出矩阵需要符合在一个称为warp的32线程组内的数据布局。对于mma运算，warp内支持的数据类型和布局是固定的，因此要高效实现混合输入乘法，必须在软件中解决数据类型转换和布局一致性的挑战。

数据类型转换

mma运算要求两个输入矩阵具有相同的数据类型。因此，混合输入矩阵乘法（其中一个操作数以U8存储在全局内存中，另一个以F16存储）需要进行从U8到F16的数据类型转换。转换将使两个操作数都变为F16，从而将混合输入矩阵乘法映射到硬件支持的混合精度Tensor Core。鉴于权重数量庞大，此类操作数量众多，我们的技术展示了如何减少其延迟并提高性能。

布局一致性

mma运算还要求warp寄存器中的两个输入矩阵的布局符合硬件规范。混合输入矩阵乘法（F16 * U8）中U8数据类型的输入矩阵B的布局需要与转换后的F16数据类型保持一致。这称为布局一致性，需要在软件中实现。

下图展示了一个mma运算从寄存器中消耗矩阵A和矩阵B，在寄存器中生成矩阵C，分布在一个warp中。线程T0被高亮显示并放大，以展示权重矩阵B经过数据类型转换，并且需要布局一致性才能映射到硬件支持的Tensor Core运算。

| 软件中混合输入（F32 = F16 * U8）运算映射到硬件中原生支持的warp级Tensor Core（F32 = F16 * F16）。（原图来源：在NVIDIA A100上将Tensor Core推向绝对极限的CUDA内核开发。） |

应对挑战的软件策略

典型的数据类型转换涉及对32位寄存器的一系列操作，如下所示。每个矩形块代表一个寄存器，相邻文本是操作。整个序列展示了从4xU8到2x(2xF16)的转换。该序列大约涉及10个操作。

在32位寄存器中从4xU8到2x(2xF16)的NumericArrayConvertor。 |

实现布局一致性的方法有很多。现有的两种解决方案是：

- 更窄位宽的共享内存加载：在这种方法中，线程发出窄位宽内存加载指令，将U8数据从共享内存移动到寄存器。这会产生两个32位寄存器，每个寄存器包含2xF16值（如上图矩阵B的线程T0所示）。更窄的共享内存加载直接实现布局一致性到寄存器中，无需任何洗牌操作；然而，它没有充分利用共享内存带宽。
- 在全局内存中进行预处理：另一种策略涉及在全局内存（内存层次结构中共享内存的上层）中重新排列数据，从而允许更宽的共享内存加载。这种方法最大限度地利用了共享内存带宽，并确保数据以符合要求的布局直接加载到寄存器中。虽然重新排列过程可以在LLM部署前离线执行，确保不影响应用程序性能，但它引入了一个额外的、非平凡的硬件特定预处理步骤，需要一个额外的程序来重新排列数据。

NVIDIA/FasterTransformer采用此方法有效解决了布局一致性的挑战。

**优化的软件策略**
为了进一步优化并减少数据类型转换和布局一致性的开销，我们分别实现了FastNumericArrayConvertor和FragmentShuffler。

FastNumericArrayConvertor在32位寄存器中对4xU8数据进行操作，而无需解包单个1xU8值。此外，它使用成本更低的算术运算，从而减少了指令数量并提高了转换速度。

U8到F16的转换序列如下所示。这些操作使用打包的32位寄存器，避免了显式的解包和打包操作。FastNumericArrayConvertor使用`permute byte`指令将4xU8的字节重新排列到两个寄存器中。此外，FastNumericArrayConvertor不使用昂贵的整数到浮点数转换指令，而是采用向量化操作，在两个包含2x(2xF16)值的32位寄存器中获得打包结果。用于U8到F16转换的FastNumericArrayConvertor大约使用六次操作，相对于上述方法减少了1.6倍。

FastNumericArrayConvertor利用字节置换和打包算术运算，减少了数据类型转换中的指令数量。

FragmentShuffler通过以允许使用更宽位宽加载操作的方式对数据进行重排，来处理布局一致性问题，从而提高了共享内存带宽利用率并减少了总操作数。

NVIDIA Ampere架构提供了一条加载矩阵指令（`ldmatrix`）。`ldmatrix`是一个warp级别的操作，一个warp的32个线程将数据从共享内存移动到寄存器中，其形状和布局符合`mma`矩阵A和B的消耗要求。使用`ldmatrix`减少了加载指令的数量，并提高了内存带宽利用率。由于`ldmatrix`指令将U8数据移动到寄存器，加载后的布局符合U8*U8 `mma`操作，而不符合F16*F16 `mma`操作。我们实现了FragmentShuffler，使用`shuffle (shfl.sync)`操作在寄存器内重新排列数据，以实现布局一致性。

这项工作最重要的贡献是通过寄存器重排实现了布局一致性，避免了在全局内存中进行离线预处理或使用更窄位宽的共享内存加载。此外，我们提供了FastNumericArrayConvertor的实现，涵盖了从U8到F16、S8到F16、U8到BF16和S8到BF16的数据类型转换。

**性能结果**
我们在NVIDIA A100 SXM芯片上测量了我们方法的八种混合输入变体（如下方蓝红所示；变化矩阵A和B的数据类型）和两种混合精度数据类型（绿色所示）的性能。性能结果以FLOPS显示（数值越高越好）。值得注意的是，前八种矩阵乘法相对于最后两种需要额外的操作，因为混合精度变体直接针对硬件加速的Tensor Core操作，不需要数据类型转换和布局一致性。即便如此，我们的方法展示的混合输入矩阵乘法性能仅略低于或与混合精度相当。

在NVIDIA A100 40GB SMX4芯片上，针对计算密集型矩阵问题形状m=3456, n=4096, k=2048的混合输入矩阵乘法性能。

**致谢**
我们要感谢几位通过技术头脑风暴和改进博客文章做出贡献的同事，包括Quentin Colombet, Jacques Pienaar, Allie Culp, Calin Cascaval, Ashish Gondimalla, Matt Walsh, Marek Kolodziej和Aman Bhatia。我们还要感谢我们的NVIDIA合作伙伴Rawn Henry, Pradeep Ramani, Vijay Thakkar, Haicheng Wu, Andrew Kerr, Matthew Nicely和Vartika Singh。

---

> 本文由AI自动翻译，原文链接：[Mixed-input matrix multiplication performance optimizations](http://blog.research.google/2024/01/mixed-input-matrix-multiplication.html)
> 
> 翻译时间：2026-01-06 04:29
