---
title: AI规模化：当量变引发质变的新挑战
title_original: AI and problems of scale — Benedict Evans
date: '2024-04-29'
source: Benedict Evans
source_url: https://www.ben-evans.com/benedictevans/2024/4/29/problems-of-scale-z7mrb
author: ''
summary: 本文探讨人工智能规模化应用带来的根本性挑战。作者通过历史案例（如电话监听、人脸识别、数据库发展）说明，许多技术在理论上小规模可行，但一旦实现大规模自动化应用，其性质可能发生本质改变，引发新的伦理、法律和社会问题。生成式AI的普及使得虚假信息、隐私侵犯等行为变得极其容易且成本低廉，规模化不仅放大了既有问题，更创造了全新的风险类型。文章指出，自动化带来的不仅是效率提升，还有大规模出错和作恶的新途径，这要求我们重新思考技术应用的边界与原则。
categories:
- 技术趋势
tags:
- 人工智能
- 规模化
- 技术伦理
- 生成式AI
- 自动化风险
draft: false
translated_at: '2026-01-08T04:29:33.631807'
---

# AI与规模化问题

乔治·西默农在1930年代的侦探小说中有个故事，每当讨论某类AI问题时我常会想起它。西默农笔下的主人公——巴黎司法警察局的梅格雷探长——吓唬了一位证人后，走到街对面的咖啡馆打电话给电话交换局。他告诉接线员，有人将从"鹈鹕"夜总会往戛尼斯拨打电话：他们必须在他赶到前保持通话线路畅通。随后他乘出租车赶到交换局，那里确实保持着通话，他得以窃听了对话。

几年前我把这个故事讲给某三字母机构的人听，对方露出了苦笑——他们现在确实不能这么做了，但他们能做其他事情，而且规模不是针对一通电话，而是数百万通。这似乎截然不同。我们可以接受警方凭搜查令一次监听一通电话，但不能接受无时无刻监听所有通话。

如今讨论AI与执法部门人脸识别时，也出现了类似情况。我想我们都认同"通缉令"海报的做法。我们理解警察会把它们贴在办公室，或许在巡逻车仪表板上也放几张。与此同时，车牌识别摄像头如今已在执法（或单纯收费）中广泛部署，却几乎无人察觉。同样，公共和私人监控摄像头已成为基本调查工具，只是引发了稍多担忧。但如果每辆警用巡逻车都配备一组摄像头，不仅能扫描每块车牌，还能将百米内的每张人脸与全国通缉令数据库比对呢？如果地铁摄像头也这么做呢？城市里所有联网摄像头都这么做呢？中国已在尝试推行这套系统，而我们似乎很确定自己不喜欢这样，但原因何在？有人可能主张这仅是规模差异而非原则区别，但规模变化本身就可能成为原则的改变。

1960至1970年代数据库兴起时，我们曾面临大量此类难题。理论上小规模可行之事突然能大规模实践，人们为此著书论述其威胁。其中虽有恐慌成分，但部分论点完全正确且至今仍是隐忧。自动化改变了一切，尽管我们的反应难以预测。在"美国诉琼斯案"（2012年）中，法院裁定警方无搜查令不得在嫌疑人车辆安装GPS追踪器，尽管传统人工跟踪无需搜查令。是我们不想要这种技术，还是不希望它过于便捷或自动化？极端案例是，美国枪支管理机构被禁止将枪支记录存入可检索数据库——所有资料必须保持模拟形式，人工查阅。自动化本身可能改变某些本质。曾有人告诉音乐行业，Napster与混音磁带没有区别——但这并未阻止2000至2014年间唱片音乐收入腰斩（直到流媒体改变一切）。

生成式AI正在创造大量新例证，表明规模本身即可构成原则差异。你可以看着AI图像生成器被滥用的现象，耸耸肩提及Photoshop：假裸照自互联网诞生之初就存在。但当高中生能将50或500名同学的照片载入机器学习模型，在家用电脑（或手机）上生成数千张此类图像（更别提视频），这确实是重大变化。伪造人声技术早已存在，但如今任何外行都能自行操作则是全新质变。作业和考试作弊历来有之，但互联网使其变得容易，而ChatGPT则让其（几乎）零成本。同样，理论上小规模可行之事变得能大规模实践，这改变了事情的本质。

然而数据库时代的经验表明，某些事物引发不安仅因其新颖陌生。在任何特定场景中，矛盾心理部分源于新奇感，而这种感受可能反复变化。这可能确实是我们完全不喜欢的新坏事；也可能虽新但我们决定不在意；我们可能认为这只是旧问题的新（更糟？）表现形式；亦或这种做法早已存在甚至规模化，但以新形式呈现使其显得不同，或只是让我们更意识到其存在。剑桥分析公司虽是骗局，却催化了人们对真实问题的认知。

此外，我迄今所举案例都涉及系统按设计运行，但实际问题半数其实出现在系统故障时。每轮自动化浪潮都创造了大规模作恶的新方式（或至少让我们犹疑之事），同时也创造了大规模出错的新途径。几代人以来，数据库失误毁掉人生的案例层出不穷——英国邮局丑闻只是最新最明显的例证。机器学习及如今的生成式AI创造了新的出错方式，最明显莫过于"AI偏见"问题（我五年前曾撰文探讨）。正如数据库时代，部分解决方案是培训技术人员尽量避免问题，但无法通过监管消除漏洞，关键仍在于确保人们明白计算机会出错。

这些问题可能是全新的，或是旧问题的新表现，但通过规模化可能演变成全新类型的问题。我们的反应取决于认知、文化和政治，而非技术。虽然我们容易在极端案例上达成共识，但中间存在巨大灰色地带，理性人群会有分歧。假裸照是恶劣的，但应否立法禁止？不同地区答案可能不同——强制国民身份证制度的态度就是绝佳例证。英国视其理念为对公民自由的根本侵犯。崇尚"自由"的法国推行身份证却毫不担忧（但法国人口普查不收集族裔信息，因纳粹占领期间曾借此围捕犹太人）。美国表面拒绝却处处索要身份证明。这里未必有正确答案，也无法通过分析流程获得——这是社会、文化和政治问题，伴随各种不可预知的结果。美国禁止建立枪支数据库，却存在扫描驾照比对数万人私人黑名单（另一个数据库）的公司，该名单被数千家酒吧夜店共享。而且没有隐私法约束。

> 本文由AI自动翻译，原文链接：[AI and problems of scale — Benedict Evans](https://www.ben-evans.com/benedictevans/2024/4/29/problems-of-scale-z7mrb)
> 
> 翻译时间：2026-01-08 04:29
