---
title: R2 SQL 正式支持 GROUP BY 及聚合查询，助力海量数据分析
title_original: Announcing support for GROUP BY, SUM, and other aggregation queries
  in R2 SQL
date: '2025-12-18'
source: Cloudflare Blog
source_url: https://blog.cloudflare.com/r2-sql-aggregations/
author: JÃ©rÃ´me Schneider
summary: Cloudflare 宣布其无服务器分布式分析查询引擎 R2 SQL 现已支持聚合功能（GROUP BY、SUM、COUNT 等）。聚合查询能对存储在
  R2 数据目录中的海量数据进行高效摘要，帮助用户发现趋势、生成报告并识别异常。文章阐述了聚合在数据分析中的重要性，并通过实例说明了其应用场景，同时深入探讨了实现聚合查询的两种技术路径：分散-聚集聚合与洗牌聚合，标志着
  R2 SQL 在分析能力上的重要扩展。
categories:
- AI基础设施
tags:
- Cloudflare
- R2 SQL
- 数据分析
- 聚合查询
- 无服务器计算
draft: false
translated_at: '2026-01-05T16:35:07.396Z'
---

当您处理大量数据时，快速获取概览会很有帮助——这正是 SQL 中聚合功能所提供的。聚合，也被称为“GROUP BY 查询”，提供了一种鸟瞰视角，让您能够从海量数据中快速获取洞察。

因此，我们很高兴地宣布，R2 SQL 现已支持聚合功能。R2 SQL 是 Cloudflare 的无服务器、分布式分析查询引擎，能够对存储在 R2 数据目录中的数据运行 SQL 查询。聚合功能将使 R2 SQL 的用户能够发现数据中的重要趋势和变化、生成报告并找出日志中的异常。

此版本建立在已支持的筛选查询基础之上，筛选查询是分析工作负载的基础，允许用户在 Apache Parquet 文件的“大海”中寻找“针”。

在本文中，我们将解析聚合功能的实用性和特点，然后深入探讨我们如何扩展 R2 SQL，以支持对存储在 R2 数据目录中的海量数据运行此类查询。

**聚合在分析中的重要性**

聚合，或称“GROUP BY 查询”，能生成底层数据的简短摘要。

聚合的一个常见用例是生成报告。假设有一个名为“sales”的表，其中包含某组织各个国家和部门的所有销售历史数据。使用以下聚合查询，可以轻松生成按部门划分的销售量报告：

```sql
SELECT department, sum(value)
FROM sales
GROUP BY department
```

“GROUP BY”语句允许我们将表行分割成多个桶。每个桶都有一个对应特定部门的标签。一旦桶被填满，我们就可以计算每个桶中所有行的“sum(value)”，从而得到相应部门的总销售量。

对于某些报告，我们可能只对销售量最大的部门感兴趣。这时“ORDER BY”语句就派上用场了：

```sql
FROM sales
GROUP BY department
ORDER BY sum(value) DESC
LIMIT 10
```

这里我们指示查询引擎按总销售量降序对所有部门桶进行排序，并且只返回前 10 个最大的部门。

最后，我们可能对过滤掉异常情况感兴趣。例如，我们可能希望报告中只包含总销售量超过五笔的部门。我们可以使用“HAVING”语句轻松实现：

```sql
SELECT department, sum(value), count(*)
FROM sales
GROUP BY department
HAVING count(*) > 5
LIMIT 10
```

这里我们在查询中添加了一个新的聚合函数——“count(*)”——它计算每个桶中最终有多少行。这直接对应于每个部门的销售笔数，因此我们还在“HAVING”语句中添加了一个谓词，以确保只保留行数超过五行的桶。

**聚合的两种方法：早计算还是晚计算**

聚合查询有一个有趣的特性：它们可以引用未存储在任何地方的列。以“sum(value)”为例：该列是由查询引擎动态计算的，这与从存储在 R2 上的 Parquet 文件中获取的“department”列不同。这种细微差别意味着，任何引用“sum”、“count”等聚合函数的查询都需要分成两个阶段。

第一阶段是计算新列。如果我们要使用“ORDER BY”语句按“count(*)”列对数据进行排序，或者使用“HAVING”语句基于该列筛选行，我们就需要知道该列的值。一旦知道了“count(*)”这类列的值，我们就可以继续执行查询的其余部分。

请注意，如果查询没有在“HAVING”或“ORDER BY”中引用聚合函数，但仍在“SELECT”中使用它们，我们可以利用一个技巧。由于我们直到最后才需要聚合函数的值，我们可以部分计算它们，并在即将返回给用户之前合并结果。

这两种方法的关键区别在于我们计算聚合函数的时机：是提前计算，以便稍后对它们执行一些额外的计算；还是动态计算，以迭代地构建用户所需的结果。

首先，我们将深入探讨动态构建结果的技术——我们称之为“分散-聚集聚合”。然后，我们将在此基础上引入“洗牌聚合”，它能够在聚合函数之上运行诸如“HAVING”和“ORDER BY”之类的额外计算。

**分散-聚集聚合**

没有“HAVING”和“ORDER BY”的聚合查询可以以类似于筛选查询的方式执行。对于筛选查询，R2 SQL 会选择一个节点作为查询执行协调器。该节点分析查询并查询 R2 数据目录，以确定哪些 Parquet 行组可能包含与查询相关的数据。每个 Parquet 行组代表一个相对较小的工作单元，可以由单个计算节点处理。协调器节点将工作分配给许多工作节点，并收集结果返回给用户。

为了执行聚合查询，我们遵循所有相同的步骤，并在工作节点之间分配小的工作单元。然而，这次工作节点不仅仅是根据“WHERE”语句中的谓词筛选行，还会计算预聚合。

预聚合代表聚合的中间状态。这是一个不完整的数据片段，表示在数据子集上部分计算的聚合函数。多个预聚合可以合并在一起，以计算聚合函数的最终值。将聚合函数拆分为预聚合，使我们能够水平扩展聚合计算，利用 Cloudflare 网络中可用的大量计算资源。

例如，“count(*)”的预聚合就是一个简单的数字，表示数据子集中的行数。计算最终的“count(*)”就像把这些数字相加一样简单。“avg(value)”的预聚合由两个数字组成：“sum(value)”和“count(*)”。然后，“avg(value)”的值可以通过将所有“sum(value)”值相加、将所有“count(*)”值相加，最后将两个和相除来计算。

一旦工作节点完成预聚合的计算，它们会将结果流式传输给协调器节点。协调器节点收集所有结果，从预聚合中计算聚合函数的最终值，并将结果返回给用户。

**超越分散-聚集极限的洗牌**

当协调器可以通过合并来自工作节点的小型、部分状态来计算最终结果时，分散-聚集方式非常高效。如果您运行像 `SELECT sum(sales) FROM orders` 这样的查询，协调器会从每个工作节点接收一个数字并将它们相加。无论 R2 中有多少数据，协调器上的内存占用都可以忽略不计。

然而，当查询需要基于聚合结果进行排序或筛选时，这种方法就变得低效了。考虑这个查询，它查找销售量排名前两位的部门：

```sql
SELECT department, sum(sales)
FROM sales
GROUP BY department
ORDER BY sum(sales) DESC
LIMIT 2
```

要正确确定全局前两名，需要知道整个数据集中每个部门的总销售量。由于数据在底层的 Parquet 文件中实际上是随机分布的，特定部门的销售数据很可能分散在许多不同的工作节点上。某个部门在每个单独的工作节点上的销售量可能都很低，无法进入任何本地前两名列表，但将所有节点的数据汇总后，其总销售量却可能是全球最高的。

下图说明了分散-聚集方法为何对此查询无效。

“A部门”是全球销售额的领先者，但由于其销售额在各工作节点间均匀分布，未能进入某些本地的前两名榜单，最终被协调器丢弃。

因此，当查询要求按全局聚合结果排序时，协调器无法依赖工作节点预过滤的结果。它必须向每个工作节点请求每个部门的总计数，以计算全局总计后才能进行排序。如果你按高基数列（如IP地址或用户ID）进行分组，这将迫使协调器接收并合并数百万行数据，在单个节点上造成资源瓶颈。

为了解决这个问题，我们需要引入“数据混洗”——一种在最终聚合发生前，将特定分组的数据归集到一起的方法。

**聚合数据混洗**

为了应对数据随机分布带来的挑战，我们引入了一个混洗阶段。工作节点不再将结果发送给协调器，而是根据分组键直接相互交换数据，以实现数据行的归集。

这种路由依赖于确定性的哈希分区。当工作节点处理一行数据时，它会哈希`GROUP BY`列以确定目标工作节点。由于这个哈希是确定性的，集群中的每个工作节点都能独立就特定数据的发送目的地达成一致。如果“工程部”被哈希到工作节点5，那么每个工作节点都知道将“工程部”的数据行路由到工作节点5。这不需要中央注册表。

下图说明了这个流程。请注意“A部门”最初是如何分布在工作节点1、2和3上的。由于哈希函数将“A部门”映射到工作节点1，所有工作节点都会将这些数据行路由到同一个目的地。

混洗聚合能产生正确的结果。然而，这种全对全交换会产生时序依赖。如果工作节点1在工作节点3完成发送其份额的数据之前，就开始计算“A部门”的最终总计，结果将是不完整的。

为了解决这个问题，我们强制执行一个严格的同步屏障。协调器跟踪整个集群的进度，而工作节点则缓冲其输出数据，并通过gRPC流将其刷新给其他工作节点。只有当每个工作节点都确认已完成其输入文件的处理并刷新了其混洗缓冲区后，协调器才会发出继续执行的命令。这个屏障保证了下一阶段开始时，每个工作节点上的数据集都是完整且准确的。

一旦同步屏障解除，每个工作节点都持有其分配分组的完整数据集。工作节点1现在拥有“A部门”100%的销售记录，可以确定地计算最终总计。

这使得我们可以将过滤和排序等计算逻辑下推到工作节点，而不是让协调器承担负担。例如，如果查询包含`HAVING count(*) > 5`，工作节点可以在聚合后立即过滤掉不符合此条件的分组。

在此阶段结束时，每个工作节点都会为其拥有的分组生成一个已排序、最终化的结果流。

拼图的最后一块是协调器。在“分散-收集”模型中，协调器负责承担聚合和排序整个数据集的昂贵任务。在混洗模型中，其角色发生了变化。

由于工作节点已经计算了最终聚合结果并在本地进行了排序，协调器只需要执行一次K路归并。它打开到每个工作节点的流，逐行读取结果。它比较来自每个工作节点的当前行，根据排序顺序选取“胜出者”，并将其添加到将发送给用户的查询结果中。

这种方法对于`LIMIT`查询尤其强大。如果用户要求前10个部门，协调器会合并流直到找到前10个项目，然后立即停止处理。它不需要加载或合并剩余的数百万行数据，从而可以在不过度消耗计算资源的情况下实现更大规模的操作。

**处理海量数据集的强大引擎**

随着聚合功能的加入，R2 SQL从一个擅长过滤数据的工具，转变为一个能够处理海量数据集的强大引擎。这是通过实现分布式执行策略（如“分散-收集”和“数据混洗”）实现的，我们能够利用Cloudflare全球计算和网络的规模，将计算推送到数据所在的位置。

无论你是生成报告、监控高流量日志中的异常，还是仅仅试图发现数据中的趋势，你现在都可以轻松地在Cloudflare开发者平台内完成所有这些工作，而无需管理复杂的OLAP基础设施或将数据移出R2的开销。

R2 SQL现已支持聚合功能。我们期待看到你如何在R2数据目录中使用这些新功能处理数据。

**开始使用**：查看我们的文档，获取运行聚合查询的示例和语法指南。

**加入讨论**：如果你有任何问题、反馈或想分享你正在构建的内容，请加入Cloudflare开发者Discord。


> 本文由AI自动翻译，原文链接：[Announcing support for GROUP BY, SUM, and other aggregation queries in R2 SQL](https://blog.cloudflare.com/r2-sql-aggregations/)
> 
> 翻译时间：2026-01-05 13:22
