---
title: 谷歌技术与社会副总裁谈AI：从神经网络到社会影响
title_original: Social Intelligence | Greylock
date: '2024-08-19'
source: Greylock Partners
source_url: https://greylock.com/reid-hoffman/social-intelligence/
author: ''
summary: 本文记录了谷歌首位技术与社会高级副总裁詹姆斯·马尼卡与格雷洛克合伙人里德·霍夫曼的对话。马尼卡分享了他从本科研究神经网络到获得AI博士学位的历程，以及他如何将技术专长应用于解决大规模社会问题。他强调了在AI发展中思考技术对社会意义、创造机遇与管理风险的重要性，并讨论了算法偏见、AGI前景等议题。马尼卡拥有跨学术界、政府与企业的多元经验，始终关注如何引导技术向积极方向发展。
categories:
- 技术趋势
tags:
- 人工智能
- 技术伦理
- 社会影响
- 谷歌
- 访谈
draft: false
translated_at: '2026-01-15T04:36:51.828004'
---

## 无论提及哪个行业、工作环境或地理区域，詹姆斯·马尼卡都能就技术与商业如何对其产生影响提供宝贵见解。

从近三十年在麦肯锡全球担任备受追捧的顾问，到在众多有影响力的董事会和委员会任职（包括奥巴马政府时期的全球发展委员会副主席），马尼卡拥有一种独特的能力，能够从看似矛盾的多重视角审视社会、经济和技术领域的复杂问题。

因此，谷歌最近任命他为公司首位技术与社会高级副总裁，也就不足为奇了。

对马尼卡而言，这一切始于一项关于神经网络的本科研究项目，随后他攻读了机器学习（当时对AI的称谓）博士学位，并毕生致力于运用这种理解来解决大规模的社会问题。

马尼卡表示，从他早期的研究到他在谷歌的新职位，其工作的主线始终深刻聚焦于以下问题："从最积极的意义上说，所有这些先进技术将对社会意味着什么？将创造哪些机遇？我们想要确保哪些事情得到妥善管理？" 以及对他而言在AI领域尤为重要的一点："我们如何做对？如何确保事情朝着正确的方向发展？"

在我们"Iconversations"系列的这次访谈中，马尼卡与格雷洛克普通合伙人、也是其长期好友和同事的里德·霍夫曼进行了对话，讨论了AI的现状、他认为通用人工智能（AGI）何时可能到来、他对算法所呈现（或更确切地说，所揭示）的偏见问题的看法，以及可以采取哪些措施来解决这些问题。

您可以在我们的YouTube频道观看活动视频，或在此处收听完整对话：

**里德·霍夫曼：** 大家好，欢迎来到格雷洛克"Iconversations"系列的另一期节目。我是里德·霍夫曼，格雷洛克的普通合伙人，也是今天活动的主持人。我非常高兴地欢迎詹姆斯·马尼卡作为我们今天的嘉宾。

詹姆斯是谷歌新任命的"技术与社会"高级副总裁。在担任此职之前，他在麦肯锡全球工作了27年多，为世界上许多顶级科技公司的领导者提供咨询。

詹姆斯的整个职业生涯都专注于人工智能、机器人技术和全球化，并且几乎在你能想象到的各种类型的工作场所——从学术界到政府机构，再到私营公司和非营利组织——都拥有丰富的经验。他的贡献形式多样，包括书籍、文章、演讲、讲座，当然还有无数在高度机密场合提供关键建议的时刻。

他曾担任多个政府顾问职务，包括奥巴马政府时期全球发展委员会的副主席，并被任命为数字经济委员会和国家创新委员会的成员。他还是外交关系委员会的董事会成员，并最近共同主持了加利福尼亚州未来工作委员会。

如今，他在多个科技领域担任职务，包括斯坦福大学以人为本人工智能研究所的特聘研究员、牛津大学的研究员和客座教授，以及麻省理工学院和哈佛大学布罗德研究所的董事会成员等。他还是美国艺术与科学学院院士，以及美国国家科学、工程和医学研究院负责任计算委员会的成员。

他也是我的挚友，我们曾共同参与许多令人难以置信的倡议和经历，包括我们最近的南极之旅，我相信詹姆斯是第一位出生于津巴布韦的南极地理极点访客。

詹姆斯，一如既往，感谢你今天与我们相聚。在你漫长而繁忙的职业生涯中，你经历了我们历史上变化最快的时期之一。直到今天，你仍在不断拓展你的探索领域，不仅仅是南极。欢迎你。

**詹姆斯·马尼卡：** 嗯，谢谢你，里德。我很高兴能和你进行这次对话。和你交谈总是很有趣。

**RH：** 我们曾在牛津大学同窗，但当时并不相识。你的整个职业生涯都专注于人工智能和机器人技术，包括从技术层面到伦理层面，这对于设计、实施和创立技术显然至关重要。是什么让你走上了这条道路？

**JM：** 嗯，感谢你提出这个问题。事实上，除了从小观看所有科幻电影——《2001太空漫游》等等——之外，我在津巴布韦读本科时发生了一件非常特别的事情。

当时我正在寻找一个本科研究项目，碰巧有一位来自加拿大的博士后访问学者。这位博士后实际上是杰弗里·辛顿的学生之一。他说："你为什么不做一个构建神经网络的项目呢？" 我回答说："那是什么？" 那实际上是我第一次真正编程实现一个神经网络，因为正如你们部分观众所知，杰夫·辛顿是推动我们如今在深度学习和神经网络领域取得成功的先驱之一。

我就是这样开始的。从那以后，我就迷上了这个领域，并去了牛津大学。在牛津，我做了几件不同的事情。但当我完成学业时，我获得了人工智能和机器人技术的博士学位。那是一段令人着迷的时光。

顺便说一下，当时由于之前的AI寒冬期，人们常常不愿意把这称为AI。所以我们实际上称之为机器感知、机器学习等等——什么都行，就是不叫AI。

**RH：** 没错。而且，人们通常不会从机器学习、机器感知的博士学位转到麦肯锡工作。那次转变是怎样的？当然，我们稍后会深入探讨这一点，特别是考虑到将社会和经济生态系统作为其中一部分来思考。

**JM：** 嗯，对我来说，这完全是个意外，里德。因为坦率地说，部分原因是为了找个借口待在加利福尼亚，因为当麦肯锡给我提供职位时，我可以去加州。顺便提一下，即使在我获得博士学位后，我还在喷气推进实验室的人机系统组担任过一段时间的访问科学家，因为我博士期间研究的一些内容当时有应用价值。此外，我的一些朋友还有个疯狂的想法，认为我们或许可以造一辆自动驾驶汽车。

所以，当我的其他朋友在伯克利工作，比如斯图尔特·拉塞尔等人时，我想："也许去麦肯锡是个待在加州、待在湾区的借口。" 于是，我实际上是从当时正在做的其他事情中请了假，只是为了找个借口待在湾区，我想我最终就留下来了。

不过，更严肃地说，我认为我当时学到的一部分是，我对大规模问题非常着迷。当然，技术是其中的重要部分，但思考大规模的社会问题也让我着迷。而麦肯锡似乎是一个实现这一点的绝佳平台和场所，尤其是在全球研究所，我最终领导该机构多年。

**RH：** 是的。那么，全球研究所显然产出了大量非常有趣且非常——"实用"这个词可能不准确——但根植于"应该做什么"以及"正在发生什么趋势"的研究。所以，这说得通。

那么：在谷歌的这个新角色是什么？你打算做什么？

**JM：** 嗯，谢谢你。里德，这感觉几乎像是我一直热衷的事情的延续，从这个意义上说，它拥有"技术与社会"这个宏大的头衔。但它真正关乎的是思考：从最积极的意义上说，所有这些先进技术将对社会意味着什么？将创造哪些机遇？我们想要确保哪些事情得到妥善管理？

因此，我将投入大量时间进行研究，与谷歌杰出的AI团队（包括Jeff、Demis等人）深入交流，同时思考下一代技术布局与投资方向及其社会影响。坦率地说，我会广泛接触谷歌内外的各界人士，致力于探讨技术与社会相关的议题。

你我长期思考的核心问题是："如何确保这一切——我们怎样才能做对？如何保证事情朝着正确的方向发展？" 我特别关注的是在我投入最多精力的AI与机器人领域——我迫切希望这个领域能走上正确的发展轨道。

RH：你即将参与美国艺术与科学院（你我都是其成员）的一项工作。他们旗下有一本思想深刻的杂志《代达罗斯》，即将推出一期AI专题特刊。

为了深入探讨这些议题以及你在麦肯锡的工作和即将在谷歌开展的计划：在这期《代达罗斯》特刊中，你将重点关注哪些议题？对于正在经历这场AI复兴的技术从业者，你认为他们应该思考哪些关键问题？

JM：首先，大约一年前美国艺术与科学院邀请我策划编辑这期《代达罗斯》特刊时，我感到非常兴奋。通常《代达罗斯》每期收录8篇论文，但这期将包含27篇。有趣的是，我成功说服了许多朋友和熟人参与撰稿。现在每位受邀者都贡献了一篇论文：Jeff Dean有一篇，微软的Kevin Scott有一篇，OpenAI的Mira Murati有一篇，伯克利的Stuart Russell也有一篇。

因此约半数撰稿人是AI先驱和前沿技术研究者，另一半则是关注社会影响的学者，包括诺贝尔奖得主Michael Spence这样的经济学家，以及哲学家、伦理学家等。这期特刊的名称正是"社会中的AI"。

回到你的问题，Reid——关于当前技术发展现状：我认为现在是一个激动人心的时刻。听众和参与者都知道，我们在深度学习和强化学习等技术领域取得了惊人进展。特别是在深度学习方面，Transformer模型的发展近期带来了巨大加速，这些系统的表现非常出色。

这期特刊中反映的一个学界热议的辩论是：**当前的技术路径是否足以实现极其强大的AI，乃至最终的人工通用智能？** 这是领域内的核心争论之一：**现有技术是否足够？** 如果召集一屋子的AI专家，半数会说"是的，这就是我们所需的一切"，而另一半则会说"这些技术很棒，但我们还需要更多突破"。

后者的核心观点在于，AI领域仍存在许多难题：这些系统能否真正进行因果推理？能否理解意义本质？能否实现迁移学习？能否完成Daniel Kahneman等人描述的"系统2"认知任务？这些仍是亟待解决的硬骨头。

这场辩论的关键在于：现有技术是否足够，还是我们需要新范式？顺便一提，当人们讨论AGI何时实现时，分歧往往源于这个问题。认为现有工具足够的人会说"AGI近在咫尺"，而持相反观点者则会强调"我们仍需重大概念性突破才能到达彼岸"。这是场有趣的辩论，你会在特刊中看到相关技术讨论。

当然，特刊还涉及其他议题。我们肯定会探讨社会影响、经济/就业效应，以及你我常聊的大国竞争话题——这项技术将如何在全球舞台展开？这将是一场广泛而精彩的讨论。

RH：让我们以此作为讨论起点。因为在这场讨论中，人们常忽略一个事实：你说"存在两个阵营，一方认为AGI还需10-30年实现"，大家总热衷于预测特定年限内实现20%/50%/80%可能性的概率游戏——你我都在各种场合做过这类开场投票。但即使AGI未能实现，这场AI复兴带来的变革影响依然巨大。

请谈谈即使不考虑AGI，你预见哪些变革即将到来？技术从业者应该思考哪些社会议题，我们作为更广泛的讨论群体又该关注什么？比如：基于现有机器学习技术可能实现什么？我们需要应对哪些重要问题？

JM：首先是经济层面。这些技术对经济增长与繁荣具有惊人的变革潜力，这确实令人振奋。用30秒经济理论简要说明：观察经济增长方式（相关研究曾获诺贝尔奖）——Bob Solow等人提出的增长核算理论表明，GDP增长来源于生产率增长和劳动力供给增长。两者结合推动GDP增长。

当前随着人口老龄化等因素，未来经济增长将主要依赖生产率提升，而生产率增长的核心在于技术创新。**此时此刻，AI及相关技术具有改变生产率增长方式的非凡潜力。** 从宏观角度看，经济发展需要这种变革。

**"AI及相关技术具有改变生产率增长方式的非凡潜力。"**

回到更实际的层面，我们与谷歌、微软等机构的朋友合作研究了经济中的用例。从崇高的经济理论层面下沉到实际应用场景观察这些技术——最初我们分析了约400个用例，现在案例库已扩展至数千个——你会发现每个经济领域都存在强大、具有经济吸引力且可商业化的用例。这不仅限于科技行业，而是遍布各行各业。从应用场景的普遍性来看，零售和运输物流是重点领域。

这不仅是行业性问题，也是职能性问题。销售与营销实际上是最大的应用场景之一。如果将供应链和物流视为企业内部职能，相关用例也随处可见。

事实上，当我们首次尝试量化评估时，Reid，仅基于现实可行的用例分析，就得出近期每年至少6万亿美元的潜在价值。如果扩展到所有新兴用例，这个数字还会持续增长。简而言之，无论对整体经济还是对企业而言，AI带来的经济可能性与潜力都是巨大的。

当然，随之而来的另一个问题——甚至在实现通用人工智能（AGI）之前——是关于就业和劳动力市场的问题。这方面的情况有些复杂，具体来说：虽然经济层面的前景是清晰的，但就业/劳动力市场问题则喜忧参半。说它复杂，是因为我们以及许多其他机构都进行了大量研究，这些研究普遍得出的结论是：首先，不必担心一个没有工作的未来，至少未来几十年内不会。因为将要发生的情况是：我们会失去一些工作岗位，但同时也会创造一些新的工作岗位——但最大的影响在于，大多数工作岗位将发生转变。

因此，尽管未来我们仍有工作，但问题在于：我们如何应对这些转变？这里的转型问题涉及技能再培训、职业变迁以及一些工资效应。这些都是我们真正需要仔细应对和思考的事情。但总的来说，不必担心一个没有工作的未来，至少未来几十年内如此。所以，劳动力市场的问题确实更为复杂一些。

此外，人们还考虑到其他影响。这些是社会、伦理等方面的问题，我相信我们也会讨论到这些。但由于我们使用这些变革性技术的方式，关于使用和滥用的问题，以及涉及信息、虚假信息、深度伪造等方面的二阶效应问题——我们不得不思考另一整套影响。这涉及到治理、使用和滥用等问题。

当然，我们还会谈到你最喜欢的话题之一，里德，那就是：这在大国竞争中会如何演变？我们知道，目前有两个国家遥遥领先于其他国家，即美国和中国。其他国家的进展速度则不尽相同。那么，当经济上利害攸关，同时国家安全和地缘政治战略利益也面临风险时，这一切意味着什么？这是该领域的另一个重大问题。

**RH：** 我完全同意，考虑到我们进行过的多次对话，这一点显而易见。我认为，部分背景是让人们认识到，尽管人工智能领域已经鼓声震天，但其产业影响目前还相对有限。然而，随着软件向——我常用的一个说法是——比特世界和原子世界转变，我们将看到一些特别巨大的变化。这可能比我们想象的更令人惊讶，也来得更快一些。

有些事情，比如就业，我认为会保留下来。工作岗位会发生转变，但工作机会依然存在。正如你所说，关键在于转型。显然，我认为让所有人对人工智能技术感到紧张的部分原因之一是它的可解释性——透明度问题，即“这个设备在做什么？”

所以，也许这个设备能驾驶车辆，但它能确保安全驾驶吗？你了解这一点吗？考虑到这些Transformer模型拥有数千亿参数的复杂程度，你如何理解它？你如何让其他人参与到讨论中来？你如何让其他人对所发生的事情建立信心？如何将这两个要素结合起来？

**JM：** 我认为这是个重要的问题，里德。因为尽管我们对这些技术充满热情，但它们确实存在一些重大局限，正如我所说，还有一些难题。但在讨论真正困难的人工智能问题之前，我认为值得花点时间谈谈这些局限和差距。

我认为，这些局限大多与可能侵蚀公众信任的事情有关。其中很多包括算法或数据中的偏见，或者我用来训练它们的语料库中的偏见，以及系统脆弱性等问题。例如，当你遇到分布外非平稳性的情况时。当你用某些数据集训练模型，然后突然给它呈现一个分布外的样本时，它可能会做出不同的预测。还有可解释性问题，因为从建立信任的角度来看——

里德，我经常觉得有趣的是，科技行业之外、不了解这项技术的人，常常认为科技行业试图在可解释性方面隐瞒什么。不，事实是神经网络结构、这些算法的结构就是如此，你实际上无法打开它并说，“它做出这个决定，是因为这个特定变量、那个特定变量或这个数据集”——尽管我们在这方面正开始做得更好。

所以问题是：我们如何应对这些可能侵蚀公众信任的局限和差距？我认为保持公众对这些系统的信任很重要，因为如果这些系统要应用于医疗、自动驾驶汽车等领域，人们需要理解并信任这些系统。

至于我们如何做到这一点——我认为还需要进行大量的研究和努力。我认为其中一些工作正在进行中；我们在这方面正开始取得进展。但同时，我认为，让公众跟上该领域的发展并理解这些系统如何运作——这需要大量的教育，以及公众在过程中的大量参与和投入。

这是我们必须做好的事情之一。我们必须继续建立公众对这些系统的信任，并对我们所知和未知的事情保持相当开放和透明的态度。因此，除了我们仍需努力解决的所有其他难题之外，这些都是我们需要克服的一些局限。还有很多工作要做。

“我们必须继续建立公众对这些系统的信任，并对我们所知和未知的事情保持相当开放和透明的态度。”

顺便提一下，我应该提到：这些侵蚀信任的局限之一，是这些算法有时会产生一些有害的输出，这种情况并非总是发生，但偶尔会出现。例如，这将是针对大语言模型（LLM）的批评之一。我相信我们会谈到大语言模型。但这就是批评之一：这些系统偶尔会产生带有性别歧视或种族歧视的输出。我们需要解决这个问题，但这是这些系统存在的侵蚀信任的问题之一。

**RH：** 是的。我们来谈谈大语言模型，这是它们正在产生影响的领域之一。据我所知，每个研究大语言模型的团队现在都非常关注种族偏见、对齐和安全等问题，部分原因是它们某种程度上反映了现有数据。

在某种程度上，这就像是对我们社会的一次部分罗夏墨迹测试，当然，也反映了数据的来源。这有点像经典刑事司法系统中的情况：一个算法在处理上报的数据集时，捕捉到了一个事实，即在过去几十年里，警察部门对有色人种社区的监管力度比对其他社区更大。

所有这些数据都被奉为圭臬，在诸如风险、假释、信贷等超级重要的事情上，你必须非常小心。我认为一件非常好的事情是，现在每个人都说：“是的，我们正在为此做些事情。”

JM：是的。事实上，我认为关于这些偏见问题——正如你所说，它们出现在刑事司法系统、金融贷款、招聘等领域——往往问题出在数据上，而且往往在于数据收集的方式。坦率地说，问题通常并不在于算法本身，而在于社会如何构建自身来收集这些数据。警务就是一个很好的例子，因为我们知道，例如：某些社区和地方的警力部署更密集，因此收集到的数据也更多。那么，当从这些数据大量收集的区域得出[某些]预测时，你会感到惊讶吗？当然不会。

同样地，在金融贷款领域的另一端，你也能看到这个问题，但情况恰恰相反——对于那些所谓"脱离金融体系"的人，算法往往难以准确预测他们是否值得贷款。而对于我们了解很多信息的人，我们往往能做出更好的预测。

因此，关于社会本身如何捕获数据的问题，其重要性不亚于算法问题。这并不是说我们不应该思考如何在算法中发现这些问题以及如何管理数据。我们应该思考。但坦率地说，这些系统实际上常常是在凸显我们自身的问题。

关于公平性和偏见，Reid，我想你读过那篇论文，一些AI研究人员试图说："好吧，那么，社会：请给我们公平的定义，这样我们才能构建出实现公平的算法。"在那篇论文中，我认为他们提出了21种不同的公平定义。那么，你究竟要如何为此创建算法呢？我认为这些系统实际上正在迫使我们作为一个社会，去问自己一些非常棘手的问题。

我认为我们从未完全定义过公平。我曾参加过一个有趣的研讨会，参与者包括AI研究人员、社会学家、律师和哲学家。顺便说一下，那次讨论的总体结论是：社会，我们从未真正定义过公平。我们倾向于使用两种代理标准。

我们使用的一种代理标准，可以称之为程序公平。换句话说，如果某件事经过了某个流程，我们就假定它是公平的。仅仅因为它走过了这个流程，我们就认为其结果是公平的。[另一种]有时被称为构成公平。我们会说："好吧，如果是这群人做出了招聘决定，我们会接受他们的意见，因为这个群体是由这些人组成的，具有这种特定的构成。"

但你会注意到，在这两种情况下，我们都没有真正定义什么是真正公平的结果。我们定义了一个我们认为公平的流程，或者定义了一个我们认为公平的决策构成。换句话说，我们仍然在回避这个问题：公平到底是什么样子？

"我认为这些系统实际上正在迫使我们作为一个社会，去问自己一些非常棘手的问题。"

RH：嗯，显然，公平性挑战的一部分在于——这也是为什么那篇出色的论文（我想我第一次读它是因为你发给了我）——它带有一定的政治性，而且人类群体之间存在冲突。他们会说："嗯，我想要这种公平定义，因为它对我更有利。"这也是为什么这些问题总是很复杂的原因之一。

你看到有哪些最好的想法，可以用来处理——广义上说——这些社会偏见的纠正？因为我认为你我有一个共同点，尽管我们所在的群体可能没有这种观点，那就是：将这个问题置于AI系统中的一个好处是，我们可以修复它。我们可以让系统变得更好。你会说："好吧，如果当前的软件算法系统在做出假释建议或金融信贷决策时表现不佳，部分原因在于现有的数据。"

你看到有哪些做法，像是"好的，这可能是一个不错的修复方案，因为这样我们可以让社会变得更好，因为我们修复了可能原本就存在的潜在偏见——因此，与其被新的AI软件系统制度化，它反而可以得到改善？"你看到有哪些想法是这方面最好的实施方向？

JM：有几件事，但首先，需要指出或承认：人们在这方面对算法感到担忧是有充分理由的，因为尽管算法有潜力做很多好事，但它们往往被一些人称为"形式化器和放大器"。

因为，如果你搞错了算法，并且要大规模部署它，将其固化到系统中。那么，在某些方面，其影响可能比单个有偏见的法官要糟糕得多，尤其是当整个法官系统现在都依赖这个算法系统时。所以，这种形式化和应用的问题是一个合理的担忧。

但回到你的问题：有哪些方法正在着手解决这些问题？我认为正在进行一些非常酷的技术工作，人们正在构建方法来实际检查数据集，并发现数据集本身的结构性偏见。

一些研究人员，比如Sylvia Chiappa，正在做一些出色的工作，比如关于反事实公平的研究，即：你如何构建相互竞争的算法，这些算法实际上试图理解并对数据进行反事实分析，从而提出："如果我们去掉这部分，我们能否做出不同的预测？如果我们去掉这部分？"所以，你可以想象，让AI真正帮助解决这个问题，是发现系统中偏见的巧妙方法之一。因此，我对这类正在进行的工作感到兴奋。

但我认为另一部分实际上是让不同类型的人参与到这个过程中来。所以，我参与的一件事，我想你一开始提到过——美国国家科学、工程和医学院组建了一个委员会，我一直参与其中，是关于负责任计算的。

你会突然意识到，其中发生的一件事是：你需要有人提出正确的问题。你需要有人真正理解并提出正确的问题——让不同学科背景的人参与进来；多样性，尤其是在学科意义上——他们能在开发过程中真正提出反事实问题。这实际上可以产生巨大的影响。

不过，Reid，我应该指出，该领域另一个有趣的辩论是——就像关于"这些技术是否足够"的有趣辩论一样——另一个辩论与开发这些系统的方法有关，其意义如下。有一个阵营认为："如果我们把这些系统推向世界，让人们使用它们并捕获错误等等，我们就能纠正和改进这些系统。所以，如果我们大规模地这样做，让真实的人使用它们，这就是改进它们的方法。"另一个阵营则说："不，不，不。在部署任何东西之前，我们需要测试、测试、再测试、再测试、再测试、再测试。"

所以你会在现实世界中看到这种情况，甚至在自动驾驶汽车的方法上也是如此，例如，一种思想流派是：把它们放到真实系统中，我们会从中学习。另一些人则说：不，不。要继续进行训练、训练、再训练。所以，这是关于"我们如何让这些系统变得正确？"这个问题的问题和竞争性方法之一。

RH：是的，我完全同意。你之前提到的一点——这个话题显然已经在对话中存在多年，也体现在你参与的加州未来工作委员会中——那就是：硅谷人士往往倾向于说：“天哪，未来马上就要来了。”这还不是指通用人工智能（AGI），而是指工作的变革。他们通常会说：“天哪，这就像《星际迷航》里的未来；机器人将生成一切。我们需要全民基本收入；工作机会正在消失。”等等。

请稍微谈谈你在这方面所做的实际研究，未来几十年的实际形态是怎样的，以便我们能够预测并以有益于社会的方式进行干预，无论是构建技术还是理解政策？那个未来的工作图景具体是什么样的？

JM：是的，我认为这里我们面临一些非常棘手的问题。

你提到的那个委员会，这是一个有趣的安排。我当时与我的联合主席共同主持该委员会，她是一位杰出的大型工会领袖。委员会成员本身包括商界人士、劳工代表、学术界人士、技术专家等。这是一个非常多无化的群体。

在审视这些关于未来工作的问题时，我认为可以将议题分为几类。一个是关于技能再培训的问题。技能再培训非常重要，因为我们知道工作正在发生变化。实际上，更多的工作会发生改变而非消失。因此，让人们能够适应并跟上这些变化是一个非常大的问题。

里德，有一个有趣又快速的练习你可以做：任何人告诉你“哦，我们正在做技能再培训”，你接下来要问的问题是：“好的，那么有多少人？”而你通常会发现，大规模进行技能再培训一直非常困难。所以人们可能会说“我们为一百人、也许一千人进行了再培训”，但未来一二十年所需的再培训规模实际上是数以百万计的。所以存在这类问题。

我们面临的另一个问题是工资效应。让我对此详细说明一下。我们已经在现实世界中看到了这种情况。好的一面是，我认为技术专家们说“这些人工智能技术将是对人的补充，而非替代”是正确的。这通常是事实，但这往往可能在以下意义上同时产生积极和消极的工资效应。

例如，想象一项技术对你、我或一位放射科医生进行补充——这实际上很棒。它让你、我和放射科医生的生产力大大提高，每个人都能受益。我们更高效，赚更多钱。结果对每个人都有利。人们从产出中获益。所以这很有效，很棒。

但看看另一端，当你对某些更基础的职业进行补充时——在某些情况下，技术实际上是在补充并完成工作中增值的部分，而留给人类的可能是工作中差异化较小的部分。

这就引出了一个经济问题：你刚刚所做的是扩大了从事该工作的可用劳动力池。换句话说，经典的例子是伦敦黑色出租车司机的例子。几十年前，在伦敦，要成为一名黑色出租车司机，你必须真正记住伦敦的地图。有一个测试叫做——

JM：“知识测试”，没错。你必须通过那个测试。一些非常好的研究已经表明，例如，随着GPS系统的出现，它确实对工资产生了影响，因为现在要在伦敦成为一名真正优秀的司机，你只需要知道如何驾驶，因为GPS会解决“知识”那部分。这样一来，它就扩大了可用劳动力池，实际上可能对工资产生抑制作用。

我们必须考虑这些工资效应。而这通常会将你引向有时关于全民基本收入（UBI）的讨论，因为这意味着认识到：一方面，正如开头所说，我们正在创造巨大的经济潜力。所以，如果我们要创造所有这些经济上的丰裕，却可能面临这些不利的工资效应甚至更糟的情况，我们难道不应该设法创造一种让人们获得收入的途径吗？这就是全民基本收入问题通常的由来。

就我个人而言，我不是全民基本收入的支持者，但我喜欢全民基本收入讨论的这一点，因为它触及了一个真正的问题：当我们创造经济剩余，但并非每个人的工资都相应增长时，会发生什么？我们对此该怎么办？我喜欢全民基本收入这个问题，因为它引发了关于工资效应的辩论，顺便说一句，这些效应已经存在。

我们从加州未来工作委员会以及全国其他研究中了解到的一点是：我们已经知道存在不平等。我们知道技术是导致不平等的多个因素之一。因此，我们需要立即应对的问题不是“我们是否会有工作？”，而是“这些工作的报酬是否足够高？”这是一个非常现实的问题。你会看到美国和其他国家，尤其是发达经济体，都有各种委员会在探讨这个问题。这是一个真实存在的问题。

RH：显然我们已经面临其中的一些问题，尽管我个人认为——我也很好奇你的观点——人们目前所说的自动化带来的工资效应，更多是全球化的工资效应。

自动化确实仍在到来，并且值得重点关注。但这就像是说“哦，机器人正在抢走你的工作！”嗯，实际上我不确定问题是否已经在于机器人正在抢走工作，而更在于：机器人能否足够快地到来，以赋能更高薪资的工作？以及我们能否获得其中更高薪资工作的部分？我认为这才是更相关的部分。你怎么看？

JM：是的，我认为你说得对。我认为，如果你回顾90年代末、21世纪初，全球化与工作和工资问题是一个合理且真实的问题，因为那实际上是当时我们看到的一些工资效应的驱动因素。但我认为这种趋势正在消退，因为我们知道几乎在所有地方——包括中国等曾经进行劳动力套利的地方——工资也在上涨。

未来的动态变化将较少集中在工资上，也较少与全球化有关。

顺便说一下，如果你审视一下——通常全球化/工资问题往往体现在制造业和其他服务业工作中——如果你现在观察，仍然存在显著劳动力套利的地方往往仅限于制造业的几个狭窄领域，通常是家具制造、部分纺织品。并非所有地方都如此。包括汽车、化工等在内的制造业大部分领域，这种效应已不再真正起作用。

从前瞻性的角度看，我认为关于工资的辩论不再是关于全球化，而是关于经济结构。我们知道，当一个经济体以服务业为主导时——大多数发达经济体都是如此，我们国家当然也是——工资问题就非常现实。我的意思是，我们可以尽情谈论制造业。如今，制造业占美国劳动力的9%。它不是主导部分。其余部分包括其他一切，包括服务业经济。制造业在经济中占很大比重的最后一次是1958年，那是其顶峰。此后一直在下降。

“从前瞻性的角度看，我认为关于工资的辩论不再是关于全球化，而是关于经济结构。”

RH：有意思。确实，虽然经典问题是服务业从就业岗位数量上吸纳了大量人口，但他们实际上并未获得提升工资的杠杆。这确实是个有趣的挑战。

JM：没错。顺便说一句，我之前对制造业的规模和体量说得有些轻率。拥有制造业的一个好处在于它具备这些乘数效应。我们知道当制造业活动进行时，对周边服务业的乘数效应实际上是积极的。因此确实需要制造业——并非每个人都要从事制造业工作，我认为这也不会发生——但它确实具有这些绝佳的乘数效应。

不过你说得对，问题在于：在服务业驱动的经济中，我们该如何看待工资和收入？我们所在的服务业领域属于幸运的部分。其他部分则像是餐厅工作者、服务业从业者等等。这些领域的工资结构截然不同。

RH：现在让我们转向通用人工智能。正如你在《代达罗斯》项目中进行的探索，以及我们众多AI研究者的现状——有些人认为“我们已掌握根本性技术”，比如你之前提到的符号推理、语言、单次学习、迁移学习等，并主张“不，这些领域尚未……我们将迎来根本性创新”；另一些人则说“实际上，这些大语言模型或基础模型的规模，加上其他创新，将真正推动技术突破”。这些观点正在影响当前发展。

关于如何思考通用人工智能在近期出现的可能性、概率和限制，你今天可以与我们社群分享哪些观察？

JM：好的。首先从大语言模型谈起。我的意思是，这些模型非常了不起，始于大约三年半前Vaswani等人在谷歌发表的经典Transformer论文。这导致现在所有人都在构建大语言模型。谷歌从BERT发展到现在的LaMDA，OpenAI从GPT-1、-2到-3且后续还有更多，微软正在构建MT-NLG，DeepMind则开发了Gopher。

现在构建的模型越来越大。性能虽不完全但似乎随规模提升而改善，不过这可能存在某些限制。正如你所知，Reid，大语言模型的非凡之处还在于它们已能实现多模态输出：不仅可以从自然语言到自然语言输出，还能实现自然语言到软件代码的转换——微软和OpenAI通过GPT-3到Codex实现了代码生成，甚至能完成自然语言到图像的转换。

这常使人们开始将其视为基础模型。问题在于：这是否是通往类通用智能的途径？

从事深度学习和强化学习的研究者——顺便提一下，强化学习在DeepMind和OpenAI的研究中很常见，DeepMind将其应用于Alpha系列、AlphaZero、AlphaFold等科学探索——普遍认为这些方法仍有很大发展空间。我们尚未触及这些技术和方法的极限，未来将见证更多创新。

但回到这个根本问题：这足够吗？我个人认为可能还不够，因为因果推理、意义理解等核心难题依然存在：我们是否真正构建并产生了理解能力？

我们在科学探索方面仍有困难。例如，创建能产生新颖性假设或数学猜想的系统依然艰难——尽管DeepMind最近关于纽结理论和拓扑学的论文很有趣——但记忆与持久性等问题仍是巨大挑战。

我们尚未完全掌握实现方法。事实上，许多人认为神经科学能提供更多启示，我们在认知智能体模型及其工作机制方面，还未充分挖掘神经科学的潜力。

坦率说，我倾向于“在实现通用人工智能前需要更多概念性突破”的阵营。但与此同时，我认为当前构建的系统将带来远超预期的价值。

关键在于：我们应从何时开始为通用人工智能的可能性做准备？我认为无需等到完全实现通用人工智能才思考其影响。坦白说，这是该领域的核心问题之一：我们如何准备？如何协同？

令人欣慰的是，目前推动这些发展的前沿研究者和机构都怀有善意。尽管竞争激烈，但他们都致力于社会福祉，并将此写入使命宣言。

这很好。但我认为情况可能不会永远如此。这些系统可能变得极其强大。因此我们需要开始思考：如何应对安全问题？如何考量控制问题与人类对齐问题？

伯克利教授Stuart Russell的著作《人类兼容的人工智能》探讨了如何构建可证明有益、与人类利益大致一致的系统。这既是艰巨的技术科学问题，也是深刻的社会议题。正如我所说，Reid，我认为仅靠深度学习是不够的。

RH：我完全同意。即使深度学习领域最资深的研究者也认为需要更多突破。真正的问题是：需要多少突破？需要多少创新才能实现？

今天讨论开始时你特别指出的关键点是：建立并维持公众信任至关重要，因为这些系统将对人们生活、经济体系、就业和工资产生巨大影响，其干预领域广泛。

公众信任的微妙之处在于——观察当前动态会发现——这一切主要由企业驱动。无论在美国、中国还是其他地方，实际上都是企业在主导。显然，人们对企业主导存在担忧：利润动机可能使某些对社会和个人更紧迫的议题（例如公平性）在企业优先级中靠后。

作为技术从业者，我们不仅应该思考这些问题，还应如何参与公共对话、采取行动来帮助建立、维持甚至重建公众信任——我认为当前公众信任度并非处于高位？

JM：是的，Reid，这是个非常困难的问题。我认为这正是AI相较于其他技术的复杂之处——正如你所说，它主要由私营部门引领。

我想到几点。其一是：我认为这个行业本身必须对其运作方式更加透明。我相信公众实际上会对此感到欣慰。我一直觉得有趣的一点是——甚至在我加入谷歌之前就有这种感受——当你与真正构建这些系统的人、以及当前开发这些系统的领导者们深入交流时，无论选择其中哪一位，你会发现他们对自己所做的事情其实非常审慎。他们会争论"这种方法是否更好？"

但你会发现他们实际上关心伦理影响。他们可能只是在争论如何实现这些目标，但他们的许多工作对公众来说并不够公开透明。

人们不知道这些讨论和辩论正在进行，这些问题正在被探讨，因此他们以为这一切完全由利润动机驱动，但事实并非如此。我认为提高透明度恰恰能展现这些系统背后投入的大量思考。这是第一点。

另一点是，我认为科技行业和开发者需要更多地与政策制定者及监管机构互动。我惊讶地发现，在监管政策制定圈子里，人们对这些系统的运作原理了解甚少。你甚至不需要观看CSPAN等平台的听证会就能发现：天啊，他们真的不懂这些技术。因此我认为需要持续对政策制定者进行教育、邀请他们参与和互动，让我们所有人——包括即将对这些系统做出决策的人——都能理解它们。

坦率地说，我认为在系统内部也需要一些同行压力和群体压力。几年前让我感到欣慰的是"人工智能合作伙伴组织"的成立，它旨在汇聚人工智能研究领域的领先企业，共同建立行业标准。

顺便说一句，我认为可以从基因组学和生物学领域的发展汲取很多经验。上世纪七八十年代著名的"阿西洛马会议"就制定了一套关于如何进行基因组学研究的同行规则与原则，这些规范大体上沿用至今。我知道你曾参与其中，里德。

这个生态系统已经尝试在做这些事情。我认为我们需要更多此类举措，但即便如此可能还不够。最终我们可能需要更清晰的基本规则。这可能需要在全球层面实现，因为这不仅仅是美国和硅谷的问题。

这些系统正在全球各地被构建。我认为这正是问题略显复杂的原因——在全球舞台上，几种不同的竞争力量正在同时发挥作用。首先是纯粹的经济利益，而经济利益不仅关乎企业，也关乎国家。因此经济利益影响着国家和企业。

其次还存在国家安全利益。你我曾共同参与国家安全创新工作组，应该能感受到其中的张力。一端是创新者和经济学家说："这对社会和经济有益"，另一端具有国家安全背景的人士则说："但这可能不符合我们的国家利益。"问题在于：我们如何应对这些矛盾？

我认为人工智能与核科学等其他涉及国家安全的技术之间，一个关键差异在于：核科学的优势在于通常由政府主导，因此在核时代和冷战时期，这项工作主要由政府领导，所有能力都集中在政府一方，利益中心是统一的。

顺便提一下，核技术的另一个优点是：一旦有人使用，我们可以检测到。而人工智能则有所不同：一方面，所有创新都来自私营部门；私营部门考虑的是全球经济机遇，而不仅是国家问题。这就产生了错位。另一个错位是可检测性与问责性问题——对于人工智能系统而言，这比生物武器或核武器要困难得多。因此这是一个更为复杂的领域，有很多问题需要思考。

RH：现场观众中有一位我特别欣赏的人——塞琳娜·托巴科瓦拉提出了一个问题。我认为这是个经典而重要的问题，适用于许多不同领域。

具体问题是："您提到'算法数据中的性别歧视和偏见'。这其中有多少是源于更好的测量和验证？又有多少取决于从事这项工作的人——他们是否具备天然的验证、交叉检验能力，以及对自己是否走在正确轨道上的判断力？您认为需要哪些要素来改进我们对齐性和算法结果？这些要素之间应如何平衡与协调？"

JM：我认为两者都需要。实际上我想再补充几点。所谓"两者"是指：既要确保参与系统开发和质疑的人员多元化——这里的多元化不仅指性别或种族，还包括学科背景，因为社会科学研究者或伦理学家往往会提出不同类型的问题。

所以这个问题提得很对。我认为让更多元化的人群参与系统开发很重要。另一方面也需要更审慎地思考和管理我们训练算法的方式——这归根结底是数据问题，涉及社会如何收集和整合数据。但除此之外，技术本身也能提供帮助。

在数据方面，我们需要为社会解决数据收集问题，比如警务数据案例。但我们也需要思考：人工智能本身能否帮助我们识别这些偏见和模式？换句话说，人工智能可以成为发现偏见的工具。事实上，我们已经开始看到一些系统尝试这样做，特别是在处理有害输出方面。

最新的大语言模型有一个优点：它们开始使用近乎对抗性的、不同的大语言模型对输出进行预检查。因此人工智能本身就能成为解决这个问题的工具。

我认为我们需要所有这些要素。至于如何权衡不同要素的重要性，我认为这高度依赖于具体领域。例如，我们在国家科学院的工作中，对商业环境（受市场力量影响）中这个问题的思考方式，就与对医疗健康或交通系统等健康安全敏感领域的思考方式截然不同。

因此我认为需要根据不同场景和领域来调整这些要素的组合方式。但所有这些要素都是必需的。

RH：既然我们已经讨论了这些非常严肃的问题，最后还有一个轻松快速的问题。詹姆斯，我一直推荐你的所有著作和行动，因为它们平衡、深思熟虑、考虑周全，既博学又包容学术深度，同时兼具理解力、实用性和实用性。对于最近让你印象深刻的事物——书籍、播客、电影等，你会向观众推荐什么？

RH：不，我指的不是这个。

JM：不，不，不，但这是真的，对吧？

JM：是真的。天哪。我是说，就我们讨论的话题而言，你的听众可能会对即将出版的这期《代达罗斯》合集感兴趣，部分原因在于撰稿人阵容非常出色。而且，顺便说一句，他们的观点也大相径庭。你阅读时会看到其中的辩论。这是其一。

埃里克·施密特、亨利·基辛格和丹·胡滕洛赫合著了一本很棒的书，试图探讨其中一些地缘政治问题。那本书确实值得一读，涉及了很多关键议题。

而且，坦率地说，还有一些非常优秀的论文。我的意思是，AI领域的一个好处是，即使在技术研究方面，我们也已经开始撰写优质、易懂、可读性强的论文。所以我常想，对于任何对深度学习感兴趣的听众来说，去年由约书亚·本吉奥、杰弗里·辛顿和扬·勒昆合写的那篇论文就很值得推荐。如你所知，他们三人因在深度学习方面的贡献获得了图灵奖。他们在那篇论文中盘点了深度学习的现状，评估了这套方法体系所处的位置以及未来需要努力的方向。这实际上是一篇非常出色且易于理解的论文。

所以，里德，我认为像这样有趣的材料还有很多。

RH：百分之百同意。那么我们的讨论就到此结束了。詹姆斯，感谢你今天参与我们的节目。你知道的，我随时都愿意和你一起做这个节目，一如既往。

JM：嗯，谢谢你。关于所有这些话题，你我之间还有很多可以辩论和争论的地方，所以……

RH：我们会在各种场合进行更多交流。我想大家都看到了，今天有很多人登录，我们格雷洛克社区的许多宝贵成员都在线，因为他们正在寻求专业知识和深刻见解，就像你提供的这些。我们非常感谢你抽出如此宝贵的时间与我们共度。再次感谢你，詹姆斯。你一如既往地博学、深刻、全面且有深度。非常感谢。

JM：谢谢邀请我，里德。

里德作为企业家和投资者，致力于构建网络以发展标志性的全球企业。

谷歌技术与社会高级副总裁

> 本文由AI自动翻译，原文链接：[Social Intelligence | Greylock](https://greylock.com/reid-hoffman/social-intelligence/)
> 
> 翻译时间：2026-01-15 04:36
