---
title: AI风险管理：保障AI系统安全的全面指南
title_original: 'AI Risk Management: A Comprehensive Guide to Securing AI Systems'
date: '2026-02-02'
source: Databricks Blog
source_url: https://www.databricks.com/blog/ai-risk-management-comprehensive-guide-securing-ai-systems
author: ''
summary: 本文探讨了AI系统在各行业快速普及所带来的复杂风险，包括安全、运营、合规伦理及数据风险。文章指出，传统的IT安全标准已不足以应对AI特有的挑战，需要建立覆盖AI全生命周期的风险管理策略。文中介绍了NIST
  AI RMF等框架，并强调需结合业务优先级，通过跨团队协作、完善的数据治理以及应对如《欧盟人工智能法案》等监管要求，来实现负责任的AI创新与部署。
categories:
- 政策监管
tags:
- AI安全
- 风险管理
- 合规
- AI治理
- 数据隐私
draft: false
translated_at: '2026-02-03T04:19:19.358241'
---

随着企业领导者寻求利用人工智能技术提升运营效率并推动创新，他们往往难以理解自身独特的风险状况以及有效管理AI风险所需的步骤。AI系统在各行业的快速普及创造了前所未有的机遇，同时也带来了复杂的挑战，需要全面的AI风险管理策略。

与现有数据资源类似，AI系统存在网络安全、隐私和监管合规方面的漏洞，同时还引入了伦理问题及意外后果，例如偏见、歧视和信任缺失。实施AI技术的组织必须建立完善的风险管理方法，既要解决传统IT安全问题，也要应对人工智能系统特有的风险。

AI风险管理的复杂性源于多重因素：复杂AI模型的不透明性、所需训练数据的规模、AI发展的速度，以及包括《欧盟人工智能法案》在内的不断演变的监管合规环境。AI风险可能出现在AI生命周期的任何阶段，从初始数据收集到AI部署及持续运营。

若缺乏适当的访问控制，AI系统可能被恶意行为者利用，导致数据泄露和模型篡改。内部用户可能进行影子AI操作，使用生成式AI模型获取本不应接触的机密数据。若缺乏对AI模型及其数据的可审计性与可追溯性，组织将面临与AI相关的合规风险。

在思科2024年数据隐私基准研究中，91%的组织认识到需要采取更多措施向客户保证其数据仅被用于AI中的预期合法用途。但他们往往对"更多措施"的具体含义感到困惑。

由于众多潜在的AI应用涉及员工、客户和合作伙伴，AI风险管理的责任范围已超越IT部门。若不了解AI系统各组件如何协同工作，且无法识别潜在风险并缓解其应用场景中的风险，组织可能被迫采取最保守方案，陷入试图解决所有可能威胁的困境。他们需要简化的AI风险管理方式，同时保持与业务优先级一致。这要求业务、数据、AI、治理和安全团队使用共同语言开展协作，在平衡中推进创新。

## 理解AI风险管理框架与策略

鉴于AI安全威胁无法通过前AI时代为确定性系统设立的安全标准视角来审视，多个AI风险管理框架应运而生，以帮助组织有效应对风险并保护数据。

美国国家标准与技术研究院（NIST）《人工智能风险管理框架（AI RMF）》等常见AI安全框架，虽能有效概述AI系统安全相关风险并提供风险识别与评估的结构化方法，但尚未完整阐述如何针对各类AI风险实施必要的控制与缓解措施。

### 什么是AI风险管理策略？

有效的AI风险管理策略需要在AI全生命周期实施全面的风险管理实践。组织需要能覆盖AI开发、部署和运营各环节潜在风险的管理框架。AI RMF管理框架通过风险缓解策略和实用风险管理方法提供风险管理指导。

### AI风险的四种类型是什么？

AI风险主要可分为四类：

安全风险：包括使AI系统易受攻击的AI安全威胁、网络威胁和安全漏洞

运营风险：涵盖系统故障、模型漂移和AI模型性能退化

合规与伦理风险：涉及监管合规、伦理影响及AI系统产生的不公平结果

数据风险：包含数据质量、数据完整性、敏感数据保护和存在偏见的训练数据

为厘清AI风险管理，Databricks AI安全框架（DASF）提供了可操作的路线图，在保持与业务优先级一致的同时，给出防御性控制建议的使用指南。DASF将其风险管理框架的AI控制措施映射至10个行业标准与框架，采用整体性方法提升数据与AI开发团队的安全意识及风险缓解能力，促使其与安全团队在AI和机器学习全生命周期中协同合作。

## 理解AI合规与安全要求

AI部署还为风险管理带来了关键的监管维度，强调需要审慎监督和负责任的AI治理。根据行业和地域差异，组织需确保符合包括《欧盟人工智能法案》在内的多项法规要求，并应对新立法带来的新兴风险。

《欧盟人工智能法案》作为里程碑式的监管框架，依据风险等级对AI系统进行分类，并对高风险AI应用提出特定要求。在欧洲部署AI系统的组织必须理解这些要求，并实施适当的风险管理框架以确保合规。全球范围内类似法规正在涌现，形成了复杂的AI治理格局。

AI系统的关键合规问题涉及数据质量与可靠性、AI安全性、韧性、问责与透明度、数据隐私，以及AI模型的公平性与偏见。组织必须通过覆盖AI全生命周期的全面风险管理实践来应对这些合规要求。

AI治理框架应包含确保负责任AI开发和部署的政策、流程与控制措施。这包括建立清晰的问责结构、定义风险承受水平、实施风险识别流程，以及对AI系统性能进行持续监控。有效的AI风险管理需要数据科学家、工程师、安全团队和业务利益相关方之间的协作，以平衡创新与风险管理。

这始于数据治理——它能更好地满足HIPAA、FedRAMP、GDPR或CCPA等法规要求。数据治理对于确保数据质量、一致性、法规合规性、内部组织政策以及数据完整性、AI安全性、数据隐私、审计和风险管理至关重要。完善的数据治理有助于防止训练数据偏见问题，并确保输入数据符合质量标准。

为满足监管合规要求，组织需具备可见性以确保可发现性，并能对双重用途基础模型使用的多源数据进行编目。这包括追踪历史数据源、监控数据收集实践，以及在AI系统开发全过程中保护敏感数据与敏感个人数据。新成立的美国AI安全研究所（USAISI）隶属于NIST，将制定AI风险评估机制指南，并为监管机构开发技术指导，涉及强大模型分类阈值设定、内容认证、AI生成内容水印、算法歧视识别与缓解、透明度保障及隐私保护AI应用推广等议题。

在人工智能应用方面领先的组织正利用AI工具应对常见运营挑战中的风险及系统性难题，例如监管合规变更管理、减少误报、防范欺诈与反洗钱，以及纠正人为失误。他们通过持续监控AI系统性能，实现AI系统监测自动化，从而确保训练数据的高质量，并建立公平、无偏见的机器学习模型。

### AI能否进行风险管理？

是的，人工智能技术能显著提升组织的风险管理能力。AI应用可通过识别潜在风险、执行定期风险评估、制定适应不断变化威胁态势的风险缓解策略来辅助风险管理。机器学习算法能够发现人类可能忽略的模式与异常，通过持续监控和自动化风险评估流程，使AI风险管理更为高效。

AI工具擅长处理海量历史数据，在风险显化前进行识别。通过预测性分析和模式识别，AI系统能标记安全漏洞、检测网络威胁，并实时向安全团队预警新出现的风险。这种主动的风险管理方法使组织能够在风险影响运营或泄露敏感信息前及时化解。

然而，依赖AI进行风险管理也会引入新的AI相关风险，必须通过全面的AI风险管理框架加以应对。组织必须确保用于风险管理的AI工具本身安全可靠、无偏见，并在适当的治理框架内运行。这要求风险管理实践既要涵盖传统风险，也要包含AI系统自身特有的风险。

## 实施有效的AI风险管理实践

风险管理实践需要理解AI系统的组成部分、通用AI风险以及与特定用例相关的AI风险。成功的AI风险管理取决于实施涵盖AI开发和部署全阶段的综合风险管理流程。DASF提出七个步骤以简化此过程：

1. 建立关于AI系统及其在开发和部署过程中需协同工作的组件的心智模型。理解AI系统架构有助于识别跨组件的潜在风险。
2. 了解参与构建和管理AI系统的人员与流程，并明确其角色（包括数据科学家、工程师和安全团队）。清晰的角色定义通过建立风险管理责任体系来支持有效的AI风险管理。
3. 理解负责任AI的内涵及所有可能的AI风险，并针对AI组件分类记录这些AI相关风险。这包括记录与AI安全、数据质量、偏见及伦理影响相关的潜在风险。
4. 理解不同的AI部署模式及其在整个AI生命周期中各阶段的风险影响。不同的部署场景会引入不同的安全风险，需要定制化的风险缓解策略。
5. 识别针对AI用例的独特威胁，并根据AI安全威胁、网络威胁和安全漏洞等潜在风险，绘制相关风险图谱。
6. 识别适用于AI用例的独特AI风险，并根据用例和风险承受能力筛选相关风险。组织必须在风险管理要求与业务目标之间取得平衡。
7. 根据用例和部署模式确定并实施相应控制措施，通过实用的风险管理方法将各风险映射至AI组件和控制措施。这包括制定针对AI应用的风险缓解策略。

在控制措施到位的情况下，AI驱动的工具能比传统安全措施更快地帮助组织检测和化解风险。通过对抗性训练，机器学习算法可检测模式和异常以进行主动威胁检测，并提供持续监控、自动化事件响应、行为分析和威胁预测，作为综合风险管理流程的组成部分。

### AI中的30%法则是什么？

AI风险管理中的30%法则指组织应将约30%的AI风险管理精力投入于AI系统部署后的持续监控与评估。这确保AI系统性能与预期目标保持一致，并有助于识别生产使用过程中出现的潜在风险。

有效的AI风险管理需要持续的风险评估，而非仅在AI开发阶段进行一次性评价。30%法则强调AI风险管理实践必须超越初始的AI系统开发和部署阶段。组织应分配大量资源用于定期风险评估、监控AI模型漂移、检测新发风险，并随着AI技术和威胁态势的发展更新风险缓解策略。

这种持续的AI风险管理方法帮助组织在安全威胁、系统故障和意外后果升级为重大事件前及时发现。通过将资源投入持续的风险管理，组织能够维护数据完整性、确保AI安全，并主动而非被动地应对风险。30%法则通过确保AI系统在整个运行生命周期中获得持续监督，来支持负责任的AI实践。

没有高质量数据就无法实现AI，而没有数据治理和监督则无法获得高质量数据。有效的治理和监督确保：

- 通过统一数据与AI资产，实现便捷的可发现性与无缝协作，并能够从各系统编目数据收集来源。
- 采用集中式方法执行细粒度访问控制、审计和治理策略，以保护敏感数据和敏感信息，确保数据资产安全。
- 通过AI驱动的监控主动识别错误、进行根本原因分析，并借助数据完整性控制维护数据与AI流水线的质量标准，从而获得高质量训练数据及公平、无偏见的机器学习模型。

## 应对生成式AI风险与安全威胁

与传统IT安全不同，AI引入了跨越数据、模型、基础设施和治理的新漏洞。在DASF中，我们识别出AI系统12个组件中的62种不同AI风险。总体而言，这些潜在风险包括：

**数据运营风险**，例如访问控制不足、数据分类缺失、数据质量低下、缺乏数据访问日志以及影响训练数据质量的数据投毒。

**模型运营风险**，例如实验未追踪且不可复现、模型漂移、超参数被盗、恶意库以及影响AI模型的评估数据投毒。

**模型部署与服务风险**，例如在AI部署过程中的提示词注入、模型反转、拒绝服务攻击、LLM幻觉和黑盒攻击。

**运营与平台风险**，例如缺乏漏洞管理、渗透测试和漏洞赏金计划、未经授权的特权访问、软件开发生命周期不完善以及监管合规问题。

这些AI风险可能引发一系列不良且代价高昂的后果：

- 安全与隐私泄露风险，因为发送至外部LLM（大语言模型）的数据可能被泄露或归纳，从而引发AI安全威胁
- 用户无意中将敏感数据及敏感个人数据发送至外部AI系统
- 数据丢失、数据机密性破坏、模型窃取及安全风险
- 不符合欧盟《人工智能法案》等现行及演进中的法规与其他合规要求
- 面向客户的AI系统发送涉及其他组织的数据，导致不公正结果

随着生成式AI和机器学习模型的应用，管理错误信息和偏见也变得至关重要。AI驱动的监控能主动识别错误、进行根本原因分析，并维护数据与AI流水线的质量标准。AI工具还可辅助风险预测，结合AI与预测分析技术，为商业决策提供实时洞察与可行建议，支持有效的AI风险管理。

## AI风险管理实施的资源与工具

为加强AI风险管理，团队应在现有组织政策基础上落实以下措施，并确保建立适当监督机制，以构建安全、稳健且符合业务目标的AI系统，同时在日益AI驱动的世界中应对不断演变的威胁。这些风险管理策略对于负责任地开发AI及安全部署AI系统至关重要：

- 对数据访问进行身份验证与授权，保护敏感信息、敏感数据及输入数据免遭未授权访问与安全威胁
- 在数据输入模型训练前实施自动化与质量检查，确保数据质量，防止训练数据偏见，并在整个AI开发过程中保持数据完整性
- 对数据进行治理、版本控制与标记，同时追踪数据血缘关系，以维护数据完整性、确保数据质量并支持合规要求
- 执行审批工作流，防止AI模型基于非预期数据源进行训练，降低AI训练过程相关风险，确保负责任的AI开发
- 追踪模型产物、数据集、版本及利益相关方，以建立AI系统开发中的信任度、可解释性与责任归属，支持AI治理与风险管理实践
- 通过评估模型在特定测试输入上的行为，在（再）训练后自动化测试损失分析，以识别潜在风险、检测异常并确保AI系统性能符合预期
- 对AI模型与端点进行加密、身份验证与授权，同时记录、审计和监控访问行为以保障AI安全，保护人工智能系统免受网络威胁与安全漏洞侵害
- 将LLM（大语言模型）及其他AI模型与内外系统隔离，以降低安全漏洞风险、控制潜在风险并防止系统故障扩散
- 通过为生产环境AI模型实施权限、版本、标签、所有权与审批控制，在部署AI系统时采用人机协同的MLOps，确保AI全生命周期的负责任实践
- 在网关后托管AI模型，实施速率限制安全过滤、个人身份信息（PII）检测、主题审核与关键词过滤，应对AI安全威胁并保护敏感个人数据
- 通过持续监控、定期风险评估及实施全面风险管理流程，在AI生命周期各阶段审计和监控数据与AI模型的访问

实施这些实际的风险管控措施需要数据科学家、工程师、安全团队与治理人员协同合作。组织应建立明确的风险管理框架，界定各类AI风险的责任归属、升级流程与响应机制。这些框架需与更广泛的组织风险承受度保持一致，并兼顾创新与风险管理目标。

安全的数据共享与协作使企业领导者能获得准确、及时且相关的洞察以支持战略决策。Databricks Data Intelligence Platform提供统一安全接入点，可整合并查询多源数据，通过AI应用快速从结构化与非结构化数据中提取洞察，同时保障AI安全与数据隐私。

通过实施强有力的AI治理，金融机构能在历史数据中建立信任基础，使AI系统能快速精准地分析庞大复杂的AI模型数据集。可信赖的AI系统需要整个组织从初始数据采集到AI开发、AI部署及持续运营的全方位风险管理投入。

## 人工智能创新与风险的平衡

负责任的AI治理要求组织通过贯穿AI开发与部署过程的全面持续监控、隐私控制与AI治理，对其数据与AI模型承担问责并实施管控。平衡创新与AI安全、协调业务优先事项的责任不再仅由首席信息官承担。业务、数据、安全、隐私及治理团队需达成共识，通过负责任的AI实践释放AI的全部潜力。

人工智能系统必须遵循优先考虑透明度、公平性与问责制的负责任AI开发原则。实施AI风险管理实践的组织应聚焦于定期风险评估、执行风险缓解策略，并维护能有效管理风险同时提供商业价值的可信赖AI系统。

Databricks正与美国国家标准与技术研究院（NIST）在人工智能安全研究所联盟中展开合作，致力于建立新的测量科学，以识别可验证、可扩展且可互操作的测量标准与方法论，促进可信赖AI系统的开发及其负责任使用。该合作支持更广泛的AI风险管理框架及AI RMF原则。

新兴风险将影响独立AI模型及Databricks日益见到的客户用于构建领域特定Agent（智能体）AI应用的智能体AI系统的开发与使用。人为失误使受监管企业损失数十亿美元，这些损失可追溯至数据问题及需追踪的海量历史数据。AI能通过发现人类可能忽略的异常、趋势与模式，并基于规则集生成警报，辅助风险管理与合规工作。

使用Databricks AI Security Framework获取通过全面AI风险管理框架安全开发、部署AI系统及规模化维护AI模型的重要指导。该框架帮助组织确保其AI模型保持安全并持续提供商业价值，同时应对AI相关风险并在所有AI技术中实施实际风险管理。这种全面的AI风险管理方法助力组织在创新与安全威胁缓解、合规要求间实现平衡。

---

> 本文由AI自动翻译，原文链接：[AI Risk Management: A Comprehensive Guide to Securing AI Systems](https://www.databricks.com/blog/ai-risk-management-comprehensive-guide-securing-ai-systems)
> 
> 翻译时间：2026-02-03 04:19
