---
title: MELON：无需相机位姿，仅凭数张图像重建3D物体
title_original: 'MELON: Reconstructing 3D objects from images with unknown poses'
date: '2024-03-18'
source: Google AI Blog
source_url: http://blog.research.google/2024/03/melon-reconstructing-3d-objects-from.html
author: null
summary: Google Research团队提出MELON技术，解决了从未知相机位姿的少量图像中重建3D物体的难题。该方法无需初始位姿估计、复杂训练或预训练数据，通过轻量级CNN编码器回归位姿，并引入模损失处理物体伪对称性，仅需4-6张图像即可实现高精度神经辐射场重建。该技术简化了3D重建流程，在合成数据集上展现出快速收敛和竞争力的渲染质量。
categories:
- AI研究
tags:
- 3D重建
- 神经辐射场
- 计算机视觉
- 相机位姿估计
- Google Research
draft: false
---

**MELON：从未知相机位姿的图像中重建3D物体**
2024年3月18日
发布者：Mark Matthews，高级软件工程师；Dmitry Lagun，研究科学家，Google Research
快速链接

人类凭借先前的经验和对世界的理解，通常能够轻松推断出一个物体的整体样貌，即使只看到它的几张2D图片。然而，多年来，让计算机仅凭几张图像就重建出物体的3D形状，一直是一个困难的算法问题。这一基础的计算机视觉任务应用广泛，从创建电子商务3D模型到自动驾驶汽车导航。

该问题的一个关键部分是如何确定图像拍摄的确切位置，即相机位姿推断。如果相机位姿已知，一系列成功的技术——如神经辐射场（NeRF）或3D高斯泼溅——可以重建物体的3D模型。但如果这些位姿未知，我们就面临一个困难的“先有鸡还是先有蛋”的问题：如果我们知道3D物体，就能确定相机位姿；但在知道相机位姿之前，我们无法重建3D物体。伪对称性使问题变得更加棘手——即许多物体从不同角度看起来相似。例如，像椅子这样的方形物体，每旋转90°往往看起来相似。通过从不同角度在转盘上渲染物体并绘制其光度自相似性图，可以揭示物体的伪对称性。

上图仅可视化了一个旋转维度。当引入更多自由度时，情况会变得更加复杂（且难以可视化）。伪对称性使得问题不适定，简单的方法通常会收敛到局部最小值。在实践中，这种方法可能会将物体的后视图误认为前视图，因为它们具有相似的轮廓。先前的技术（如BARF或SAMURAI）通过依赖接近全局最小值的初始位姿估计来规避这个问题。但是，如果没有这些初始估计，我们该如何处理呢？

诸如GNeRF和VMRF等方法利用生成对抗网络（GAN）来克服这个问题。这些技术能够人为地“放大”有限数量的训练视图，辅助重建。然而，GAN技术通常具有复杂且有时不稳定的训练过程，使得在实践中难以实现稳健可靠的收敛。其他一系列成功的方法，如SparsePose或RUST，可以从有限数量的视图中推断位姿，但需要在大型带位姿标注的图像数据集上进行预训练，而这些数据并非总是可用，并且在推断不同类型图像的位姿时可能遭受“领域差距”问题。

在3DV 2024会议上重点介绍的论文《MELON: NeRF with Unposed Images in SO(3)》中，我们提出了一种技术，可以在重建物体3D模型的同时，完全从零开始确定以物体为中心的相机位姿。MELON（NeRF的模等价隐式优化）是最早能够在无需初始相机位姿估计、复杂训练方案或带标签数据预训练的情况下实现这一目标的技术之一。MELON是一种相对简单的技术，可以轻松集成到现有的NeRF方法中。我们证明，MELON能够以最先进的精度从无位姿图像中重建NeRF，且仅需物体的4-6张图像。

**MELON**

我们利用两种关键技术来辅助这个不适定问题的收敛。第一种是一个非常轻量级、动态训练的卷积神经网络（CNN）编码器，它从训练图像中回归相机位姿。我们将缩小的训练图像传递给一个四层CNN，由它推断相机位姿。这个CNN从随机噪声初始化，无需预训练。其容量非常小，迫使看起来相似的图像得到相似的位姿，提供了一种隐式正则化，极大地帮助了收敛。

第二种技术是模损失，它同时考虑物体的伪对称性。对于每个训练图像，我们从一组固定的视点渲染物体，仅通过最匹配训练图像的视图反向传播损失。这有效地考虑了每个图像对应多个视图的可能性。在实践中，我们发现大多数情况下只需要N=2个视图（从另一侧观察物体），但对于方形物体，有时使用N=4个视图会得到更好的结果。

这两种技术被集成到标准的NeRF训练中，不同之处在于，相机位姿不是固定的，而是由CNN推断并由模损失进行复制。光度梯度通过最佳匹配的相机反向传播到CNN中。我们观察到相机通常能快速收敛到全局最优位姿（见下方动画）。在神经场训练完成后，MELON可以使用标准的NeRF渲染方法合成新视图。

我们通过使用NeRF-Synthetic数据集来简化问题，这是NeRF研究的常用基准，在姿态推断文献中也很常见。这个合成数据集的相机距离精确固定，且具有一致的“向上”方向，因此我们只需要推断相机的极坐标。这相当于一个物体位于球体中心，相机始终指向它并在球体表面移动。那么我们只需要纬度和经度（2个自由度）来指定相机位姿。

**结果**

我们计算了两个关键指标来评估MELON在NeRF Synthetic数据集上的性能。真实位姿与推断位姿之间的方向误差可以量化为一个单一的角度误差，我们将其在所有训练图像上取平均，即位姿误差。然后，我们通过测量与保留测试视图的峰值信噪比（PSNR）来测试MELON从新视图渲染物体的准确性。我们看到，MELON在训练的前1,000步内迅速收敛到大多数相机的近似位姿，并在50k步后达到了具有竞争力的27.5 dB的PSNR。

MELON在NeRF Synthetic数据集的其他场景中也取得了类似的结果。

**噪声图像**

当从极其嘈杂、无位姿的图像中执行新视图合成时，MELON也表现良好。我们在训练图像中添加了不同强度σ的高斯白噪声。例如，下方σ=1.0的物体图像已无法辨认，但MELON仍能确定其位姿并生成物体的新视图。

考虑到像RawNeRF这样的技术已经证明了NeRF在已知相机位姿下出色的去噪能力，这或许并不太令人惊讶。但MELON对于未知相机位姿的噪声图像也能如此稳健地工作，这一点出乎意料。

**结论**

我们提出了MELON，这是一种能够确定以物体为中心的相机位姿以重建3D物体的技术，无需近似的位姿初始化、复杂的GAN训练方案或带标签数据的预训练。MELON是一种相对简单的技术，可以轻松集成到现有的NeRF方法中。尽管我们仅在合成图像上演示了MELON，但我们正在调整我们的技术以适应现实世界条件。请参阅论文和MELON网站以了解更多信息。

**致谢**

我们要感谢论文合著者Axel Levy、Matan Sela和Gordon Wetzstein，以及Florian Schroff和Hartwig Adam在构建这项技术过程中持续提供的帮助。我们也感谢Matthew Brown、Ricardo Martin-Brualla和Frederic Poitevin对论文草稿提出的宝贵反馈。同时，我们感谢使用了SLAC共享科学数据设施（SDF）的计算资源。

---

> 本文由AI自动翻译，原文链接：[MELON: Reconstructing 3D objects from images with unknown poses](http://blog.research.google/2024/03/melon-reconstructing-3d-objects-from.html)
> 
> 翻译时间：2026-01-05 17:12
